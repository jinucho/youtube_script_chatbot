{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "import whisper\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 디바이스 설정\n",
    "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Whisper 모델 로드\n",
    "model = whisper.load_model(\"large\", device=device)\n",
    "\n",
    "def get_title_hash(url):\n",
    "    try:\n",
    "        # YouTube 객체 생성\n",
    "        yt = YouTube(url)\n",
    "\n",
    "        # 1. 영상 제목 추출\n",
    "        title = yt.title\n",
    "\n",
    "        # 2. 해시태그 추출\n",
    "        description = yt.description\n",
    "        hashtags = re.findall(r\"#\\w+\", description)\n",
    "        hashtags = \" \".join(hashtags)\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'hashtags': hashtags\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def get_script(url, language='ko'):\n",
    "    try:\n",
    "        # 유튜브 영상 ID 추출\n",
    "        video_id = url.split(\"=\")[1]\n",
    "\n",
    "        # 1. 자막 추출 시도\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])\n",
    "            return transcript\n",
    "        except (NoTranscriptFound, TranscriptsDisabled):\n",
    "            print(\"자막이 없거나 비활성화되어 있습니다. 음성 추출을 시도합니다.\")\n",
    "\n",
    "        # 2. 자막이 없는 경우, 음성 추출 및 Whisper 사용\n",
    "        # 유튜브 영상에서 오디오 스트림 다운로드\n",
    "        yt = YouTube(url, on_progress_callback=on_progress)\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        \n",
    "        # 오디오 데이터를 파일로 저장\n",
    "        temp_audio_file = \"temp_audio.wav\"  # 임시로 사용할 파일 이름\n",
    "        audio_stream.download(output_path='.', filename=temp_audio_file)\n",
    "\n",
    "        # 오디오 파일을 Whisper 모델에 입력하여 텍스트 변환 수행\n",
    "        result = model.transcribe(temp_audio_file, language=language)\n",
    "\n",
    "        # Whisper 결과에서 각 세그먼트를 사용하여 시간 정보와 텍스트 추출\n",
    "        checked_text = set()\n",
    "        transcript_with_timestamps = []\n",
    "        for segment in result['segments']:\n",
    "            start = segment['start']  # 시작 시간 (초 단위)\n",
    "            end = segment['end']      # 종료 시간 (초 단위)\n",
    "            text = segment['text']    # 텍스트\n",
    "            if text not in checked_text:\n",
    "                checked_text.add(text)\n",
    "\n",
    "                # 시작 시간과 지속 시간을 계산하여 딕셔너리 형식으로 저장\n",
    "                transcript_with_timestamps.append({\n",
    "                    'text': text.strip(),\n",
    "                    'start': start,\n",
    "                    'duration': end - start\n",
    "                })\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # 3. 임시 파일 삭제\n",
    "        if os.path.exists(temp_audio_file):\n",
    "            os.remove(temp_audio_file)\n",
    "\n",
    "        # 변환된 텍스트 반환\n",
    "        return transcript_with_timestamps\n",
    "\n",
    "    except VideoUnavailable:\n",
    "        return \"Error: 이 영상을 찾을 수 없습니다. 링크가 올바른지 확인하세요.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: 알 수 없는 오류가 발생했습니다. {str(e)}\"\n",
    "    \n",
    "def main(url):\n",
    "    # 1. 영상 제목 추출\n",
    "    title_hash = get_title_hash(url)\n",
    "    script = get_script(url)\n",
    "    return title_hash, script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자막이 없거나 비활성화되어 있습니다. 음성 추출을 시도합니다.\n",
      "{'title': '아메리칸 스타일로 부탁해', 'hashtags': '#소개팅앱 #소개팅 #데이트 #만남'} \n",
      "\n",
      "안녕하세요 여러분\n",
      "오늘\n",
      "앱블리케이션 소개령이 있는 날이에요\n",
      "저는 정말 기대되고 있어요\n",
      "예쁜 여자가\n",
      "내 동네까지 픽업 왔어요\n",
      "한국여자 정말 너무 스윗해요\n",
      "후우\n",
      "가볼게요\n",
      "안녕하세요\n",
      "오 마이 갓\n",
      "저는 업다운 리이고\n",
      "텍사스에서 왔어요\n",
      "솔직히\n",
      "앱블리케이션 만나면 하는 거 처음이에요\n",
      "긴장돼요\n",
      "잘 부탁해요\n",
      "귀엽네\n",
      "옷 벗고 뒤에 타\n",
      "배꼽부터 한번 맞춰보자\n",
      "오 배꼽?\n",
      "왜? 뒤에 타라니까\n",
      "죄송해요\n",
      "잘 이해 못했어요\n",
      "뒤에서 업다운 운동 좀 하자고\n",
      "바운스 바운스 투게더 오케이?\n",
      "No it's not okay\n",
      "No no 그거 아니에요\n",
      "그거 안돼요\n",
      "미국에서 왔다며\n",
      "아메리칸 스타일로 시원하게 한번 하자는데\n",
      "그게 그렇게 어려워?\n",
      "그냥 스포츠 한 게임 뛴다고 생각해\n",
      "Oh calm down please stop\n",
      "왜?\n",
      "미국에서도 이렇게 냅다꼽진 않아요\n",
      "Maybe?\n",
      "혹시 내 돈 줘야 돼요?\n",
      "아 혹시 내 받는 거야?\n",
      "혹시 내 받는 거야?\n",
      "뭐?\n",
      "Okay stop\n",
      "I got it\n",
      "뒤로 가면 되죠\n",
      "Fuck off bitch\n",
      "야 너 폰\n",
      "Okay okay\n",
      "You know\n",
      "나는\n",
      "좀 서로 좀\n",
      "알아가고 싶어요\n",
      "그래\n",
      "알아보자는 거잖아\n",
      "나 오늘 파스타 맛집도 알아놨고\n",
      "and then\n",
      "아 진짜 잘하네\n",
      "뭐 먹고 뭐 할 건데?\n",
      "커피 마시고 싶고\n",
      "커피 마시고 뭐 할 건데?\n",
      "분위기 좋은 bar 가서\n",
      "술 마시고 뭐 할 건데?\n",
      "아 씨X야 어차피 할 거잖아\n",
      "시간도 없는데 진짜 짜증나게\n",
      "야 너 안 할 거야?\n",
      "안 할 거야? 안 할 거냐고\n",
      "할 거잖아\n",
      "I mean 해야 할 것 같긴 한데요\n",
      "요리 완성되어 있는 그런 느낌이란 말이에요\n",
      "그럼 그냥 먹어\n",
      "I don't know about it\n",
      "야\n",
      "야 갖고 꺼져\n",
      "야 가 꺼져 꺼져\n",
      "아 씨\n",
      "아 씨X야\n",
      "Okay let's go\n",
      "Right now right here bounce bounce\n",
      "Let's go bounce bounce\n",
      "Let's go right now right here\n",
      "오늘 완전히 Let's go\n",
      "Let's go\n"
     ]
    }
   ],
   "source": [
    "title, script = main(\"https://youtu.be/HsxWL3kDYh8?si=aGGS9vmvp6dNX8P2\")\n",
    "print(title,\"\\n\")\n",
    "for _ in script:\n",
    "    print(_['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinu/miniconda3/envs/youtubee/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "model = WhisperModel(\"large-v3\",device=\"cuda\",compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자막이 없거나 비활성화되어 있습니다. 음성 추출을 시도합니다.\n",
      " ↳ |████████████████████████████████████████████| 100.0%\r"
     ]
    }
   ],
   "source": [
    "def get_script(url, language='ko'):\n",
    "    # 유튜브 영상 ID 추출\n",
    "    video_id = url.split(\"=\")[1]\n",
    "\n",
    "    # 1. 자막 추출 시도\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])\n",
    "        return transcript\n",
    "    except (NoTranscriptFound, TranscriptsDisabled):\n",
    "        print(\"자막이 없거나 비활성화되어 있습니다. 음성 추출을 시도합니다.\")\n",
    "\n",
    "    # 2. 자막이 없는 경우, 음성 추출 및 Whisper 사용\n",
    "    # 유튜브 영상에서 오디오 스트림 다운로드\n",
    "    yt = YouTube(url, on_progress_callback=on_progress)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    \n",
    "    # 오디오 데이터를 파일로 저장\n",
    "    temp_audio_file = \"temp_audio.wav\"  # 임시로 사용할 파일 이름\n",
    "    audio_stream.download(output_path='.', filename=temp_audio_file)\n",
    "\n",
    "get_script(\"https://youtu.be/HsxWL3kDYh8?si=aGGS9vmvp6dNX8P2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"temp_audio.wav\", beam_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 7.68  Hello my name is Luis Serrano and in this video you're going to learn about the math behind\n",
      "7.68 13.26  attention mechanisms in large language models. Attention mechanisms are really important in\n",
      "13.26 17.44  large language models. As a matter of fact they're one of the key steps that make transformers work\n",
      "17.44 23.52  really well. Now in a previous video I showed you how attention works in very high level with words\n",
      "23.52 28.12  flying towards each other and gravitating towards other words in order for the model to understand\n",
      "28.12 33.5  context. In this video we're going to do an example in much more detail with all the math involved.\n",
      "34.3 38.5  Now as I mentioned before the concept of a transformer and the attention mechanism were\n",
      "38.5 43.120000000000005  introduced in this groundbreaking paper called attention is all you need. Now this is a series\n",
      "43.120000000000005 47.52  of three videos. In the first video I showed you what attention mechanisms are in high level.\n",
      "47.84 53.38  In this video I'm going to do it with math and in the third video that is upcoming I will put them\n",
      "53.38 57.14  all together and show you how a transformer model works.\n",
      "57.68000000000001 58.1  So in this video I'm going to show you how a transformer model works.\n",
      "58.1 58.120000000000005  So in this video I'm going to show you how a transformer model works.\n",
      "58.120000000000005 62.34  In this video in particular you're going to learn about some concepts similarity between words and\n",
      "62.34 66.96000000000001  pieces of text is one of the concepts. One way to do this is with dot product and another one with\n",
      "66.96000000000001 71.80000000000001  cosine similarity so we'll learn both. And next you're going to learn what the key query and value\n",
      "71.80000000000001 78.92  matrices are as linear transformations and how they have an involvement in the attention mechanism.\n",
      "82.66 88.10000000000001  So let's do a quick review of the first video. First we had embeddings and embeddings are\n",
      "88.10000000000001 94.60000000000001  a way to put words or longer piece of text in this case it's the plane but in reality you put it in a\n",
      "94.60000000000001 101.4  high dimensional space in such a way that words that are similar get sent to points that are close.\n",
      "101.74000000000001 108.48  So for example these are fruits there's a strawberry an orange a banana and a cherry and they're all\n",
      "108.48 114.4  in the top corner of the image because they're similar words so they get sent to similar points.\n",
      "114.4 117.66000000000001  And then over here we have a bunch of brands.\n",
      "117.66 123.88  We have Microsoft we have Android and we also have a laptop and a phone so it's the technology corner.\n",
      "123.88 127.22  And then the question we had in the previous video is where would you put the word apple\n",
      "127.22 133.04  and that's complicated because it's both a technology brand and also a fruit so we wouldn't\n",
      "133.04 138.01999999999998  know. In particular let's take a look at this and the orange is on the top right and the phone\n",
      "138.01999999999998 143.32  is in the bottom left. Where would you put an apple? Well then you need to look at context so\n",
      "143.32 146.96  if you have a sentence like please buy an apple and an orange then you know you're talking about\n",
      "146.96 147.3  the fruit.\n",
      "147.66 153.04  If you have a sentence like apple unveiled the new phone then you know you're talking about the technology brand.\n",
      "153.04 158.5  So therefore this word needs to be given context and the way it's given context is by the neighboring words.\n",
      "158.5 160.88  In particular the word orange is the one that helps us here.\n",
      "160.88 167.6  So what we do is that we look at where orange is and then move the apple in that direction and then we're going to use those new\n",
      "167.6 170.06  coordinates instead of the old ones for the apple.\n",
      "170.06 176.96  So then now the apple is closer to the fruit so it knows more about its context given the other words the word orange.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/youtubee/lib/python3.11/site-packages/faster_whisper/transcribe.py:594\u001b[0m, in \u001b[0;36mWhisperModel.generate_segments\u001b[0;34m(self, features, tokenizer, options, encoder_output)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seek \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m encoder_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(segment)\n\u001b[1;32m    589\u001b[0m (\n\u001b[1;32m    590\u001b[0m     result,\n\u001b[1;32m    591\u001b[0m     avg_logprob,\n\u001b[1;32m    592\u001b[0m     temperature,\n\u001b[1;32m    593\u001b[0m     compression_ratio,\n\u001b[0;32m--> 594\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mno_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n\u001b[1;32m    598\u001b[0m     should_skip \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mno_speech_prob \u001b[38;5;241m>\u001b[39m options\u001b[38;5;241m.\u001b[39mno_speech_threshold\n",
      "File \u001b[0;32m~/miniconda3/envs/youtubee/lib/python3.11/site-packages/faster_whisper/transcribe.py:884\u001b[0m, in \u001b[0;36mWhisperModel.generate_with_fallback\u001b[0;34m(self, encoder_output, prompt, tokenizer, options)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    879\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: options\u001b[38;5;241m.\u001b[39mbeam_size,\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m: options\u001b[38;5;241m.\u001b[39mpatience,\n\u001b[1;32m    882\u001b[0m     }\n\u001b[0;32m--> 884\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_no_speech_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_blank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppress_blank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppress_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_initial_timestamp_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_initial_timestamp_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    899\u001b[0m tokens \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msequences_ids[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# Recover the average log prob from the returned score.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(segment.start,    segment.end,    segment.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
