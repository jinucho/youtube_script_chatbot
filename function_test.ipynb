{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=7BeeQipYT58\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=aGGS9vmvp6dNX8P2! This is most likely caused by:\n",
      "\n",
      "Subtitles are disabled for this video\n",
      "\n",
      "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_script(url):\n",
    "    try:\n",
    "        video_id = url.split(\"=\")[1]\n",
    "        # YouTube 영상의 자막을 가져옴\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id,languages=('ko','en'))\n",
    "        \n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "transcript = get_script(\"https://youtu.be/HsxWL3kDYh8?si=aGGS9vmvp6dNX8P2\")\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 이 영상의 자막이 비활성화되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
    "\n",
    "def get_script(url):\n",
    "    try:\n",
    "        # 유튜브 영상 ID 추출\n",
    "        video_id = url.split(\"=\")[1]\n",
    "        \n",
    "        # 자막을 가져옴\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])\n",
    "        \n",
    "        return transcript\n",
    "    except NoTranscriptFound:\n",
    "        return \"Error: 이 영상에는 자막이 없습니다.\"\n",
    "    except TranscriptsDisabled:\n",
    "        return \"Error: 이 영상의 자막이 비활성화되어 있습니다.\"\n",
    "    except VideoUnavailable:\n",
    "        return \"Error: 이 영상을 찾을 수 없습니다. 링크가 올바른지 확인하세요.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: 알 수 없는 오류가 발생했습니다. {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='converted_audio.wav'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "yt = YouTube(url,on_progress_callback=on_progress)\n",
    "audio = yt.streams.filter(only_audio=True).first().download(output_path='.',filename='audio.wav')\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 다운로드된 오디오 파일 로드 및 변환\n",
    "input_file = \"audio.wav\"\n",
    "output_file = \"converted_audio.wav\"\n",
    "\n",
    "# 기존 파일을 로드하고 WAV 형식으로 변환\n",
    "audio = AudioSegment.from_file(input_file)\n",
    "audio.export(output_file, format=\"wav\", codec=\"pcm_s16le\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "# 사용할 수 있는 장치를 확인하여 설정\n",
    "if torch.cuda.is_available():  # CUDA(GPU)가 사용 가능한지 확인\n",
    "    device = torch.device(\"cuda\")\n",
    "else:  # GPU가 없을 경우 CPU 사용\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def recognize_speech(file_path, language='ko'):\n",
    "    # Whisper 모델 로드 (모델 크기는 tiny, base, small, medium, large 중 선택 가능)\n",
    "    model = whisper.load_model(\"medium\",device=device)  # 'base' 대신 원하는 모델을 선택하세요.\n",
    "\n",
    "    # 오디오 파일을 Whisper로 변환\n",
    "    result = model.transcribe(file_path, language=language)\n",
    "\n",
    "    # Whisper 결과에서 각 세그먼트를 사용하여 시간 정보와 텍스트 추출\n",
    "    transcript_with_timestamps = []\n",
    "    for segment in result['segments']:\n",
    "        start = segment['start']  # 시작 시간 (초 단위)\n",
    "        end = segment['end']      # 종료 시간 (초 단위)\n",
    "        text = segment['text']    # 텍스트\n",
    "\n",
    "        # 시작 시간과 지속 시간을 계산하여 딕셔너리 형식으로 저장\n",
    "        transcript_with_timestamps.append({\n",
    "            'text': text.strip(),\n",
    "            'start': start,\n",
    "            'duration': end - start\n",
    "        })\n",
    "\n",
    "    return transcript_with_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinucho/miniconda3/envs/youtube/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/jinucho/miniconda3/envs/youtube/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "text = recognize_speech(\"converted_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ↳ |████████████████████████████████████████████| 100.0%\r"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "from youtube_transcript_api import (NoTranscriptFound, TranscriptsDisabled,\n",
    "                                    VideoUnavailable, YouTubeTranscriptApi)\n",
    "\n",
    "\n",
    "def get_youtube_transcript_or_audio_transcription(url):\n",
    "    try:\n",
    "        # 유튜브 영상 ID 추출\n",
    "        video_id = url.split(\"=\")[1]\n",
    "\n",
    "        # 1. 자막 추출 시도\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])\n",
    "            return transcript\n",
    "        \n",
    "        except (NoTranscriptFound, TranscriptsDisabled):\n",
    "            pass\n",
    "\n",
    "        # 2. 자막이 없는 경우, 음성 추출 및 Whisper 사용\n",
    "        # 유튜브 영상에서 오디오 스트림 다운로드\n",
    "        yt = YouTube(url, on_progress_callback=on_progress)\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        \n",
    "        # 오디오 파일을 메모리 내에서 처리\n",
    "        audio_data = io.BytesIO()\n",
    "        audio_stream.stream_to_buffer(audio_data)  # 오디오 스트림을 버퍼에 저장\n",
    "        audio_data.seek(0)  # 파일 포인터를 처음으로 이동\n",
    "\n",
    "        # pydub을 사용하여 오디오 데이터를 로드하고, raw 데이터를 가져옴\n",
    "        audio_segment = AudioSegment.from_file(audio_data)\n",
    "        \n",
    "        # 오디오 데이터를 numpy 배열로 변환\n",
    "        samples = np.array(audio_segment.get_array_of_samples()).astype(np.float32)\n",
    "\n",
    "        # Whisper가 기대하는 샘플 레이트(16000Hz)로 변환\n",
    "        if audio_segment.frame_rate != 16000:\n",
    "            samples = samples.reshape((-1, audio_segment.channels))  # 채널 정보 포함\n",
    "            samples = librosa.resample(samples, orig_sr=audio_segment.frame_rate, target_sr=16000).flatten()\n",
    "\n",
    "        # Whisper 모델이 기대하는 포맷으로 변환\n",
    "        samples = samples / 32768.0  # int16 -> float32로 정규화\n",
    "\n",
    "        # 3. Whisper를 사용하여 음성 인식 및 텍스트 변환\n",
    "        if torch.cuda.is_available():  # GPU 사용 가능 여부 확인\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:  # GPU가 없을 경우 CPU 사용\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "        # Whisper 모델 로드\n",
    "        model = whisper.load_model(\"medium\", device=device)  # 원하는 모델 크기 선택 가능\n",
    "\n",
    "        # 오디오 파일 변환\n",
    "        result = model.transcribe(samples, language=['ko', 'en'])\n",
    "\n",
    "        # Whisper 결과에서 각 세그먼트를 사용하여 시간 정보와 텍스트 추출\n",
    "        transcript_with_timestamps = []\n",
    "        for segment in result['segments']:\n",
    "            start = segment['start']  # 시작 시간 (초 단위)\n",
    "            end = segment['end']      # 종료 시간 (초 단위)\n",
    "            text = segment['text']    # 텍스트\n",
    "\n",
    "            # 시작 시간과 지속 시간을 계산하여 딕셔너리 형식으로 저장\n",
    "            transcript_with_timestamps.append({\n",
    "                'text': text.strip(),\n",
    "                'start': start,\n",
    "                'duration': end - start\n",
    "            })\n",
    "\n",
    "        # 4. 변환된 텍스트 반환\n",
    "        return transcript_with_timestamps\n",
    "        \n",
    "    except VideoUnavailable:\n",
    "        return \"Error: 이 영상을 찾을 수 없습니다. 링크가 올바른지 확인하세요.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: 알 수 없는 오류가 발생했습니다. {str(e)}\"\n",
    "\n",
    "# 테스트용 URL\n",
    "result = get_youtube_transcript_or_audio_transcription(\"https://youtu.be/HsxWL3kDYh8?si=aGGS9vmvp6dNX8P2\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
