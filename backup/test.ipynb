{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "\n",
    "import tiktoken\n",
    "from langchain_teddynote.callbacks import StreamingCallback\n",
    "from langchain import hub\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import VLLM\n",
    "import json\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"beomi/Qwen2.5-7B-Instruct-kowiki-qa-context\", temperature=0.7, streaming=True, base_url=\"http://localhost:8080/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = ChatOpenAI(model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 9, 'total_tokens': 20, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-729a0205-fd3d-44f6-b7e4-3317370ab033-0', usage_metadata={'input_tokens': 9, 'output_tokens': 11, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2.invoke(\"í•˜ì´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'beomi/Qwen2.5-7B-Instruct-kowiki-qa-context'}, id='run-51a856e8-4899-400d-841c-f2f2914582ee-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"í•˜ì´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class CustomStreamingCallbackHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.partial_result = \"\"\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.partial_result += token\n",
    "        print(token, end=\"\", flush=True)  # ì‹¤ì‹œê°„ ì¶œë ¥\n",
    "        # '}'ê°€ ìƒì„±ë˜ë©´ ì¤‘ë‹¨\n",
    "        if \"}\" in self.partial_result:\n",
    "            raise StopIteration(\"ì¤‘ë‹¨ ì¡°ê±´ '}'ì´ ìƒì„±ë˜ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTIAL_SUMMARY_PROMPT_TEMPLATE = \"\"\"Please summarize the sentence according to the following REQUEST.\n",
    "                                            This task is partial summay, Please Do not summarize too much.\n",
    "    \n",
    "                                            REQUEST:\n",
    "                                            1. Summarize the main points in KOREAN.\n",
    "                                            2. Translate the summary into KOREAN if it is written in ENGLISH.\n",
    "                                            3. DO NOT translate any technical terms.\n",
    "                                            4. DO NOT include any unnecessary information.\n",
    "                                            \n",
    "                                            CONTEXT:\n",
    "                                            {context}\n",
    "                                            \n",
    "                                            SUMMARY:\n",
    "                                            \"\"\"\n",
    "                                            \n",
    "FINAL_SUMMARY_PROMPT_TEMPLATE = \"\"\"\n",
    "ë‹¤ìŒ REQUESTì— ë”°ë¼ CONTEXTë¥¼ ìš”ì•½í•˜ê³ , ì¶œë ¥ì€ ì•„ë˜ì— ì œê³µëœ ì¶œë ¥ í˜•ì‹(OUTPUT_FORMAT)ê³¼ ì •í™•íˆ ë™ì¼í•˜ê²Œ í•œ ë²ˆë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "REQUEST:\n",
    "1. ì£¼ì–´ì§„ OUTPUT(JSON í˜•ì‹) ì™¸ì˜ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "2. CONTEXTì™€ HUMAN MESSAGEëŠ” ì¶œë ¥í•˜ì§€ë§ˆì„¸ìš”.\n",
    "3. ë‹¨ í•˜ë‚˜ì˜ OUTPUTë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "4. ì£¼ìš” ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ë˜, ì „ë¬¸, ê¸°ìˆ  ìš©ì–´ëŠ” ì›ë³¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "5. ìš”ì•½ëœ ê° ë¬¸ì¥ì€ í•´ë‹¹ ì˜ë¯¸ì™€ ì˜ ì–´ìš¸ë¦¬ëŠ” ì´ëª¨ì§€ í•˜ë‚˜ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "6. ë‹¤ì–‘í•œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ì„ í¥ë¯¸ë¡­ê²Œ ì‘ì„±í•˜ë˜, ê°„ê²°í•˜ê³  ê´€ë ¨ì„± ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”.\n",
    "7. ë¬¸ì„œì˜ ë‹¨ì¼ ì£¼ìš” ì£¼ì œì™€ ì „ë°˜ì ì¸ ìš”ì•½ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.\n",
    "8. ê° ìš”ì•½ì—ì„œ ì£¼ìš” ì£¼ì œë¥¼ ëª…í™•íˆ ë‚˜íƒ€ë‚´ì„¸ìš”.\n",
    "9. CONTEXTì˜ ë‚´ìš©ì´ ì¶©ë¶„íˆ ë§ë‹¤ë©´, ìš”ì•½ ë¬¸ì¥ì„ ì¶©ë¶„íˆ ìƒì„±í•˜ì„¸ìš”.\n",
    "10. ìš”ì•½ëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì„¸ ê°€ì§€ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "OUTPUT_FORMAT(JSON í˜•ì‹):\n",
    "{{\n",
    "    \"FINAL_SUMMARY\": {{\n",
    "        \"Key_topic\": ì£¼ìš” ì£¼ì œ ë‚´ìš©,\n",
    "        \"Summaries\": [\n",
    "            \"â€¢ Emoji ìš”ì•½ëœ ë‚´ìš©1\",\n",
    "            \"â€¢ Emoji ìš”ì•½ëœ ë‚´ìš©2\",\n",
    "            ...ì¶”ê°€ ìš”ì•½ ë‚´ìš© ë‚˜ì—´\n",
    "        ]\n",
    "    }},\n",
    "    \"RECOMMEND_QUESTIONS\": [\n",
    "        \"ì²« ë²ˆì§¸ ì§ˆë¬¸ (í•œêµ­ì–´)\",\n",
    "        \"ë‘ ë²ˆì§¸ ì§ˆë¬¸ (í•œêµ­ì–´)\",\n",
    "        \"ì„¸ ë²ˆì§¸ ì§ˆë¬¸ (í•œêµ­ì–´)\"\n",
    "    ]\n",
    "}}\n",
    "OUTPUT:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=10\n",
    ")\n",
    "summarize_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, chunk_overlap=500\n",
    ")\n",
    "partial_summary_prompt = PromptTemplate.from_template(\n",
    "    PARTIAL_SUMMARY_PROMPT_TEMPLATE\n",
    ")\n",
    "final_summary_prompt = PromptTemplate.from_template(\n",
    "    FINAL_SUMMARY_PROMPT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../runpod_backend/data/backup.json\",\"r\") as f:\n",
    "#     data = json.load(f)\n",
    "# script = data[\"m25Lz9KWyDkNx6Vv\"][\"script_info\"][\"script\"]\n",
    "with open(\"./test1234/transcript.json\",\"r\") as f:\n",
    "    script = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "            Document(page_content=\"\\n\".join([t[\"text\"] for t in script]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_summary_chain = create_stuff_documents_chain(\n",
    "            llm=llm, prompt=partial_summary_prompt\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "summarize_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000, chunk_overlap=400\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "calculate_tokens(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = summarize_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    emoji: str = Field(..., description=\"ìš”ì•½ì— ì‚¬ìš©í•˜ëŠ” ì´ëª¨ì§€\")\n",
    "    content: str = Field(..., description=\"ìš”ì•½ëœ ë‚´ìš©\")\n",
    "\n",
    "class FinalSummary(BaseModel):\n",
    "    key_topic: str = Field(..., description=\"ì£¼ìš” ì£¼ì œ ë‚´ìš©\")\n",
    "    summaries: List[Summary] = Field(..., description=\"ìš”ì•½ëœ ë‚´ìš© ë¦¬ìŠ¤íŠ¸\")\n",
    "\n",
    "class RecommendQuestions(BaseModel):\n",
    "    questions: List[str] = Field(..., description=\"ì¶”ì²œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\")\n",
    "\n",
    "class FullStructure(BaseModel):\n",
    "    FINAL_SUMMARY: FinalSummary = Field(..., description=\"ìµœì¢… ìš”ì•½ ì •ë³´\")\n",
    "    RECOMMEND_QUESTIONS: RecommendQuestions = Field(..., description=\"ì¶”ì²œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser(pydantic_object=FullStructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary_chain = create_stuff_documents_chain(\n",
    "            llm=llm, prompt=final_summary_prompt, output_parser=parser\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = partial_summary_chain.invoke({\"context\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_summary = [Document(page_content=summary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = summarize_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_handler = CustomStreamingCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = final_summary_chain.invoke({\"context\": docs})\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary[\"FINAL_SUMMARY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary[\"RECOMMEND_QUESTIONS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"\"\n",
    "summary += f'{list(final_summary.get(\"FINAL_SUMMARY\").items())[0][0]}:{list(final_summary.get(\"FINAL_SUMMARY\").items())[0][1]}\\n'\n",
    "joined_summary = '\\n'.join(list(final_summary.get(\"FINAL_SUMMARY\").items())[1][1])\n",
    "summary += f'{list(final_summary.get(\"FINAL_SUMMARY\").items())[1][0]}:{joined_summary}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = final_summary.get(\"RECOMMEND_QUESTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)\n",
    "print(\"------\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].page_content += f\"\\n{summary}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store = FAISS.from_documents(split_docs, hf_embeddings)\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k = 10\n",
    "vec_retriever = vec_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "retriever = EnsembleRetriever(\n",
    "                retrievers=[bm25_retriever, vec_retriever],\n",
    "                weights=[0.7, 0.3],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€\n",
    "# response_schemas = [\n",
    "#     ResponseSchema(name=\"answer\", description=\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€\"),\n",
    "# ]\n",
    "# # ì‘ë‹µ ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "# output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "            \"\"\"ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ì˜ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "                ë‹¹ì‹ ì˜ ì£¼ìš” ì„ë¬´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "                1. ê¸°ë³¸ì ìœ¼ë¡œ ê²€ìƒ‰ëœ ë¬¸ë§¥(context)ê³¼ ì´ì „ ëŒ€í™” ë‚´ìš©(chat_history)ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ OUTPUT_FORMATì˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œì„œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "                2. ì£¼ì–´ì§„ OUTPUT(JSON í˜•ì‹) ì™¸ì˜ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "                3. ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì—ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë¶€ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:\n",
    "                    - ê²€ìƒ‰ëœ ë¬¸ë§¥ì´ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì™„ë²½í•˜ê²Œ ì¶©ì¡±í•˜ì§€ ëª»í•  ë•Œ\n",
    "                    - ì˜ìƒì˜ ì „ë°˜ì ì¸ ì£¼ì œì™€ ì—°ê´€ë˜ì§€ë§Œ êµ¬ì²´ì ì¸ ë‹µë³€ì´ ë¬¸ë§¥ì— ì—†ì„ ë•Œ\n",
    "                    - ë¬¸ë§¥ì—ì„œ ë¶€ë¶„ì ì¸ ì •ë³´ë§Œ ì°¾ì„ ìˆ˜ ìˆì„ ë•ŒëŠ” ë¬¸ë§¥ì˜ ì •ë³´ì™€ ë‚´ë¶€ ì§€ì‹ì„ ì¡°í•©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”\n",
    "\n",
    "                4. ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ì§€ì¼œì£¼ì„¸ìš”:\n",
    "                - í•­ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "                - ë¬¸ë§¥ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë”ë¼ë„, ê·¸ ì‚¬ì‹¤ì„ ì–¸ê¸‰í•˜ì§€ ë§ê³  ë°”ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "                - ê¸°ìˆ  ìš©ì–´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì›ì–´ë¥¼ ìœ ì§€í•˜ì„¸ìš”\n",
    "                - ì „ë¬¸ì ì¸ ë‚´ìš©ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”\n",
    "\n",
    "                5. ë§Œì•½ ì§ˆë¬¸ì´ ì˜ìƒì˜ ì£¼ì œë‚˜ ë‚´ìš©ê³¼ ì „í˜€ ê´€ë ¨ì´ ì—†ë‹¤ë©´ \"ì˜ìƒê³¼ ê´€ê³„ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "                ì´ì „ ëŒ€í™” ë‚´ìš©:\n",
    "                {chat_history}\n",
    "\n",
    "                ì§ˆë¬¸:\n",
    "                {question}\n",
    "\n",
    "                ë¬¸ë§¥:\n",
    "                {context}\n",
    "\n",
    "                OUTPUT_FORMAT:\n",
    "                {{\"answer\": \"ë‹µë³€\"}}\n",
    "                \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chat_parser(BaseModel):\n",
    "    answer: dict = Field(..., description=\"ì±„íŒ… ì‘ë‹µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "                {\n",
    "                    \"context\": itemgetter(\"question\") | retriever,\n",
    "                    \"question\": itemgetter(\"question\"),\n",
    "                    \"chat_history\": itemgetter(\"chat_history\"),\n",
    "                }\n",
    "                | prompt\n",
    "                # | chat_llm\n",
    "                | llm\n",
    "                | JsonOutputParser(pydantic_object=chat_parser)\n",
    "                # | StrOutputParser()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_message_store = {}\n",
    "def _get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "        \"\"\"ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        if session_id not in _message_store:\n",
    "            _message_store[session_id] = ChatMessageHistory()\n",
    "        return _message_store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "                chain,\n",
    "                _get_session_history,\n",
    "                input_messages_key=\"question\",\n",
    "                history_messages_key=\"chat_history\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(prompt):\n",
    "    return chain_with_history.invoke(\n",
    "                    {\"question\": prompt},\n",
    "                    config={\"configurable\": {\"session_id\": \"test1234\"}},\n",
    "                    callbacks = [callback_handler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë©°, ê·¸ ì¤‘ìš”ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
    "\n",
    "2. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ í† í°ì˜ ê³ ì°¨ì› ë²¡í„°ë¥¼ ì–´ë–»ê²Œ ì¡°ì •í•˜ì—¬ ë¬¸ë§¥ì— ë”°ë¥¸ ì˜ë¯¸ë¥¼ ë” í’ë¶€í•˜ê²Œ ë§Œë“œëŠ”ê°€ìš”?\n",
    "\n",
    "3. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì—¬ëŸ¬ í—¤ë“œëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë©°, ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat('Transformerì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ ì¤„ ìˆ˜ ìˆë‚˜ìš”?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000, chunk_overlap=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"script.json\", \"r\") as f:\n",
    "    script_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"test1234\",exist_ok=True)\n",
    "with open(\"test1234/transcript.json\", \"w\") as f:\n",
    "    json.dump(script_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "            Document(page_content=\"\\n\".join([t[\"text\"] for t in script_data]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = summarize_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store.save_local(\"test1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store_load = FAISS.load_local(\"test11\", embeddings=embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"[FINAL SUMMARY]\\nKey topic: ë ˆê·¸ì˜ ì´í•´ ë° ì •ë³´ ì²˜ë¦¬\\n\\nâ€¢ ğŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í•˜ê¸° ìœ„í•œ ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.  \\nâ€¢ ğŸ”„ ë°˜ë³µ í•™ìŠµì„ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì„ ì´í•´í•´ì•¼ í•œë‹¤.  \\nâ€¢ âœï¸ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì •ë³´ ì°¸ì¡°ë¥¼ í†µí•´ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆëŠ” AIì´ë‹¤.  \\nâ€¢ âš™ï¸ ì‚¬ì „í•™ìŠµëœ ì •ë³´ì™€ ìµœì‹  ì •ë³´ì˜ ì°¨ì´ë¥¼ ì´í•´í•´ì•¼ í•˜ë©°, ì •ë³´ì˜ íë¦„ì„ ìƒì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤.  \\nâ€¢ ğŸ” íš¨ê³¼ì ì¸ ì •ë³´ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ì˜ í˜ì´ì§€ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.  \\nâ€¢ ğŸ“„ ë¬¸ì„œì˜ íŠ¹ì • ë‹¨ë½ì„ ì„ íƒí•˜ê³ , ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.  \\nâ€¢ ğŸ’¡ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ë¬¸ì¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚¨ë‹¤.\\n\\n[RECOMMEND QUESTIONS]\\n1. ë ˆê·¸ë¥¼ í™œìš©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ì–´ë–»ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ ì œê³µí•  ìˆ˜ ìˆì„ê¹Œ?\\n2. ì‚¬ì „í•™ìŠµëœ ì •ë³´ì™€ ìµœì‹  ì •ë³´ì˜ í™œìš© ì‹œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€?\\n3. ì¸ë² ë”© ê³¼ì •ì´ ì •ë³´ ê²€ìƒ‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆì„ê¹Œ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[0].strip(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[0].strip(\"\\n\\n\").replace(\"\\n\\n\", \"\\n\").replace(\"\\n\\n\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.container?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "import re\n",
    "\n",
    "\n",
    "class YouTubeService:\n",
    "    async def get_title_and_hashtags(self, url: str):\n",
    "        yt = await _create_youtube_instance(url)\n",
    "        print(\"ì˜ìƒ ì •ë³´ í™•ì¸\")\n",
    "        title = yt.title\n",
    "        description = yt.description\n",
    "        hashtags = re.findall(r\"#\\w+\", description)\n",
    "        return {\"title\": title, \"hashtags\": \" \".join(hashtags)}\n",
    "\n",
    "    async def get_video_info(self, url: str):\n",
    "        yt = await _create_youtube_instance(url)\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        print(\"ìŒì„± ì¶”ì¶œ ì™„ë£Œ\")\n",
    "        return {\n",
    "            \"title\": yt.title,\n",
    "            \"audio_url\": audio_stream.url if audio_stream else None,\n",
    "        }\n",
    "\n",
    "    async def _create_youtube_instance(self, url: str):\n",
    "        print(\"YouTube ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "        return YouTube(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import ffmpeg\n",
    "import requests\n",
    "import soundfile as sf\n",
    "from faster_whisper import BatchedInferencePipeline, WhisperModel\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "class WhisperTranscriptionService:\n",
    "    def __init__(self):\n",
    "        model = WhisperModel(\n",
    "            \"large-v3\", device=\"cuda\", compute_type=\"float16\"\n",
    "        )\n",
    "        model = BatchedInferencePipeline(model=model)\n",
    "        language = None\n",
    "        okt = Okt()\n",
    "        print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "    def create_session(self):\n",
    "        session = requests.Session()\n",
    "        retry = Retry(\n",
    "            total=5, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry, pool_connections=100, pool_maxsize=100)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        return session\n",
    "\n",
    "    def download_chunk(self, args):\n",
    "        url, start, end, chunk_number, temp_dir = args\n",
    "\n",
    "        headers = {\"Range\": f\"bytes={start}-{end}\"}\n",
    "        session = create_session()\n",
    "\n",
    "        try:\n",
    "            response = session.get(url, headers=headers, stream=True)\n",
    "            chunk_path = os.path.join(temp_dir, f\"chunk_{chunk_number:04d}\")\n",
    "\n",
    "            with open(chunk_path, \"wb\") as f:\n",
    "                for data in response.iter_content(chunk_size=8192):\n",
    "                    f.write(data)\n",
    "\n",
    "            return chunk_path, chunk_number\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading chunk {chunk_number}: {str(e)}\")\n",
    "            return None, chunk_number\n",
    "\n",
    "    def _single_stream_download(self, url: str, temp_dir: str) -> str:\n",
    "        \"\"\"ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "        print(\"Starting single stream download...\")\n",
    "        session = create_session()\n",
    "        output_path = os.path.join(temp_dir, \"complete_audio.mp4\")\n",
    "\n",
    "        try:\n",
    "            with session.get(url, stream=True) as response:\n",
    "                response.raise_for_status()\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "            return output_path\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to download file: {str(e)}\")\n",
    "\n",
    "    def parallel_download(self, url: str, temp_dir: str, num_chunks: int = 10) -> str:\n",
    "        \"\"\"ë³‘ë ¬ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•˜ê³ , ì‹¤íŒ¨ ì‹œ ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ í´ë°±\"\"\"\n",
    "        session = create_session()\n",
    "\n",
    "        try:\n",
    "            # HEAD ìš”ì²­ìœ¼ë¡œ íŒŒì¼ í¬ê¸° í™•ì¸ ì‹œë„\n",
    "            response = session.head(url, allow_redirects=True)\n",
    "            total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "            # HEAD ìš”ì²­ì´ ì‹¤íŒ¨í•˜ë©´ GET ìš”ì²­ìœ¼ë¡œ ì‹œë„\n",
    "            if total_size == 0:\n",
    "                response = session.get(url, stream=True)\n",
    "                total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "            # íŒŒì¼ í¬ê¸°ë¥¼ ì—¬ì „íˆ í™•ì¸í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "            if total_size == 0:\n",
    "                print(\n",
    "                    \"Warning: Could not determine file size. Falling back to single stream download.\"\n",
    "                )\n",
    "                return _single_stream_download(url, temp_dir)\n",
    "            print(\"Starting parallel download...\")\n",
    "            chunk_size = total_size // num_chunks\n",
    "            chunks = []\n",
    "\n",
    "            for i in range(num_chunks):\n",
    "                start = i * chunk_size\n",
    "                end = start + chunk_size - 1 if i < num_chunks - 1 else total_size - 1\n",
    "                chunks.append((start, end))\n",
    "\n",
    "            download_args = [\n",
    "                (url, start, end, i, temp_dir) for i, (start, end) in enumerate(chunks)\n",
    "            ]\n",
    "\n",
    "            chunk_paths = []\n",
    "            with concurrent.futures.ThreadPoolExecutor(\n",
    "                max_workers=num_chunks\n",
    "            ) as executor:\n",
    "                futures = executor.map(download_chunk, download_args)\n",
    "                chunk_paths = [(path, num) for path, num in futures if path is not None]\n",
    "\n",
    "            if not chunk_paths:\n",
    "                raise Exception(\"No chunks were downloaded successfully\")\n",
    "\n",
    "            chunk_paths.sort(key=lambda x: x[1])\n",
    "            output_path = os.path.join(temp_dir, \"complete_audio.mp4\")\n",
    "\n",
    "            with open(output_path, \"wb\") as outfile:\n",
    "                for chunk_path, _ in chunk_paths:\n",
    "                    with open(chunk_path, \"rb\") as infile:\n",
    "                        outfile.write(infile.read())\n",
    "                    os.remove(chunk_path)\n",
    "\n",
    "            return output_path\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error in parallel download: {str(e)}. Falling back to single stream download.\"\n",
    "            )\n",
    "            return _single_stream_download(url, temp_dir)\n",
    "\n",
    "    def convert_to_wav(self, input_path: str, output_path: str) -> bool:\n",
    "        try:\n",
    "            stream = ffmpeg.input(input_path)\n",
    "            stream = ffmpeg.output(\n",
    "                stream, output_path, acodec=\"pcm_s16le\", ar=\"16000\", ac=\"1\"\n",
    "            )\n",
    "            ffmpeg.run(stream, capture_stdout=True, capture_stderr=True)\n",
    "            return True\n",
    "        except ffmpeg.Error as e:\n",
    "            print(\"FFmpeg error:\", e.stderr.decode())\n",
    "            return False\n",
    "\n",
    "    def process_audio_chunk(self, chunk_data: tuple,promp:str = None,filtered_words:list = None) -> List[Dict[str, Any]]:\n",
    "        audio_path, start_time, duration = chunk_data\n",
    "        try:\n",
    "            segments, info = model.transcribe(\n",
    "                audio_path,\n",
    "                beam_size=5,\n",
    "                best_of=7,\n",
    "                batch_size=32,\n",
    "                temperature=0.7,\n",
    "                word_timestamps=True,\n",
    "                initial_prompt=f\"ìŒì„± ì œëª©: {promp}\",\n",
    "                repetition_penalty=2,\n",
    "                no_repeat_ngram_size=3,\n",
    "                length_penalty=1.1,\n",
    "                log_prob_threshold=-0.5,\n",
    "                no_speech_threshold=0.7,\n",
    "                patience=1.2,\n",
    "                hotwords=filtered_words\n",
    "            )\n",
    "            if info and hasattr(info, \"language\"):\n",
    "                language = info.language\n",
    "            return _process_segments(segments, start_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk at {start_time}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def _process_segments(\n",
    "        self, segments, start_time: float = 0\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        transcript = []\n",
    "        for segment in segments:\n",
    "            transcript.append(\n",
    "                {\n",
    "                    \"start\": round(segment.start + start_time, 2),\n",
    "                    \"end\": round(segment.end + start_time, 2),\n",
    "                    \"text\": segment.text,\n",
    "                }\n",
    "            )\n",
    "        return transcript\n",
    "\n",
    "    async def process_with_progress(\n",
    "        self, url: str, prompt:str, filtered_words:str,chunk_duration: int = 30, num_download_chunks: int = 10\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            mp4_path = parallel_download(url, temp_dir, num_download_chunks)\n",
    "            print(\"Download complete!\")\n",
    "\n",
    "            wav_path = os.path.join(temp_dir, \"audio.wav\")\n",
    "            if not convert_to_wav(mp4_path, wav_path):\n",
    "                raise Exception(\"Failed to convert audio to WAV format\")\n",
    "\n",
    "            wav_info = sf.info(wav_path)\n",
    "            total_duration = wav_info.duration\n",
    "            total_chunks = math.ceil(total_duration / chunk_duration)\n",
    "\n",
    "            chunks_data = []\n",
    "            for i in range(total_chunks):\n",
    "                start_time = i * chunk_duration\n",
    "                chunk_wav_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "\n",
    "                duration = min(chunk_duration, total_duration - start_time)\n",
    "                stream = ffmpeg.input(wav_path, ss=start_time, t=duration)\n",
    "                stream = ffmpeg.output(\n",
    "                    stream, chunk_wav_path, acodec=\"pcm_s16le\", ar=\"16000\", ac=\"1\"\n",
    "                )\n",
    "                ffmpeg.run(stream, quiet=True)\n",
    "\n",
    "                chunks_data.append((chunk_wav_path, start_time, duration))\n",
    "\n",
    "            all_segments = []\n",
    "            for chunk_data in chunks_data:\n",
    "                segments = process_audio_chunk(chunk_data,prompt,filtered_words)\n",
    "                all_segments.extend(segments)\n",
    "\n",
    "                if os.path.exists(chunk_data[0]):\n",
    "                    os.remove(chunk_data[0])\n",
    "\n",
    "        return all_segments\n",
    "\n",
    "    async def transcribe(self, audio_url: str,prompt: str = None) -> Dict[str, Any]:\n",
    "        try:\n",
    "            try:\n",
    "                tagged = okt.pos(prompt)\n",
    "                filtered_words = []\n",
    "                for word, tag in tagged:\n",
    "                    if tag == \"Noun\" or tag == \"Hashtag\":\n",
    "                        filtered_words.append(word)\n",
    "            except:\n",
    "                filtered_words = None\n",
    "            segments = await process_with_progress(\n",
    "                audio_url, prompt, filtered_words,chunk_duration=30, num_download_chunks=10\n",
    "            )\n",
    "\n",
    "            print(\"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ\")\n",
    "\n",
    "            return {\"script\": segments, \"language\": language}\n",
    "        except Exception as e:\n",
    "            print(f\"Error in transcribe: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = YouTubeService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = await youtube.get_video_info(\"https://youtu.be/EMMC0ym0QOI?si=bx7raBo-QwR3MGy7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info[\"audio_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper = WhisperTranscriptionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = await whisper.transcribe(video_info[\"audio_url\"],video_info[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in transcript[\"script\"]:\n",
    "    print(script[\"text\"],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = await whisper.transcribe(video_info[\"audio_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in transcript[\"script\"]:\n",
    "    print(script[\"text\"],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### ì£¼ì œ: ë ˆê·¸ì˜ ê°œë… ë° êµ¬í˜„ ë°©ë²•\\n\\n- ğŸ“š ë ˆê·¸ ë¹„ë²•ë…¸íŠ¸ë¥¼ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì— ëŒ€í•œ ì´í•´ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.\\n- ğŸ” ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ë°˜ë³µì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ì´í•´ë„ë¥¼ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.\\n- â“ ë ˆê·¸ì˜ ì£¼ìš” ëª©ì ì€ ìµœì‹  ì •ë³´ë¥¼ í¬í•¨í•œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\\n- ğŸ†š GPTëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ì˜ì¡´í•˜ì§€ë§Œ, ë ˆê·¸ëŠ” ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n- ğŸ“Š ì˜¤ë˜ëœ ì •ë³´ëŠ” ì •í™•í•œ ë‹µë³€ì„ ë°©í•´í•˜ë©°, ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ì…ë‹ˆë‹¤.\\n- ğŸ“‘ ë¬¸ë§¥ì„ í†µí•´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ê³ , ìœ ì‚¬ë„ ê³„ì‚°ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\\n- ğŸ”„ í…ìŠ¤íŠ¸ëŠ” íŠ¹ì • í‚¤ì›Œë“œë¡œ ë¶„í• ë˜ì–´ì•¼ í•˜ë©°, ì²­í¬ ì˜¤ë²„ë©ì„ í†µí•´ ì •ë³´ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.\\n- ğŸ’¾ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ê° ë‹¨ë½ì„ ìˆ«ì í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- ğŸ“Š ì¸ë² ë”© ì´í•´ í›„, ë°ì´í„°ë¥¼ ì €ì¥í•´ì•¼ í•˜ë©°, ì´ ê³¼ì •ì—ì„œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.\\n- ğŸ“š ë‹¤ìŒ ì˜ìƒì—ì„œëŠ” ë ˆê·¸ì˜ í›„ë°˜ë¶€ ë‚´ìš©ì„ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.\\n\\n### ì¶”ì²œ ì§ˆë¬¸:\\n1. ë ˆê·¸ì˜ êµ¬í˜„ ë°©ì‹ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\\n2. ì¸ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì€ ì–´ë–»ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆë‚˜ìš”?\\n3. ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"### KEY TOPIC: ë ˆê·¸ì˜ ê¸°ëŠ¥ê³¼ ì •ë³´ ì ‘ê·¼ ë°©ì‹\\n\\n- ğŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ì°©í•˜ê¸°ê¹Œì§€ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.  \\n- ğŸ”„ ë ˆê·¸ì— ëŒ€í•œ ì´í•´ë¥¼ ìœ„í•´ ë°˜ë³µ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.  \\n- ğŸ¨ ë ˆê·¸ì˜ ëª©ì ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•  ì˜ˆì •ì…ë‹ˆë‹¤.  \\n- â“ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.  \\n- ğŸ“° ê¸°ì¡´ ì±„ì° PTì™€ ë¹„êµí•˜ì—¬ ì •ë³´ ì ‘ê·¼ ë°©ì‹ì„ ì„¤ëª…í•©ë‹ˆë‹¤.  \\n- âš™ï¸ í”„ë¡¬í”„íŠ¸ì˜ ë³€í™”ë¡œ ë ˆê·¸ì˜ ê¸°ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤.  \\n- ğŸ“„ PDFì™€ ê°™ì€ ìë£Œë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•¨.  \\n- ğŸ”‘ ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ì„.  \\n- ğŸ“ íŠ¹ì • ë‹¨ë½ë§Œ í•„ìš”í•œ ê²½ìš° ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì„¤ì •í•˜ì—¬ ë¶„í• í•¨.  \\n- ğŸ” ìœ ì‚¬ë„ ê³„ì‚°ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ë½‘ì•„ëƒ…ë‹ˆë‹¤.  \\n- ğŸ“Š ì„ë² ë”©ì€ ë¬¸ìì—´ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„.  \\n- ğŸ”— ë™ì¼í•œ ìˆ«ì ê°œìˆ˜ë¡œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥í•¨.  \\n- ğŸ’° ì¸ë² ë”© ê³¼ì •ì—ì„œ ë¹„ìš©ì´ ë°œìƒí•˜ë©°, ë§ì€ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ ì‹ ì¤‘í•´ì•¼ í•¨.  \\n- ğŸ“½ï¸ ì´ë²ˆ ì˜ìƒì€ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë‹¤ë£¨ì—ˆê³ , ë‹¤ìŒ ì˜ìƒì—ì„œëŠ” í›„ë°˜ë¶€ë¥¼ ë‹¤ë£° ì˜ˆì •.\\n\\n### RECOMMENDED QUESTIONS:\\n1. ë ˆê·¸ì˜ ì •ë³´ ì ‘ê·¼ ë°©ì‹ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\\n2. ì„ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\\n3. ë ˆê·¸ì˜ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë°˜ë³µ í•™ìŠµì˜ í•„ìš”ì„±ì€ ì–´ë–¤ ì ì—ì„œ ì¤‘ìš”í•œê°€ìš”?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Key Topic: RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë° ì´í•´\\n\\n- ğŸ‰ ì—¬ëŸ¬ë¶„ì€ RAGì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.\\n- ğŸ”„ RAGì˜ ë‚´ìš©ì„ ë°˜ë³µí•˜ì—¬ ì´í•´ë¥¼ ë†’ì´ì„¸ìš”.\\n- ğŸ“‚ ì‹¤ìŠµ íŒŒì¼ì„ í†µí•´ RAG í”„ë¡œì„¸ìŠ¤ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\\n- ğŸ§ RAGê°€ ë¬´ì—‡ì¸ì§€ì™€ êµ¬í˜„ ë°©ë²•ì„ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.\\n- ğŸ¨ RAG ì‚¬ìš© ëª©ì ì„ ê·¸ë¦¼ìœ¼ë¡œ ì„¤ëª…í•  ì˜ˆì •ì…ë‹ˆë‹¤.\\n- â“ RAGì˜ í•„ìš”ì„±ì„ ì±„ì° PTì™€ ë¹„êµí•˜ì—¬ ì„¤ëª…í•  ê²ƒì…ë‹ˆë‹¤.\\n- ğŸ“„ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ RAGì˜ ì£¼ìš” ëª©ì ì…ë‹ˆë‹¤.\\n- ğŸ“Š GPDëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ì˜ì¡´í•˜ë¯€ë¡œ ì •ë³´ê°€ ì˜¤ë˜ë˜ë©´ ì •í™•í•œ ë‹µë³€ì„ í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\\n- ğŸ”— RAGëŠ” ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ê°€ ë°”ë€ë‹ˆë‹¤.\\n- ğŸ“š GPDëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- â³ ì˜¤ë˜ëœ ì‚¬ì „í•™ìŠµ ì •ë³´ëŠ” ì •í™•í•œ ë‹µë³€ì„ ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤.\\n- ğŸ” í”„ë¡¬í”„íŠ¸ê°€ ë³€ê²½ë˜ì–´ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ë„ë¡ í•©ë‹ˆë‹¤.\\n- ğŸ“„ PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- âš ï¸ ë§ì€ ì •ë³´ë¥¼ ì…ë ¥í•  ê²½ìš° ë¹„ìš©ì´ ì¦ê°€í•˜ê³  ì •ë³´ íƒìƒ‰ì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- ğŸ”‘ ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ì…ë‹ˆë‹¤.\\n- ğŸ“ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê¸ì–´ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\\n- ğŸ” ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\\n- ğŸ“ˆ ìœ ì‚¬ë„ê°€ ë†’ì€ ë‹¨ë½ì„ ê²€ìƒ‰í•´ ìµœìƒìœ„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\\n- ğŸ§® ì¸ë² ë”©ì€ ë¬¸ì¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ì–´ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\\n- ğŸ’¾ ì¸ë² ë”© í›„ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n- ğŸ” ì €ì¥ëœ ë°ì´í„°ëŠ” ê²€ìƒ‰ì–´ë¥¼ í†µí•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\\n- ğŸ“½ï¸ ì´ë²ˆ ì˜ìƒì€ ì‚¬ì „ ë‹¨ê³„ê¹Œì§€ ì‚´í´ë³´ì•˜ê³ , ë‹¤ìŒ ì˜ìƒì—ì„œ í›„ë°˜ë¶€ë¥¼ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.\\n\\n### RECOMMENDED QUESTIONS:\\n1. RAG ì‹œìŠ¤í…œì´ ê¸°ì¡´ GPDì™€ ì–´ë–»ê²Œ ì°¨ë³„í™”ë˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‚˜ìš”?\\n2. RAGì˜ ì¸ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì€ ì–´ë–¤ ìš”ì†Œì— ì˜í•´ ê²°ì •ë˜ë‚˜ìš”?\\n3. PDF ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ìœ ì‚¬ë„ ê³„ì‚°ì€ ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://youtu.be/AA621UofTUA?si=gn4XutRMWUDSYLFL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Please summarize the sentence according to the following FINAL REQUEST. \n",
    "FINAL REQUEST:\n",
    "1. The provided summary sections are partial summaries of one document. Please combine them into a single cohesive summary.\n",
    "2. Summarize the main points in bullet points in KOREAN.\n",
    "3. Each summarized sentence must start with a single emoji that fits the meaning of the sentence.\n",
    "4. Use various emojis to make the summary more interesting, but keep it concise and relevant.\n",
    "5. Focus on identifying and presenting only one main topic and one overall summary for the document.\n",
    "6. Avoid redundant or repeated points, and ensure that the summary covers all key ideas without introducing multiple conclusions or topics.\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\n",
    "FINAL SUMMARY:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points in KOREAN.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. Translate the summary into KOREAN if it is written in ENGLISH.\\n5. DO NOT translate any technical terms.\\n6. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please summarize the sentence according to the following FINAL REQUEST. \\nFINAL REQUEST:\\n1. The provided summary sections are partial summaries of one document. Please combine them into a single cohesive summary.\\n2. Summarize the main points in bullet points in KOREAN, but DO NOT translate any technical terms.\\n3. Each summarized sentence must start with a single emoji that fits the meaning of the sentence.\\n4. Use various emojis to make the summary more interesting, but keep it concise and relevant.\\n5. Focus on identifying and presenting only one main topic and one overall summary for the document.\\n6. Avoid redundant or repeated points, and ensure that the summary covers all key ideas without introducing multiple conclusions or topics.\\n7. Please refer to each summary and indicate the key topic.\\n8. If the original text is in English, we have already provided a summary translated into Korean, so please do not provide a separate translation.\\n\\nCONTEXT: \\n{context}\\n\\nFINAL SUMMARY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"[FINAL SUMMARY]\\nâ€¢ ğŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ëŠ” ë°˜ë³µ í•™ìŠµê³¼ ë ˆê·¸ì— ëŒ€í•œ ê¹Šì€ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\\nâ€¢ ğŸ–¼ï¸ RAGì˜ ë„ì…ì€ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì¤‘ìš”í•˜ë©°, ì¢Œì¸¡ì˜ ë ˆê·¸ì™€ ìš°ì¸¡ì˜ ê¸°ì¡´ ë°©ë²•ì„ ë¹„êµí•´ ì„¤ëª…í•©ë‹ˆë‹¤.\\nâ€¢ ğŸ“ˆ í”„ë¡¬í”„íŠ¸ì˜ ë³€í™”ì™€ ì •ë³´ì˜ ì •í™•ì„±ì´ ì¤‘ìš”í•˜ë©°, ì‚¬ì „í•™ìŠµëœ ì •ë³´ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ ì‹ ë¢°ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.\\nâ€¢ ğŸ”‘ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì°¾ì•„ë‚´ê³ , í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°ì™€ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ì •ë³´ì˜ ì •í™•ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.\\nâ€¢ ğŸ’° ë§ì€ ì…ë ¥ ì •ë³´ëŠ” ë¹„ìš© ì¦ê°€ì™€ ì •ë³´ íƒìƒ‰ì˜ ì–´ë ¤ì›€ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n[RECOMMEND QUESTIONS]\\n1. RAGì˜ ë„ì…ì´ ì™œ ì¤‘ìš”í•œê°€ìš”?\\n2. ìœ ì‚¬ë„ ê²€ìƒ‰ì—ì„œ ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ê´€ë ¨ ë‹¨ë½ì„ ì°¾ë‚˜ìš”?\\n3. ì…ë ¥ ì •ë³´ê°€ ë§ì„ ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[1].split(\"\\n\")[1].split(\".\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = [{\"start\": 0.0, \"end\": 29.42, \"text\": \" ì—¬ëŸ¬ë¶„ ì•ˆë…•í•˜ì„¸ìš” ë“œë””ì–´ ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë ˆê·¸ íŒŒíŠ¸ê¹Œì§€ ì˜¤ì‹œëŠë¼ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤ ë ˆê·¸ì˜ ì „ë°˜ì ì¸ ë‚´ìš©ì„ ë¨¼ì € í•œë²ˆ ë“¤ì–´ë³´ì‹œê³ ìš” ê·¸ë¦¬ê³  ì˜ ì´í•´ê°€ ì•ˆë˜ë©´ ë˜ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹¤ ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹œê³  ê·¸ë¦¬ê³  ë” ì¤‘ìš”í•œ ê±°ëŠ” ì´ ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ì—¬ëŸ¬ë¶„ë“¤ì´ ë°˜ë³µí•´ì„œ ë³´ì‹œë©´ì„œ ê³„ì† ë ˆê·¸ì— ëŒ€í•œ í”„ë¡œì„¸ìŠ¤ ì´í•´ê°€ ìˆì–´ì•¼ ê·¸ ë‹¤ìŒì— ë‹¤ì‹œ ì—­ìœ¼ë¡œ ëŒì•„ê°€ì„œ ìš°ë¦¬ê°€ ì´ëŸ° ê²ƒë“¤ì„ ì‚´í´ë³¼ ê±°ì—ìš” ì•„í”„íŒŒì„œë‘ ëª¨ë¸ ë©”ëª¨ë¦¬ ì²´ì¸ë“¤ ì´ëŸ° ê²ƒë“¤ì„ ì­‰ ì‚´í´ë³¼ ë•Œ ì—­ìœ¼ë¡œ ë” ì´í•´ê°€ ì˜ ë˜ì‹¤ ê±°ë¼ëŠ” ìƒê°ì´ ë“¤ë”ë¼êµ¬ìš”\"}, {\"start\": 30.0, \"end\": 42.5, \"text\": \" ìš°ë¦¬ê°€ ì—¬ê¸° ì²˜ìŒë¶€í„° ë‹¤ í•˜ê³  ê°€ë ¤ë©´ ë„ˆë¬´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë‹ˆê¹Œ ì´ë²ˆ ì‹œê°„ì—ëŠ” ë ˆê·¸ë¥¼ ì¢€ ê¹Šê²Œ ë‹¤ë¤„ë³´ê¸° ë³´ë‹¤ëŠ” ì¼ë‹¨ì€ ë ˆê·¸ê°€ ë­”ì§€ ê·¸ë¦¬ê³  ì–´ë–¤ ì‹ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ”ì§€ ëŒ€ì¶© ê°ì„ ì¡ëŠ”ë‹¤ ê·¸ëŸ° ìƒê°ìœ¼ë¡œ ì˜¤ì‹œë©´ ë©ë‹ˆë‹¤.\"}, {\"start\": 43.21, \"end\": 60.03, \"text\": \" ì €í¬ê°€ ë¨¼ì € ì—¬ê¸° ë ˆê·¸ì˜ ë² ì´ì‹, ì´ ì •ë„ ìˆ˜ì¤€ì—ì„œ ë¨¼ì € ë³¼ ê±´ë°ìš”. ë¨¼ì € ê·¸ëŸ¬ë ¤ë©´ì€ ìš°ë¦¬ê°€ ë ˆê·¸ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•  ê²ƒ ê°™ì•„ìš”. ê·¸ë˜ì„œ ì œê°€ ì¢€ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë ¤ì™”ì–´ìš”. ì œê°€ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë¦¬ëŠ” ê±¸ ë˜ê²Œ ì¢‹ì•„í•˜ëŠ”ë° ì´ ë ˆê·¸ë¼ëŠ” ê±¸ ë„ëŒ€ì²´ ì™œ ì“°ëŠëƒ, ìš°ë¦¬ê°€ ê·¸ ê°•ì˜ ì´ˆë°˜ì—ë„ ë§ì”€ë“œë ¸ì–ì•„ìš”.\"}, {\"start\": 60.0, \"end\": 74.72, \"text\": \" ë ˆê·¸ë¥¼ ì“°ëŠ” ëª©ì ì— ëŒ€í•´ì„œ ë‹¤ì‹œ í•œ ë²ˆë§Œ ì§šê³  ë„˜ì–´ê°€ ë³¼ê²Œìš”. ìš°ë¦¬ê°€ ë ˆê·¸ë¥¼ ì•ˆ ì“°ê³  ì±„ì° PT ê°™ì€ ê±¸ í†µí•´ì„œ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì±„ì° PTì—ì„œ ì“°ëŠ” ê±°ëŠ” ì´ëŸ° ë°©ì‹ì´ê±°ë“ ìš”. ì—¬ê¸°ì— ì—¬ëŸ¬ë¶„ë“¤ì´ ì´ëŸ¬í•œ í€˜ì…˜ë“¤ì„ ë„£ì–´ì¤˜ìš”.\"}, {\"start\": 76.47, \"end\": 89.55, \"text\": \" í”„ë¡¬í”„íŠ¸ë¡œ ë“¤ì–´ê°€ì£ . ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì´ëŸ° ê²ƒë“¤ì´ ë“¤ì–´ê°€ê³ ìš”. ê·¸ ë‹¤ìŒì— ì¢€ ë” í™•ëŒ€í•´ì„œ ë³´ì—¬ë“œë¦¬ë©´ ì´ë ‡ê²Œ ë“¤ì–´ê°€ì£ . ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë‹µë³€ì„ í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸.\"}, {\"start\": 90.82, \"end\": 117.02, \"text\": \" ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì—¬ê¸° ë“¤ì–´ì™€ìš”. ê·¸ëŸ¬ë©´ ìš°ë¦¬ê°€ ìŠ¤íŠ¸ë¦¬ë°‹ìœ¼ë¡œ êµ¬í˜„í•œ ê²ƒì²˜ëŸ¼ ìš”ê±°ì— ëŒ€í•´ì„œ í”„ë¡¬í”„íŠ¸ ì™„ì„±ì„ í•´ì„œ ê²°êµ­ì—ëŠ” ì´ LLMí•œí…Œ ì „ë‹¬ì´ ëœë‹¤ëŠ” ê±°ì˜ˆìš”. ìš°ë¦¬ê°€ ê·¸ê±¸ GPTë¥¼ ì“¸ ìˆ˜ë„ ìˆê³  ì•„ë‹ˆë©´ ë­ í´ë¡œë“œë¼ëŠ” ëª¨ë¸ì„ ì“¸ ìˆ˜ë„ ìˆê³  ë¼ë§ˆ3ë¼ëŠ” ì˜¤í”ˆëª¨ë¸ì„ ì“¸ ìˆ˜ë„ ìˆê³ ìš”. ì–´ì¨Œë“  ì´ê±¸ ë„£ì–´ì„œ ìš°ë¦¬ê°€ ì–»ëŠ” ë‹µë³€ì€ ë­ëƒë©´ ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ AIì˜ ì´ë¦„ì€ ìš”ê±°ëŠ” ì œê°€ ì±„ì°PTí•œí…Œ ë¬¼ì–´ë³¸ ê±°ê±°ë“ ìš”. ë‹µë³€ì„ ì´ì œ ì´ëŸ° ì‹ìœ¼ë¡œ ì¤€ë‹¤ëŠ” ê±°ì˜ˆìš”.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = [script[\"text\"] for script in scripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\",torch_dtype=torch.bfloat16,device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë” ëª…í™•í•œ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt_template = \"\"\"ì´ ë¬¸ì„œì˜ ì˜¤íƒˆìì™€ ì–´ìƒ‰í•œ í‘œí˜„ì„ ì „ë¬¸ êµì •ìì˜ ì…ì¥ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ì‚¬í•­ì„ ì¤‘ì ì ìœ¼ë¡œ ê²€í† í•´ì£¼ì„¸ìš”:\n",
    "1. ë¬¸ë§¥ì— ë§ì§€ ì•ŠëŠ” ë‹¨ì–´ë¥¼ ìˆ˜ì •\n",
    "2. ì˜ì–´ ë°œìŒì€ ì•ŒíŒŒë²³ìœ¼ë¡œ ë³€ê²½\n",
    "3. ê¸°ìˆ ì ì¸ ìš©ì–´ëŠ” ì›ì–´ë¡œ ë³€ê²½\n",
    "4. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•˜ì§€ ë§ ê²ƒ\n",
    "\n",
    "ì›ë¬¸: {prompt}\n",
    "\n",
    "êµì • ê²°ê³¼:\"\"\"\n",
    "\n",
    "# ì…ë ¥ í…ì„œ ìƒì„± ë° GPU ì´ë™\n",
    "text = scripts[0]\n",
    "model_inputs = tokenizer(prompt_template.format(prompt=text), return_tensors=\"pt\")\n",
    "model_inputs = {k: v.to(\"cuda\") for k, v in model_inputs.items()}\n",
    "\n",
    "# ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 0.7,        # ì°½ì˜ì„± ì¡°ì ˆ (0.0-1.0)\n",
    "    \"top_p\": 0.9,             # nucleus sampling\n",
    "    \"do_sample\": True,        # ë‹¤ì–‘í•œ ì¶œë ¥ì„ ìœ„í•´ ìƒ˜í”Œë§ ì‚¬ìš©\n",
    "    \"num_return_sequences\": 1, # ìƒì„±í•  ê²°ê³¼ ìˆ˜\n",
    "    \"top_k\": 50,              # top-k sampling\n",
    "    \"repetition_penalty\": 1.2, # ë°˜ë³µ ë°©ì§€\n",
    "    \"no_repeat_ngram_size\": 3  # n-gram ë°˜ë³µ ë°©ì§€\n",
    "}\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìƒì„±\n",
    "outputs = model.generate(**model_inputs, **generation_config)\n",
    "\n",
    "# ê²°ê³¼ ë””ì½”ë”©\n",
    "output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "# ì›ë³¸ê³¼ êµì •ë³¸ ë¹„êµ ì¶œë ¥\n",
    "print(\"=== ì›ë³¸ ===\")\n",
    "print(text)\n",
    "print(\"\\n=== êµì •ë³¸ ===\")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "import json\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "youtube_cookies = os.getenv(\"YOUTUBE_COOKIES\")\n",
    "\n",
    "cookie_data = base64.b64decode(youtube_cookies).decode(\"utf-8\")\n",
    "\n",
    "# ì¿ í‚¤ê°€ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  Netscape í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "json_cookies = json.loads(cookie_data)\n",
    "\n",
    "# Netscape í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "netscape_cookies = \"# Netscape HTTP Cookie File\\n\"\n",
    "for cookie in json_cookies:\n",
    "    if (\n",
    "        \"domain\" in cookie\n",
    "        and \"path\" in cookie\n",
    "        and \"name\" in cookie\n",
    "        and \"value\" in cookie\n",
    "    ):\n",
    "        secure = \"TRUE\" if cookie.get(\"secure\", False) else \"FALSE\"\n",
    "        http_only = (\n",
    "            \"TRUE\" if cookie.get(\"httpOnly\", False) else \"FALSE\"\n",
    "        )\n",
    "        expires = str(int(cookie.get(\"expirationDate\", 0)))\n",
    "        netscape_cookies += f\"{cookie['domain']}\\tTRUE\\t{cookie['path']}\\t{secure}\\t{expires}\\t{cookie['name']}\\t{cookie['value']}\\n\"\n",
    "\n",
    "cookie_data = netscape_cookies\n",
    "\n",
    "ydl_opts = {\n",
    "\"quiet\": True,\n",
    "\"no_warnings\": True,\n",
    "\"extract_flat\": True,  # ê¸°ë³¸ ì •ë³´ë§Œ ì¶”ì¶œí•˜ë„ë¡ ë³€ê²½\n",
    "\"nocheckcertificate\": True,\n",
    "\"ignoreerrors\": True,\n",
    "\"no_color\": True,\n",
    "\"socket_timeout\": 30,  # ì†Œì¼“ íƒ€ì„ì•„ì›ƒ ì„¤ì •\n",
    "\"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "\"cookiefile\": cookie_data\n",
    "}\n",
    "\n",
    "ydl = YoutubeDL(ydl_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://youtu.be/VKIl0TIDKQg?si=2p-s_Fd_ww2C9oJ2\"\n",
    "info = ydl.extract_info(url, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_url ì¶”ì¶œ ë° ì €ì¥\n",
    "audio_url = None\n",
    "for i in info.get(\"requested_formats\"):\n",
    "    if i.get(\"vcodec\") == \"none\":\n",
    "        audio_url = i.get(\"url\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
    "\n",
    "\n",
    "model = WhisperModel(\n",
    "    \"large-v3\", device=\"cuda\", compute_type=\"bfloat16\"\n",
    ")\n",
    "model = BatchedInferencePipeline(model=model)  # ë°°ì¹˜ ëª¨ë¸ì¼ ê²½ìš°\n",
    "print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "segments, info = model.transcribe(\n",
    "    audio_url,\n",
    "    batch_size=32,  # ë°°ì¹˜ ëª¨ë¸ì¸ ê²½ìš°\n",
    "    repetition_penalty=1.5,\n",
    "    beam_size=10,\n",
    "    patience=2,\n",
    "    no_repeat_ngram_size=4,\n",
    "    initial_prompt=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_segments = [\n",
    "    {\"start\": segment.start, \"end\": segment.end, \"text\": segment.text}\n",
    "    for segment in segments\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0.0,\n",
       "  'end': 15.936,\n",
       "  'text': ' ë„¤ ì•ˆë…•í•˜ì„¸ìš” ë“œë””ì–´ ê¸°ë‹¤ë¦¬ê³  ê¸°ë‹¤ë¦¬ë˜ mcp í•œë²ˆ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. MCP ìš”ì¦˜ ì •ë§ í•«í•œ ê²ƒ ê°™ì•„ìš” ì €ë„ ìµœê·¼ì— ì‚¬ì‹¤ MCP ê´€ë ¨ëœ ì˜ìƒë“¤ë„ ë§ì´ ì°¸ê³ í•´ë³´ê³  ì €í¬ ìì²´ì ìœ¼ë¡œ ë„ íŒ€ ë‚´ë¶€ì—ì„œ'},\n",
       " {'start': 15.936,\n",
       "  'end': 32.688,\n",
       "  'text': ' ë§ì€ í…ŒìŠ¤íŠ¸ì™€ ì‹¤í—˜ì„ í–ˆì—ˆìŠµë‹ˆë‹¤. ì¼ë‹¨ ê²°ë¡ ì€ ì•ìœ¼ë¡œ MCPê°€ ëŒ€ì„¸ ê°€ ë  ê²ƒì„ì—ëŠ” ì´ê²¬ì´ ì—†ìŠµë‹ˆë‹¤ í•˜ë‚˜ì˜ íŒ ì„ ë’¤í”ë“œëŠ” ê·¸ëŸ° í‚¤ ì—­í• ì„ í•˜ê²Œë ê²ƒì´ë¼ê³  ìƒê°ì´ ë“œëŠ”ë°ìš”, mcpì— ëŒ€í•´ì„œ ì˜ ì•„ì‹œëŠ” ë¶„ë“¤ë„ ê³„ì‹œê³  ì˜ ëª¨ë¥´ì‹œëŠ”ë¶„ë“¤ ë„ê³„ì‹¤ê²ë‹ˆë‹¤.'},\n",
       " {'start': 32.688,\n",
       "  'end': 62.016,\n",
       "  'text': ' ì´ê²Œ ê¶ê¸ˆí•˜ì‹  ë¶„ë“¤ë„ ì•„ë§ˆ ê³„ì‹¤ ê±°ì˜ˆìš”. ê·¸ë˜ì„œ ì˜¤ëŠ˜ì€ ì´ MCPì— ëŒ€í•´ì„œ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…ì„ ë“œë¦¬ê³ ìš”, MCPê°€ ì™œ ìµœê·¼ì˜ ì¸ê¸°ê°€ ìˆëŠ”ì§€ ê·¸ë¦¬ê³  ì œê°€ ìƒê°í•˜ê¸°ì— ì•ìœ¼ë¡œ ì™œ mcp ê°€ ëŒ€ì œê°€ ë  ê²ƒ ê°™ì€ ì§€ ê·¸ê±¸ ì •ë¦¬í•´ì„œ ì„¤ëª…ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ ì ë¨¼ì € ì—¬ê¸°ì— ë³´ì‹œë©´ì€ MCP Introducing the Model Context Protocol ì´ë¼ê³  í•´ì„œ 2024ë…„ë„ 11ì›” 26ì¼ë‚  MCPê°€ ë‚˜ì˜¤ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ MCP ë¼ëŠ” ê²ƒì€ ë‹¤ë¥¸ ì˜ìƒì—ì„œë„ ë‚´ìš©ë“¤ì„ ë³´ì‹  ë¶„ë“¤ì€ ì˜ ì•„ì‹¤ ê±°ì—ìš” ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œ ì…ë‹ˆë‹¤'},\n",
       " {'start': 62.016,\n",
       "  'end': 86.288,\n",
       "  'text': ' ì—¬ê¸°ì„œ í•µì‹¬ì€ í”„ë¡œí† ì½œì´ë¼ê³  ë³¼ ìˆ˜ê°€ ìˆëŠ”ë°ìš”. í•œë§ˆë””ë¡œ í”„ë¡œí† ì»¬ ì€ ê·€ì´ì•½ ê°™ì€ ê²ë‹ˆë‹¤ ë­”ê°€ ì•½ì†ê³¼ ê°™ì´ ë³´ì‹œë©´ ë˜ìš” ê·¸ë˜ì„œ ëŒ€í‘œì ì¸ê²Œ ë­ hdp í†µì‹ ì´ë‚˜ ì•„ë‹ˆë©´ api ì´ëŸ° ê²ƒë“¤ì„ ë§ì´ ì–¸ê¸‰ë˜ê³  ìˆìŠµë‹ˆë‹¤ ì œê°€ ì£¼ëª©í•œ ê±´ ì´ê±°ì˜€ì–´ìš” mc p ê°€ 11ì›” 26ì¼ ì‘ë…„ì— ë‚˜ì™”ê±°ë“ ìš” ê·¸ëŸ°ë° ìš”ì¦˜ì˜ ai ì‹œëŒ€ì—ì„œëŠ” ë¬´ì–¸ê°€ ìƒˆë¡­ ê²Œ ë‚˜ì˜¤ë©´ ë‹¹ì¼ë‚  ì—„ì²­ë‚˜ê²Œ ë§ì€ ê´€ì‹¬ì´ ëª°ë ¤ìš”'},\n",
       " {'start': 86.288,\n",
       "  'end': 115.6,\n",
       "  'text': ' 11ì›” 26ì¼ë‚  ë‚˜ì™”ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì™œ ë„ëŒ€ì²´ ì§€ê¸ˆ ì¸ê¸°ì¸ê°€ ì´ê²Œ ì•„ë§ˆ ê¶ê¸ˆí•˜ì‹  ë¶„ë“¤ë„ ê³„ì‹¤ ìˆ˜ê°€ ìˆì„ ê²ƒ ê°™ì•„ìš” ê·¸ë˜ì„œ ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œë„ ê°™ì´ í•œë²ˆ ì„¤ëª…ì„ ë“œë¦¬ë„ë¡ í• ê²Œìš” ì ë¨¼ì € MCP ì— ëŒ€í•´ì„œ ì‚´í´ë³´ê¸° ì „ì—ìš” ì´ agent ì˜ êµ¬ì¡°ì— ëŒ€í•´ ë¨¼ì € ì‚´í´ ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì,ì´ Agentì˜ êµ¬ì¡°ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ë³´ë©´ì€ ì—¬ê¸°ì—ì„œ LLMì´ í•µì‹¬ ì—­í• ì¼ í•˜ê³ ìš” LLM ì€ ìš°ë¦¬ê°€ GPTë¥¼ ì‚¬ìš© í•  ìˆ˜ë„ ìˆê³  ë­ í´ë¡œë“œë¥¼ ì‚¬ìš©í• ìˆ˜ë„ìˆê³  ì¬ë¯¸ë‚˜ì´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê² ì£  ê·¸ë¦¬ê³  ì´ agent ê°€ ì¢‹ì€ ì  ì¤‘ì— í•˜ë‚˜ê°€ ë°”ë¡œ ì—¬ê¸°ì— ë‚˜ì™€ìˆëŠ” ì™¸ë¶€ íˆ¬ë¥¼ ì“¸ìˆ˜ ìˆë‹¤ëŠ” ê²ë‹ˆë‹¤ ê·¸ëŸ¬ë‹ˆê¹Œ ê¸°ì¡´ì˜ llm ì—ì„œ'},\n",
       " {'start': 115.6,\n",
       "  'end': 120.56,\n",
       "  'text': ' ëŠ¥ë ¥ í™•ì¥ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê±°ì£ . ê·¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ Reactë¼ëŠ” í”„ë ˆì„ì›Œí¬ ë•ë¶„ì— ì–˜ê°€'},\n",
       " {'start': 120.56,\n",
       "  'end': 149.872,\n",
       "  'text': ' Thought, Action, Observation ê³¼ì •ì„ ë£¨í•‘ì„ í•˜ë©´ì„œ ë¬¸ì œ í•´ê²°ì„ ìŠ¤ìŠ¤ë¡œ í•´ê²°ë‚˜ê°„ë‹¤. ì´ëŸ° ê²ƒë“¤ë„ ì—ì´ì „íŠ¸ì˜ í° ì¥ì ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ í¬ê²Œ ì •ë¦¬í•˜ìë©´ ì—ì´ì „ë“œì— í°ì¥ ì ì€ ì™¸ë¶€ íˆ´ ì„ ì‚¬ìš©í• ìˆ˜ ìˆë‹¤ì™€ ê·¸ ë‹¤ìŒì— React í”„ë ˆì„ì›Œí¬ë¼ê³  ë³¼ ìˆ˜ê°€ ìˆëŠ”ë°ìš” ì—¬ê¸°ì—ì„œ ë°”ë¡œ MCP ì˜ ì—­í•  ì€ ì–´ëŠ ë¶€ë¶„ì„ ë‹´ë‹¹ í•˜ëƒë©´ ì—¬ê¸°ì— ë‚˜ì™€ìˆëŠ” ì´ Toolë¶€ë¶„ì„ ë‹® ë‹¹í•œë‹¤ê³  ë³¼ìˆ˜ê°€ìˆìŠµë‹ˆë‹¤ ë¬¼ë¡  mcp ì—ë„ ë­ promptë‚˜ ë¦¬ì†ŒìŠ¤ ë“±ì„ ì‚¬ìš© í•  ìˆ˜ê°€ ìˆëŠ”ë° ìš” ì‚¬ì‹¤ ì œê°€ ë´¤ì„ ë•ŒëŠ” ê·¸ê²Œ ë©”ì¸ì€ ì•„ë‹ˆë¼ ê³  ìƒê°ì´ ë“¤ì–´ìš”'},\n",
       " {'start': 149.872, 'end': 151.312, 'text': ' ì´ê²Œ êµ‰ì¥íˆ ë§¤ë ¥ì ì¸'},\n",
       " {'start': 151.312,\n",
       "  'end': 180.624,\n",
       "  'text': ' í¬ì¸íŠ¸ë¼ê³  ìƒê°ì´ ë“­ë‹ˆë‹¤ ì ì´ê²Œ ë¬´ìŠ¨ ë§ì¸ì§€ ì¡°ê¸ˆ ë” ì‚´í´ë³´ë„ë¡ í• ê²Œìš” ë§Œì•½ì— ìš°ë¦¬ê°€ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“ ë‹¤ ë¼ê³  í–ˆì„ ë•Œ ëœ ì²´ì¸ì´ë‚˜ ë§¹ ê·¸ë˜í”„ë¡œ ì˜ ì „íˆ¬ë¥¼ ë§Œë“¤ì–´ìš” ê·¸ëŸ¬ë©´ ëƒ‰ì²´ ì¸ ì•ˆì— ìˆëŠ” ì–´ë–¤ ì½”ë“œë¥¼ ê°€ì§€ê³  ë‚¸ ì±„ ë‚œì˜ integration ë˜ì–´ ìˆëŠ” íˆ´ ë“¤ì„ ê²°í•© ì„ ì‹œì¼œì„œ ë¦¬ì•¡íŠ¸ í”„ë ˆì„ì›Œí¬ ëŠ” ë‚´ì¥ì´ ë˜ì–´ìˆê±°ë“ ìš” ê·¸ë˜ì„œ agent ë¼ëŠ” ê±¸ ë§Œë“­ë‹ˆ ë‹¤ ì˜¤ë¦¬ê°„ ì•µ ì²´ì•¤ í• ì•¤ë“œ ì•ìœ¼ë¡œ ì• ì • ë˜ ë§Œë“¤ì–´ ì„œ ë‹¤ì–‘í•œ ë­ ê·¸ í”Œë¡œìš°ë¥¼ êµ¬ì„±í•œë‹¤ ì•Œì§€ ì•„ë‹ˆë©´ ë¬¸ì œ í•´ê²°í–ˆì„ë•Œ í”„ë¡œê·¸ë˜ë° ì ìœ¼ë¡œ í•´ê²°ë  ìˆ˜ê°€ ìˆë‹¤ëŠ” ê±° ê±°ë“ ìš” ê·¼ë° ì´ ì—˜ì „ íŠ¸ë¼ëŠ” ê²ƒì€ ë¬¼ë¡  2025 ë…„ë„ì— ëŒ€ì„¸ë¼ ê³  í•˜ì§€ë§Œ êµ‰ì¥íˆ'},\n",
       " {'start': 180.624,\n",
       "  'end': 206.144,\n",
       "  'text': ' ìƒˆë¡œìš´ ê°œë…ì€ ì•„ë‹ˆì—ìš” ì´ë¯¸ ì‘ë…„ë¶€í„° ì•Œê³  ìˆì—ˆë˜ ë‚´ìš©ì´ë¼ëŠ” ê±°ì£  ì ê·¼ë° ì œê°€ ì•„ê¹Œ ë§ì”€ë“œë ¸ë‹¤ì‹œí”¼ mcp ê°€ ì´ íˆ´ ì—­í• ì„ ëŒ€ì²´í•œë‹¤ê³  í–ˆëŠ”ë° ì´ê²Œ ì™œ ë„ëŒ€ì²´ ìš”ì¦˜ì— êµ‰ì¥íˆ ê´€ì‹¬ì´ ì¼ìœ¼í‚¤ê³  ìˆëŠ”ì§€ ê·¸ ë¶€ë¶„ì—ì„œ ì¢€ ë” ì‚´í´ë³¼ í•„ìš”ê°€ ìˆì–´ìš” ì—¬ê¸° êµ¬ê¸€ íŠ¸ë Œë“œ ë³´ì‹œë©´ìš” ìµœê·¼ì˜ ì¸ê¸°ê°€ ì˜¬ë¼ì˜¤ëŠ”ë° MCP ë‚˜ì˜¨ ì‹œì ì´ í•œ ìš” ì •ë„ ë˜ê±°ë“ ìš” ê·¸ëŸ°ë° ì—”ì”¨ í”¼ê°€ ë‚˜ì˜¤ ë‚˜ì„œ ì¸ê¸° ì—„ì²­ ë§ì•˜ëŠëƒ ê·¸ê²Œ ì•„ë‹Œ ê±°ì˜ˆìš” ê·¸ëƒ¥ ê·¸ëŸ­ì €ëŸ­ í–ˆìŠµë‹ˆë‹¤ ê·¸ëŸ¬ë‹¤ê°€ ì–´ëŠ ì‹œì ë¶€í„°'},\n",
       " {'start': 206.144,\n",
       "  'end': 218.24,\n",
       "  'text': ' ê°‘ìê¸° ì´ ê³¡ì„  ë³´ì´ì‹œì£ ? ë§ˆì¹˜ ìƒí•œê°€ ê°€ë“¯ì´ ê°‘ìê¸° ë›°ì–´ì˜¤ë¥´ëŠ” ì‹œê¸°ê°€ ìˆëŠ”ë°ìš”. ì´ ì‹œê¸°ì— ì£¼ëª©í•´ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤ ì, ì´ì‹ì´ê°€ ì–¸ì œì¯¤ ë˜ëƒë©´ ë°”ë¡œ Cursor AIì˜ MCP ì—…ë°ì´íŠ¸ ë˜ëŠ”ì‹œì  2ì›” 19ì¼ ì •ë„ ë¼ìš”'},\n",
       " {'start': 218.24,\n",
       "  'end': 247.536,\n",
       "  'text': ' 2ì›” 19ì¼ ì •ë„ë©´ ëŒ€ëµì ìœ¼ë¡œ í•œ 20ì ì¯¤ ë˜ê±°ë“ ìš”. ê·¸ëŸ¬ë©´ ì»¬ì„œ AIê°€ MCP ì—…ë°ì´íŠ¸ ë˜ëŠ” ê²Œ ì™œ MCPì˜ ì¸ê¸°ë¥¼ ë¶ˆëŸ¬ì™”ëŠ”ê°€ ì—¬ê¸°ì— ì£¼ëª©í•´ ë³¼ í•„ìš”ê°€ ìˆë‹¤ëŠ” ê±°ì£ . ì»¬ì„œ ai ê°€ mcp ì—… ë°ì´íŠ¸ë˜ëŠ” ê²ƒê³¼ ìµœê·¼ì— ì— ì”¨í”¼ê°€ ì™œ ì´ë ‡ê²Œ ì¸ê¸°ê°€ ë§ê²Œ ëëŠ”ì§€ ê·¸ê±°ë¥¼ ì´ì œ ì—°ê´€ ì§€ì–´ì„œ í•œë²ˆ ìƒê°í•´ë³¼ê²Œìš” ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ ëŒì•„ì™€ ì„œ ì²˜ìŒì—” c p ê°€ ë‚˜ì˜¤ê³  ë‚˜ì„œ MCP ë„ëŒ€ì²´ ë­ê¸¸ë˜ í•˜ê³  ì¢€ ì‚´í´ë´¤ì–´ìš” ê·¼ë° ì œê°€ ì•„ê¹Œë„ ë§ì”€ë“œë ¸ë‹¤ì‹œ í”¼ ì—¬ëŸ¬ê°€ì§€ ë¶€ê° ê¸°ëŠ¥ë“¤ì´ ìˆì§€ë§Œ ê°€ì¥'},\n",
       " {'start': 247.536,\n",
       "  'end': 265.136,\n",
       "  'text': ' ì—­í• ì„ í•´ì¤€ë‹¤ë¼ëŠ” ê±°ê±°ë“ ìš”. ê·¸ëŸ°ë° ì´ íˆ´ ì—­í™œì„ í•´ì¤€ë‹¤ëŠ” ê²Œ ì €ëŠ” ì™œ ë„ëŒ€ì²´ ì´ê²Œ ìƒˆë¡œìš´ ê±°ì§€? ì‚¬ëŒë“¤ì´ ì´ë ‡ê²Œ ì—´ê´‘í•˜ëŠ”ê±°ì§€ ë¼ëŠ” ì˜ë¬¸ì  ì„ ê°€ì§€ê²Œ ë˜ì—ˆì–´ìš” ê·¸ëŸ¬ë‹ˆê¹Œ ì €ì˜ ì…ì¥ì—ì„œëŠ” ë­ ì²´ì¸ì´ë‚˜ ì•„ë‹ˆë©´ ë¨ ê·¸ë˜í”„ë‚˜ ì´ê±¸ë¡œ ì´ë¯¸ ì¸í…Œê·¸ë ˆì´ì…˜ ë˜ì–´ ìˆëŠ” íˆ´ì‚¬ìš©í•´ì„œ ì—ì´ì „íŠ¸ ë§ì´ ë§Œë“¤ ìˆ˜ ìˆê±°ë“ ìš”'},\n",
       " {'start': 265.136,\n",
       "  'end': 293.008,\n",
       "  'text': ' ë­ì²´ì¸ì— ì¸í…Œê·¸ë ˆì´ì…˜ ë˜ì–´ ìˆëŠ” íˆ´ì„ í•œë²ˆ ë³´ì—¬ë“œë¦´ê²Œìš”. ë  ì²´ì¸ì„ ê°€ë³´ì‹œë©´ì€, íˆ´ë“¤ì´ ì´ë ‡ê²Œë‚˜ ë§ìŠµë‹ˆë‹¤ ì—¬ê¸°ì— Rangchain Toolsë¥¼ í´ë¦­í•´ë³¼ê²Œìš” ì—¬ê¸° ë³´ì‹œë©´ ì„œì¹˜íˆ´ìœ¼ë¡œ ì½”ë“œ ì¸í„°ë¸Œë¦¬í„°ê°€ ìˆê³  Productivity ì›¹ë¸”ë¼ìš°ì§• ë°ì´í„°ë² ì´ìŠ¤ ê·¸ ë‹¤ìŒì— ì´ë ‡ê²Œ ë§ì€ í„¸ë“¤ë¡œ ì¸í…Œë¼ë¥¼ ì´ë¯¸ ë˜ì–´ìˆì–´ìš” ì—¬ê¸°ì„œëŠ” ì´ì œ ë§ì€ ì‚¬ëŒë“¤ì´ ìš”ì¦˜ MCP í™œìš©í•´ì„œ ì‚¬ìš©ê¸°ì— ìì£¼ ë“±ì¥í•˜ëŠ” íŒŒì¼ ì‹œìŠ¤í…œë“¤ì„ ê±´ë“œë¦°ë‹¤ë“ ì§€ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìƒì‚°ì„± ê´€ë ¨ íˆ¬ë‘ ì—°ê´€ ì§€ì–´ì„œ ë§Œë“¤ì–´ ë³¼ ìˆ˜ìˆëŠ” ê²ƒë“¤ ì´ëŸ°ê²ƒë“¤ì„ ê°€ì§€ê³ '},\n",
       " {'start': 293.008,\n",
       "  'end': 317.168,\n",
       "  'text': ' ë‹¤ì–‘í•œ ì˜ˆì œë“¤ì„ ìŸì•„ë‚´ê³  ìˆëŠ”ë° ì‚¬ì‹¤ ì œê°€ ë´¤ì„ ë•ŒëŠ” ì–´ ì´ê²Œ ì™œ ìƒˆë¡œìš´ ê±°ì§€ ë¼ëŠ” ìƒê°ì„ í–ˆì—ˆë˜ ê±°ì£  ì ê·¸ëŸ°ë° ì œê°€ ì˜ëª» ìƒê°í•œ ë¶€ë¶„ì´ í•˜ë‚˜ ìˆë”ë¼êµ¬ìš” ì €ì˜ ê²½ìš°ì—ëŠ” ë­ì²´ì¸ì´ë‚˜ ë¨ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ëŠ” ì†Œìˆ˜ì— ì‚¬ëŒì´ë¼ëŠ”ê±°ì£  ì´ ë  ì²´ì¸ë‘ ê·¸ë˜í”„ ë¥¼ ì‚¬ìš©í•´ì„œ 2 íˆ´ë“¤ì˜ ì¸í…Œê·¸ë ˆì´ì…˜ ì¨ì„œ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì‚¬ëŒë“¤ì€ ì¼ë¶€ ê°œë°œì ì¼ ê²ƒì´ì—ìš”'},\n",
       " {'start': 317.168,\n",
       "  'end': 347.04,\n",
       "  'text': ' ê³µê°œê°€ ëë‹¤ëŠ” ì ì´ì£ . ì´ MCPë¼ëŠ” íˆ´ì´ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì“¸ ìˆ˜ ìˆë„ë¡ ì™¸ë¶€ ë§ˆì¼“í”Œë ˆì´ìŠ¤ ê°™ì€ ê³³ì— ë“±ì¬ê°€ ë˜ì—ˆë‹¤ í•˜ë”ë¼ë„ìš” ì—¬ê¸°ì— ë³´ì‹œëŠ” ê²ƒì²˜ëŸ¼ ì´ë ‡ê²Œ ì•„ë¬´ëŸ° ê´€ì‹¬ì„ ë°›ì§€ ëª»í–ˆë‹¤ë€ ê±°ì£  ì¦‰ ì´ê±´ ì–´ë–»ê²Œ í•´ì„í•´ ë³¼ ìˆ˜ê°€ ìˆëŠëƒ í•˜ë©´ ìš°ë¦¬ê°€ ëˆ„êµ¬ë‚˜ ì“°ì¼ìˆ˜ìˆë„ë¡ ì—¬ê¸°ì„œ ëˆ„êµ°í•˜ë¼ê³  í•˜ëŠ”ê±´ ë­ëƒë©´ ë­ì²´ì¸ì´ë‚˜ ë Œê·¸ë˜í”„ì™€ê°™ì€ ê°œë°œ í”„ë ˆì„ì›Œí¬ì˜ ì¢…ì†ì ì´ì§€ ì•Šê¸°ì— ì™„ì „íˆ ë…ë¦½ì ì¸ íˆ¬ë¥¼ ì™¸ë¶€ë¡œ ê³µê°œë˜ì—ˆë‹¤ê³  í•´ë„ ê·¸ë˜ë„ ê·¸ë ‡ê²Œ ê´€ì‹¬ë„ ëª»ë°›ìœ¼ì‹¤ìˆ˜ê°€ ìˆëŠ”ê±°ì—ìš” ê·¸ë˜ì„œ ì—¬ê¸°ì—ì„œ ê´€ë¦¬í• ìˆ˜ë°–ì— ì—†ëŠ” ì´ìœ ê°€ ìˆì£ '},\n",
       " {'start': 347.04,\n",
       "  'end': 373.616,\n",
       "  'text': ' ì´ íˆ´ì„ ë°›ì•„ì¤„ ìˆ˜ ìˆëŠ” LLMê³¼ ë¦¬ì•¡íŠ¸ í”„ë ˆì„ì›Œí¬ ì´ê±¸ êµ¬ë™í• ìˆ˜ìˆëŠ” ì–´ë–¤ ëª¸ì²´ê°€ ì—†ëŠ”ê±°ì—ìš” ë§ê·¸ëŒ€ë¡œ ì†ë°œë§Œì´ ìˆëŠ” ê±°ê³  ë¨¸ë¦¬ì™€ ëª¸ì´ì—†ëŠ” ìƒí™©ì¸ ê±°ì£  ê·¸ëŸ¬ë‹ˆê¹Œ ì‚¬ìš©ìë¡œë¶€í„° ì•„ë¬´ëŸ° ê´€ì‹¬ ë°›ì§€ ëª»í–ˆì–´ìš” ì™œëƒë©´,ì‚¬ìš©ì²˜ ìì²´ ì—†ë‹¤ ë³´ë‹ˆê¹Œ ê·¸ëŸ°ë° Cursor AIê°€ í˜œì„±ì²˜ëŸ¼ ë“±ì¥í•´ì„œ ì˜ì›…ì˜ ì—­í™œí•˜ê²Œ ë˜ëŠ”ê²ƒì´ì£  MCP ì—…ë°ì´íŠ¸ í•´ì£¼ë©´ì„œ ì´ LRm ê³¼ ê·¸ ë‹¤ìŒì— ëª¸ì²´ì—­ì°°ê¹Œì§€ ë‹¤ í•´ì¤€ ê±°ì˜ˆìš” í•œë§ˆë””ë¡œ ì—¬ê¸° ë¶€ë¶„ ìˆì£ ? ìš”ë¶€ë¶„'},\n",
       " {'start': 373.616,\n",
       "  'end': 398.768,\n",
       "  'text': ' ì´ ë¶€ë¶„ì´ Cursor AIê°€ ë‹´ë‹¹ì„ í•˜ê²Œ ë˜ëŠ” ê±°ê³  MCPì˜ íˆ´ë“¤ì´ ì—­í• ì„ í•˜ëŠ” ê±°ì˜ˆìš”. ì´ê±° ë‘ ê°œë¥¼ ê²°í•©í•˜ë©´ ë‚´ê°€ ì½”ë”©í•˜ì§€ ëª»í•˜ë”ë¼ë„ ëˆ„êµ¬ë‚˜ ì“¸ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ì–´ë–¤ ìƒí™©ì´ ë˜ëƒë©´, MCPs ì»¨ì…‰ì€ ë„ˆë¬´ ì¢‹ì•˜ìœ¼ë‚˜ ì´ê²Œ ìì¹« ê´€ì‹¬ì„ ë°›ì§€ ì•Šê³  ê·¸ëƒ¥ ë¶€ëŸ¬ì ¸ ë²„ë¦´ ìˆ˜ ìˆë˜ í”„ë¡œì íŠ¸ë¥¼ ì™„ì „íˆ ë©±ì‚´ ì¡ê³  ì˜¬ë ¤ì¤€ ì¼€ì´ìŠ¤ë¼ê³  ë³¼ìˆ˜ ìˆëŠ” ê±°ì£ '},\n",
       " {'start': 398.768,\n",
       "  'end': 425.248,\n",
       "  'text': ' MCPì— ëŒ€í•´ì„œ ë„ëŒ€ì²´ ì´ ë„êµ¬ë“¤ì„ ì–´ë–»ê²Œ ì™¸ë¶€ì—ì„œ ì“¸ ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ ì¤€ë‹¤ëŠ” ê±°ëƒ ì´ê±° ì— ëŒ€í•´ ë³¼ í•„ìš”ê°€ ìˆëŠ”ë° ì˜ìƒ ì´ˆë°˜ì˜ ë§ì”€ë“œë¦° ê²ƒì²˜ëŸ¼ ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œ ì´ì—ìš” ì´ê²Œ ì™œ ì¤‘ìš”í•˜ëƒë©´ ë­ ì²´ì¸ ë³´ì‹œë©´ ì´ë ‡ê²Œ ë§ì€ ì¢‹ì€ íˆ´ë“¤ì´ ì¸í…Œê·¸ë ˆì´ì…˜ ë˜ì–´ ìˆë‹¤ê³  í–ˆì–ì•„ìš” ê·¸ëŸ°ë°, ì´ ë ˆì´ì²¼íˆ´ì€ ì–´ë””ì„œë§Œ ì‚¬ìš©í• ìˆ˜ ìˆëŠëƒë©´ìš”? Rang chain ecosystem ì•ˆì—ì„œë§Œë“¤ì–´ê°ˆìˆ˜ ìˆëŠ”ê±°ì£  ê·¸ëŸ¬ë‹ˆê¹Œ ë‚´ê°€ ë ì±„ì¸ì„ ë°°ìš°ê³  ë¨ ê·¸ë˜í”„ë¥¼ ë°°ì›Œì•¼ë§ˆ ì—¬ê¸°ì— ë‚˜ì™€ìˆëŠ” ì¢‹ì€ íˆ¬ë¥¼ ê°€ì§€ê³ '},\n",
       " {'start': 425.248,\n",
       "  'end': 448.416,\n",
       "  'text': ' ì¨ë¨¹ì–´ì„œ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ê°€ ìˆëŠ” ê±´ë° ì§€ê¸ˆ ì´ íˆ´ë“¤ì€ ë­ì²´ì¸ì´ë‚˜ ë¨ê·¸ë˜í”„ì˜ ì˜ì¡´ì„±ì´ ìˆì–ì•„ìš”. ì´ê²Œ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì•„ë¬´ê²ƒë„ ì“¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œì€ ì´ê±°ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ê°€ì ¸ê°€ê² ë‹¤ëŠ” ê±°ì˜ˆìš” ê·¸ëŸ¬ë©´ì„œ ë³¸ì¸ë“¤ì´ í‘œì¤€ ê·œì•½ì„ ë§Œë“¤ê³  í´ë¼ì´ì–¸ë“œë“¤ì˜ í‘œì¤€ëŒ€í•™ì— ë§ì¶°ì„œ ê°œë°œí•´ì£¼ë©´ ì–´ë””ì„œë“  ì“°ì¼ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ ì£¼ê² ë‹¤ ë¼ëŠ” ê¸°ë…ì…ë‹ˆë‹¤'},\n",
       " {'start': 448.416,\n",
       "  'end': 477.744,\n",
       "  'text': ' ì´ê±¸ ì¢€ ë” ì‰½ê²Œ ì„¤ëª…í•œ ìë£Œê°€ ë°”ë¡œ ì—¬ê¸° ë‚˜ì™€ìˆëŠ” ì´ ìœ ëª…í•œ ìë£ë° ì—¬ê¸°ì— ë³´ì‹œë©´ì€ USB-C íƒ€ì…ì— ë¹„êµí•˜ëŠ” ê±¸ ë³¼ ìˆ˜ê°€ ìˆê±°ë“ ìš”? í•œë§ˆë””ë¡œ ë„ˆë„¤ ê°€ ì•…ì„¸ì„œë¦¬ë¥¼ ë§Œë“¤ ë•Œ, USB Cíƒ€ì… ì— ë§ì¶°ì„œ ë§Œë“¤ê¸°ë§Œ í•˜ë©´ ì œì¡°ì‚¬ë“¤ì´ usb c íƒ€ì´í”„ ì§€ì›í•˜ë©´ ê±°ê¸° ì–´ë””ë“ ì§€ ì–´ë–¤ íˆ´ë“¤ ì§€ ì‰½ê²Œ ê½‚ì„ ìˆ˜ ìˆë‹¤ëŠ” ê±°ì—ìš”. ë­ì²´ì¸ì˜ ì‚¬ë¡€ë¥¼ ë³´ë©´ ì€ ë  ì²´ì¸ ê°™ì€ ê²½ìš°ì—ëŠ” ì´ íˆ´ ë“¤ ì„ ë§ì´ ë§Œë“¤ì–´ ë†“ê¸´ í–ˆëŠ”ë° ì‰½ê²Œ ì–˜ê¸°í•´ì„œ ë­ ìš”ëŸ°ì‹ ì˜ íƒ€ì´ë¸Œë¡œ ë§Œë“¤ì–´ ë†¨ë˜ ê±°ì˜ˆìš” ì´ê±°ëŠ” ë§¹ì²´ì— ì„œë©´ í˜¸í™˜ì´ ë˜ëŠ” íƒ€ì„ ì¸ê±°ì£  ê·¸ëŸ¬ë‹ˆê¹Œ'},\n",
       " {'start': 477.744,\n",
       "  'end': 484.336,\n",
       "  'text': ' ì—¬ê¸°ì„œ ì—´ì‹¬íˆ ë§Œë“¤ì–´ ë†“ê¸´ í–ˆê³  êµ‰ì¥íˆ ë§ì€ íˆ´ë“¤ì´ ìˆìœ¼ë‚˜ ì´ê±°ëŠ” ë­ì²´ì¸ ì•ˆì—ì„œë§Œ í˜¸í™˜ë˜ëŠ” ì•„ì£¼ íŠ¹ìˆ˜í•œ'},\n",
       " {'start': 484.336,\n",
       "  'end': 509.328,\n",
       "  'text': ' ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê±´ë° ì´ MCP ë¼ëŠ” ê²ƒì€ í•œë§ˆë””ë¡œ USB-C íƒ€ì… ì´ëŸ° í‘œì¤€ ê·œì•½ì„ ë§Œë“¤ì–´ ë†¨ë‹¤ê³  ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ì´ì œ ë­ ìŠ¬ë™ì´ë‚˜ ì§€ë©”ì¼ ì´ë‚˜ ìº˜ë¦°ë” ì´ê±° ë„ˆ ì—ì´ì „íŠ¸ë‘ ì—°ë™ì‹œí‚¤ê³  ì‹¶ì–´? ê·¸ë¦¬ê³  í”„ë ˆì„ì›Œí¬ ë§ìœ¼ë©´ ê·¸ê±° í•˜ë‚˜í•˜ë‚˜ë¥¼ ë‹¤ ì–¸ì œ ë„¤ê°€ ì¸í„°ë² ë¦¬ì…”ë§ í•˜ê³  ìˆì„ë˜. ê·¸ëƒ¥ usb cíƒ€ì…ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ ê·¸ëŸ¬ë©´ ì œì¡°ì‚¬ë“¤ì´ ì•Œì•„ì„œ USB Cíƒ€ì…ì—ë‹¤ ì°¨ìš©í•˜ê²Œ ë  ê±°ê³  ê·¸ëŸ¼ ì—¬ê¸°ë‹¤ê°€ ë„ˆë„¤ë“¤ ìš”ê±° í•˜ë‚˜ë§Œ ê°œë°œí•´ ë‘ë©´'},\n",
       " {'start': 509.328,\n",
       "  'end': 538.608,\n",
       "  'text': ' í•„ìš”í•œ ì‚¬ëŒë“¤ì´ ë‹¤ ê½‚ì•„ì„œ ì“¸ ê±°ì•¼. ì´ëŸ° ì»¨ì…‰ì¸ ê±°ì˜ˆìš” ê·¸ë˜ì„œ ì´ MCP ì•„í‚¤í…ì²˜ ê°™ì€ ê²½ìš°ì—ëŠ” ì²˜ìŒì— í‘œì¤€ê¸°ì•½ì´ ë‚˜ì™”ì„ ë•Œ ì½˜ì…‰íŠ¸ëŠ” ë˜ê²Œ ì¢‹ì•˜ë‹¤ ê·¼ë° ì—¬ê¸°ì„œ ë¬¸ì œê°€ ìˆì£  ì–´ë–¤ ë¬¸ì œê°€ëƒë©´ ì˜ˆë¥¼ ë“¤ì–´ì„œ ê³¼ê±° ì‚¬ë¡€ë¥¼ í•œë²ˆ ë³´ë©´ìš” USB-C íƒ€ì…ì´ë¼ëŠ” ê²Œ ë‚˜ì™”ë˜ ì• í”Œ, ì‚¼ì„± ì´ëŸ°ë°ì—ì„œ ë§Œì•½ì— usb cíƒ€ì… ì“°ì§€ ì•Šì•„ìš” ìš°ë¦¬ê°€ íœ´ëŒ€í° ì¶©ì „í•´ì•¼ ë˜ê³  ë­ ê·¸ ë°–ì— ì—¬ëŸ¬ê°€ì§€ êµ°ëŒ€ë¡œ ì¨ì•¼ ë˜ëŠ”ë° ë©”ì´ì € íšŒì‚¬ì¸ ì• í”Œë¦¬ë‚˜ 3 ì„± ì—ì„œ usc íƒ‘ì˜ ì´ˆê¸°ì— ê±°ë“¤ë– ë³´ì§€ë„ ì•Šì•„ ê·¸ëŸ¼ ì–´ë–»ê²Œ ë˜ì£  ì—¬ê¸°ì— ìˆëŠ”'},\n",
       " {'start': 538.608,\n",
       "  'end': 565.36,\n",
       "  'text': ' ë‹¹ì—°íˆ ì•ˆ ë§Œë“¤ê² ì£ . ë‚´ê°€ ì—´ì‹¬íˆ USB-C íƒ€ì… ë§Œë“¤ì–´ ë´¤ì ì–˜ë„¤ë“¤ì´ ì•ˆ ì¨ì£¼ë‹ˆê¹Œ í˜¸í™˜ì´ ì•ˆë˜ëŠ” ê±°ì˜ˆìš” ê·¸ ìƒí™© ì´ ë­ì˜€ëƒë©´, ë°”ë¡œ ìš”ìƒí™©ì´ì—ˆë‹¤ ë¼ê³  ë³¼ ìˆ˜ê°€ ìˆëŠ” ê±°ì£  ê·¸ëŸ¬ë‹¤ê°€ usb cíƒ€ì… ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ ë§ì´ ì“°ëŠ” Cursor AI ì—ì„œ ì¸í…Œê·¸ë ˆì´ì…˜ í•´ì¤€ ê±°ì—ìš” ê·¸ëŸ¬ë‹ˆê¹Œ CURSOR AIA ìœ ì €ê°€ ì—„ì²­ ë§ì–ì•„ìš”? ì¼ë‹¨ ë‚´ê°€ USB-cíƒ­ì„ ë§Œë“¤ë©´ ì—„ì²­ë‚˜ê²Œ ë§ì€ ìœ ì ¸ë¥¼ ë³´ìœ í•œ cursor aiì— ê½‚ì„ ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ ì´ì œ ì—¬ê¸°ë¡œ ì‚¬ëŒë“¤ì´'},\n",
       " {'start': 565.36,\n",
       "  'end': 594.816,\n",
       "  'text': ' ê´€ì‹¬ì„ ê°€ì§€ê²Œ ë˜ëŠ” ê±°ì£ . ë‘ ë²ˆì§¸ë¡œëŠ” ì—¬ê¸°ì—ì„œ Cursor AIì˜ ì—­í• ì´ êµ‰ì¥íˆ ì¤‘ìš”í–ˆë˜ ê±´ ë§ì•„ìš”. Cursar AI ëŠ” ì—„ì²­ë‚˜ê²Œ ë§ì€ ìœ ì €ë¥¼ ì´ë¯¸ ë³´ìœ í•˜ê³  ìˆê³  ê·¸ë¦¬ê³  ì—¬ê¸°ì—ë‹¤ ì¸í…Œê·¸ë ˆì´ì…˜ ëë‹¤ë¼ëŠ” ê²ƒì€ ìˆœì‹ê°„ì— ë§ì€ ì‚¬ëŒë“¤ë¡œë¶€í„° ê´€ì‹¬ ë°›ì„ ìˆ˜ ìˆëŠ” ê±°ë‹ˆê¹Œìš” ê·¸ê±° ìì²´ë§Œìœ¼ë¡œë„ ì‚¬ì‹¤ ì˜ë¯¸ê°€ ìˆì§€ë§Œ, cursor ai ê°€ integration í•´ì£¼ë©´ì„œ ë˜ ì¢‹ì€ ì  í•˜ë‚˜ ìˆì£ ? cursor aid ëŠ” IDE ë¼ëŠ” ì—ë””í„°ì—ìš” ì´ ì—ë””í„´ì€ ê·¸ëƒ¥ ìš°ë¦¬ê°€ ì¼ë°˜ ë­ì²´ì¸ì´ë‚˜ ë¨ê·¸ë˜í”„ë¡œ ê°œë°œí•˜ëŠ” ì—ì´ì „íŠ¸ì™€'},\n",
       " {'start': 594.816,\n",
       "  'end': 613.776,\n",
       "  'text': ' ì°¨ì›ì´ ë‹¤ë¥´ì£ . ì™œ ì°¨ì›ì´ë‚˜ë¥´ëƒë©´ ìš°ë¦¬ê°€ ëª…ë ¹ì–´ë¥¼ ë‚´ë¦¬ë©´ ë‹¨ìˆœíˆ ì±„íŒ…ìœ¼ë¡œ ë‹µë³€ ì£¼ê³  ëë‚˜ëŠ” ìˆ˜ì¤€ì´ ì•„ë‹ˆì–ì•„ìš” ì–˜ëŠ” ì—ë””í„°ì´ê¸° ë•Œë¬¸ì— ê·¸ì—ë””í„°ë¥¼ í¬í•¨ë˜ì–´ ìˆëŠ” ìˆ˜ë§ì€ ê¸°ëŠ¥ë“¤ì´ ìˆì–´ìš” ì˜ˆë¥¼ë“¤ì–´ì„œ ì½”ë“œë¥¼ ìˆ˜ì •í•´ ì¤€ë‹¤ë„ì§€ íŒŒì¼ì„ ë°”ë¡œë°”ë¡œ ì ‘ê·¼í•´ì„œ íŒŒì¼ë‚´ìš© ì„ìˆ˜ ì •í•´ì¤˜ì•¼ í•  ì§€ ì´ê²Œ ì—ë””ë”ë¡œì„œì˜ ê¸°ë³¸ ê¸°ëŠ¥ ì´ê±°ë“ ìš” ê·¸ëŸ¬ë‹ˆê¹Œ ì´ëŸ°'},\n",
       " {'start': 613.776,\n",
       "  'end': 629.616,\n",
       "  'text': ' ê°–ì¶”ê²Œ ë˜ë‹ˆê¹Œ êµ‰ì¥íˆ ë§¤ë ¥ë„ê°€ ë†’ì•„ì§€ê²Œ ë˜ëŠ” ê±°ì£  ê·¸ë˜ì„œ ì´ ì§€ê¸ˆ USB-C íƒ€ì… í‘œì¤€ì„ ê°œë°œí•œ ê²Œ í´ë¡œë“œì—ì„œ MCPë¥¼ ë‚´ë†“ì€ ê±°ë¼ê³  ë³¼ ìˆ˜ê°€ ìˆê³ , í˜„ì¬ë¡œì„œëŠ” ì´ usb cíƒ€ì… ì„ ë§Œë“¤ê¸° ìœ„í•œ ì‹œì¥ì— ì—„ì²­ë‚˜ê²Œ ë§ì€ ì†”ë£¨ì…˜ ê°œë°œë¼ëŠ” ì‚¬ëŒë“¤ í˜¹ì€ ë‚´ê°€'},\n",
       " {'start': 629.616,\n",
       "  'end': 650.48,\n",
       "  'text': ' í•œë²ˆ ì¸ê¸°ìˆëŠ” íˆ´ì„ ë§Œë“¤ê³  ì‹¶ë‹¤ ì œ 2ì˜ ì¹´ì¹´ì˜¤í†¡ì´ ë˜ê³ ì‹¶ë‹¤ëŠ” ì‚¬ëŒë“¤ì€ ì „ë¶€ ë‹¤ ë›°ì–´ë“¤ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆì£  ê°œë°œìë“¤ì´ íˆ´ëŒ€í•™ì— ë§ì´ ë›°ì–´ ë“¤ë‹¤ë³´ë‹ˆê¹Œ ì§€ê¸ˆ ì´ ìŠ¤ë¯¸ë”ë¦¬ë¼ëŠ”ê²Œ ë„˜ë²„ì› ëª¨ë¸ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œ ì„œë²„ë¼ê³  ë³´ì‹œë©´ ë˜ìš”. ë§ˆì¼“í”Œë ˆì´ìŠ¤ ë¼ê³  ë³´ë©´ ë¼ìš” íˆ¬ë§ˆì¼€í‹€ë² ì´ìŠ¤ë° ì—„ì²­ë‚˜ê²Œ ë¹ ë¥´ê²Œ í„¸ë“¤ì´ ì¨ë°‹ë˜ê³  ìˆìŠµë‹ˆë‹¤'},\n",
       " {'start': 650.48,\n",
       "  'end': 671.84,\n",
       "  'text': ' ê·¸ë˜ì„œ ë§¤ì¼ê°™ì´ ë“¤ì–´ê°ˆ ë•Œë§ˆë‹¤ ì´ ìˆ«ìë“¤ì„ í™•ì¸í•´ë³´ë©´ ì—„ì²­ ë¹ ë¥´ê²Œ ëŠ˜ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ê°€ ìˆì–´ìš”. ê·¸ëŸ¬ë‹ˆê¹Œ ì‚¬ëŒë“¤ì´ ì´ë¯¸ ëƒ„ìƒˆë¥¼ ë§¡ì€ ê±°ì£  ì²˜ìŒì— ìŠ¤ë§ˆíŠ¸í° ì‹œì¥ì—ì„œ í‚¬ëŸ¬ ì•± ë§Œë“¤ì–´ê°€ì§€ê³ , ì—„ì²­ë‚˜ê²Œ ì¸ê¸°ë¥¼ ì–»ì–´ì„œ ìœ ë‹ˆì½˜ ëœ íšŒì‚¬ë“¤ì´ ë˜ê²Œ ë§ì–ì•„ìš” ê·¸ëŸ° ê²ƒì²˜ëŸ¼ ì•„ ì´ê²ƒë„ ë‚´ê°€ íˆ´ ì˜ ë§Œë“¤ì–´ì„œ ì—¬ê¸° ì•±ìŠ¤í† ì–´ì— ë“¤ì–´ê°€ê²Œ ë˜ë©´ ë‚˜ë„ ì¸ê¸°ìˆëŠ” í”„ë¡œì íŠ¸ë¥¼ í•  ìˆ˜ ìˆê² êµ¬ë‚˜ ì´ëŸ° ìƒê°ë“¤ë„ ìˆëŠ” ê²ƒ ê°™ì•„ìš” ì—¬ê¸°ì„œ ëì´ ì•„ë‹ˆì£ '},\n",
       " {'start': 671.84,\n",
       "  'end': 684.464,\n",
       "  'text': ' ì´ê²Œ ì„ ìˆœí™˜ìœ¼ë¡œ ë¬¼ê³  ë“¤ì–´ì˜¤ëŠ” ê±´ë° ì•„ê¹Œ ì•±ìŠ¤í† ì–´ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íˆ´ë“¤ì´ ë§ì´ ëŠ˜ì–´ë‚œë‹¤ê³  í–ˆì–ì•„ìš”. ì´ê²Œ ëŠ˜ì–´ë‚˜ê²Œ ë˜ë©´ í• ìˆ˜ìˆëŠ” ê²ƒë“¤ì´ ë§ì•„ì§€ë‹ˆê¹Œ ì´ Cursor AIì™€ MCPì•± ì¡°í•©ì„ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìë“¤ì˜'},\n",
       " {'start': 684.464,\n",
       "  'end': 711.328,\n",
       "  'text': ' ì—„ì²­ë‚˜ê²Œ ëŠ˜ì–´ë‚˜ëŠ” ê±°ì˜ˆìš” ì´ê²Œ ëŠ˜ì–´ë‚œ ê²Œ ë˜ê³  ê·¸ë¡œ ì¸í•´ì„œ ìš”ê²ƒë„ ë“œëŸ¬ë‚˜ê³  ê·¸ëŸ¼ ì´ ì‚¬ìš©ìë“¤ì´ ë§ì€ ìœ ìŠ¤ì¼€ì´ìŠ¤ë“¤ì„ ì°½ì˜ì ìœ¼ë¡œ ë§ì´ ë§Œë“¤ì–´ ë‚´ê³  ìˆì–´ìš” ì˜ˆë¥¼ ë“¤ì–´ì„œ Figmaë¥¼ ê·¸ë ¤ë‚¸ë‹¤ ì•„ë‹ˆë©´ DBì— ì ‘ê·¼í•œë‹¤ë¼ë“ ì§€ ì½”ë”©ì„ ìë™ìœ¼ë¡œ ì‘ì„±í•´ì¤€ë‹¤ê³  í•  ì§€ìš” ì´ëŸ° ì¢‹ì€ ë‰´ìŠ¤ ì¼€ì´ìŠ¤ê°€ ë‚˜ì˜¤ë‹ˆê¹Œ ë” ë§ì€ ì‚¬ëŒë“¤ì´ ìœ ì…ì´ ë˜ê³ ìš” ê·¸ëŸ¬ë©´ ë”ë§ì€ íˆ´ë“¤ë„ ì•ìœ¼ë¡œë„ ìƒê²¨ì•¼ ë  ê±°êµ¬ìš” ê·¸ëŸ¬ë‹ˆê¹Œ ë¬´ì„œìš´ ê²ƒì´'},\n",
       " {'start': 711.328,\n",
       "  'end': 723.088,\n",
       "  'text': ' ì´ ì•ˆì—ì„œ í•˜ë‚˜ì˜ ìƒíƒœê³„ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°ì„±ì´ ë˜ê³  ìˆëŠ” ê±°ì˜ˆìš”. ê·¸ëŸ¬ë©´ ì§€ê¸ˆ í˜„ì¬ë¡œì„œëŠ” í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ì´ë‘ ì»¬ì„œ, MCP ì´ë ‡ê²Œ 3ê°œì˜ í•©ì‘í’ˆì´ë¼ê³  ë³¼ ìˆ˜ê°€ ìˆëŠ”ë°'},\n",
       " {'start': 723.088,\n",
       "  'end': 752.368,\n",
       "  'text': ' Cursor AIë§Œ ì¸í…Œê·¸ë ˆì´ì…˜ì´ ë ê¹Œìš”? ì´ì œëŠ” ìœˆë“œì„œí”„ë„ ì§€ì›ì„ í•˜ê³  ë” ë§ì€ IDEë“¤ì´ ë“¤ì–´ì™€ì„œ ì´ MCPë¥¼ ì§€ì›í•˜ë ¤ê³  í•˜ê² ì£ . ì™œëƒí•˜ë©´ ì´ê²Œ Cursor APIê°€ ë…ì í•´ì„œ ê°€ì ¸ê°€ë©´ ì•ˆ ë˜ëŠ” ê±°ë‹ˆê¹Œ ì§€ê¸ˆ IDì— êµ­í•œë˜ì–´ ìˆëŠ”ë° ê³¼ì—° ì½”ë“œ ì—ë””í„° ê¸°ë°˜ì˜ ì–´ë–¤ ì—ë”•íŒ… íˆ´ì—ë§Œ êµ­í•œì´ ë ê¹Œìš” ì €ëŠ” ê·¸ë ‡ì§€ ì•Šë‹¤ê³  ë´…ë‹ˆë‹¤. ì´ mcp ë¼ëŠ” ê²ƒì€ ë§ ê·¸ëŒ€ë¡œ USB-C íƒ€ì… ê°™ì€ í‘œì¤€ ê·œì•½ì¸ë°, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ë‹¤ ì–´ë–¤ ì—ë””í„°ë§Œ ë¬¶ì—¬ ìˆê±°ë“ ìš” ê·¼ë° ì´ ì—ë””í„° ê°€ í™•ì¥ì´ ë˜ê°€ì§€ê³  ë‹¤ì–‘í•œ ì–´í”Œ'},\n",
       " {'start': 752.368,\n",
       "  'end': 777.008,\n",
       "  'text': ' MCPë¥¼ ê½‚ì•„ì„œ ì“¸ ìˆ˜ ìˆëŠ” ê·¸ëŸ° ì‹œì¥ì´ ì—´ë¦¬ê²Œ ë˜ê² ì£ . ì´ë¯¸ ì—´ë¦¬ê³  ìˆê³ ìš” ê·¸ë˜ì„œ ì´ mcp ê°€ í™•ì¥ë  ìˆ˜ë°–ì— ì—†ëŠ” ì´ìœ ëŠ” ì´ê±°ì˜ˆìš” ì§€ê¸ˆ í˜„ì¬ ìœ ìŠ¤ì¼€ì´ìŠ¤ê°€ ì¢‹ë‹¤ ì €ëŠ” ì´ê±°ëŠ” êµ‰ì¥íˆ ì¼ë¶€ë¼ê³  ìƒê°ì´ ë“¤ê³ , ìƒíƒœê³„ë¥¼ ë´¤ê±°ë“ ìš” ì‚¬ëŒë“¤ì´? ë‹¹ì—°íˆ ë” ë§ì€ íˆ´ë“¤ì´ ì¸í…Œê·¸ë ˆì´ì…˜ ìì—°ìŠ¤ëŸ½ê²Œ ë“¤ì–´ì˜¬ ê±°ê³  ë” ë§ì€ í´ë¼ì´ì–¸íŠ¸ë“¤ë“¤ì´ ë§ì´ ìƒê¸¸ê±°êµ¬ìš”'},\n",
       " {'start': 777.008,\n",
       "  'end': 792.432,\n",
       "  'text': ' ê·¸ë˜ì„œ ì´ ìƒíƒœê³„ê°€ ì»¤ì§€ì§€ ì•Šì„ê¹Œ ë¼ëŠ” ìƒê°ì´ ë“­ë‹ˆë‹¤. ê·¼ë° ì—¬ê¸°ì„œ ì¬ë°ŒëŠ” ê´€ì „ í¬ì¸íŠ¸ ì¤‘ì— í•˜ë‚˜ê°€ ë­ëƒë©´ ìµœê·¼ì— ì˜¤í”ˆ AIì—ì„œë„ íˆ´ë“¤ì„ ê³µê°œë¥¼ í–ˆì–´ìš”. ê·¸ë˜ì„œ íˆ´ì„ ê³µê°œí–ˆëŠ”ë°, ì•„ì§ê¹Œì§€ëŠ” MCPë¥¼ ì§€ì›í•˜ê³  ìˆì§€ ì•Šì£ ? ë¬¼ë¡  APIë¡œ ë¬¼ë ¤ì„œ ì´ë ‡ê²Œ ì“¸ ìˆ˜ ìˆê² ì§€ë§Œìš”'},\n",
       " {'start': 792.432,\n",
       "  'end': 821.712,\n",
       "  'text': ' ìì²´ì ìœ¼ë¡œ ê³µì‹ ì§€ì›ì€ í•˜ì§€ ì•ŠëŠ”ë° ê·¼ë° MCPê°€ ì´ê²Œ ë„ˆë¬´ ì»¤ì§€ê³  í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ê³¼ ì—°ê³„ì„±ì´ ì¢‹ì•„ì§€ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ í´ë¼ìš°ë“œë„ ìœ ì €ë“¤ë„ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì„ ì˜¤í”ˆ AIë„ ë³´ê³  ìˆì„ ê±°ê±°ë“ ìš” ê·¸ë˜ì„œ ì•ìœ¼ë¡œì˜ ì˜¤í€ì— ì¶”ì´ ë„ êµ‰ì¥íˆ ê¶ê¸ˆí•˜ë”ë¼êµ¬ìš” ì´ì œ í˜„ì¬ ëŠ” USB-C íƒ€ì… ìœ¼ë¡œ ëª¨ë‘ í†µì¼ ëì£  ì• í”Œë„ ê²°êµ­ì—ëŠ” í•­ë³µ í–ˆì–ì•„ìš” ë¼ì´íŠ¸ë‹ ì¼€ì´ë¸” ë²„ë¦¬ê³  usb cíƒ€ì… ë¡œ ì™”ìŠµë‹ˆë‹¤ ì´ëŸ° ê²ƒì²˜ëŸ¼ mcp ë¥¼ ì‚¬ìš©í•˜ëŠ” ìœ ì € ë“¤ ì´ ë§ì•„ ì§€ê³ ,mcpë¥¼ ì§€ì› í•˜ëŠ” í´ë˜ì–¸íŠ¸ë“¤ì´'},\n",
       " {'start': 821.712,\n",
       "  'end': 837.92,\n",
       "  'text': ' ì •ë§ ëŒ€ì œë¡œ ìë¦¬ ì¡ì„ ìˆ˜ ìˆì„ ê±°ë€ ìƒê°ì´ ë“­ë‹ˆë‹¤. ì•„ê¹Œ ì œê°€ ë­ì²´ì¸ ë§ì”€ì„ ë“œë ¸ëŠ”ë°, ì´ì œëŠ” MCPë¥¼ ì§€ì›í•˜ëŠ” í”„ë¡œì íŠ¸ë“¤ì„ ë§ì´ ë‚´ê³  ìˆì–´ìš”. ê·¼ë° ì–˜ë„¤ë“¤ë„ ë°”ë³´ê°€ ì•„ë‹ˆì£ ?'},\n",
       " {'start': 837.92,\n",
       "  'end': 865.472,\n",
       "  'text': ' MCPë¥¼ ì ê·¹ì ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤. ì™œëƒë©´ì€ ë­ì²´ì¸ ê°™ì€ ê²½ìš°ì—ë„ íˆ´ë„ ê°œë°œì„ í•˜ì§€ë§Œ ì´ ëª¸ì²´ë¥¼ ê°œë°œë¡œ í•˜ì–ì•„ìš”, í”„ë ˆì„ì›Œí¬ì´ê¸° ë•Œë¬¸ì— ê·¸ë˜ì„œ ì–´..ë­ ì²´ì¸ì—ì„œë„ ì•ìœ¼ë¡œ ì ê·¹ì  ìœ¼ë¡œ mcp ë¥¼ ì§€ì›í•  ê²ƒì´ë¼ê³  ì˜ˆìƒì´ ë˜êµ¬ìš” ë­ ì²´ì—ëŠ” í•œì‹œë¦„ ë‚¬ì£  ì˜¤íˆë ¤ ë³¸ì¸ë“¤ì´ ë‚˜ì„œì„œ íˆ´ë“¤ì„ ë‹¤ ì¸í…Œê·¸ë¦¬ì…˜ í–ˆì–´ì•¼ ëì—ˆì–´ìš” í˜¹ì€ íŒŒíŠ¸ë„ˆì‚¬ë“¤ì— ë§‰ ë©´ë‹´ í•´ê°€ì§€ê³  ì´ëŸ°ê²ƒë“¤ì˜ ì´ë°ê²Œì´ì…˜í•´ë‹¬ë¼ ì´ë ‡ê²Œ ìš”ì²­í–ˆì–´ì•¼ ë˜ëŠ”ë° ì˜¤íˆë ¤ 2íŒŒíŠ¸ê°€ ë–¨ì–´ì ¸ ë‚˜ê°€ë©´ì„œ ì œê°€ ë´¤ì„ ë•ŒëŠ” ë¶€ë‹¹ê°ì´'},\n",
       " {'start': 865.472,\n",
       "  'end': 894.768,\n",
       "  'text': ' ëœí•´ì§€ì§€ ì•Šì„ê¹Œ ë¼ëŠ” ìƒê°ì´ ë“­ë‹ˆë‹¤. ì•ìœ¼ë¡œ ë°©í–¥ì„±ì€ ì´ì œ ì´ í´ë¼ì´ì–¸íŠ¸ë“¤ ì§€ì›í•˜ëŠ” í´ë¼ì´ì–´íŠ¸ ë“¤ì´ ë§ì´ ëŠ˜ì–´ë‚  ê±°ê³ ìš” mcp ì„œë²„ì˜ ì¸í…Œê·¸ë ˆì´ì…˜ ë˜ì–´ ìˆëŠ” íˆ´ë“¤ë„ ë§ì´ ëŠ˜ì–´ ë‚  ê²ƒì´ë¼ê³  ë³´ê³  ìˆì–´ìš” ì—¬ê¸°ë„ ë³´ë©´ ë ˆí¼ëŸ°ìŠ¤ì„œë²„ê°€ ìˆê³  ë­ ì¨ë“œíŒŒí‹°ìˆê³  ì»¤ë®¤ë‹ˆí‹°ë¡œì„œ ê°€ ìˆëŠ”ë° ì—¬ê¸°ì— ë‚˜ì™€ìˆëŠ” íˆ¬ ë¿ë§Œ ì•„ë‹ˆë¼ ì—„ì²­ë‚˜ê²Œ ë§ì€ ì¶œë“¤ì´ ì „ì„¸ê³„ ê°œë°œìì—ì„œ ëª°ë ¤ì„œ ê³„ë°”ë¥¼ í•  ê²ƒì´ë‹¤ë¼ëŠ” ìƒê°ì´ë“œë ¤ìš” ì €ëŠ” ì´ê±¸ ë³´ë©´ì„œìš” ì´ë²ˆì— ëŒ€í•œë¯¼êµ­ ê¸°ì—…ë“¤í•œí…Œ êµ‰ì¥íˆ í°ê¸°íšŒë¼ê³ '},\n",
       " {'start': 894.768,\n",
       "  'end': 923.984,\n",
       "  'text': ' ê°œë°œ í•˜ì‹œê³  ê³„ì‹  ë¶„ë“¤ì´ ì´ ì¢‹ì€ ì†”ë£¨ì…˜ì„ mcp ë¡œ ë§ì´ ì—´ì–´ì„œ ë¹¨ë¦¬ ë“±ë¡í•´ ë†¨ìœ¼ë©´ ì¢‹ê² ì–´ìš” ìš°ë¦¬ë‚˜ë¼ ì‹œì¥ êµ‰ì¥íˆ ì¢ì–ì•„ìš” ê·¼ë° lm ì— ì˜ í˜¸í™˜ë  ìˆ˜ ìˆëŠ” MCP í˜•ì‹ìœ¼ë¡œ ë©í•‘ í•´ê°€ì§€ê³  ë§ˆì¼“í”Œë ˆì´ìŠ¤ì— ë“±ëª©í•´ì„œ ì´ê²Œ ì¸ê¸°ë¥¼ ì–»ëŠ”ë‹¤ ë¼ê³  í•˜ë©´ì€ ì´ê±°ëŠ” ê¸€ë¡œë²Œì‹œì¥ì„ ë°”ë¡œ ì§„ì¶œí•˜ê²Œ ë˜ëŠ” ê²¹ì´ê±°ë“ ìš” ê·¸ë˜ì„œ í˜¹ì‹œë¼ë„ íšŒì‚¬ ì¤‘ì—ì„œ MCP ì˜ ë“±ë¡í•  ë§Œí•œ ì¢‹ì€ì†”ìš°ì…˜ ê°€ì§€ê³ ê³„ì‹ ë¶„ë“¤ì´ë¼ë©´ ê·¸ë ‡ë‹¤ë©´ ì´ë²ˆì— ë¹¨ë¦¬ ì— ì”¨í”¼í˜• ì‹ìœ¼ë¡œ ë ˆí•„ í•´ì„œ'},\n",
       " {'start': 923.984,\n",
       "  'end': 944.08,\n",
       "  'text': ' ë§ˆì¼“í”Œë ˆì´ìŠ¤ëŠ” í˜„ì¬ ìŠ¤ë¯¸ë”ë¦¬ê°€ ì œì¼ ì¸ê¸°ê°€ ë§ë”ë¼ê³ ìš”. ì—¬ê¸°ì— ë“±ë¡í•˜ì‹œë©´ ë  ê²ƒ ê°™ì•„ìš” MCPë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ì‹ë„ ë„ˆë¬´ ê°„ë‹¨í•´ìš” íŒŒì´ì¬ì´ë‚˜ ê·¸ ë°–ì— ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë„ ì§€ì›ì„ í•˜ëŠ”ë°ìš” ì—¬ê¸° ë³´ë©´ì€ íŒ¨ìŠ¤íŠ¸ mcp ë¥¼ ê°€ì§€ê³  ì™€ì„œ íˆ´ë¡œ ì´ë ‡ê²Œ ë°ì½”ë ˆì´í„°ë¥¼ ì”Œì›Œì£¼ë©´ ë°”ë¡œ MCP í˜•ì‹ì˜ íˆ´ ë¡œ ì§€ì›í•˜ê²Œ ë©ë‹ˆë‹¤ ì „ì„¸ê³„ì¸ìœ¼ë¡œ ëŒ€ìƒìœ¼ë¡œ ì„œë¹„ìŠ¤ í•  ë•ŒëŠ”'},\n",
       " {'start': 944.08,\n",
       "  'end': 958.912,\n",
       "  'text': ' í•˜ë©´ ì•ˆë˜ê³  ì¢€ ë” ë³µì¡í•˜ê²Œ ë¡œì§ êµ¬í˜„ì´ ë˜ê² ì§€ë§Œ ì œê°€ ë§ì”€ë“œë¦¬ê³  ì‹¶ì€ ê±°ëŠ” ì €ë„ ì´ë²ˆì— êµ¬ì—°ì„ í•´ë³´ë‹ˆê¹Œ ìƒê°ë³´ë‹¤ êµ¬í˜„ë ¥ì€ ê·¸ë ‡ê²Œ ì–´ë µì§€ ì•Šë‹¤ëŠ” ì ì´ì—ìš” ê·¸ë˜ì„œ ì—¬ê¸°ì— ë³´ë©´ mcp íŒŒì´ì¬ stk ë¼ê³  ë‚˜ì™€ ìˆê±°ë“ ìš” ìš”ê±°ì— ë¬¸ì„œ ë‚´ìš© í•œë²ˆ ë³´ì‹œë©´ì„œ ê°œë°œí•´ ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë¦¬êµ¬ìš”'},\n",
       " {'start': 958.912,\n",
       "  'end': 988.208,\n",
       "  'text': ' ì´ì œ FATCAMPUSì—ì„œ ê°•ì˜ë¥¼ í•˜ê³  ìˆëŠ”ë° ì´ë²ˆ ì£¼ì£¼ì´íšŒì˜ ì£¼ì œë¡œ MCPsë¥¼ ì¡ì•˜ê±°ë“ ìš” ê·¸ë˜ì„œ ì €í¬ íŒ€ ë‚´ë¶€ì— ê°œë°œí•˜ê³  ìˆëŠ” í”„ë¡œì íŠ¸ë“¤ë„ ì´ë²ˆ ì£¼ì£¼ë¥¼ ì†Œê°œí•´ë“œë¦´ê±°ë‹ˆê¹Œ í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹  ë¶„ë“¤ì€ ì„¸ë¯¸ë‚˜ ì‹ ì²­ë„ í•´ì£¼ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤ ë§ˆì§€ë§‰ìœ¼ë¡œ ì œê°€ ì˜¤ëŠ˜ ê°œë°œëë˜ ìœ ìŠ¤ì¼€ì´ìŠ¤ë“¤ì„ ëª‡ê°€ì§€ ì†Œê°œë¥¼ í•´ë“œë¦¬ê³  ì§ì ‘ ì‹œì—°ì„ ë³´ì—¬ë“œë¦¬ë ¤ê³  í•´ìš” ì—¬ê¸°ì—ì„œ ë³´ì—¬ë“œë¦´ê²Œìš” ë¨¼ì € 4 ê°€ì§€ë¥¼ ê°€ì§€ê³  ì™”ëŠ”ë°ìš” ì²«ë²ˆì§¸ë¡œëŠ” Rangchain-RegLocal ìš”ê±°ë¥¼ mcpë¡œ ë§Œë“¤ì–´ë†¨ê³ ìš” ì´ê±¸ ë§Œë“¤ì–´ ë†“ìœ¼ë©´ ë­ê°€ ì¢‹ëƒë©´ ë‚´ê°€ ë­ì²´ì¸ ì½”ë“œë¥¼'},\n",
       " {'start': 988.208,\n",
       "  'end': 1006.0,\n",
       "  'text': ' ì´ê±¸ MCP ì„œë²„ë¡œ ë„ìš°ëŠ” ê±°ì˜ˆìš”. ê·¸ëŸ¬ë©´ Cursor AIê°€ ì´ Rangchainìœ¼ë¡œ ë§Œë“¤ì–´ ë†“ì€ ë ˆê·¸ ì‹œìŠ¤í…œì„ ì°¸ì¡°í•˜ê³  ê·¸ë¦¬ê³  í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ì—ì„œë„ ì´ê²ƒì´ ì°¸ì¡°ë  ìˆ˜ ìˆê²Œ ë¼ìš” ë˜ DeFië¡œ ë¬¼ë ¤ì„œ, ë””íŒŒì´ì— External Knowledge API ê°€ ìˆì–´ìš”.'},\n",
       " {'start': 1006.0,\n",
       "  'end': 1028.272,\n",
       "  'text': ' Cursor AIë‚˜ í´ë¡œë“œ ë°ìŠ¤íƒ‘ì—ì„œ DeFië¡œ ìš”ì²­ì„ ë³´ë‚´ì„œ External Knowledgeë¥¼ ì°¸ì¡°í•´ì„œ ê·¸ê±¸ ê°€ì ¸ì˜¤ê²Œ ë” ì´ë ‡ê²Œ ë§Œë“¤ì–´ ë†“ëŠ” ì˜ˆì œë“¤ë„ í•˜ë‚˜ ë§Œë“¤ì–´ë†¨êµ¬ìš” ê·¸ ë‹¤ìŒì— ë””íŒŒì´ ì›Œí¬í”Œë¡ ì¸ë° ì œê°€ ìµœê·¼ì— ë”” íŒŒì˜ ê´€ë ¨ëœ ì˜ìƒë“¤ ë§ì´ ì˜¬ë ¸ì£ . ë””íŒŒì´ë¡œ ì‰½ê²Œ ì›Œí¬ë¥¼ êµ¬ì¶•í•˜ì‹¤ ìˆ˜ê°€ ìˆëŠ”ë°, ê·¸ êµ¬ì¶œí•´ ë†“ì€ workflow ë¥¼ í˜¸ì¶”í•˜ëŠ”ê±° ì´ ì˜ˆì œë¥¼ í•˜ë‚˜ë§Œ ë“¤ì–´ ë†¨ê³ ìš” ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ Python function ì¸ë° ê°„ë‹¨í•˜ê²Œ ìš°ë¦¬ê°€ íŒŒì´ì¬ í€ì…˜ ìœ¼ë¡œ ì»¤ìŠ¤í…€í•œ'},\n",
       " {'start': 1028.272,\n",
       "  'end': 1045.488,\n",
       "  'text': ' ê¸°ëŠ¥ë“¤ ë¡œì§ë“¤ì„ êµ¬í˜„í•´ ë†“ê³  ê·¸ê±°ë¥¼ mcp ì„œë²„ë¡œ ë„ìš´ ë‹¤ìŒì— í˜¸ì¶œí•˜ëŠ” ì˜ˆì œë¥¼ ë§Œë“¤ì–´ ë†¨ì–´ìš” ì—¬ê¸°ì—ì„œ ì‚¬ìš©í•œ ì˜ˆë“œëŠ” íƒœë¸”ë¦¿ ì›¹ì„œì¹˜ ë„êµ¬ë¥¼ ì“°ëŠ” ì˜ˆì œ ë¥¼ ë§Œë“¤ì–´ë†¨êµ¬ìš” 4ê°€ì§€ ì‚¬ë¡€ ì •ë„ë©´ Rangchain, DeFi ê·¸ë‹¤ìŒì— íŒŒì´ì¬ ëŒ€ë¶€ë¶„ì€ ì»¤ë²„ê°€ ê°€ëŠ¥í•˜ì‹œë‹ˆê¹Œ í•œë²ˆ ë³´ì…”ë„ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ í”„ë¡œì íŠ¸ëŠ”'},\n",
       " {'start': 1045.488,\n",
       "  'end': 1070.592,\n",
       "  'text': ' í˜„ì¬ëŠ” ì¸í„°ë„ë¡œ ë˜ì–´ ìˆì§€ë§Œ ê³§ ê³µê°œí•  ì˜ˆì •ì´ì—ìš”. ê³µê°œë¥¼ í•˜ê³  ë‚˜ì„œ ì˜ìƒ ë”ë³´ê¸°ë€ì— ì œê°€ ë§í¬ë¥¼ ì£¼ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ ì´ í”„ë¡œì íŠ¸ë¥¼ ë‹¤ìš´ë°›ì•„ì„œ ì“°ì‹œë©´ ë˜ê² ê³ ìš” ì˜ì–´ë¡œë„ ê³µê°œë˜ì—ˆê³  ì €í¬ê°€ í•œêµ­ì–´ ë²„ì „ë“¤ë„ ë§Œë“¤ì–´ ë†¨ê±°ë“ ìš”? ì´ê±°ë¥¼ ë³´ì‹œë©´ì„œ ë”°ë¼ í•˜ì‹œë©° ë¬´ë¦¬ì—†ì´ ìˆ˜í–‰ì´ ë ê±°ì—ìš” ì œê°€ ì´ê±¸ ë¼ì´ë¸Œë¡œ í•œë²ˆ ë°ëª¨ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš” ì ë¨¼ì € ì €ëŠ” ì§€ê¸ˆ MCP ì„œë²„ë¥¼ ì´ë ‡ê²Œ ë¬¼ë ¤ë†¨ëŠ”ë°ìš” ì´ê²ƒì„ ì‚¬ìš©í•˜ì‹œëŠ” ë°©ë²•ì€ êµ‰ì¥íˆ ê°„ë‹¨í•©ë‹ˆë‹¤ í”„ë¡œì íŠ¸ì˜ ë‹¤ìš´ ë¡œë“œ ë°›ì€ ë‹¤ìŒì— ë¨¼ì € ì¼€ì´ìŠ¤ 1 ìª½ìœ¼ë¡œ ê°€ë³¼ê²Œìš” CD-1'},\n",
       " {'start': 1070.592,\n",
       "  'end': 1099.44,\n",
       "  'text': ' ì´ë ‡ê²Œ ê°€ì„œ ì—¬ê¸° ì™¼ìª½ì— ë³´ì‹œë©´ì€ .env.exampleì´ë¼ê³  ë˜ì–´ ìˆì–´ìš” í™˜ê²½ ë³€ìˆ˜ë“¤ì„ ë“±ë¡í•˜ëŠ” ì˜ˆì œê³  example1 í•´ë³´ì‹¤ ë¶„ë“¤ì€ ìš”ê±°, 2í•´ë³´ì…¨ì„ë¶„ë“¤ì€ ì´ê±° 3ëŠ” ì´ê±°ë‘ 4ëŠ” ì´ê²ƒ ì´ê±°ë¥¼ ì„¤ì •í•˜ì‹  ë‹¤ìŒì— ì‹¤í–‰í•˜ì‹œë©´ ë¼ìš” ë‹¹ì—°íˆ exmpelloë¡œ ì‹¤í–¥ í•˜ì‹œ ë©´ ì•ˆë˜êµ¬ ì €ì²˜ëŸ¼ ì  emb ë¡œ ë°”ê¿”ì„œ ì§„í–‰í•´ì£¼ë©´ë©ë‹ˆë‹¤ ì ì´ë ‡ê²Œ ë°”ê¾¸ì–´ì„œ í‚¤ê°’ë“¤ì„ ë‹¤ ì„¸íŒ…í•˜ì…¨ìœ¼ë©´ ê·¸ëŸ¬ë©´ ì—¬ê¸°ì— case 1ì— ê°€ì…”ì„œ íŒŒì´ì¬ì˜ ì €í¬ê°€ ì˜¤í† ì»´í”¼ê·¸ë¥¼ ë§Œë“¤ì–´ ë†¨ì–´ìš” auto mcp json ì´ë¼ê³  ë§Œë“¤ì—ˆëŠ”ë°'},\n",
       " {'start': 1099.44,\n",
       "  'end': 1126.88,\n",
       "  'text': ' ì´ê±¸ ì‹¤í–‰í•˜ë©´ APIí‚¤ë¥¼ ë°›ì•„ë‹¤ê°€ ì•Œì•„ì„œ ë§Œë“¤ì–´ì¤˜ìš”. ë°ì´ìŠ¨ íŒŒì¼ì´ ì´ë ‡ê²Œ ë‚˜ì˜¤ê²Œ ë˜ê±°ë“ ìš”? ì—¬ê¸° OpenAIì˜ í‚¤ê°’ ë“¤ì–´ê°€ ìˆê³ , ì´ê²ƒì„ ì‹¤í–‰í•˜ëŠ” ê²ƒë“¤ë„ ì˜ ë‚˜ì™€ìˆì–´ìš” ì´ê±°ë¥¼ ì–´ë–»ê²Œ í•˜ì‹œë©´ ë˜ëƒë©´ ë ˆê·¸ë¶€í„° ì—¬ê¸°ê¹Œì§€ë¥¼ ë³µì‚¬í•˜ì‹œëŠ” ê±°ì˜ˆìš” ë³µì‚¬ë¥¼ í•´ì„œ ì„¸íŒ…ìŠ¤ ê°€ì‹¤ ìˆ˜ê°€ ìˆê±°ë“ ìš” í†±ë‹ˆë°”í€´ ëˆ„ë¥´ê³  Add New Global MCP Serverë¼ê³  ë‚˜ì™€ ìˆê±°ë“  ìš” ëˆŒëŸ¬ë³¼ê²Œìš” ì ëˆŒëŸ¬ ë³´ë©´ ì €ëŠ” ë“±ë¡ì´ ë§ì´ ë˜ì–´ ìˆì–´ìš” ì›ë˜ëŠ” ì²˜ìŒ ë“±ëª©í•˜ì‹  ë¶„ë“¤ì—ê²Œ ë‹¤ ë¹„ì›Œì ¸ ìˆì„ ê±°ì—ìš” ê·¸ëŸ¬ë©´ ì§€ìš°ê³  ì—¬ê¸°ì— ë¶™ì—¬ ë„£ìœ¼ì„¸ìš”'},\n",
       " {'start': 1126.88,\n",
       "  'end': 1145.968,\n",
       "  'text': ' ë ˆê·¸ MCPëŠ” ë­ì²´ì¸ ì½”ë“œë¡œ ë§Œë“¤ì–´ë†“ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰ì„ í•´ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´, MCPì— íŒŒë€ ë¶ˆì´ ë“¤ì–´ì˜¤ë©´ ì„¸íŒ…ëœê±°ì—ìš”'},\n",
       " {'start': 1145.968,\n",
       "  'end': 1175.44,\n",
       "  'text': ' í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¼ ì°¨ë¡€ì¸ë°, ë¬¸ì„œê°€ 2025ë…„ 3ì›” ì¸ê³µì§€ëŠ¥ ì‚°ì—…ì˜ ìµœì‹  ë™í–¥ì´ê±°ë“ ìš”. ì´ë ‡ê²Œ ì­‰ ë‚˜ì™€ ìˆì–´ìš” ì—¬ê¸° ìˆëŠ” ë‚´ìš©ë“¤ì„ ë°”ë¡œ REGë¥¼ í•´ ë³¼ ìˆ˜ê°€ ìˆì£  ì œê°€ 13í˜ì´ì§€ì— ìˆëŠ” GROK3 ì— ëŒ€í•œ ë‚´ìš©ì„ ë¬¼ì–´ë³¼ê²Œìš” ì—¬ê¸°ì— ë„êµ¬ ì´ë¦„ì€ ë ˆê·¸ MCPë¡œ ì‘ì„±í•´ ë†¨ì–ì•„ìš” ê·¸ëŸ¬ë©´ ë¬¼ì–´ ë³¼ë•Œ REGMCP ë¥¼ ì‚¬ìš©í•´ì„œ ê·¸ë¡ ì“°ë¦¬ ì¶œì‹œì¼ ì–¸ì œì¸ì§€ ì•Œë ¤ì¤˜'},\n",
       " {'start': 1175.44,\n",
       "  'end': 1200.784,\n",
       "  'text': ' ì €í¬ê°€ ë§Œë“¤ì–´ ë†“ì€ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ì„œ ë‹µë³€ì„ ì£¼ê²Œ ë¼ìš” ì ì–˜ í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ë¥¼ í–ˆì£  ê¸°ë³¸ì ìœ¼ë¡œ ì´ì œ í•˜ì´ ë¸Œë¦¬íŠ¸ì„œì¹˜ í•´ì„œ ì„¤ì¹˜ë¡œ ë¦¬ì €ë¥´íŠ¸ë¥¼ ë³´ë©´ pdf ë¬¸ì„œë¥¼ ë ˆê·¸ë¡œ ê°€ì ¸ì˜¨ ê²ƒì„ ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ì´ë ‡ê²Œ ê°€ì¡Œì—ˆì§€ìš” ì—¬ê¸°ì—ì„œ ë§Œì•½ì— hybrid searchê°€ ì•„ë‹ˆë¼ semantic-searchë¡œ ê²€ìƒ‰ì„ í•˜ê³  ì‹¶ë‹¤ ìš”ê±°ë¥¼ ìˆ˜ì •í•´ ë³¼ê²Œìš” Semantic Search í•´ ì¤˜ ì´ë ‡ê²Œ ì“°ë©´ ì€ ë„êµ¬í˜¸ì¶œë‚  ì ì— ì‹œë©˜í‹± SEARCHë¥¼ í•  ê±°ì˜ˆìš”'},\n",
       " {'start': 1200.784,\n",
       "  'end': 1217.568,\n",
       "  'text': ' ì ì´ë²ˆì—ëŠ” ì‹œë©˜í‹± ì„œì¹˜í•´ì„œ ê²°ê³¼ë¥¼ ì£¼ëŠ” ê²ƒì„ ë³¼ ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤ ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ê²ƒë„ í•œë²ˆ í•´ë³¼ê¹Œìš” ì¶œì²˜ë¥¼ ë‹µë³€ì— í¬í•¨í•´ì¤˜ ì´ë ‡ê²Œ ì“°ê²Œ ë˜ë©´ì€, ì¶œë ¬ì„ ë‹µë³€ì„ í†µí•´ ë§í•´ì£¼ëŠ” ê±¸ ë³¼ ìˆ˜ ìˆì£  ì´ëŸ° ì‹ìœ¼ë¡œ ìš°ë¦¬ê°€ ë§Œë“¤ì–´ ë†“ì€ ë­ ì²´ì¸ ë ˆê·¸ ì‹œìŠ¤í…œ ê¸°ë°˜ ìœ¼ë¡œ'},\n",
       " {'start': 1217.568,\n",
       "  'end': 1245.904,\n",
       "  'text': ' ë‹µë³€í•˜ëŠ” ê±°ë¥¼ ì»¬ì„œì—ì„œ ë°”ë¡œ í…ŒìŠ¤íŠ¸ í•´ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ê·¼ë° ì´ê²Œ ì»¬ì„œì˜ ì¡°ê·¸ë§Œ ì°½ ì—ì„œ í•´ ë³´ì‹œê¸° ë¶ˆí¸í•˜ë‹¤ í•˜ì‹  ë¶„ë“¤ì€ í´ë¡œë“œ ë°ìŠ¤íƒ‘ì—ì„œë„ í•  ìˆ˜ ìˆê±°ë“ ìš” ì´ë ‡ê²Œ ì—´ë¦¬ê²Œ ë˜ë©´ì€ ìƒë‹¨ì— í´ë¡¸ë“œ ì˜ ì„¸íŒ…ìŠ¤ ë¼ê³  ìˆì–´ìš”. settings ê°€ì„œ ë””ë²¨ë¡­í¼ ì—ë”§ì»´í”½ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤ ìš”ê±°ë¥¼ ì—´ ë©´ ì€ ì œì´ìŠ¨ ì»¨í”¼ê·¸ íŒŒì¼ì´ ìˆëŠ”ë° ì´ê±°ë¥¼ í„ì„œë¡œ ì—´ìœ¼ë©´ë˜ìš” ì,ì—´ì–¼ì–´ë³¼ê²Œìš” ì ì—´ë©´ìš”ë¡œì¼€ ë‚˜ì˜¤ëŠ”ë° ì—¬ê¸°ì—ë‹¤ê°€ ìš”ë ‡ê²Œ regmcpë¼ê³  í•´ì„œ ì¶”ê°€ë¥¼ í•´ì£¼ëŠ” ê±°ì˜ˆìš” ì €ë ‡ê²Œ ì¶”ê°€í–ˆìœ¼ë©´ ì´ê±¸ í”„ë¡œê·¸ë¨ ì„ ê»ë‹¤ ê°€ ë‹¤ì‹œ í•œë²ˆ ì¼œë´ì•¼ ë¼ìš”'},\n",
       " {'start': 1246.288,\n",
       "  'end': 1273.952,\n",
       "  'text': ' ì¼œì£¼ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì,ì¼°ì£ ? ê·¸ëŸ¬ë©´ ì—¬ê¸° ë„êµ¬ì— ë³´ë©´ìš” ì €í¬ í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ë‘ ê·¸ ë‹¤ìŒì— í‚¤ì›Œë“œë„ ì„¤ì¹˜ ê·¸ë¦¬ê³  ì‹œë©˜í‹±ì„œì¹˜ê°€ ì´ë ‡ê²Œ ë ˆê·¸ MCPê°€ ì˜ ë“¤ì–´ì™€ ìˆëŠ” ê±¸ ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ì—¬ê¸°ì—ë‹¤ê°€ ë˜‘ê°™ì€ ì§ˆë¬¸ì„ í•´ë³´ëŠ” ê±°ì£  ì €í¬ê°€ í–ˆë˜ ìš”ê±° ë‚´ìš©ì„ ë³µì‚¬í•´ ê°€ì§€ê³ ìš” ì—¬ê¸°ë‹¤ ê°€ë‘ ë¶™ì—¬ ë„£ì–´ì„œ í•´ ë³¼ê²Œìš” ê·¸ëŸ¼ ì´ íˆ´ ì„ ì“°ê²Œ ë˜ì£ .ë ˆê·¸ë ‰ì‹œí”¼ ì•Œë¡œìš° í´ë””ìŠ¤ì±—! ìš”ë ‡ê²Œ í•´ì£¼ê³  ê²€ìƒ‰ í•´ì˜¤ê³  ì£¼ìš” ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ê°€ìˆì–´ìš” ìŠ¤í”„ë¦¬ AI ë¸Œë£¨í”„ì˜ 3ì›”í˜¸ê¹Œì§€ ì˜ ê°€ì ¸ì˜¤ì ¸ ê·¸ëŸ¬ë‹ˆê¹Œ'},\n",
       " {'start': 1273.952,\n",
       "  'end': 1287.92,\n",
       "  'text': ' ìš°ë¦¬ê°€ ì•ìœ¼ë¡œëŠ” í´ë¡œë“œ ë°ìŠ¤íƒ‘ì— ë­ ì²´ì¸ìœ¼ë¡œ ë§Œë“¤ì–´ ë†“ì€ ë ˆê·¸ ì‹œìŠ¤í…œì„ ë¶™ì—¬ì„œ í•´ ë³¼ ìˆ˜ê°€ ìˆëŠ” ê±°ì˜ˆìš”. ì €ê¸°ë‹¤ê°€ ë¬¸ì„œë“¤ë§Œ ë„£ì–´ì£¼ë©´ ì €ëŠ” í´ë¡¸ë“œì—ì„œ ê·¸ ë¬¸ì„œë¥¼ ê¸°ë°˜í•œ ë ˆê·¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ ì›ë˜ ì´ ì±—ë³¼ì‹œìŠ¤í…œë§Œ ë§Œë“¤ê¸° ìœ„í•´ì„œ ì–´ë–»ê²Œ í–ˆì—ˆì£ ? ìŠ¤íŠ¸ë¦¼ë‹˜,'},\n",
       " {'start': 1287.92,\n",
       "  'end': 1317.2,\n",
       "  'text': ' í”„ë¡ íŠ¸ ì•± ê°œë°œí•´ì„œ ë§Œë“¤ì—ˆì–ì•„ìš” í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ê³¼ ì»¬ì‚¬ AIê°€ ìˆìœ¼ë‹ˆê¹Œ ì´ í”„ëŸ°íŠ¸ê°€ í•„ìš” ì—†ì–´ì§€ëŠ”ê±°ì—ìš” ìš°ë¦¬ê°€ ë°±ì—”ë“œë• ì¦‰ ë­ì²´ì¸ìœ¼ë¡œ êµ¬í˜„ì„ í•˜ì‹œë˜ ë””íŒŒì´ë¡œ êµ¬í˜„ëœë‹¤ ì•„ë‹ˆë©´ ê·¸ ë°–ì˜ ì–´ë–¤ê±¸ë¡œ ê°œë°œë˜ì–´ ìˆì–´ë„ ê·¸ê²ƒë§Œ í•´ ë†“ìœ¼ë©´ ì‰½ê²Œ ë ˆê·¸ ì‹œìŠ¤í…œì´ ë  ìˆ˜ ìˆëŠ” ê±°ì—ìš” í•˜ë‚˜ë§Œ ë” ë³´ì—¬ë“œë¦´ê²Œìš” ì¼€ì´ìŠ¤ 3ì— ëŒ€í•œ ë‚´ìš©ì¸ë° DeFi ì›Œí¬í”Œë£¨ì–´ë‘ ë¬¼ë ¤ë†¨ìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ë”” íŒŒì´ì› í”ŒëŸ¬ìš°ì—ì„œ ì´ê²ƒë³´ë‹¤ í›¨ì”¬ ë³µì¡í•œ ê±¸ ë§Œë“¤ì–´ ë‘˜ìˆ˜ìˆê² ì§€ë§Œ ì €ëŠ” í…ŒìŠ¤íŠ¸ ì‚¼ì•„ì„œ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ í•´ë´¤ê±°ë“ ìš” ì´ë²ˆì—ëŠ” ì§€ì‹ê²€ìƒ‰ ì„ ì¶”ê°€í•´ë†“ì€ ê±°ì˜ˆìš” ë™ì¼í•œ íŒŒì¼ë“¤'},\n",
       " {'start': 1317.2,\n",
       "  'end': 1345.456,\n",
       "  'text': ' API ì•¡ì„¸ìŠ¤ì— ê°€ì„œ ì—¬ê¸° ìˆëŠ” api ì„œë²„ì™€ ê·¸ ë‹¤ìŒì— Apikyë¥¼ ë°œê¸‰ì„ ë°›ìŠµë‹ˆë‹¤ ê·¸ë˜ì„œ ì´ ìƒ˜í”Œ ì—ìˆëŠ” api url ê·¸ë‹¤ìŒì— APIKY ë¥¼ ë„£ì–´ì£¼ì‹œë©´ í•˜ë©´ ë¼ìš” ê·¸ëŸ¬ë©´ ë‚´ê°€ ë§Œë“  ì›Œí¬í”Œë¡œìš°ë¥¼ë“¤ í´ë¡œë“œ ë°ìŠ¤í¬íƒ‘ ì´ë‘ ì»¬ì‚¬ AIì—ì„œ ì“¸ ìˆ˜ê°€ ìˆê²Œ ë˜ëŠ” ìƒí™©ì´ê±°ë“ ìš” ì,ê·¸ëŸ¬ë©´ ë°˜í–‰ ë²„íŠ¼ ëˆŒëŸ¬ì£¼ê³  CDì˜ ì¼€ì´ìŠ¤ 3ë¡œ ê°€ì„¸ìš” íŒŒì´ì¸ ì˜ ì˜¤í†  MCP ì œì´ìŠ´ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤ ë§Œë“¤ì–´ ì£¼ë©°ëŠ” ì´ë ‡ê²Œ ìƒì„±ì´ ë˜ ê±°ë“ ìš” ìš” ë‚´ìš© ì¤‘ì—ì„œ'},\n",
       " {'start': 1345.456,\n",
       "  'end': 1374.96,\n",
       "  'text': ' ë””íŒŒì´ ì›Œí¬í”Œë¡œìš° ë¶€í„° ë³µì‚¬ë¥¼ í•´ê°€ì§€ê³  í´ë¡¸ë“œ ë°ìŠ¤íƒ‘ ì»¨í”¼ê·¸ì—ë‹¤ê°€ ì´ë ‡ê²Œ ë¶™ì—¬ ë„£ì–´ì¤„ê²Œìš” ì, ë”” íŒŒì´ì›Œí¬ë£¨ í”ŒëŸ¬ìš°ë¥¼ ë¶™ì˜€ìŠµë‹ˆë‹¤ ê·¸ëŸ¬ë©´ì€ ì´ì œ ì €í¬ê°€ í•˜ëŠ” ê±°ëŠ” ë°ìŠ¤íƒ‘ì—ì„œ ë”” íŒŒì´ì–´ ê·¸ í”„ë¡œë¥¼ í˜¸ì¶œí•´ì„œ ë‹µë³€ì„ ë°›ì„ ê±°ì—ìš” ì €ë ‡ê²Œ ì…‹ì—… í•´ì¤¬ê³  í´ë¡  ëŒ€ì‚¬ ì¢…ë£Œí•  ê²Œìš” ë‹¤ì‹œ ê»ë‹¤ í‚µë‹ˆë‹¤ ë‹¤ ì¼°êµ¬ìš” ì´ì œ ë„êµ¬ê°€ í•˜ë‚˜ ë” ë“¤ì–´ ë‚«ê±°ë“ ìš” ì´ê±¸ ëˆŒëŸ¬ ë³´ë©´ ì€ d5 ì›Œí¬ í”Œë¼ì›Œ ë¼ëŠ” ë„êµ¬ ê°€ ìƒê¸´ ê²ƒì„ ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ì–˜ë¥¼ ê°€ì§€ê³  ì‚¬ìš© í•´ì„œ ê·¸ë£¹'},\n",
       " {'start': 1374.96,\n",
       "  'end': 1404.16,\n",
       "  'text': ' 3ì˜ ì¶œì‹œì¼ì„ ì•Œë ¤ì¤˜ ë¼ê³  í•´ë³¼ê²Œìš”. ê·¸ëŸ¬ë©´ ë””íŒŒì´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•´ë³´ê² ë‹¤ê³  í•˜ì£ ? í—ˆìš©í•´ì£¼ê³ ìš” ìš°ë¦¬ê°€ ë§Œë“ , ë””íŒŒì´ì—ì„œ ë§Œë“œëŠ” ì›Œí¬ í”ŒëŸ¬ì›Œë¥¼ í†µí•´ì„œ ì •ë³´ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤ ê·¸ ì–»ì€ì •ë³´ ë°”íƒ•ìœ¼ë¡œ ì´ë ‡ê²Œ ë‹µë³€ì„ í•´ì£¼ëŠ”ê±°ì—ìš” ì!ì´ë ‡ê²Œ ì˜ ë‚˜ì™”ì ¸ ì—¬ê¸°ì— ë‚´ìš©ë„ ë³´ë©´ ìŠ¤í”„ë¦¬ AI ë¸Œë¤¼í”„ì—ì„œ ê²€ìƒ‰í•´ì¤€ ê±°êµ¬ìš” ì •ë¦¬í•˜ìë©´ ìš°ë¦¬ê°€ ì´ì œ ë”” íŒŒì´ì—ì„œ ë§Œë“¤ì–´ë†“ìœ¼ì‹  ìˆ˜ë§ì€ ì›í´ í”„ë¡œë‘ êµ‰ì¥íˆ ì†ì‰½ê²Œ ìš°ë¦¬ í´ë¡¸ë“œ ë°ìŠ¤í¬íƒ‘ ì„ ë¶™ì—¬ê°€ì§€ê³  ì“¸ ìˆ˜ ìˆê²Œ ë˜ëŠ” ê²ë‹ˆë‹¤ ë§ˆì§€ë§‰ ìœ¼ë¡œ ì œê°€'},\n",
       " {'start': 1404.16,\n",
       "  'end': 1429.984,\n",
       "  'text': ' ì—¬ê¸°ì— ì˜ê°ì„ ì–»ì–´ì„œìš”, ë§Œë“  ë­ì²´ì¸ ë ê·¸ë˜í”„ ë°”ì´ë¸Œ ì½”ë” í”„ë¡œì íŠ¸ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”. ì´ RangchainRengraphBiveCoderProjectëŠ” RngChainARì—ì„œ ìµœê·¼ì— ê³µê°œí•œ MCPDocì´ë¼ëŠ” Projectê°€ ìˆëŠ”ë°ìš” ê±°ê¸°ì„œ ì˜ê° ë°›ì•„ì„œ ì €ë§Œì˜ ë°©ì‹ìœ¼ë¡œ í•œë²ˆ í’€ì–´ë´¤ì–´ìš” ì´ê±° ì˜ ë™ì‘ë°©ì‹ì€ ì €í¬ê°€ Cursa ARì´ë‚˜ Cloud Desktopì„ ë¬¼ë¦´ ê±´ë° ì œê°€ êµ¬í˜„ í•œ ë¶€ë¶„ ì€ ì—¬ê¸°ì„œë¶€í„° ì—¬ê¸°ê¹Œì§€ ë¼ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤ ê²°êµ­ ëª©ì ì´ ê±°ì—ìš” CurseARë¥¼ ì‚¬ìš©í•´ì„œ ì œê°€ ê·¸ë™ì•ˆ ë§Œë“¤ì–´ ë†¨ë˜ ìˆ˜ë§ì€ íŠœí† ë¦¬ì–¼'},\n",
       " {'start': 1429.984,\n",
       "  'end': 1459.776,\n",
       "  'text': ' ê·¸ ë‹¤ìŒì— ìµœê·¼ì— ì§„í–‰í–ˆë˜ ë­ì²´ì¸ ì˜¤í”ˆ íŠœí† ë¦¬ì–¼ ìë£Œë“¤ ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ Rangchain API ë ˆí¼ëŸ°ìŠ¤ ë„íë©˜í…Œì´ì…˜ì„ ì‚¬ìš©í•´ì„œ ì½”ë”© ì™¸ ì†ì€ ìµœëŒ€í•œ ëŒ€ì§€ ì•Šê³  ìš°ë¦¬ê°€ í”„ë¡¬í”„íŠ¸ ì…ë ¥ë§Œ ìœ¼ë¡œë„ í”„ë¡œì íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í• ìˆ˜ ìˆëŠ” ê·¸ëŸ° ë¨ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ìˆëŠ”ì§€ë¥¼ ì‹œí—˜í•´ë³´ê³ ì í–ˆë˜ê±°ì—ìš” ë§ì€ ë¶„ë“¤ ì•„ì‹œê² ì§€ë§Œ, ë  ì²´ì¸ë‚˜ ë Œ ê·¸ë˜í”„ì½”ë“œëŠ” êµ‰ì¥íˆ ë¹¨ë¦¬ ë°”ë€Œê²Œ ë˜ëŠ”ë° ê·¸ë˜ì„œ GPTë‚˜ í´ë¡œë“œ ì— ë¬¼ì–´ë´ë„ ì œëŒ€ë¡œ ëœ ì½”ë“œë¥¼ ì•ˆ ì¤ë‹ˆë‹¤. ê·¸ë§ì€ ë¬´ì¡°ê±´ reg system ì„ ì¨ì•¼ì§€ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ì½”ë”©ì„ ë°›ì„ ìˆ˜ ìˆë‹¤ëŠ” ê±´ë° ì§€ê¸ˆ í˜„ì¬ë¡œì„œëŠ” ì›¹ ì„œì¹˜ íˆ¬ë¥¼ ë¶™ì´ë‹¤ í•˜ë”ë¼ë„'},\n",
       " {'start': 1459.776,\n",
       "  'end': 1487.28,\n",
       "  'text': ' ì œëŒ€ë¡œ ëœ ì½”ë“œì— ëŒ€í•œ í”¼ë“œë°±ì„ ì•ˆ ì¤ë‹ˆë‹¤ ê·¸ë˜ì„œ ë­ê·¸ë˜í”„ë‚˜, ë ì²´ì¸ì½”ë“œë¥¼ ìš°ë¦¬ê°€ í”„ë¡¬í”„íŠ¸ ì…ë ¥ìœ¼ë¡œ ìë™í™” í•˜ëŠ” ê²ƒì€ êµ‰ì¥íˆ ì–´ë µê³ ìš” ì—¬ëŸ¬ë¶„ë“¤ í˜¹ì‹œ ìœ í”¼í‹°í•œí…Œ ë¬¼ì–´ë´ì„œ ì½”íŒ… í•˜ì‹  ë¶„ë“¤ì€ ëŒ€ë¶€ë¶„ì´ ì—„ì²­ ì˜›ë‚  ì½”ë“œëŠ” ì•„ì›ƒë°ì´íŠ¸ ë˜ëŠ” ì½”ë“œë§Œ ì¤„ ê±°ì—ìš”. ê±°ì˜ ì‹œë„í•˜ëŠ” ê²ƒ ì¡°ì°¨ ì €ëŠ” ì‹œê°„ ë‚­ë¹„ë¼ê³  ìƒê°ì´ ë“­ë‹ˆë‹¤ ê·¸ëŸ°ë° ëŒ€ì„¸ê°€ ë°”ì´ë¸Œì½”ë‹ í•˜ëŠ” ì‹œëŒ€ ì–ì•„ìš”? ì œê°€ ì–´ë–»ê²Œ í•˜ë©´ì€ ë°œí‘œí•  ìˆ˜ ìˆì„ê¹Œ ê³ ë¯¼í•˜ë‹¤ê°€ ì§€ê¸ˆê¹Œì§€ ë§Œë“¤ì–´ë†¨ë˜ ìë£Œì™€ ê·¸ ë‹¤ìŒì— ë§ ì²´ì¸ì„ ì œê³µí•œ ê³µì‹ API ë ˆí¼ëŸ°ìŠ¤ ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ì¿±ë¶ ì˜ˆì œë“¤ ì­‰'},\n",
       " {'start': 1487.28,\n",
       "  'end': 1516.96,\n",
       "  'text': \" ê¸ì–´ ëª¨ì•˜ì–´ìš”. ë¬¸ì„œí™” ì‹œí‚¤ë‹ˆê¹Œ ì—„ì²­ë‚˜ê²Œ ë‚´ìš©ì´ ë°©ëŒ€í•˜ë”ë¼êµ¬ìš” ê·¸ë˜ì„œ ê·¸ê±°ë¥¼ ë‘ ê°€ì§€ë¡œ í–ˆëŠ”ë° ë¨¼ì € ëª©ë¡í˜•ìœ¼ë¡œ ë‚˜ì—´ëœ LLM's textë¼ê³  ìˆëŠ”ë° ìµœê·¼ì— ì›¹ì‚¬ì´íŠ¸ ë‹¤ ì´ê±¸ ë‘ì ì´ê±°ì˜ˆìš”. LLMsë“¤ì´ ì›¹ ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ì‰½ê²Œ ê°€ì ¸ê°ˆ ìˆ˜ ìˆëŠ” ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¼ê³  ë³´ì‹œë©´ ë˜ìš” ê·¸ë˜ì„œ ëª©ë¡í˜• ìœ¼ë¡œ lms í…ìŠ¤íŠ¸ì˜ í˜•ì‹ì„ ë§ì¶° ë§Œë“¤ì–´ë†“ì€ ê·¸ëŸ° ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•´ë†¨ê³  ë˜ í•˜ë‚˜ëŠ” ë²¡í„° ì„œì¹˜ ì—¬ê¸°ì—ìˆëŠ” ë‚´ìš©ë“¤ì„ chunking í•˜ë‹ˆê¹Œ ë­ 2ë§Œê°œ ì´ìƒì˜ chunksê°€ ë‚˜ì˜¤ë”ë¼ê³ ìš”\"},\n",
       " {'start': 1516.96,\n",
       "  'end': 1540.752,\n",
       "  'text': ' ê°„ë‹¨í•œ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ í•˜ë‚˜ ë§Œë“¤ì—ˆì–´ìš”. ì´ ë ˆíŠ¸ë¦¬ ë²„ëŠ” ë­ê·¸ë˜í”„ í´ë¼ìš°ë“œì— í˜„ì¬ í˜¸ìŠ¤íŒ…ì„ í•´ ë†“ì€ ìƒíƒœê³ ìš” ê·¸ëŸ¬ë©´ ì´ í”Œë¡œìš°ê°€ ì–´ë–»ê²Œ ë˜ëƒë©´ ë§Œì•½ ì‚¬ìš©ìê°€ Rangraph ê´€ë ¨ëœ ì½”ë”© ì„ í•´ì¤˜ ë¼ê³  ìš”ì²­ì„ ë‚´ë¦¬ê²Œ ë˜ë©´ ì„œë²„ ê°€ ë¨¼ì € ë€ ê·¸ë˜í”„ë¡œ í´ë¼ìš°ë“œë¡œ ìš”ì²­í•˜ê²Œ ë©ë‹ˆë‹¤ ì´ë¥¼ ë§í¬ í´ë¼ë¸Œ ì•ˆì—ëŠ” ë²¡í„° db ì— ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆëŠ” ì •ë³´ë“¤ê³¼ lms í…ìŠ¤íŠ¸ì˜ ì •ë³´ ë“¤ì´ ê°€ì§€ê³  ìˆì–´ìš” ê·¸ëŸ¼ ì´ì•ˆ ì•±ë˜ í”„ë ˆ íƒœì›Œì„œ ì§€ì‹ ê²€ìƒ‰ ìˆ˜í–‰ í•˜ê²Œ ë˜ê³  2 ì½”ë””ë„ˆ ì‡¼ í•˜ê¸° ìœ„í•œ ì •ë³´ë¥¼ ë°˜í™˜í•´ ì¤ë‹ˆë‹¤'},\n",
       " {'start': 1540.752,\n",
       "  'end': 1567.952,\n",
       "  'text': ' í˜„ì¬ ì œê°€ ê°„ë‹¨í•˜ê²Œ í˜¸ìŠ¤íŒ…í•´ë†“ì€ ëœê·¸ë˜í”„ í´ë¼ìš°ë“œì— ë°°í¬ëœ ì´ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ë³¼ ìˆ˜ê°€ ìˆëŠ”ë°ìš”. ì´ ë ˆíŠ¸ë¦¬ê°€ ë°”ë¡œ ì§€ê¸ˆê¹Œì§€ ì •ë¦¬í•œ ìë£Œë“¤ê³¼ API ë ˆí¼ëŸ°ìŠ¤ë“¤ì„ ê²€ìƒ‰í•´ì£¼ëŠ” ê·¸ëŸ° Retrieverë¼ê³  ë³´ì‹œë©´ ë¼ìš” êµ¬ì¡° ìì²´ëŠ” êµ‰ì¥íˆ ì‹¬í”Œí•©ë‹ˆë‹¤ ê·¸ëŸ°ë° ì´ Retieber ê°€ ì´ì œ ë²¡í„° ë”¥ì´ ì €ì¥ë˜ì–´ ìˆëŠ” ê³³ì—ì„œ ê²€ìƒ‰ì„ í•´ì„œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ ì¤„ ê±°ì—ìš” ì˜ˆì‹œë¡œ ë³´ì—¬ë“œë¦¬ë©´ self query retrievers ë¼ê³  í•œë²ˆ ê²€ìƒ‰ í•´ ë´…ì‹œë‹¤ ì´ë ‡ê²Œ í•˜ë©´ ê²°ê³¼ ë“¤ì´ ë‚˜ì˜¤ê±°ë“ ìš” ì—¬ê¸° ë­ Raptor ë„ ìˆê³  ëª‡ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤'},\n",
       " {'start': 1567.952,\n",
       "  'end': 1591.328,\n",
       "  'text': ' í´ë¦­ì„ í–ˆë”ë‹ˆ ì´ì œ ì…€í”„ ì»¤ë¦¬ ê²€ìƒ‰ê¸° ë¼ê³  í•´ì„œ ìš” ë‚´ìš©ë“¤ì´ ë‚˜ì˜¤ëŠ” ê±¸ ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ì ê·¸ëŸ°ë° ì—¬ê¸°ì„œ ì¬ë¯¸ë‚œ ì‚¬ì‹¤ì€ ì´ ê´€ë ¨ëœ ë‚´ìš©ë“¤ì˜ ê²€ì¦ì´ ë˜ëŠ”ë° ì§€ê¸ˆ ë§í¬ ë“¤ë§Œ ì£¼ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆê±°ë“ ìš” ì´ê²Œ ì™œ ê·¸ëŸ¬ëƒë©´ ìš°ë¦¬ê°€ ì—ì´ì „íŠ¸ë¥¼ ì“°ê²Œ ë˜ë©´ ì€ ì•ˆì—ìˆëŠ” ë‚´ìš©ë“¤ì„ í•œë²ˆì— ë‹¤ ì¤„ í•„ìš”ê°€ ì—†ì–´ìš” ì´ë ‡ê²Œ ë§í¬ë“¤ì„ ë°˜í™˜ í•´ì£¼ë©´ íŒ¨ì¹˜ url ë„êµ¬ë¥¼ í•˜ë‚˜ ë” ë§Œë“¤ì–´ ë†¨ê±°ë“ ìš” ê·¸ëŸ¼ agent ê°€ ì´ë§ í¬ë“œë¥¼ ë°°ì¹˜ë¥¼ í•´ ê°€ì§€ê³  ê²°ê³¼ë¥¼ í•œ ë²ˆ ë” ê°€ì ¸ì˜µë‹ˆë‹¤ ê°€ì ¸ì™€ì„œ'},\n",
       " {'start': 1591.328,\n",
       "  'end': 1621.28,\n",
       "  'text': ' ê·¸ ë‚´ìš©ë“¤ì„ í•˜ë‚˜ì”© ë³´ë©´ì„œ ì–˜ê°€ ì•Œì•„ì„œ ì ìš©í•˜ê¸° ë•Œë¬¸ì— ì œê°€ í•´ë³´ë‹ˆê¹Œ ì»¨í…ì¸ ë¥¼ ë°”ë¡œ ë°˜í™˜ì„ í•˜ëŠ” ê²ƒë³´ë‹¤ ê·¸ëƒ¥ ì´ ë§í¬ë“¤ì„ ì£¼ëŠ” ê²Œ ë” ë‚«ê² ë”ë¼ê³ ìš” ê·¸ë˜ì„œ ì´ëŸ° ì‹ìœ¼ë¡œ ë„£ì–´ë†¨ê³ ìš” ì§€ê¸ˆ ë­ì²´ì¸ DevDocsë¥¼ ìƒˆë¡­ê²Œ ì¶”ê°€í•´ ë†“ì€ ìƒíƒœêµ¬ìš” ì ê·¸ëŸ¬ë©´ ì—¬ê¸° ë¹ˆ íŒŒì¼ì¸ë°, ì—¬ê¸°ì— ëª…ë ¹ì–´ë¥¼ í•œë²ˆ ë‚´ë ¤ë³´ì£ .'},\n",
       " {'start': 1621.28,\n",
       "  'end': 1650.448,\n",
       "  'text': ' ì´ë ‡ê²Œ í•´ë³¼ê²Œìš”. ì´ í‚¤ìœ„ì˜ BM25 ì‚¬ìš©í•˜ëŠ” ì˜ˆì œëŠ” ì •ë§ ì—†ê±°ë“ ìš” ì œê°€ ë§Œë“¤ì–´ ë†“ì€ íŠœí† ë¦¬ì–¼ì„ ì˜ ê²€ìƒ‰í•´ì„œ ê°€ì§€ê³  ì˜¤ëŠ”ì§€ í•œë²ˆ ë³¼ê²Œìš” ì ì´ëŸ¬ë©´ Search on RankChain Knowledge Baseë¥¼ ê²€ìƒ‰í•˜ê±°ë“ ìš” ê·¸ë˜ì„œ ì´ì œ Wikidocsë‘ ëª‡ ê°€ì§€ ì˜ˆì œë“¤ì„ ì§€ê¸ˆ ê²€ìƒ‰í–ˆì–´ìš” ì´ë ‡ê²Œ FetchDock ì„ í•´ê°€ì§€ê³  ë§í¬ë“¤ ì­‰ ë“¤ê³  ì˜µë‹ˆë‹¤ ì–˜ë„ fetch dock í•˜ê³ ìš” ì­ˆì¯•ì«‘ë“¤ê³  ì™€ì„œ ì–˜ê°€ í‚¤íŒŒì´íŒŒì´ë‘ ë­í¬BM 25ë¥¼ ì„¤ì¹˜í•´ìš” ì•Œì•„ì„œ ì„¤ì¹˜ë¥¼ í•˜ì£  ê·¸ ë‹¤ìŒì— kiwi-bm25 exampleì„ ë§Œë“­ë‹ˆë‹¤ ë§Œë“¤ì—ˆëŠ”ë° ì œê°€ ìœ„í‚¤ë…ìŠ¤ì— ì˜¬ë ¤ë†“ì€ ì˜ˆì œê°€ ìš”ê±°ì˜ˆìš” ìš”ëŸ° ì‹ìœ¼ë¡œ ì˜¬ë ¤ ë†¨ ê±°ë“ ìš” ì´ê±°ë¥¼ ì˜ ê°€ì ¸ì˜¤ëŠ”ì§€ í•œ ë²ˆ ë³´ê»˜'},\n",
       " {'start': 1650.448,\n",
       "  'end': 1677.664,\n",
       "  'text': ' ì ì´ëŸ°ì‹ìœ¼ë¡œ ì­‰ ê°€ì ¸ì™”êµ¬ìš”. ì—¬ê¸° acceptë§Œ ëˆ„ë¥´ë©´ ë˜ì£ ? ìš”ê²ƒë„ accept ë³´ë©´ì€ íŒŒì¼ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤, ì ë§Œë“¤ì—ˆê³ ìš” ì˜ˆì œì—ë³´ë©´ ê¸ˆìœµë³´í—˜ê¸ˆìœµì €ì¶•ë³´í—˜ë³´í—˜ì´ëŸ°ì˜ˆì œë“¤ì­ˆìš± ê°€ì§€ê³  ì˜¤ì–ì•„ìš” í•´ì„œ ì´ë ‡ê²Œ ë§Œë“œê±°ë“ ìš” ì–˜ê°€ ê·¼ë° ì—¬ê¸°ì— ì˜ˆì œë¥¼ ë³´ë©°ëŠ” ì´ê±° ì§„ì§œ ê´´í• í•œ.. ì˜ˆì  ë°...ì´ê±° ì œê°€ ë§Œë“¤ì–´ ë†“ì€ ì˜ˆì¬ì—ìš” ìš”ë ‡ê²Œ ì˜ ê²€ìƒ‰í•´ê°€ì§€ê³  ê°€ì§€ê³  ì˜¨ ê±°ë¥¼ ë³¼ ìˆ˜ê°€ ìˆì–´ìš” ê·¸ë˜ì„œ ì• ê°€ ì´ë¥´ì¼€ ë§Œë“¤ê³  ê·¸ ë‹¤ìŒì— í† í°í•˜ì´ì¦ˆë„ ë§Œë“¤êµ¬í•´ì„œ ìˆ˜í–‰ê¹Œì§€ í•´ê°€ì§€êµ¬ ë¦¬ì ˆíŠ¸ ê¹Œì§€ ë³´ëŠ” ê±° ìš”ë¡·ê²Œ ë§Œë“¤ì–´ì£¼ êµ¬ìš” ìš”ê±°ë¥¼ ì €í¬ê°€ ê°–ê³  ìˆëŠ” ë ˆê·¸ì²´ì¸ì´ë‘ ê²°í•©í•´ ê°€ì§€êµ¬'},\n",
       " {'start': 1677.664,\n",
       "  'end': 1699.2,\n",
       "  'text': ' ë©”ì¸ ì‹¤í–‰í•˜ë©´ ì´ë ‡ê²Œ ë‚˜ì˜¤ëŠ” ê²ƒê¹Œì§€ êµ‰ì¥íˆ ì˜ ë§Œë“¤ì–´ ì¤€ ê±¸ ë³¼ ìˆ˜ê°€ ìˆì£  ìš”ê±°ë¥¼ ë‚˜ì¤‘ì— ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°°í¬í•˜ê³  ì‹¶ë‹¤ ì´ëŸ¬ë©´ì€ ìŠ¤íŠ¸ë¦¼ ìœ„ì£¼ë¡œ ë² í”„ í•´ì£¼ë©´ë˜ìš” ì§€ê¸ˆ ì‹¤í–‰í•˜ë‹¤ê°€ ì˜¤ë¥˜ê°€ ë‚¬ê±°ë“ ìš” api í‚¤ ì—†ì–´ì„œ ê·¸ëŸ°ë° API í‚¤ë§Œ ë„£ì–´ì£¼ë©´ ë ê²ƒ ê°™ì•„ìš” MCP ìœ ìŠ¤ì¼€ì´ìŠ¤ëŠ” í¼ë¸”ë¦­ ìœ¼ë¡œ ê³µê°œë¥¼ í•´ì„œ ì˜ìƒ ë”ë³´ê¸° ë€ì— ë§í¬ë¥¼ ë‘˜ê²ë‹ˆë‹¤ ì—¬ëŸ¬ë¶„ë“¤ì´ ì—¬ê¸°ì— ë‚˜ì™€ìˆëŠ” use case ë³´ì‹œê³  í•œë²ˆ í•´ë³´ì‹œêµ¬ìš” ì•„ ë§ë‹¤ ì´ê±°ëŠ”'},\n",
       " {'start': 1699.2,\n",
       "  'end': 1716.048,\n",
       "  'text': ' í…Œë””ë…¸íŠ¸ íŒ€ì˜ í•œíƒë‹˜ê»˜ì„œ ì´ë ‡ê²Œ ì˜ ë§Œë“¤ì–´ì„œ ê³µìœ ë¥¼ í•´ì£¼ì…¨ì–´ìš”. ì˜ìƒì— ë¨¼ì € ë§ì”€ë“œë¦°ë‹¤ê³  í•˜ëŠ” ê±°ë¥¼ ê¹œë¹¡í–ˆë„¤ìš”. í•œíƒ±ë‹˜ì´ ì‰ê¸€ë¦¬ì‹œë‘ í•œêµ­ì–´ ë²„ì „ë„ ë”°ë¡œ ë§Œë“¤ì–´ ì¤¬ìœ¼ë‹ˆê¹Œ êµ‰ì¥íˆ ì¹œì ˆí•˜ê²Œ ì´ ë¬¸ì„œë“¤ì„ ì‘ì„±ì„ í•´ì¤¬ê±°ë“ ìš” ê·¸ëŸ¬ë‹ˆê¹Œ í•œë²ˆ ë³´ì‹œë©´ì„œ ë”°ë¼í•´ ë³´ì‹œë‹¤ê°€ ê¶ê¸ˆí•˜ì‹  ì  ìˆìœ¼ì‹œë©´ ë˜ ëŒ“ê¸€ ë‚¨ê²¨ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”'},\n",
       " {'start': 1716.048,\n",
       "  'end': 1745.488,\n",
       "  'text': ' 5ì½”ë”ë¥¼ ìœ„í•œ MCP ë­ì²´ì¸ë‹¥ìŠ¤ ì´ í”„ë¡œì íŠ¸ëŠ” ëŒì•„ì˜¤ëŠ” í† ìš”ì¼ë‚  íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì—ì„œ ì„¸ë¯¸ë‚˜ë¥¼ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ê·¸ ì„¸ë¯¸ë‚˜ ì•ˆì—ì„œ ë¨¼ì € ë§Œë“œëŠ” ê³¼ì •ë“¤ ì†Œê°œí•´ë“œë¦´ ê±°ê³ ìš” ê°•ì˜ë¥¼ ìˆ˜ê°•í•˜ì‹  ë¶„ë“¤ì€ ë³„ë„ ì‹ ì²­í•˜ì‹¤ í•„ìš” ì—†êµ¬ìš”, ê°•ì˜ìˆ˜ê°•í•˜ì§€ ì•ŠëŠ” ë¶„ë“¤ ì¤‘ì—ì„œëŠ” ì„¤ë¬¸ì§€ì— ì‘ì„±ì„ í•´ì£¼ì‹œë©´ì€ ì¶”ì²¨ì„ í†µí•´ì„œ ì„¸ë¯¸ ë‚˜ ì°¸ì„í•  ìˆ˜ ìˆëŠ” ë§í¬ë¡œ ë³´ë‚´ë“œë¦¬ê³  ìˆì–´ìš” ì„¸ë¯¼ì•„ë§Œ ì°¸ì—¬ í•˜ì‹¤ë¶„ë“¤ì€ ê·¸ë ‡ê²Œ ë”°ë¡œ ì„¤ëª… ì œì‹œí•´ ì£¼ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤ ê·¸ë•Œ ëŠ” ì´ì œ mcp ì¸ë²„ ë§Œë“ ê±°ì™€ ì–´ë–¤ ì‹ìœ¼ë¡œ ì§„í–‰í–ˆëŠ”ì§€ ì¢€ ë” ì„¸ì„¸í•˜ê²Œ ì‚´í´ ë³¼ ì˜ˆì •ì´ ë§ˆì§€ë§‰ìœ¼ë¡œ 5 ì½”ë”'},\n",
       " {'start': 1745.488,\n",
       "  'end': 1755.408,\n",
       "  'text': ' ë“œë¦¬ë©´ì„œ mcpì— ëŒ€í•´ì„œ ì „ë°˜ì ì¸ ë‚´ìš©ë“¤ì„ í•œë²ˆ ì‚´í´ë´¤ëŠ”ë°ìš”. ì œê³µí•´ë“œë¦¬ëŠ” íŠœí† ë¦¬ì–¼ ì˜ˆì œ ì½”ë“œë¥¼ í™œìš©í•´ì„œ ê¼­ í•œ ë²ˆ í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤ ì €ëŠ” ë‹¤ìŒ ì˜ìƒìœ¼ë¡œ ë˜ ëµ™ê² ìŠµë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import math\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import concurrent.futures\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import threading\n",
    "import ffmpeg\n",
    "\n",
    "class ProgressBar:\n",
    "    def __init__(self, total_size, desc=\"Downloading\"):\n",
    "        pbar = tqdm(total=total_size, unit=\"iB\", unit_scale=True, desc=desc)\n",
    "        lock = threading.Lock()\n",
    "\n",
    "    def update(self, size):\n",
    "        with lock:\n",
    "            pbar.update(size)\n",
    "\n",
    "    def close(self):\n",
    "        pbar.close()\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=0.1,\n",
    "        status_forcelist=[500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(\n",
    "        max_retries=retry,\n",
    "        pool_connections=100,\n",
    "        pool_maxsize=100\n",
    "    )\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "def download_chunk(args):\n",
    "    url, start, end, chunk_number, temp_dir, progress_bar = args\n",
    "    \n",
    "    headers = {\"Range\": f\"bytes={start}-{end}\"}\n",
    "    session = create_session()\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, headers=headers, stream=True)\n",
    "        chunk_path = os.path.join(temp_dir, f\"chunk_{chunk_number:04d}\")\n",
    "        \n",
    "        with open(chunk_path, \"wb\") as f:\n",
    "            for data in response.iter_content(chunk_size=8192):\n",
    "                size = f.write(data)\n",
    "                progress_bar.update(size)\n",
    "        \n",
    "        return chunk_path, chunk_number\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading chunk {chunk_number}: {str(e)}\")\n",
    "        return None, chunk_number\n",
    "\n",
    "def parallel_download(url, temp_dir, num_chunks=10):\n",
    "    session = create_session()\n",
    "    response = session.head(url)\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    \n",
    "    if total_size == 0:\n",
    "        raise ValueError(\"Could not determine file size\")\n",
    "    \n",
    "    chunk_size = total_size // num_chunks\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = start + chunk_size - 1 if i < num_chunks - 1 else total_size - 1\n",
    "        chunks.append((start, end))\n",
    "    \n",
    "    progress_bar = ProgressBar(total_size, \"Parallel downloading\")\n",
    "    \n",
    "    download_args = [\n",
    "        (url, start, end, i, temp_dir, progress_bar)\n",
    "        for i, (start, end) in enumerate(chunks)\n",
    "    ]\n",
    "    \n",
    "    chunk_paths = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_chunks) as executor:\n",
    "        futures = executor.map(download_chunk, download_args)\n",
    "        chunk_paths = [(path, num) for path, num in futures if path is not None]\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    chunk_paths.sort(key=lambda x: x[1])\n",
    "    output_path = os.path.join(temp_dir, \"complete_audio.mp4\")\n",
    "    \n",
    "    with open(output_path, \"wb\") as outfile:\n",
    "        for chunk_path, _ in chunk_paths:\n",
    "            with open(chunk_path, \"rb\") as infile:\n",
    "                outfile.write(infile.read())\n",
    "            os.remove(chunk_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def convert_to_wav(input_path, output_path):\n",
    "    \"\"\"MP4ë¥¼ WAVë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        stream = ffmpeg.input(input_path)\n",
    "        stream = ffmpeg.output(stream, output_path, \n",
    "                             acodec=\"pcm_s16le\", \n",
    "                             ar=\"16000\",\n",
    "                             ac=\"1\")\n",
    "        ffmpeg.run(stream, capture_stdout=True, capture_stderr=True)\n",
    "        return True\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"FFmpeg error:\", e.stderr.decode())\n",
    "        return False\n",
    "\n",
    "def process_audio_chunk(chunk_data):\n",
    "    \"\"\"ê°œë³„ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬\"\"\"\n",
    "    model, audio_path, start_time, duration = chunk_data\n",
    "    try:\n",
    "        segments, info = model.transcribe(\n",
    "            audio_path,\n",
    "            beam_size=5,\n",
    "            batch_size=32,\n",
    "            word_timestamps=True,\n",
    "            initial_prompt=None\n",
    "        )\n",
    "        \n",
    "        # segmentsë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ì‹œê°„ ì¡°ì •\n",
    "        chunk_segments = []\n",
    "        for segment in segments:\n",
    "            segment_dict = {\n",
    "                \"start\": segment.start + start_time,\n",
    "                \"end\": segment.end + start_time,\n",
    "                \"text\": segment.text,\n",
    "                \"words\": [\n",
    "                    {\n",
    "                        \"start\": word.start + start_time,\n",
    "                        \"end\": word.end + start_time,\n",
    "                        \"word\": word.word,\n",
    "                        \"probability\": word.probability\n",
    "                    }\n",
    "                    for word in segment.words\n",
    "                ]\n",
    "            }\n",
    "            chunk_segments.append(segment_dict)\n",
    "        \n",
    "        return chunk_segments\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk at {start_time}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_with_progress(url, model, chunk_duration=30, num_download_chunks=10):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        print(\"Starting parallel download...\")\n",
    "        mp4_path = parallel_download(url, temp_dir, num_download_chunks)\n",
    "        print(\"Download complete!\")\n",
    "        \n",
    "        # MP4ë¥¼ WAVë¡œ ë³€í™˜\n",
    "        wav_path = os.path.join(temp_dir, \"audio.wav\")\n",
    "        if not convert_to_wav(mp4_path, wav_path):\n",
    "            raise Exception(\"Failed to convert audio to WAV format\")\n",
    "        \n",
    "        # WAV íŒŒì¼ ì •ë³´ ì½ê¸°\n",
    "        wav_info = sf.info(wav_path)\n",
    "        total_duration = wav_info.duration\n",
    "        \n",
    "        # ì²­í¬ ê³„ì‚°\n",
    "        total_chunks = math.ceil(total_duration / chunk_duration)\n",
    "        \n",
    "        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        pbar = tqdm(total=total_chunks, desc=\"Processing audio chunks\")\n",
    "        \n",
    "        # ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "        chunks_data = []\n",
    "        for i in range(total_chunks):\n",
    "            start_time = i * chunk_duration\n",
    "            chunk_wav_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "            \n",
    "            # ì²­í¬ ì¶”ì¶œ\n",
    "            duration = min(chunk_duration, total_duration - start_time)\n",
    "            stream = ffmpeg.input(wav_path, ss=start_time, t=duration)\n",
    "            stream = ffmpeg.output(stream, chunk_wav_path, \n",
    "                                 acodec=\"pcm_s16le\", \n",
    "                                 ar=\"16000\",\n",
    "                                 ac=\"1\")\n",
    "            ffmpeg.run(stream, quiet=True)\n",
    "            \n",
    "            chunks_data.append((model, chunk_wav_path, start_time, duration))\n",
    "        \n",
    "        # ì²­í¬ ì²˜ë¦¬ ë° ê²°ê³¼ ìˆ˜ì§‘\n",
    "        all_segments = []\n",
    "        for chunk_data in chunks_data:\n",
    "            segments = process_audio_chunk(chunk_data)\n",
    "            all_segments.extend(segments)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # ì‚¬ìš©í•œ ì²­í¬ íŒŒì¼ ì‚­ì œ\n",
    "            if os.path.exists(chunk_data[1]):\n",
    "                os.remove(chunk_data[1])\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "    return all_segments\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = WhisperModel(\n",
    "    \"large-v3\", \n",
    "    device=\"cuda\", \n",
    "    compute_type=\"float16\"  # bfloat16 ëŒ€ì‹  float16 ì‚¬ìš©\n",
    ")\n",
    "print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "model = BatchedInferencePipeline(model=model)\n",
    "\n",
    "# íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì‹¤í–‰\n",
    "segments = process_with_progress(\n",
    "    audio_stream.url,\n",
    "    model,\n",
    "    chunk_duration=30,\n",
    "    num_download_chunks=10\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "for i, segment in enumerate(segments):\n",
    "    print(f\"{segment[\"start\"]:.2f} -> {segment[\"end\"]:.2f}: {segment[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://youtu.be/AA621UofTUA?si=gn4XutRMWUDSYLFL\"\n",
    "\n",
    "# from faster_whisper import WhisperModel\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "# import tempfile\n",
    "# import os\n",
    "# import ffmpeg\n",
    "# import subprocess\n",
    "# from yt_dlp import YoutubeDL\n",
    "# import io\n",
    "\n",
    "# def get_audio_stream(url):\n",
    "#     \"\"\"URLì—ì„œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "#     ydl_opts = {\n",
    "#         \"format\": \"bestaudio/best\",\n",
    "#         \"quiet\": True,\n",
    "#         \"no_warnings\": True,\n",
    "#         \"extract_audio\": True\n",
    "#     }\n",
    "    \n",
    "#     with YoutubeDL(ydl_opts) as ydl:\n",
    "#         info = ydl.extract_info(url, download=False)\n",
    "#         audio_url = info[\"url\"]\n",
    "#         duration = info.get(\"duration\", 0)\n",
    "        \n",
    "#         return audio_url, duration\n",
    "\n",
    "# def process_stream_with_progress(url, model, chunk_duration=30):\n",
    "#     \"\"\"\n",
    "#     ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - url: ì˜¤ë””ì˜¤ URL\n",
    "#     - model: WhisperModel ì¸ìŠ¤í„´ìŠ¤\n",
    "#     - chunk_duration: ê° ì²­í¬ì˜ ê¸¸ì´(ì´ˆ)\n",
    "#     \"\"\"\n",
    "#     # ìŠ¤íŠ¸ë¦¼ URL ê°€ì ¸ì˜¤ê¸°\n",
    "#     audio_url, total_duration = get_audio_stream(url)\n",
    "    \n",
    "#     # ffmpeg ëª…ë ¹ì–´ ì„¤ì •\n",
    "#     ffmpeg_cmd = [\n",
    "#         \"ffmpeg\",\n",
    "#         \"-i\", audio_url,\n",
    "#         \"-f\", \"wav\",\n",
    "#         \"-ar\", \"16000\",\n",
    "#         \"-ac\", \"1\",\n",
    "#         \"-hide_banner\",\n",
    "#         \"-loglevel\", \"error\",\n",
    "#         \"pipe:1\"\n",
    "#     ]\n",
    "    \n",
    "#     # ì§„í–‰ë¥  í‘œì‹œ ì„¤ì •\n",
    "#     total_chunks = int(np.ceil(total_duration / chunk_duration))\n",
    "#     pbar = tqdm(total=total_chunks, desc=\"Processing audio chunks\")\n",
    "    \n",
    "#     # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "#     all_segments = []\n",
    "    \n",
    "#     try:\n",
    "#         # ffmpeg í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n",
    "#         process = subprocess.Popen(\n",
    "#             ffmpeg_cmd,\n",
    "#             stdout=subprocess.PIPE,\n",
    "#             bufsize=10**8  # ë²„í¼ í¬ê¸° ì„¤ì •\n",
    "#         )\n",
    "        \n",
    "#         # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "#         with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#             chunk_size = int(16000 * chunk_duration * 2)  # 16000Hz * seconds * 2 bytes per sample\n",
    "#             chunk_number = 0\n",
    "            \n",
    "#             while True:\n",
    "#                 # ì²­í¬ ì½ê¸°\n",
    "#                 audio_chunk = process.stdout.read(chunk_size)\n",
    "#                 if not audio_chunk:\n",
    "#                     break\n",
    "                \n",
    "#                 # ì²­í¬ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "#                 chunk_path = os.path.join(temp_dir, f\"chunk_{chunk_number}.wav\")\n",
    "#                 with open(chunk_path, \"wb\") as f:\n",
    "#                     # WAV í—¤ë” ì‘ì„±\n",
    "#                     f.write(b\"RIFF\")\n",
    "#                     f.write((chunk_size + 36).to_bytes(4, \"little\"))\n",
    "#                     f.write(b\"WAVE\")\n",
    "#                     f.write(b\"fmt \")\n",
    "#                     f.write((16).to_bytes(4, \"little\"))\n",
    "#                     f.write((1).to_bytes(2, \"little\"))  # PCM\n",
    "#                     f.write((1).to_bytes(2, \"little\"))  # Mono\n",
    "#                     f.write((16000).to_bytes(4, \"little\"))  # Sample rate\n",
    "#                     f.write((32000).to_bytes(4, \"little\"))  # Byte rate\n",
    "#                     f.write((2).to_bytes(2, \"little\"))  # Block align\n",
    "#                     f.write((16).to_bytes(2, \"little\"))  # Bits per sample\n",
    "#                     f.write(b\"data\")\n",
    "#                     f.write(len(audio_chunk).to_bytes(4, \"little\"))\n",
    "#                     f.write(audio_chunk)\n",
    "                \n",
    "#                 try:\n",
    "#                     # ì²­í¬ ì²˜ë¦¬\n",
    "#                     segments, _ = model.transcribe(\n",
    "#                         chunk_path,\n",
    "#                         beam_size=5,\n",
    "#                         batch_size=32,\n",
    "#                         word_timestamps=True,\n",
    "#                         condition_on_previous_text=True\n",
    "#                     )\n",
    "                    \n",
    "#                     # ì‹œê°„ ì˜¤í”„ì…‹ ì¡°ì • ë° ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥\n",
    "#                     time_offset = chunk_number * chunk_duration\n",
    "#                     for segment in segments:\n",
    "#                         segment_dict = {\n",
    "#                             \"start\": segment.start + time_offset,\n",
    "#                             \"end\": segment.end + time_offset,\n",
    "#                             \"text\": segment.text,\n",
    "#                             \"words\": [\n",
    "#                                 {\n",
    "#                                     \"start\": word.start + time_offset,\n",
    "#                                     \"end\": word.end + time_offset,\n",
    "#                                     \"word\": word.word,\n",
    "#                                     \"probability\": word.probability\n",
    "#                                 }\n",
    "#                                 for word in segment.words\n",
    "#                             ]\n",
    "#                         }\n",
    "#                         all_segments.append(segment_dict)\n",
    "                \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing chunk {chunk_number}: {str(e)}\")\n",
    "                \n",
    "#                 finally:\n",
    "#                     # ì„ì‹œ íŒŒì¼ ì‚­ì œ\n",
    "#                     if os.path.exists(chunk_path):\n",
    "#                         os.remove(chunk_path)\n",
    "                \n",
    "#                 # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "#                 pbar.update(1)\n",
    "#                 chunk_number += 1\n",
    "    \n",
    "#     finally:\n",
    "#         pbar.close()\n",
    "#         if process.poll() is None:\n",
    "#             process.terminate()\n",
    "#             process.wait()\n",
    "    \n",
    "#     return all_segments\n",
    "\n",
    "# # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = WhisperModel(\n",
    "#     \"large-v3\", \n",
    "#     device=\"cuda\", \n",
    "#     compute_type=\"float16\"\n",
    "# )\n",
    "# print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# # íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì‹¤í–‰\n",
    "# segments = process_stream_with_progress(\n",
    "#     url,  # ìœ íŠœë¸Œ URL\n",
    "#     model,\n",
    "#     chunk_duration=30\n",
    "# )\n",
    "\n",
    "# # ê²°ê³¼ ì¶œë ¥\n",
    "# for segment in segments:\n",
    "#     print(f\"{segment[\"start\"]:.2f} -> {segment[\"end\"]:.2f}: {segment[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"script.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "            Document(page_content=\"\\n\".join([t[\"text\"] for t in data]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def calculate_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_tokens(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "summarize_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000, chunk_overlap=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = summarize_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(split_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import hub\n",
    "summary_prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7, streaming=True)\n",
    "summary_chain = create_stuff_documents_chain(llm, summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumaries = []\n",
    "for split_doc in split_docs:\n",
    "    print(type(split_doc.page_content))\n",
    "    partial_summary = summary_chain.invoke({\"context\": [split_doc]})\n",
    "    sumaries.append(partial_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_summary = Document(page_content= \"\\n\".join(sumaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_RESULT = summary_chain.invoke(\n",
    "                {\"context\": partial_summaries_doc}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SUMMARY_RESULT.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_qa_with_sources_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pytubefix import YouTube\n",
    "import asyncio\n",
    "import torch\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì •\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(url):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    return {\n",
    "        \"title\": yt.title,\n",
    "        \"audio_url\": audio_stream.url if audio_stream else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/shorts/a--NSC19MXM\"\n",
    "video_info = get_video_info(video_url)\n",
    "print(f\"Video Title: {video_info[\"title\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = WhisperModel(\"large-v3\", device=device, compute_type=compute_type)\n",
    "\n",
    "def transcribe_audio(audio_url):\n",
    "    segments, info = whisper_model.transcribe(audio_url)\n",
    "    transcript = [{\"text\": segment.text, \"start\": segment.start, \"end\": segment.end} for segment in segments]\n",
    "    return {\"script\": transcript, \"language\": info.language}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = transcribe_audio(video_info[\"audio_url\"])\n",
    "print(f\"Transcript Language: {transcript[\"language\"]}\")\n",
    "print(f\"First few lines of transcript: {transcript[\"script\"][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "summary_prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            streaming=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader, TextLoader\n",
    "docs = TextLoader(\"script.txt\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "document = [Document(page_content=\"\\n\".join([t[\"text\"] for t in transcript[\"script\"]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = create_stuff_documents_chain(llm,summary_prompt)\n",
    "result = await summary_chain.ainvoke({\"context\": document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([t[\"text\"] for t in transcript[\"script\"]])\n",
    "for doc in documents:\n",
    "    doc.page_content += \"\\n\" + summary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "you_url = \"https://youtube.com/shorts/a--NSC19MXM?si=yiun-HK_7wX1sNvL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = \"https://api.runpod.ai/v2/uq96boxkzy99ev/runsync\"\n",
    "\n",
    "# FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„° (ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„° ì„¤ì •)\n",
    "body = {\"input\":{\n",
    "    \"api\":{\n",
    "        \"method\":\"POST\",\n",
    "        \"endpoint\":\"/ping\",\n",
    "    },\n",
    "    \"payload\":{},\n",
    "}}\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# ì‘ì—… ID (ì‘ì—… ì™„ë£Œëœ job ID)\n",
    "job_id = response.json()[\"id\"]\n",
    "\n",
    "# RunPod API STATUS ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "status_url = f\"https://api.runpod.ai/v2/wm1xrz07all039/status/{job_id}\"\n",
    "\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ í™•ì¸ ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.get(status_url, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    job_result = response.json()\n",
    "    if job_result.get(\"status\") == \"COMPLETED\":\n",
    "        print(\"Job Completed! Result:\", job_result.get(\"output\"))\n",
    "    else:\n",
    "        print(f\"Job Status: {job_result.get(\"status\")}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = f\"https://api.runpod.ai/v2/{endpoint_id}/runsync\"\n",
    "you_url = \"https://youtu.be/omEk2BNDt1I?si=xjtbYANtlux5CTfB\"\n",
    "\n",
    "\n",
    "# FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„°\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"endpoint\": \"/get_title_hash\",\n",
    "        \"method\": \"GET\",\n",
    "        # \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "        \"params\": {\"url\": you_url},\n",
    "    }\n",
    "}\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "# api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "# endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# # RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "# url = f\"https://api.runpod.ai/v2/{endpoint_id}/runsync\"\n",
    "\n",
    "# # FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„°\n",
    "# payload = {\n",
    "#     \"input\": {\n",
    "#         \"endpoint\": \"/get_script_summary\",\n",
    "#         \"method\": \"GET\",\n",
    "#         \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "#         \"params\": {\"url\": you_url},\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {api_key}\",\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "# # RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "# response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# # ì‘ë‹µ í™•ì¸\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Response:\", response.json())\n",
    "# else:\n",
    "#     print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = f\"https://api.runpod.ai/v2/{endpoint_id}/run\"\n",
    "\n",
    "# FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„°\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"endpoint\": \"/get_script_summary\",\n",
    "        \"method\": \"GET\",\n",
    "        \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "        \"params\": {\"url\": you_url},\n",
    "    }\n",
    "}\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Initial Response:\", result)\n",
    "    \n",
    "    if result.get(\"status\") in [\"IN_PROGRESS\",\"IN_QUEUE\"]:\n",
    "        job_id = result.get(\"id\")\n",
    "        status_url = f\"https://api.runpod.ai/v2/{endpoint_id}/status/{job_id}\"\n",
    "        \n",
    "        while True:\n",
    "            status_response = requests.get(status_url, headers=headers)\n",
    "            if status_response.status_code == 200:\n",
    "                status_data = status_response.json()\n",
    "                print(f\"Current status: {status_data.get(\"status\")}\")\n",
    "                \n",
    "                if status_data.get(\"status\") == \"COMPLETED\":\n",
    "                    print(f\"ê²°ê³¼ê°’:{status_data}\")\n",
    "                    result_url = f\"https://api.runpod.ai/v2/{endpoint_id}/result/{job_id}\"\n",
    "                    result_response = requests.get(result_url, headers=headers)\n",
    "                    \n",
    "                    if result_response.status_code == 200:\n",
    "                        final_result = result_response.json()\n",
    "                        print(\"Final Result:\", final_result)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Error fetching results: {result_response.status_code}\")\n",
    "                        print(f\"Error message: {result_response.text}\")\n",
    "                        break\n",
    "                elif status_data.get(\"status\") == \"FAILED\":\n",
    "                    print(\"Job failed\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Error checking status: {status_response.status_code}\")\n",
    "                print(f\"Error message: {status_response.text}\")\n",
    "                break\n",
    "            \n",
    "            time.sleep(5)  # 5ì´ˆ ëŒ€ê¸° í›„ ë‹¤ì‹œ ìƒíƒœ í™•ì¸\n",
    "    else:\n",
    "        print(\"Job completed immediately\")\n",
    "        print(\"Final Result:\", result)\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = f\"https://api.runpod.ai/v2/{endpoint_id}/status/{job_id}\"\n",
    "url2 = f\"https://api.runpod.ai/v2/{endpoint_id}/result/{job_id}\"\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "while True:\n",
    "    # RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "    response = requests.get(url,headers=headers)\n",
    "\n",
    "    # ì‘ë‹µ í™•ì¸\n",
    "    if response.status_code == 200:\n",
    "        if response.json().get(\"status\") == \"COMPLETED\":\n",
    "            response = requests.get(url2,headers=headers)\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Job status: {response.json().get(\"status\")}\")\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "RUNPOD_API_URL = f\"https://api.runpod.ai/v2/{endpoint_id}/runsync\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"endpoint\": \"/rag_stream_chat\",\n",
    "        \"method\": \"POST\",\n",
    "        \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "        \"params\": {\"prompt\": \"ì˜ìƒì˜ ì£¼ì œê°€ ë­”ê°€ìš”?\"},\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    RUNPOD_API_URL, headers=headers, json=payload, stream=True\n",
    ")\n",
    "\n",
    "# for chunk in response.iter_content(chunk_size=None):\n",
    "#     if chunk:\n",
    "#         chunk_data = chunk.decode(\"utf-8\").strip()\n",
    "#         if chunk_data.startswith(\"data: \"):\n",
    "#             chunk_content = chunk_data[6:]\n",
    "#             if chunk_content == \"[DONE]\":\n",
    "#                 break\n",
    "#             try:\n",
    "#                 content = json.loads(chunk_content)\n",
    "#                 print(\"Stream content:\", content)\n",
    "#             except json.JSONDecodeError:\n",
    "#                 print(\"Invalid JSON:\", chunk_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\n",
    "for chunk in response.json().get(\"output\"):\n",
    "    answer += chunk.get(\"content\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"script.txt\",\"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "url = \"https://www.youtube.com/watch?v=yF_YIxxjWU4\"\n",
    "yt = YouTube(url, use_po_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1RPJ223J7MY4YHK5UDRZ5F05GBFX7H9C4R8R5RW\n",
    "S1RPJ223J7MY4YHK5UDRZ5FO5GBFX7H9C4R8R5RW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "cookie_data = os.getenv(\"YOUTUBE_COOKIES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "cookie_data = base64.b64decode(cookie_data).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'domain': '.youtube.com',\n",
       "  'expirationDate': 1761776434.318973,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': 'LOGIN_INFO',\n",
       "  'path': '/',\n",
       "  'sameSite': 'no_restriction',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'AFmmF2swRQIgTeEWqOY9Z_6OixLw2Vtg4geLBxPWddIDQpA4COLU_w0CIQCqFau5rdTu8mpMmGvpI8uZqqZk8EHqKy8f3wUc9MJP3A:QUQ3MjNmemVwa3pObTg4QmlDa3FMaUdOTEEtZ1dPdWNfUjdYUFI5V3I1OUZ0VjdqRDJWSUM0Q3UwU0NqN3JwZVh1TVctYUpfRWJkRnUyVE1YTHNaT0tmT3dvLTNNbUw1WlFkZ2JRdFZtdndwME55YjQ4elpUdXRHdXZZNENkdjVrQkt5VFBjOVE4YmhjaFBmbmZpNXk4bWk5WXl0TkFzajF3'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.70996,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': 'HSID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'AWsS9hESIEnYMsU-A'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.710192,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': 'SSID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'AJi2nJkY2L-Yggyor'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.710439,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'APISID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'Ka3V_eFb1cAj_a9a/ApAugbpab_Nmh9joG'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.710549,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'SAPISID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'MLUWJ6icCQqiORUf/AZpqx2XzVfuKRHFXd'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.710644,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': '__Secure-1PAPISID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'MLUWJ6icCQqiORUf/AZpqx2XzVfuKRHFXd'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.710727,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': '__Secure-3PAPISID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'no_restriction',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'MLUWJ6icCQqiORUf/AZpqx2XzVfuKRHFXd'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1775102280.64494,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'PREF',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'f6=40000080&repeat=NONE&tz=Asia.Seoul&f7=100'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.711261,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'SID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'g.a000twixe91NaNcQDevwyL_O7gusj1AiqlcIKaejh21ozIM5e1aTtsfFd6-A7F73n1nwJ1qdqgACgYKAbQSARISFQHGX2MiX7fLwCpHI0vqFnWIzuV0nxoVAUF8yKrr5suNTfPF3rBqmbHottKD0076'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.711331,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': '__Secure-1PSID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'g.a000twixe91NaNcQDevwyL_O7gusj1AiqlcIKaejh21ozIM5e1aTqpB0K9yBIBaU3ScWiXuoAwACgYKAQISARISFQHGX2MivMNK5wIRTNpnwlYZM3xFNxoVAUF8yKq3LakDSayzg2pCPVgH61lg0076'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1774327408.711403,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': '__Secure-3PSID',\n",
       "  'path': '/',\n",
       "  'sameSite': 'no_restriction',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'g.a000twixe91NaNcQDevwyL_O7gusj1AiqlcIKaejh21ozIM5e1aTMjor4Q-eAMtm9lYcdENxZAACgYKAbgSARISFQHGX2MitDsvozbD751SpkVcz8QKVBoVAUF8yKrwe1k_GE9DrEDX_Tivx-Pm0076'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1740542286,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'ST-1b',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'disableCache=true&itct=CBYQsV4iEwiQ4qSiueCLAxXE7UwCHS0bDKc%3D&csn=e5uzKG5E76jxWGyE&session_logininfo=AFmmF2swRQIgTeEWqOY9Z_6OixLw2Vtg4geLBxPWddIDQpA4COLU_w0CIQCqFau5rdTu8mpMmGvpI8uZqqZk8EHqKy8f3wUc9MJP3A%3AQUQ3MjNmemVwa3pObTg4QmlDa3FMaUdOTEEtZ1dPdWNfUjdYUFI5V3I1OUZ0VjdqRDJWSUM0Q3UwU0NqN3JwZVh1TVctYUpfRWJkRnUyVE1YTHNaT0tmT3dvLTNNbUw1WlFkZ2JRdFZtdndwME55YjQ4elpUdXRHdXZZNENkdjVrQkt5VFBjOVE4YmhjaFBmbmZpNXk4bWk5WXl0TkFzajF3&endpoint=%7B%22clickTrackingParams%22%3A%22CBYQsV4iEwiQ4qSiueCLAxXE7UwCHS0bDKc%3D%22%2C%22commandMetadata%22%3A%7B%22webCommandMetadata%22%3A%7B%22url%22%3A%22%2F%22%2C%22webPageType%22%3A%22WEB_PAGE_TYPE_BROWSE%22%2C%22rootVe%22%3A3854%2C%22apiUrl%22%3A%22%2Fyoutubei%2Fv1%2Fbrowse%22%7D%7D%2C%22browseEndpoint%22%3A%7B%22browseId%22%3A%22FEwhat_to_watch%22%7D%7D'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1740542286,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'ST-yve142',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'session_logininfo=AFmmF2swRQIgTeEWqOY9Z_6OixLw2Vtg4geLBxPWddIDQpA4COLU_w0CIQCqFau5rdTu8mpMmGvpI8uZqqZk8EHqKy8f3wUc9MJP3A%3AQUQ3MjNmemVwa3pObTg4QmlDa3FMaUdOTEEtZ1dPdWNfUjdYUFI5V3I1OUZ0VjdqRDJWSUM0Q3UwU0NqN3JwZVh1TVctYUpfRWJkRnUyVE1YTHNaT0tmT3dvLTNNbUw1WlFkZ2JRdFZtdndwME55YjQ4elpUdXRHdXZZNENkdjVrQkt5VFBjOVE4YmhjaFBmbmZpNXk4bWk5WXl0TkFzajF3'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1740542287,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'ST-tladcw',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'session_logininfo=AFmmF2swRQIgTeEWqOY9Z_6OixLw2Vtg4geLBxPWddIDQpA4COLU_w0CIQCqFau5rdTu8mpMmGvpI8uZqqZk8EHqKy8f3wUc9MJP3A%3AQUQ3MjNmemVwa3pObTg4QmlDa3FMaUdOTEEtZ1dPdWNfUjdYUFI5V3I1OUZ0VjdqRDJWSUM0Q3UwU0NqN3JwZVh1TVctYUpfRWJkRnUyVE1YTHNaT0tmT3dvLTNNbUw1WlFkZ2JRdFZtdndwME55YjQ4elpUdXRHdXZZNENkdjVrQkt5VFBjOVE4YmhjaFBmbmZpNXk4bWk5WXl0TkFzajF3'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1772078282.5309,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': '__Secure-1PSIDTS',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'sidts-CjIBEJ3XVzDf85tuOkEK3FzAPGwKPf1HW4HztizgaYZdgo_IZJWehWhNpX6x8IhFtVd8oBAA'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1772078282.530963,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': '__Secure-3PSIDTS',\n",
       "  'path': '/',\n",
       "  'sameSite': 'no_restriction',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'sidts-CjIBEJ3XVzDf85tuOkEK3FzAPGwKPf1HW4HztizgaYZdgo_IZJWehWhNpX6x8IhFtVd8oBAA'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1740542287,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'ST-3opvp5',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'session_logininfo=AFmmF2swRQIgTeEWqOY9Z_6OixLw2Vtg4geLBxPWddIDQpA4COLU_w0CIQCqFau5rdTu8mpMmGvpI8uZqqZk8EHqKy8f3wUc9MJP3A%3AQUQ3MjNmemVwa3pObTg4QmlDa3FMaUdOTEEtZ1dPdWNfUjdYUFI5V3I1OUZ0VjdqRDJWSUM0Q3UwU0NqN3JwZVh1TVctYUpfRWJkRnUyVE1YTHNaT0tmT3dvLTNNbUw1WlFkZ2JRdFZtdndwME55YjQ4elpUdXRHdXZZNENkdjVrQkt5VFBjOVE4YmhjaFBmbmZpNXk4bWk5WXl0TkFzajF3'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1772078285.12273,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': False,\n",
       "  'name': 'SIDCC',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': False,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'AKEyXzWCPeicpoMl_KFGpPCoMrnr2G2DsgQyXB5m5_UPGDRLkG_drtSc1glzvtGkXqDlF0Abyg'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1772078285.122929,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': '__Secure-1PSIDCC',\n",
       "  'path': '/',\n",
       "  'sameSite': 'unspecified',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'AKEyXzV7S4IegmqpS6ZT9DRWMNvd2EH5uK8QSvCbtl4Zl_oz5yEBL1xAXw8YDMmmRAPmrgbV1e8'},\n",
       " {'domain': '.youtube.com',\n",
       "  'expirationDate': 1772078285.123041,\n",
       "  'hostOnly': False,\n",
       "  'httpOnly': True,\n",
       "  'name': '__Secure-3PSIDCC',\n",
       "  'path': '/',\n",
       "  'sameSite': 'no_restriction',\n",
       "  'secure': True,\n",
       "  'session': False,\n",
       "  'storeId': '0',\n",
       "  'value': 'AKEyXzWksndwB5bSAix4qM7a-MmqBYZeRYBzWKnrVK_JSRv7ketFJ_pohhSQ-jiF8YEPDsR5e14'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookie_data\n",
    "import json\n",
    "\n",
    "cookie_data = json.loads(cookie_data)\n",
    "cookie_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
