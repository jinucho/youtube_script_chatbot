{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-12 08:58:01 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='beomi/Qwen2.5-7B-Instruct-kowiki-qa-context', speculative_config=None, tokenizer='beomi/Qwen2.5-7B-Instruct-kowiki-qa-context', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=beomi/Qwen2.5-7B-Instruct-kowiki-qa-context, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 11-12 08:58:02 model_runner.py:915] Starting to load model beomi/Qwen2.5-7B-Instruct-kowiki-qa-context...\n",
      "INFO 11-12 08:58:02 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ba5a76387242f7966bfb891cbfbbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-12 08:58:04 model_runner.py:926] Loading model weights took 14.2487 GB\n",
      "INFO 11-12 08:58:07 gpu_executor.py:122] # GPU blocks: 2657, # CPU blocks: 4681\n",
      "INFO 11-12 08:58:08 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-12 08:58:08 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-12 08:58:15 model_runner.py:1335] Graph capturing finished in 7 secs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import VLLM\n",
    "from langchain_teddynote.messages import stream_response\n",
    "# vllm 0.6.0\n",
    "\n",
    "llm = VLLM(\n",
    "    model=\"beomi/Qwen2.5-7B-Instruct-kowiki-qa-context\",\n",
    "    trust_remote_code=True,  # Hugging Face ëª¨ë¸ì˜ ê²½ìš° í•„ìˆ˜\n",
    "    max_new_tokens=256,\n",
    "    top_k=1,\n",
    "    top_p=0.9,\n",
    "    temperature=0.5,\n",
    "    dtype = \"bfloat16\",\n",
    "    eos_token_id=151643)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10992/264388901.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a highly capable AI assistant. Please answer the given questions in Korean.\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.23s/it, est. speed input: 10.40 toks/s, output: 60.54 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPT-4oì— ëŒ€í•œ ê³µì‹ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GPT-3ì˜ ê²½ìš°, ìž…ë ¥ í† í°ì€ 2048ê°œ, ì¶œë ¥ í† í°ì€ ì´ì™€ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ì œí•œë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ GPT-4oê°€ ì‹¤ì œë¡œ ì¡´ìž¬í•˜ê³  ì´ì™€ ë‹¤ë¥¸ ì„±ëŠ¥ì„ ê°€ì§„ë‹¤ë©´, ì •í™•í•œ ìˆ«ìžëŠ” ê³µê°œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìµœì‹  ì •ë³´ë¥¼ ì–»ìœ¼ë ¤ë©´ ê´€ë ¨ ê¸°ê´€ì´ë‚˜ ê°œë°œìžì—ê²Œ ì§ì ‘ ë¬¸ì˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. \n",
      "GPT-4oì— ëŒ€í•œ ì •ë³´ê°€ ì—†ë‹¤ë©´, GPT-3ì˜ ê²½ìš° ìµœëŒ€ ìž…ë ¥ í† í°ê³¼ ì¶œë ¥ í† í°ì€ ê°ê° 2048ê°œìž…ë‹ˆë‹¤. ì´ ì •ë³´ê°€ GPT-4oì— ì ìš©ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. \n",
      "ë‹µë³€: GPT-4oì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, GPT-3ì˜ ê²½ìš° ìµœëŒ€ ìž…ë ¥ í† í°ê³¼ ì¶œë ¥ í† í°ì€ ê°ê° 2048ê°œìž…ë‹ˆë‹¤. \n",
      "(ë§Œì•½ GPT-4oì— ëŒ€í•œ ì •ë³´ê°€ ìžˆë‹¤ë©´, ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer = llm_chain.invoke(\"gpt-4oì˜ ìµœëŒ€ ìž…ì¶œë ¥ í† í°ì€ ëª‡ì¸ê°€ìš”?\")[\"text\"]\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/0f7nfvt16ln8630csjtkk_1w0000gn/T/ipykernel_78641/2497576997.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000, chunk_overlap=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"script.json\", \"r\") as f:\n",
    "    script_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"test1234\",exist_ok=True)\n",
    "with open(\"test1234/transcript.json\", \"w\") as f:\n",
    "    json.dump(script_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "            Document(page_content=\"\\n\".join([t[\"text\"] for t in script_data]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = summarize_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store.save_local(\"test1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store_load = FAISS.load_local(\"test11\", embeddings=embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"In the last chapter, you and I started to step through the internal workings of a transformer.\\nThis is one of the key pieces of technology inside large language models, and a lot of\\nother tools in the modern wave of AI.\\nIt first hit the scene in a now-famous 2017 paper called Attention is All You Need, and\\nin this chapter, you and I will dig into what this attention mechanism is, visualizing how\\nit processes data.\\nAs a quick recap, here's the important context I want you to have in mind.\\nThe goal of the model that you and I are studying is to take in a piece of text and predict\\nwhat word comes next.\\nThe input text is broken up into little pieces that we call tokens, and these are very often\\nwords or pieces of words, but just to make the examples in this video easier for you\\nand me to think about, let's simplify by pretending that tokens are always just words.\\nThe first step in a transformer is to associate each token with a high-dimensional vector,\\nwhat we call its embedding.\\nNow the most important idea I want you to have in mind is how directions in this high-dimensional\\nspace of all possible embeddings can correspond with semantic meaning.\\nIn the last chapter we saw an example for how direction can correspond to gender, in\\nthe sense that adding a certain step in this space can take you from the embedding of a\\nmasculine noun to the embedding of the corresponding feminine noun.\\njust one example, you could imagine how many other directions in this high-dimensional space\\ncould correspond to numerous other aspects of a word's meaning. The aim of a transformer is to\\nprogressively adjust these embeddings so that they don't merely encode an individual word,\\nbut instead they bake in some much, much richer contextual meaning. I should say up front that a\\nlot of people find the attention mechanism, this key piece in a transformer, very confusing, so\\ndon't worry if it takes some time for things to sink in. I think that before we dive into the\"),\n",
       " Document(metadata={}, page_content=\"could correspond to numerous other aspects of a word's meaning. The aim of a transformer is to\\nprogressively adjust these embeddings so that they don't merely encode an individual word,\\nbut instead they bake in some much, much richer contextual meaning. I should say up front that a\\nlot of people find the attention mechanism, this key piece in a transformer, very confusing, so\\ndon't worry if it takes some time for things to sink in. I think that before we dive into the\\ncomputational details and all the matrix multiplications, it's worth thinking about a\\ncouple examples for the kind of behavior that we want attention to enable. Consider the phrases\\nAmerican true mole, one mole of carbon dioxide, and take a biopsy of the mole. You and I know\\nthat the word mole has different meanings in each one of these, based on the context.\\nBut after the first step of a transformer, the one that breaks up the text and associates each\\ntoken with a vector, the vector that's associated with mole would be the same in all three of these\\ncases, because this initial token embedding is effectively a lookup table with no reference to\\nthe context. It's only in the next step of the transformer that the surrounding embeddings have\\nthe chance to pass information into this one. The picture you might have in mind is that there\\nare multiple distinct directions in this embedding space encoding the multiple distinct meanings of\\nthe word mole, and that a well-trained attention block calculates what you need to add to the\\ngeneric embedding to move it to one of these more specific directions, as a function of the context.\\nTo take another example, consider the embedding of the word tower. This is presumably some very\\ngeneric, non-specific direction in the space, associated with lots of other large, tall nouns.\\nIf this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update\\nthis vector so that it points in a direction that more specifically encodes the Eiffel Tower,\"),\n",
       " Document(metadata={}, page_content=\"generic embedding to move it to one of these more specific directions, as a function of the context.\\nTo take another example, consider the embedding of the word tower. This is presumably some very\\ngeneric, non-specific direction in the space, associated with lots of other large, tall nouns.\\nIf this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update\\nthis vector so that it points in a direction that more specifically encodes the Eiffel Tower,\\nmaybe correlated with vectors associated with Paris and France and things made of steel.\\nIf it was also preceded by the word miniature, then the vector should be updated even further\\nso that it no longer correlates with large tall things. More generally than just refining the\\nmeaning of a word, the attention block allows the model to move information encoded in one\\nembedding to that of another, potentially ones that are quite far away, and potentially\\nwith information that's much richer than just a single word.\\nWhat we saw in the last chapter was how after all of the vectors flow through the network,\\nincluding many different attention blocks, the computation that you perform to produce\\na prediction of the next token is entirely a function of the last vector in the sequence.\\nSo imagine, for example, that the text you input is most of an entire mystery novel,\\nway up to a point near the end which reads, therefore the murderer was, if the model is\\ngoing to accurately predict the next word, that final vector in the sequence which began its life\\nsimply embedding the word was will have to have been updated by all of the attention blocks\\nto represent much much more than any individual word, somehow encoding all of the information\\nfrom the full context window that's relevant to predicting the next word. To step through the\\nthe computations though let's take a much simpler example. Imagine that the input includes the\"),\n",
       " Document(metadata={}, page_content=\"going to accurately predict the next word, that final vector in the sequence which began its life\\nsimply embedding the word was will have to have been updated by all of the attention blocks\\nto represent much much more than any individual word, somehow encoding all of the information\\nfrom the full context window that's relevant to predicting the next word. To step through the\\nthe computations though let's take a much simpler example. Imagine that the input includes the\\nphrase a fluffy blue creature roamed the verdant forest and for the moment suppose that the only\\ntype of update that we care about is having the adjectives adjust the meanings of their\\ncorresponding nouns. What I'm about to describe is what we would call a single head of attention\\nand later we will see how the attention block consists of many different heads run in parallel.\\nAgain, the initial embedding for each word is some high-dimensional vector\\nthat only encodes the meaning of that particular word with no context.\\nActually, that's not quite true. They also encode the position of the word.\\nThere's a lot more to say about the specific way that positions are encoded,\\nbut right now all you need to know is that the entries of this vector are enough to tell you\\nboth what the word is and where it exists in the context. Let's go ahead and denote these\\nembeddings with the letter E, the goal is to have a series of computations produce a\\nnew refined set of embeddings where, for example, those corresponding to the nouns have ingested\\nthe meaning from their corresponding adjectives.\\nAnd playing the deep learning game, we want most of the computations involved to look\\nlike matrix-vector products where the matrices are full of tunable weights, things that the\\nmodel will learn based on data.\\nTo be clear, I'm making up this example of adjectives updating nouns just to illustrate\\nthe type of behavior that you could imagine an intention had doing.\"),\n",
       " Document(metadata={}, page_content=\"the meaning from their corresponding adjectives.\\nAnd playing the deep learning game, we want most of the computations involved to look\\nlike matrix-vector products where the matrices are full of tunable weights, things that the\\nmodel will learn based on data.\\nTo be clear, I'm making up this example of adjectives updating nouns just to illustrate\\nthe type of behavior that you could imagine an intention had doing.\\nAs with so much deep learning, the true behavior is much harder to parse, because it's based\\non tweaking and tuning a huge number of parameters to minimize some cost function.\\nIt's just that as we step through all of the different matrices filled with parameters\\nthat are involved in this process, I think it's really helpful to have an imagined example\\nof something that it could be doing to help keep it all more concrete.\\nFor the first step of this process, you might imagine each noun, like creature, asking the\\nquestion, hey, are there any adjectives sitting in front of me, and for the words fluffy and\\nblue to each be able to answer, yeah, I'm an adjective and I'm in that position.\\nThat question is somehow encoded as yet another vector, another list of numbers, which we\\ncall the query for this word.\\nThis query vector, though, has a much smaller dimension than the embedding vector, say 128.\\nComputing this query looks like taking a certain matrix, which I'll label wq, and multiplying\\nit by the embedding.\\nCompressing things a bit, let's write that query vector as q, and then anytime you see\\nme put a matrix next to an arrow like this one, it's meant to represent that multiplying\\nthis matrix by the vector at the arrow's start gives you the vector at the arrow's end.\\nIn this case, you multiply this matrix by all of the embeddings in the context, producing\\none query vector for each token.\\nThe entries of this matrix are parameters of the model, which means the true behavior\\nis learned from data, and in practice what this matrix does in a particular attention\"),\n",
       " Document(metadata={}, page_content=\"me put a matrix next to an arrow like this one, it's meant to represent that multiplying\\nthis matrix by the vector at the arrow's start gives you the vector at the arrow's end.\\nIn this case, you multiply this matrix by all of the embeddings in the context, producing\\none query vector for each token.\\nThe entries of this matrix are parameters of the model, which means the true behavior\\nis learned from data, and in practice what this matrix does in a particular attention\\nhead is challenging to parse.\\nBut for our sake, imagining an example that we might hope it would learn, we'll suppose\\nthat this query matrix maps the embeddings of nouns to certain directions in this smaller\\nquery space that somehow encodes the notion of looking for adjectives in preceding positions.\\nAs to what it does to other embeddings, who knows, maybe it simultaneously tries to accomplish\\nsome other goal with those, right now we're laser focused on the nouns.\\nAt the same time, associated with this is a second matrix called the key matrix, which\\nyou also multiply by every one of the embeddings.\\nThis produces a second sequence of vectors that we call the keys.\\nConceptually you want to think of the keys as potentially answering the queries.\\nThis key matrix is also full of tunable parameters, and just like the query matrix it maps the\\nembedding vectors to that same smaller dimensional space.\\nYou think of the keys as matching the queries whenever they closely align with each other.\\nIn our example, you would imagine that the key matrix maps the adjectives, like fluffy\\nand blue, to vectors that are closely aligned with the query produced by the word creature.\\nTo measure how well each key matches each query, you compute a dot product between each\\npossible key-query pair.\\nI like to visualize a grid full of a bunch of dots, where the bigger dots correspond\\nthe larger dot products, the places where the keys and queries align. For our adjective-noun example,\"),\n",
       " Document(metadata={}, page_content=\"In our example, you would imagine that the key matrix maps the adjectives, like fluffy\\nand blue, to vectors that are closely aligned with the query produced by the word creature.\\nTo measure how well each key matches each query, you compute a dot product between each\\npossible key-query pair.\\nI like to visualize a grid full of a bunch of dots, where the bigger dots correspond\\nthe larger dot products, the places where the keys and queries align. For our adjective-noun example,\\nthat would look a little more like this, where if the keys produced by fluffy and blue really do\\nalign closely with the query produced by creature, then the dot products in these two spots would be\\nsome large positive numbers. In the lingo, machine learning people would say that this means the\\nembeddings of fluffy and blue attend to the embedding of creature. By contrast to the dot\\nproduct between the key for some other word like the and the query for creature would be some small\\nor negative value that reflects that these are unrelated to each other. So we have this grid of\\nvalues that can be any real number from negative infinity to infinity giving us a score for how\\nrelevant each word is to updating the meaning of every other word. The way we're about to use these\\nscores is to take a certain weighted sum along each column weighted by the relevance. So instead\\nInstead of having values range from negative infinity to infinity, what we want is for\\nthe numbers in these columns to be between 0 and 1, and for each column to add up to\\n1, as if they were a probability distribution.\\nIf you're coming in from the last chapter, you know what we need to do then.\\nWe compute a softmax along each one of these columns to normalize the values.\\nIn our picture, after you apply softmax to all of the columns, we'll fill in the grid\\nwith these normalized values.\\nAt this point, you're safe to think about each column as giving weights\"),\n",
       " Document(metadata={}, page_content=\"the numbers in these columns to be between 0 and 1, and for each column to add up to\\n1, as if they were a probability distribution.\\nIf you're coming in from the last chapter, you know what we need to do then.\\nWe compute a softmax along each one of these columns to normalize the values.\\nIn our picture, after you apply softmax to all of the columns, we'll fill in the grid\\nwith these normalized values.\\nAt this point, you're safe to think about each column as giving weights\\naccording to how relevant the word on the left is to the corresponding value at the top.\\nWe call this grid an attention pattern.\\nNow, if you look at the original Transformer paper,\\nthere's a really compact way that they write this all down.\\nHere, the variables q and k represent the full arrays of query and key vectors respectively,\\nthose little vectors you get by multiplying the embeddings by the query and the key matrices.\\nThis expression up in the numerator is a really compact way to represent the grid of all possible\\ndot products between pairs of keys and queries. A small technical detail that I didn't mention\\nis that for numerical stability it happens to be helpful to divide all of these values by the\\nsquare root of the dimension in that key query space. Then this softmax that's wrapped around\\nthe full expression, is meant to be understood to apply column by column.\\nAs to that V term, we'll talk about it in just a second.\\nBefore that, there's one other technical detail that so far I've skipped.\\nDuring the training process, when you run this model on a given text example, and all\\nof the weights are slightly adjusted and tuned to either reward or punish it based on how\\nhigh a probability it assigns to the true next word in the passage, it turns out to\\nmake the whole training process a lot more efficient if you simultaneously have it predict\\nevery possible next token following each initial sub-sequence of tokens in this passage.\"),\n",
       " Document(metadata={}, page_content=\"During the training process, when you run this model on a given text example, and all\\nof the weights are slightly adjusted and tuned to either reward or punish it based on how\\nhigh a probability it assigns to the true next word in the passage, it turns out to\\nmake the whole training process a lot more efficient if you simultaneously have it predict\\nevery possible next token following each initial sub-sequence of tokens in this passage.\\nFor example, with the phrase that we've been focusing on, it might also be predicting what\\nwords follow creature, and what words follow the.\\nThis is really nice, because it means what would otherwise be a single training example\\neffectively acts as many.\\nFor the purposes of our attention pattern, it means that you never want to allow later\\nwords to influence earlier words, since otherwise they could kind of give away the answer for\\nwhat comes next. What this means is that we want all of these spots here, the ones representing\\nlater tokens influencing earlier ones, to somehow be forced to be zero. The simplest thing you might\\nthink to do is to set them equal to zero, but if you did that the columns wouldn't add up to one\\nanymore, they wouldn't be normalized. So instead a common way to do this is that before applying\\nsoftmax you set all of those entries to be negative infinity. If you do that then after\\nAfter applying softmax, all of those get turned into zero, but the columns stay normalized.\\nThis process is called masking.\\nThere are versions of attention where you don't apply it, but in our GPT example, even\\nthough this is more relevant during the training phase than it would be, say, running it as\\na chatbot or something like that, you do always apply this masking to prevent later tokens\\nfrom influencing earlier ones.\\nAnother fact that's worth reflecting on about this attention pattern is how its size is\\nequal to the square of the context size.\\nSo this is why context size can be a really huge bottleneck for large language models,\"),\n",
       " Document(metadata={}, page_content=\"though this is more relevant during the training phase than it would be, say, running it as\\na chatbot or something like that, you do always apply this masking to prevent later tokens\\nfrom influencing earlier ones.\\nAnother fact that's worth reflecting on about this attention pattern is how its size is\\nequal to the square of the context size.\\nSo this is why context size can be a really huge bottleneck for large language models,\\nand scaling it up is non-trivial.\\nAs you might imagine, motivated by a desire for bigger and bigger context windows, recent\\nyears have seen some variations to the attention mechanism aimed at making context more scalable.\\nBut right here, you and I are staying focused on the basics.\\nOkay, great, computing this pattern lets the model deduce which words are relevant to which\\nother words.\\nNow you need to actually update the embeddings, allowing words to pass information to whichever\\nother words they're relevant to.\\nFor example, you want the embedding of fluffy to somehow cause a change to creature that\\nmoves it to a different part of this 12,000 dimensional embedding space that more specifically\\nencodes a fluffy creature.\\nWhat I'm going to do here is first show you the most straightforward way that you could\\ndo this, though there's a slight way that this gets modified in the context of multi-headed\\nattention.\\nThis most straightforward way would be to use a third matrix, what we call the value\\nmatrix, which you multiply by the embedding of that first word, for example fluffy.\\nThe result of this is what you would call a value vector, and this is something that\\nyou add to the embedding of the second word, in this case something you add to the embedding\\nof creature.\\nSo, this value vector lives in the same very high dimensional space as the embeddings.\\nWhen you multiply this value matrix by the embedding of a word, you might think of it\\nas saying if this word is relevant to adjusting the meaning of something else, what exactly should\"),\n",
       " Document(metadata={}, page_content=\"The result of this is what you would call a value vector, and this is something that\\nyou add to the embedding of the second word, in this case something you add to the embedding\\nof creature.\\nSo, this value vector lives in the same very high dimensional space as the embeddings.\\nWhen you multiply this value matrix by the embedding of a word, you might think of it\\nas saying if this word is relevant to adjusting the meaning of something else, what exactly should\\nbe added to the embedding of that something else in order to reflect this? Looking back in our\\ndiagram, let's set aside all of the keys and the queries, since after you compute the attention\\npattern you're done with those, then you're going to take this value matrix and multiply it by every\\none of those embeddings to produce a sequence of value vectors. You might think of these value\\nvectors as being kind of associated with the corresponding keys.\\nFor each column in this diagram, you multiply each of the value vectors by the corresponding\\nweight in that column.\\nFor example, here, under the embedding of creature, you would be adding large proportions\\nof the value vectors for fluffy and blue, while all of the other value vectors get zeroed\\nout, or at least nearly zeroed out.\\nAnd then finally, the way to actually update the embedding associated with this column,\\npreviously encoding some context-free meaning of creature, you add together all of these\\nrescaled values in the column, producing a change that you want to add that I'll label\\ndelta E, and then you add that to the original embedding.\\nHopefully what results is a more refined vector encoding the more contextually rich meaning,\\nlike that of a fluffy blue creature.\\nAnd of course you don't just do this to one embedding, you apply the same weighted sum\\nacross all of the columns in this picture, producing a sequence of changes.\\nAdding all of those changes to the corresponding embeddings produces a full sequence of more\"),\n",
       " Document(metadata={}, page_content=\"delta E, and then you add that to the original embedding.\\nHopefully what results is a more refined vector encoding the more contextually rich meaning,\\nlike that of a fluffy blue creature.\\nAnd of course you don't just do this to one embedding, you apply the same weighted sum\\nacross all of the columns in this picture, producing a sequence of changes.\\nAdding all of those changes to the corresponding embeddings produces a full sequence of more\\nrefined embeddings popping out of the attention block.\\nZooming out, this whole process is what you would describe as a single head of attention.\\nAs I've described things so far, this process is parameterized by three distinct matrices,\\nall filled with tunable parameters, the key, the query, and the value.\\nI want to take a moment to continue what we started in the last chapter with the scorekeeping\\nwhere we count up the total number of model parameters using the numbers from GPT-3.\\nThese key and query matrices each have 12,288 columns, matching the embedding dimension,\\nand 128 rows, matching the dimension of that smaller key query space.\\nThis gives us an additional 1.5 million or so parameters for each one.\\nIf you look at that value matrix by contrast, the way I've described things so far would\\nsuggest that it's a square matrix that has 12,288 columns and 12,288 rows, since both\\nits inputs and its outputs live in this very large embedding space.\\nIf true, that would mean about 150 million added parameters.\\nAnd to be clear, you could do that, you could devote orders of magnitude more parameters\\nto the value map than to the key and query.\\nBut in practice, it is much more efficient if instead you make it so that the number\\nof parameters devoted to this value map is the same as the number devoted to the key\\nin the query.\\nThis is especially relevant in the setting of running multiple attention heads in parallel.\\nThe way this looks is that the value map is factored as a product of two smaller matrices.\"),\n",
       " Document(metadata={}, page_content=\"And to be clear, you could do that, you could devote orders of magnitude more parameters\\nto the value map than to the key and query.\\nBut in practice, it is much more efficient if instead you make it so that the number\\nof parameters devoted to this value map is the same as the number devoted to the key\\nin the query.\\nThis is especially relevant in the setting of running multiple attention heads in parallel.\\nThe way this looks is that the value map is factored as a product of two smaller matrices.\\nConceptually, I would still encourage you to think about the overall linear map, one\\nwith inputs and outputs both in this larger embedding space, for example taking the embedding\\nof blue to this blueness direction that you would add to nouns.\\nIt's just that it's broken up into two separate steps.\\nThe first matrix on the right here has a smaller number of rows, typically the same size as\\nthe key query space.\\nWhat this means is you can think of it as mapping the large embedding vectors down to\\na much smaller space.\\nThis is not the conventional naming, but I'm going to call this the value down matrix.\\nThe second matrix maps from this smaller space back up to the embedding space, producing\\nthe vectors that you use to make the actual updates.\\nI'm going to call this one the value-up matrix, which, again, is not conventional.\\nThe way that you would see this written in most papers looks a little different.\\nI'll talk about it in a minute.\\nIn my opinion, it tends to make things a little more conceptually confusing.\\nTo throw in linear algebra jargon here, what we're basically doing is constraining the\\noverall value map to be a low-rank transformation.\\nTurning back to the parameter count, all four of these matrices have the same size, and\\nThen adding them all up, we get about 6.3 million parameters for one attention head.\\nAs a quick side note, to be a little more accurate, everything described so far is what\"),\n",
       " Document(metadata={}, page_content=\"In my opinion, it tends to make things a little more conceptually confusing.\\nTo throw in linear algebra jargon here, what we're basically doing is constraining the\\noverall value map to be a low-rank transformation.\\nTurning back to the parameter count, all four of these matrices have the same size, and\\nThen adding them all up, we get about 6.3 million parameters for one attention head.\\nAs a quick side note, to be a little more accurate, everything described so far is what\\npeople would call a self-attention head, to distinguish it from a variation that comes\\nup in other models that's called cross-attention.\\nThis isn't relevant to our GPT example, but if you're curious, cross-attention involves\\nmodels that process two distinct types of data, like text in one language and text in\\nanother language that's part of an ongoing generation of a translation.\\nOr maybe audio input of speech, and an ongoing transcription.\\nA cross-attention head looks almost identical.\\nThe only difference is that the key and query maps act on different datasets.\\nIn a model doing translation, for example, the keys might come from one language, while\\nthe queries come from another, and the attention pattern could describe which words from one\\nlanguage correspond to which words in another.\\nAnd in this setting there would typically be no masking, since there's not really any\\nnotion of later tokens affecting earlier ones.\\nStaying focused on self-attention though, if you understood everything so far, and if\\nyou were to stop here, you would come away with the essence of what attention really\\nis.\\nAll that's really left to us is to lay out the sense in which you do this many, many\\ndifferent times.\\nIn our central example we focused on adjectives updating nouns, but of course there are lots\\nof different ways that context can influence the meaning of a word.\\nIf the words they crashed the preceded the word car, it has implications for the shape\"),\n",
       " Document(metadata={}, page_content=\"you were to stop here, you would come away with the essence of what attention really\\nis.\\nAll that's really left to us is to lay out the sense in which you do this many, many\\ndifferent times.\\nIn our central example we focused on adjectives updating nouns, but of course there are lots\\nof different ways that context can influence the meaning of a word.\\nIf the words they crashed the preceded the word car, it has implications for the shape\\nand the structure of that car, and a lot of associations might be less grammatical.\\nIf the word wizard is anywhere in the same passage as Harry, it suggests that this might\\nbe referring to Harry Potter, whereas if instead the words Queen, Sussex, and William were\\nin that passage, then perhaps the embedding of Harry should instead be updated to refer\\nto the prince.\\nFor every different type of contextual updating that you might imagine, the parameters of\\nthese key and query matrices would be different to capture the different attention patterns,\\nand the parameters of our value map would be different based on what should be added to the\\nembeddings. And again, in practice the true behavior of these maps is much more difficult\\nto interpret, where the weights are set to do whatever the model needs them to do to best\\naccomplish its goal of predicting the next token. As I said before, everything we described is a\\nsingle head of attention, and a full attention block inside a transformer consists of what's\\ncalled multi-headed attention where you run a lot of these operations in parallel each with its own\\ndistinct key query and value maps. GPT-3 for example uses 96 attention heads inside each block.\\nConsidering that each one is already a bit confusing it's certainly a lot to hold in your\\nhead. Just to spell it all out very explicitly this means you have 96 distinct key and query\\nmatrices producing 96 distinct attention patterns. Then each head has its own distinct value matrices\"),\n",
       " Document(metadata={}, page_content=\"called multi-headed attention where you run a lot of these operations in parallel each with its own\\ndistinct key query and value maps. GPT-3 for example uses 96 attention heads inside each block.\\nConsidering that each one is already a bit confusing it's certainly a lot to hold in your\\nhead. Just to spell it all out very explicitly this means you have 96 distinct key and query\\nmatrices producing 96 distinct attention patterns. Then each head has its own distinct value matrices\\nused to produce 96 sequences of value vectors. These are all added together using the\\ncorresponding attention patterns as weights. What this means is that for each position in the\\ncontext, each token, every one of these heads produces a proposed change to be added to the\\nembedding in that position. So what you do is you sum together all of those proposed changes,\\none for each head, and you add the result to the original embedding of that position.\\nThis entire sum here would be one slice of what's outputted from this multi-headed attention block,\\na single one of those refined embeddings that pops out the other end of it.\\nAgain, this is a lot to think about, so don't worry at all if it takes some time to sink in.\\nThe overall idea is that by running many distinct heads in parallel,\\nyou're giving the model the capacity to learn many distinct ways that context changes meaning.\\nPulling up our running tally for parameter count with 96 heads, each including its own variation\\nof these four matrices, each block of multi-headed attention ends up with around 600 million\\nparameters. There's one added slightly annoying thing that I should really mention for any of you\\nwho go on to read more about transformers. You remember how I said that the value map is factored\\nout into these two distinct matrices, which I labeled as the value down and the value up\\nmatrices. The way that I framed things would suggest that you see this pair of matrices\"),\n",
       " Document(metadata={}, page_content=\"of these four matrices, each block of multi-headed attention ends up with around 600 million\\nparameters. There's one added slightly annoying thing that I should really mention for any of you\\nwho go on to read more about transformers. You remember how I said that the value map is factored\\nout into these two distinct matrices, which I labeled as the value down and the value up\\nmatrices. The way that I framed things would suggest that you see this pair of matrices\\ninside each attention head, and you could absolutely implement it this way. That would\\nbe a valid design. But the way that you see this written in papers and the way that it's\\nimplemented in practice looks a little different. All of these value up matrices for each head\\nappear stapled together in one giant matrix that we call the output matrix, associated with\\nthe entire multi-headed attention block. And when you see people refer to the value matrix for a\\ngiven attention head, they're typically only referring to this first step, the one that I\\nwas labeling as the value down projection into the smaller space. For the curious among you,\\nI've left an on-screen note about it. It's one of those details that runs the risk of distracting\\nfrom the main conceptual points, but I do want to call it out just so that you know if you read\\nabout this in other sources. Setting aside all the technical nuances, in the preview from the\\nlast chapter, we saw how data flowing through a transformer doesn't just flow through a single\\nattention block. For one thing, it also goes through these other operations called multi-layer\\nperceptrons. We'll talk more about those in the next chapter. And then it repeatedly goes through\\nmany, many copies of both of these operations. What this means is that after a given word imbibes\\nsome of its context, there are many more chances for this more nuanced embedding to be influenced\\nby its more nuanced surroundings. The further down the network you go, with each embedding\"),\n",
       " Document(metadata={}, page_content=\"attention block. For one thing, it also goes through these other operations called multi-layer\\nperceptrons. We'll talk more about those in the next chapter. And then it repeatedly goes through\\nmany, many copies of both of these operations. What this means is that after a given word imbibes\\nsome of its context, there are many more chances for this more nuanced embedding to be influenced\\nby its more nuanced surroundings. The further down the network you go, with each embedding\\ntaking in more and more meaning from all the other embeddings, which themselves are getting\\nmore and more nuanced, the hope is that there's the capacity to encode higher level and more\\nabstract ideas about a given input beyond just descriptors and grammatical structure.\\nThings like sentiment and tone and whether it's a poem and what underlying scientific truths are\\nare relevant to the piece, and things like that.\\nTurning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the\\ntotal number of key, query, and value parameters is multiplied by another 96, which brings\\nthe total sum to just under 58 billion distinct parameters devoted to all of the attention\\nheads.\\nThat is a lot, to be sure, but it's only about a third of the 175 billion that are\\nin the network in total.\\nSo even though attention gets all of the attention, the majority of parameters come from the blocks\\nsitting in between these steps.\\nIn the next chapter, you and I will talk more about those other blocks and also a lot more\\nabout the training process.\\nA big part of the story for the success of the attention mechanism is not so much any\\nspecific kind of behavior that it enables, but the fact that it's extremely parallelizable,\\nmeaning that you can run a huge number of computations in a short time using GPUs.\\nthat one of the big lessons about deep learning in the last decade or two has been that scale\\nalone seems to give huge qualitative improvements in model performance. There's a huge advantage to\"),\n",
       " Document(metadata={}, page_content=\"about the training process.\\nA big part of the story for the success of the attention mechanism is not so much any\\nspecific kind of behavior that it enables, but the fact that it's extremely parallelizable,\\nmeaning that you can run a huge number of computations in a short time using GPUs.\\nthat one of the big lessons about deep learning in the last decade or two has been that scale\\nalone seems to give huge qualitative improvements in model performance. There's a huge advantage to\\nparallelizable architectures that let you do this. If you want to learn more about this stuff, I've\\nleft lots of links in the description. In particular, anything produced by Andre Karpathy or Chris Ola\\ntend to be pure gold. In this video, I wanted to just jump into attention in its current form,\\nbut if you're curious about more of the history for how we got here and how you might reinvent\\nthis idea for yourself, my friend Vivek just put up a couple videos giving a lot more of\\nthat motivation. Also, Britt Cruz from the channel The Art of the Problem\\nhas a really nice video about the history of large language models.\\nyou\")]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[FINAL SUMMARY]\\nKey topic: ë ˆê·¸ì˜ ì´í•´ ë° ì •ë³´ ì²˜ë¦¬\\n\\nâ€¢ ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í•˜ê¸° ìœ„í•œ ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.  \\nâ€¢ ðŸ”„ ë°˜ë³µ í•™ìŠµì„ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì„ ì´í•´í•´ì•¼ í•œë‹¤.  \\nâ€¢ âœï¸ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì •ë³´ ì°¸ì¡°ë¥¼ í†µí•´ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìžˆëŠ” AIì´ë‹¤.  \\nâ€¢ âš™ï¸ ì‚¬ì „í•™ìŠµëœ ì •ë³´ì™€ ìµœì‹  ì •ë³´ì˜ ì°¨ì´ë¥¼ ì´í•´í•´ì•¼ í•˜ë©°, ì •ë³´ì˜ íë¦„ì„ ìžƒì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤.  \\nâ€¢ ðŸ” íš¨ê³¼ì ì¸ ì •ë³´ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ì˜ íŽ˜ì´ì§€ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.  \\nâ€¢ ðŸ“„ ë¬¸ì„œì˜ íŠ¹ì • ë‹¨ë½ì„ ì„ íƒí•˜ê³ , ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.  \\nâ€¢ ðŸ’¡ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ë¬¸ìž¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚¨ë‹¤.\\n\\n[RECOMMEND QUESTIONS]\\n1. ë ˆê·¸ë¥¼ í™œìš©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ì–´ë–»ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ ì œê³µí•  ìˆ˜ ìžˆì„ê¹Œ?\\n2. ì‚¬ì „í•™ìŠµëœ ì •ë³´ì™€ ìµœì‹  ì •ë³´ì˜ í™œìš© ì‹œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€?\\n3. ì¸ë² ë”© ê³¼ì •ì´ ì •ë³´ ê²€ìƒ‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìžˆì„ê¹Œ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Key topic: ë ˆê·¸ì˜ ì´í•´ ë° ì •ë³´ ì²˜ë¦¬\\n\\nâ€¢ ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í•˜ê¸° ìœ„í•œ ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.  \\nâ€¢ ðŸ”„ ë°˜ë³µ í•™ìŠµì„ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì„ ì´í•´í•´ì•¼ í•œë‹¤.  \\nâ€¢ âœï¸ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì •ë³´ ì°¸ì¡°ë¥¼ í†µí•´ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìžˆëŠ” AIì´ë‹¤.  \\nâ€¢ âš™ï¸ ì‚¬ì „í•™ìŠµëœ ì •ë³´ì™€ ìµœì‹  ì •ë³´ì˜ ì°¨ì´ë¥¼ ì´í•´í•´ì•¼ í•˜ë©°, ì •ë³´ì˜ íë¦„ì„ ìžƒì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤.  \\nâ€¢ ðŸ” íš¨ê³¼ì ì¸ ì •ë³´ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ì˜ íŽ˜ì´ì§€ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.  \\nâ€¢ ðŸ“„ ë¬¸ì„œì˜ íŠ¹ì • ë‹¨ë½ì„ ì„ íƒí•˜ê³ , ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.  \\nâ€¢ ðŸ’¡ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ë¬¸ìž¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚¨ë‹¤.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[0].strip(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Key topic: ë ˆê·¸ì˜ ì´í•´ ë° ì •ë³´ ì²˜ë¦¬\\nâ€¢ ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í•˜ê¸° ìœ„í•œ ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.  \\nâ€¢ ðŸ”„ ë°˜ë³µ í•™ìŠµì„ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì„ ì´í•´í•´ì•¼ í•œë‹¤.  \\nâ€¢ âœï¸ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì •ë³´ ì°¸ì¡°ë¥¼ í†µí•´ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìžˆëŠ” AIì´ë‹¤.  \\nâ€¢ âš™ï¸ ì‚¬ì „í•™ìŠµëœ ì •ë³´ì™€ ìµœì‹  ì •ë³´ì˜ ì°¨ì´ë¥¼ ì´í•´í•´ì•¼ í•˜ë©°, ì •ë³´ì˜ íë¦„ì„ ìžƒì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤.  \\nâ€¢ ðŸ” íš¨ê³¼ì ì¸ ì •ë³´ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ì˜ íŽ˜ì´ì§€ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.  \\nâ€¢ ðŸ“„ ë¬¸ì„œì˜ íŠ¹ì • ë‹¨ë½ì„ ì„ íƒí•˜ê³ , ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.  \\nâ€¢ ðŸ’¡ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ë¬¸ìž¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚¨ë‹¤.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[0].strip(\"\\n\\n\").replace(\"\\n\\n\", \"\\n\").replace(\"\\n\\n\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mborder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Key | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DeltaGenerator'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Insert a multi-element container.\n",
      "\n",
      "Inserts an invisible container into your app that can be used to hold\n",
      "multiple elements. This allows you to, for example, insert multiple\n",
      "elements into your app out of order.\n",
      "\n",
      "To add elements to the returned container, you can use the ``with`` notation\n",
      "(preferred) or just call methods directly on the returned object. See\n",
      "examples below.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "\n",
      "height : int or None\n",
      "    Desired height of the container expressed in pixels. If ``None`` (default)\n",
      "    the container grows to fit its content. If a fixed height, scrolling is\n",
      "    enabled for large content and a grey border is shown around the container\n",
      "    to visually separate its scroll surface from the rest of the app.\n",
      "\n",
      "    .. note::\n",
      "        Use containers with scroll sparingly. If you do, try to keep\n",
      "        the height small (below 500 pixels). Otherwise, the scroll\n",
      "        surface of the container might cover the majority of the screen\n",
      "        on mobile devices, which makes it hard to scroll the rest of the app.\n",
      "\n",
      "border : bool or None\n",
      "    Whether to show a border around the container. If ``None`` (default), a\n",
      "    border is shown if the container is set to a fixed height and not\n",
      "    shown otherwise.\n",
      "\n",
      "key : str or None\n",
      "    An optional string to give this container a stable identity.\n",
      "\n",
      "    Additionally, if ``key`` is provided, it will be used as CSS\n",
      "    class name prefixed with ``st-key-``.\n",
      "\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Inserting elements using ``with`` notation:\n",
      "\n",
      ">>> import streamlit as st\n",
      ">>>\n",
      ">>> with st.container():\n",
      "...     st.write(\"This is inside the container\")\n",
      "...\n",
      "...     # You can call any Streamlit command, including custom components:\n",
      "...     st.bar_chart(np.random.randn(50, 3))\n",
      ">>>\n",
      ">>> st.write(\"This is outside the container\")\n",
      "\n",
      ".. output ::\n",
      "    https://doc-container1.streamlit.app/\n",
      "    height: 520px\n",
      "\n",
      "Inserting elements out of order:\n",
      "\n",
      ">>> import streamlit as st\n",
      ">>>\n",
      ">>> container = st.container(border=True)\n",
      ">>> container.write(\"This is inside the container\")\n",
      ">>> st.write(\"This is outside the container\")\n",
      ">>>\n",
      ">>> # Now insert some more in the container\n",
      ">>> container.write(\"This is inside too\")\n",
      "\n",
      ".. output ::\n",
      "    https://doc-container2.streamlit.app/\n",
      "    height: 300px\n",
      "\n",
      "Using ``height`` to make a grid:\n",
      "\n",
      ">>> import streamlit as st\n",
      ">>>\n",
      ">>> row1 = st.columns(3)\n",
      ">>> row2 = st.columns(3)\n",
      ">>>\n",
      ">>> for col in row1 + row2:\n",
      ">>>     tile = col.container(height=120)\n",
      ">>>     tile.title(\":balloon:\")\n",
      "\n",
      ".. output ::\n",
      "    https://doc-container3.streamlit.app/\n",
      "    height: 350px\n",
      "\n",
      "Using ``height`` to create a scrolling container for long content:\n",
      "\n",
      ">>> import streamlit as st\n",
      ">>>\n",
      ">>> long_text = \"Lorem ipsum. \" * 1000\n",
      ">>>\n",
      ">>> with st.container(height=300):\n",
      ">>>     st.markdown(long_text)\n",
      "\n",
      ".. output ::\n",
      "    https://doc-container4.streamlit.app/\n",
      "    height: 400px\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/youtube/lib/python3.10/site-packages/streamlit/elements/layouts.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.container?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "import re\n",
    "\n",
    "\n",
    "class YouTubeService:\n",
    "    async def get_title_and_hashtags(self, url: str):\n",
    "        yt = await self._create_youtube_instance(url)\n",
    "        print(\"ì˜ìƒ ì •ë³´ í™•ì¸\")\n",
    "        title = yt.title\n",
    "        description = yt.description\n",
    "        hashtags = re.findall(r\"#\\w+\", description)\n",
    "        return {\"title\": title, \"hashtags\": \" \".join(hashtags)}\n",
    "\n",
    "    async def get_video_info(self, url: str):\n",
    "        yt = await self._create_youtube_instance(url)\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        print(\"ìŒì„± ì¶”ì¶œ ì™„ë£Œ\")\n",
    "        return {\n",
    "            \"title\": yt.title,\n",
    "            \"audio_url\": audio_stream.url if audio_stream else None,\n",
    "        }\n",
    "\n",
    "    async def _create_youtube_instance(self, url: str):\n",
    "        print(\"YouTube ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "        return YouTube(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import ffmpeg\n",
    "import requests\n",
    "import soundfile as sf\n",
    "from faster_whisper import BatchedInferencePipeline, WhisperModel\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "class WhisperTranscriptionService:\n",
    "    def __init__(self):\n",
    "        model = WhisperModel(\n",
    "            \"large-v3\", device='cuda', compute_type=\"float16\"\n",
    "        )\n",
    "        self.model = BatchedInferencePipeline(model=model)\n",
    "        self.language = None\n",
    "        self.okt = Okt()\n",
    "        print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "    def create_session(self):\n",
    "        session = requests.Session()\n",
    "        retry = Retry(\n",
    "            total=5, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry, pool_connections=100, pool_maxsize=100)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        return session\n",
    "\n",
    "    def download_chunk(self, args):\n",
    "        url, start, end, chunk_number, temp_dir = args\n",
    "\n",
    "        headers = {\"Range\": f\"bytes={start}-{end}\"}\n",
    "        session = self.create_session()\n",
    "\n",
    "        try:\n",
    "            response = session.get(url, headers=headers, stream=True)\n",
    "            chunk_path = os.path.join(temp_dir, f\"chunk_{chunk_number:04d}\")\n",
    "\n",
    "            with open(chunk_path, \"wb\") as f:\n",
    "                for data in response.iter_content(chunk_size=8192):\n",
    "                    f.write(data)\n",
    "\n",
    "            return chunk_path, chunk_number\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading chunk {chunk_number}: {str(e)}\")\n",
    "            return None, chunk_number\n",
    "\n",
    "    def _single_stream_download(self, url: str, temp_dir: str) -> str:\n",
    "        \"\"\"ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "        print(\"Starting single stream download...\")\n",
    "        session = self.create_session()\n",
    "        output_path = os.path.join(temp_dir, \"complete_audio.mp4\")\n",
    "\n",
    "        try:\n",
    "            with session.get(url, stream=True) as response:\n",
    "                response.raise_for_status()\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "            return output_path\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to download file: {str(e)}\")\n",
    "\n",
    "    def parallel_download(self, url: str, temp_dir: str, num_chunks: int = 10) -> str:\n",
    "        \"\"\"ë³‘ë ¬ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•˜ê³ , ì‹¤íŒ¨ ì‹œ ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ í´ë°±\"\"\"\n",
    "        session = self.create_session()\n",
    "\n",
    "        try:\n",
    "            # HEAD ìš”ì²­ìœ¼ë¡œ íŒŒì¼ í¬ê¸° í™•ì¸ ì‹œë„\n",
    "            response = session.head(url, allow_redirects=True)\n",
    "            total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "            # HEAD ìš”ì²­ì´ ì‹¤íŒ¨í•˜ë©´ GET ìš”ì²­ìœ¼ë¡œ ì‹œë„\n",
    "            if total_size == 0:\n",
    "                response = session.get(url, stream=True)\n",
    "                total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "            # íŒŒì¼ í¬ê¸°ë¥¼ ì—¬ì „ížˆ í™•ì¸í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ë‹¨ì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "            if total_size == 0:\n",
    "                print(\n",
    "                    \"Warning: Could not determine file size. Falling back to single stream download.\"\n",
    "                )\n",
    "                return self._single_stream_download(url, temp_dir)\n",
    "            print(\"Starting parallel download...\")\n",
    "            chunk_size = total_size // num_chunks\n",
    "            chunks = []\n",
    "\n",
    "            for i in range(num_chunks):\n",
    "                start = i * chunk_size\n",
    "                end = start + chunk_size - 1 if i < num_chunks - 1 else total_size - 1\n",
    "                chunks.append((start, end))\n",
    "\n",
    "            download_args = [\n",
    "                (url, start, end, i, temp_dir) for i, (start, end) in enumerate(chunks)\n",
    "            ]\n",
    "\n",
    "            chunk_paths = []\n",
    "            with concurrent.futures.ThreadPoolExecutor(\n",
    "                max_workers=num_chunks\n",
    "            ) as executor:\n",
    "                futures = executor.map(self.download_chunk, download_args)\n",
    "                chunk_paths = [(path, num) for path, num in futures if path is not None]\n",
    "\n",
    "            if not chunk_paths:\n",
    "                raise Exception(\"No chunks were downloaded successfully\")\n",
    "\n",
    "            chunk_paths.sort(key=lambda x: x[1])\n",
    "            output_path = os.path.join(temp_dir, \"complete_audio.mp4\")\n",
    "\n",
    "            with open(output_path, \"wb\") as outfile:\n",
    "                for chunk_path, _ in chunk_paths:\n",
    "                    with open(chunk_path, \"rb\") as infile:\n",
    "                        outfile.write(infile.read())\n",
    "                    os.remove(chunk_path)\n",
    "\n",
    "            return output_path\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error in parallel download: {str(e)}. Falling back to single stream download.\"\n",
    "            )\n",
    "            return self._single_stream_download(url, temp_dir)\n",
    "\n",
    "    def convert_to_wav(self, input_path: str, output_path: str) -> bool:\n",
    "        try:\n",
    "            stream = ffmpeg.input(input_path)\n",
    "            stream = ffmpeg.output(\n",
    "                stream, output_path, acodec=\"pcm_s16le\", ar=\"16000\", ac=\"1\"\n",
    "            )\n",
    "            ffmpeg.run(stream, capture_stdout=True, capture_stderr=True)\n",
    "            return True\n",
    "        except ffmpeg.Error as e:\n",
    "            print(\"FFmpeg error:\", e.stderr.decode())\n",
    "            return False\n",
    "\n",
    "    def process_audio_chunk(self, chunk_data: tuple,promp:str = None,filtered_words:list = None) -> List[Dict[str, Any]]:\n",
    "        audio_path, start_time, duration = chunk_data\n",
    "        try:\n",
    "            segments, info = self.model.transcribe(\n",
    "                audio_path,\n",
    "                beam_size=5,\n",
    "                best_of=7,\n",
    "                batch_size=32,\n",
    "                temperature=0.7,\n",
    "                word_timestamps=True,\n",
    "                initial_prompt=f\"ìŒì„± ì œëª©: {promp}\",\n",
    "                repetition_penalty=2,\n",
    "                no_repeat_ngram_size=3,\n",
    "                length_penalty=1.1,\n",
    "                log_prob_threshold=-0.5,\n",
    "                no_speech_threshold=0.7,\n",
    "                patience=1.2,\n",
    "                hotwords=filtered_words\n",
    "            )\n",
    "            if info and hasattr(info, \"language\"):\n",
    "                self.language = info.language\n",
    "            return self._process_segments(segments, start_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk at {start_time}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def _process_segments(\n",
    "        self, segments, start_time: float = 0\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        transcript = []\n",
    "        for segment in segments:\n",
    "            transcript.append(\n",
    "                {\n",
    "                    \"start\": round(segment.start + start_time, 2),\n",
    "                    \"end\": round(segment.end + start_time, 2),\n",
    "                    \"text\": segment.text,\n",
    "                }\n",
    "            )\n",
    "        return transcript\n",
    "\n",
    "    async def process_with_progress(\n",
    "        self, url: str, prompt:str, filtered_words:str,chunk_duration: int = 30, num_download_chunks: int = 10\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            mp4_path = self.parallel_download(url, temp_dir, num_download_chunks)\n",
    "            print(\"Download complete!\")\n",
    "\n",
    "            wav_path = os.path.join(temp_dir, \"audio.wav\")\n",
    "            if not self.convert_to_wav(mp4_path, wav_path):\n",
    "                raise Exception(\"Failed to convert audio to WAV format\")\n",
    "\n",
    "            wav_info = sf.info(wav_path)\n",
    "            total_duration = wav_info.duration\n",
    "            total_chunks = math.ceil(total_duration / chunk_duration)\n",
    "\n",
    "            chunks_data = []\n",
    "            for i in range(total_chunks):\n",
    "                start_time = i * chunk_duration\n",
    "                chunk_wav_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "\n",
    "                duration = min(chunk_duration, total_duration - start_time)\n",
    "                stream = ffmpeg.input(wav_path, ss=start_time, t=duration)\n",
    "                stream = ffmpeg.output(\n",
    "                    stream, chunk_wav_path, acodec=\"pcm_s16le\", ar=\"16000\", ac=\"1\"\n",
    "                )\n",
    "                ffmpeg.run(stream, quiet=True)\n",
    "\n",
    "                chunks_data.append((chunk_wav_path, start_time, duration))\n",
    "\n",
    "            all_segments = []\n",
    "            for chunk_data in chunks_data:\n",
    "                segments = self.process_audio_chunk(chunk_data,prompt,filtered_words)\n",
    "                all_segments.extend(segments)\n",
    "\n",
    "                if os.path.exists(chunk_data[0]):\n",
    "                    os.remove(chunk_data[0])\n",
    "\n",
    "        return all_segments\n",
    "\n",
    "    async def transcribe(self, audio_url: str,prompt: str = None) -> Dict[str, Any]:\n",
    "        try:\n",
    "            try:\n",
    "                tagged = self.okt.pos(prompt)\n",
    "                filtered_words = []\n",
    "                for word, tag in tagged:\n",
    "                    if tag == \"Noun\" or tag == \"Hashtag\":\n",
    "                        filtered_words.append(word)\n",
    "            except:\n",
    "                filtered_words = None\n",
    "            segments = await self.process_with_progress(\n",
    "                audio_url, prompt, filtered_words,chunk_duration=30, num_download_chunks=10\n",
    "            )\n",
    "\n",
    "            print(\"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ\")\n",
    "\n",
    "            return {\"script\": segments, \"language\": self.language}\n",
    "        except Exception as e:\n",
    "            print(f\"Error in transcribe: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = YouTubeService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ\n",
      "ìŒì„± ì¶”ì¶œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "video_info = await youtube.get_video_info(\"https://youtu.be/EMMC0ym0QOI?si=bx7raBo-QwR3MGy7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://rr3---sn-ab02a0nfpgxapox-bh2es.googlevideo.com/videoplayback?expire=1730288214&ei=9sUhZ-S4KqmS1d8P2fC86AI&ip=106.254.102.210&id=o-APMMqsFIdvorwX2g8mZSYwSI97kewVVffUbfm63s3jaW&itag=139&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1730266614%2C&mh=in&mm=31%2C26&mn=sn-ab02a0nfpgxapox-bh2es%2Csn-un57sne7&ms=au%2Conr&mv=m&mvi=3&pcm2cms=yes&pl=18&rms=au%2Cau&initcwndbps=631250&vprv=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=3098057&dur=507.866&lmt=1730247679854257&mt=1730266148&fvip=5&keepalive=yes&fexp=51312688%2C51326932&c=ANDROID_VR&txp=5532434&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAJ1iwrkBkHIGgBxoEOdXDVUki9JxnzCxlH4NwZNL-c7VAiAIuPvuo8iG1lVUslal7d0UgXVSbKRlNX40w6N0WY8ndg%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpcm2cms%2Cpl%2Crms%2Cinitcwndbps&lsig=ACJ0pHgwRgIhALIR7EC_OxXJaEcXyq70r6pKBJzcOc-VBpVflruAyVIaAiEA1Xwp3212wT-5N5XJYpYahE_QW5RwDB_BtFuDeiiUkLA%3D'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info[\"audio_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì‹œë¦¬ê°€ AI ì—ì´ì „íŠ¸ê°€ ëœë‹¤?! ì• í”Œì˜ AI, Apple Intelligence ì•Œì•„ë³´ê¸°  iOS 18.1, iOS 18.2 ê°œë°œìž Beta ì—…ë°ì´íŠ¸'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../miniconda3/envs/youtube/lib/python3.10/site-packages/faster_whisper/assets/pyannote_vad_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "whisper = WhisperTranscriptionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel download...\n",
      "Download complete!\n",
      "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "transcript = await whisper.transcribe(video_info[\"audio_url\"],video_info[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì˜¬í•´ WWDCì—ì„œ ê³µê°œëœ ì• í”Œì˜ AI, Apple Intelligenceê°€ ë“œë””ì–´ iOS 18.1 ì •ì‹ ë²„ì „ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìžˆê²Œ ê³µê°œê°€ ë˜ì—ˆìŠµë‹ˆë‹¤ ë˜ ì¶”ê°€ë¡œ ë” ë§Žì€ AI ê¸°ëŠ¥ë“¤ì´ iOS 18.2 ê°œë°œìž ë² íƒ€ ë²„ì „ì„ í†µí•´ ê³µê°œê°€ ë˜ì—ˆëŠ”ë°ìš” ì—…ë°ì´íŠ¸ëœ AI ê¸°ëŠ¥ë“¤ì„ í•˜ë‚˜ì”© í•¨ê»˜ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤ ì´ë²ˆ iOS 18.1ì— í¬í•¨ëœ AI ê¸°ëŠ¥ë“¤ì€ ê°•ë ¥í•´ì§„ ì‹œë¦¬ë¶€í„° ê¸€ì“°ê¸° ë„êµ¬, ì•Œë¦¼ ê´€ë ¨ AI, í´ë¦°ì—… ì¸ë°ìš” ê°•ë ¥í•´ì§„ ì‹œë¦¬ëŠ” ë””ìžì¸ì´ ë³€ê²½ë˜ì—ˆê³  \n",
      "\n",
      " ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ë¡œ ì—…ë°ì´íŠ¸ëœ ì‹œë¦¬ëŠ” ì‚¬ìš©ìžê°€ í™”ë©´ì—ì„œ ë³´ê³  ìžˆëŠ” ê²ƒì„ íŒŒì•…í•˜ê³  ê·¸ì— ë§žì¶¤ ìž‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆëŠ”ë°ìš” ë¿ë§Œ ì•„ë‹ˆë¼ ë” ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì§€ì›í•´ì„œ ì‚¬ìš©ìžê°€ ë§ì„ ë”ë“¬ê±°ë‚˜ ë©ˆì¶”ë”ë¼ë„ ì´í•´í•˜ê³  ë°˜ì‘í•  ìˆ˜ ìžˆê²Œ ë˜ì—ˆê³  ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•´ ëŒ€í™” ë§¥ë½ë„ ì´í•´í•©ë‹ˆë‹¤ ë‹¤ìŒìœ¼ë¡œ ê¸€ì“°ê¸° ë„êµ¬ëŠ” ì´ë ‡ê²Œ ë²„íŠ¼ë§Œ ë”¸ê¹í•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ êµì •í•˜ê³  ë‹¤ì‹œ ì“°ê³  ìš”ì•½í•´ì£¼ëŠ” ê¸°ëŠ¥ìž…ë‹ˆë‹¤ ë§žì¶¤ë²•ì„ ê³ ì¹˜ê±°ë‚˜ í…ìŠ¤íŠ¸ì˜ ëŠë‚Œì„ ì¢€ ë” ì¹œê·¼í•˜ê²Œ ë˜ëŠ” ì „ë¬¸ì ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤ \n",
      "\n",
      " ë„¤ì´í‹°ë¸Œ ì•±ì€ ë¬¼ë¡  ì„œë“œíŒŒí‹° ì•±ì—ì„œë„ í™œìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë©”ì¼ ì•±ì´ë‚˜ ë©”ì‹œì§€ ì•±ì—ì„œëŠ” ì´ë©”ì¼ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ê³  ì•Œë¦¼ì„ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ëŠ” ê¸°ëŠ¥ê³¼ ë‹µë³€ì„ ì¶”ì²œí•´ì£¼ëŠ” ìŠ¤ë§ˆíŠ¸ ë‹µìž¥ ê¸°ëŠ¥ë„ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. Reduce Interruption ì´ë¼ëŠ” ìƒˆë¡œìš´ ë°©í•´ ê¸ˆì§€ ëª¨ë“œë„ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. AIê°€ ì•Œë¦¼ì˜ ì¤‘ìš”ë„ë¥¼ íŒë‹¨í•´ì„œ ì¤‘ìš”í•œ ì•Œë¦¼ë§Œ ë…¸ì¶œì‹œì¼œì¤ë‹ˆë‹¤. ì• í”Œ ì›Œì¹˜ì—ì„œë„ ë™ì¼í•˜ê²Œ ì´ ë°©í•´ ê¸ˆì§€ ëª¨ë“œë¥¼ ì ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚¬ì§„ì˜ íŠ¹ì • ë¶€ë¶„ì„ ì§€ìš°ëŠ” \n",
      "\n",
      " ê¸°ëŠ¥ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ë²ˆ iOS 18.2 ê°œë°œìž ë² íƒ€ ì—…ë°ì´íŠ¸ì—ì„œëŠ” ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ì˜ ë‹¤ë¥¸ ê¸°ëŠ¥ë“¤ë„ ë¯¸ë¦¬ ì²´í—˜í•´ ë³¼ ìˆ˜ ìžˆì—ˆëŠ”ë°ìš”. Genmoji, Image Playground, Visual Intelligence, ChatGPTì™€ í†µí•©ëœ Sirië¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì—…ë°ì´íŠ¸ì—ì„œëŠ” ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ìƒì„± AI ê¸°ëŠ¥ì´ í¬í•¨ë˜ì—ˆëŠ”ë°ìš”. ë² íƒ€ ë²„ì „ì—ì„œëŠ” ì›¨ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹ ì²­í•˜ê³  ìŠ¹ì¸ì´ ë˜ì–´ì•¼ ì“¸ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. GenmojiëŠ” ë‚˜ë§Œì˜ ì´ëª¨ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìžˆëŠ” ê¸°ëŠ¥ìž…ë‹ˆë‹¤. \n",
      "\n",
      " ì›í•˜ëŠ” ì´ëª¨ì§€ì— ê°„ë‹¨í•œ ì„¤ëª…ì„ ìž…ë ¥í•˜ë©´ ì œëª¨ì§€ê°€ ìƒì„±ë˜ëŠ”ë°ìš” ìƒì„±ëœ ì´ëª¨ì§€ ì¤‘ì— ë§ˆìŒì— ë“œëŠ” ê²ƒì„ ì„ íƒí•´ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ë“¯ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ ë‹¤ìŒìœ¼ë¡œ ì´ë¯¸ì§€ í”Œë ˆì´ê·¸ë¼ìš´ë“œëŠ” ì• í”Œì˜ ì´ë¯¸ì§€ ìƒì„± AIë¡œ ìƒˆë¡œ ìƒê¸´ ì•± ë˜ëŠ” ë©”ì‹œì§€ ì•±ê³¼ ë©”ì¼ ì•± ë“±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ”ë°ìš” í…ìŠ¤íŠ¸ë¡œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìž…ë ¥í•˜ë©´ ë§Œí™”ë‚˜ ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë¡œ ë¹ ë¥´ê²Œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ë©° ì¶”ê°€ë¡œ ì•„ì´í…œì´ë‚˜ ì˜ìƒì„ ë§ë¶™ì—¬ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì •í•  ìˆ˜ë„ ìžˆê³  ë‚´ ì‚¬ì§„ì„ ê¸°ë°˜ìœ¼ë¡œë„ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ \n",
      "\n",
      " ì¶”ê°€ë¡œ ì•„ì´íŒ¨ë“œì—ì„œëŠ” Image Wandë¼ëŠ” ê¸°ëŠ¥ë„ ì‚¬ìš© ê°€ëŠ¥í•œë°ìš”. ë©”ëª¨ì—ì„œ ê°„ë‹¨í•œ ìŠ¤ì¼€ì¹˜ë¥¼ í•˜ë©´ ì´ë¥¼ ì •êµí•œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤. ì´ì œ ì•„ì´í° 16 ì‹œë¦¬ì¦ˆì˜ ì¹´ë©”ë¼ ë²„íŠ¼ì„ ê¾¹ ëˆ„ë¥´ë©´ Visual Intelligenceë¥¼ í™œìš©í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤. ì´ ìƒíƒœë¡œ ì‚¬ë¬¼ì„ ì´¬ì˜í•˜ë©´ ê´€ë ¨ëœ ì§ˆë¬¸ì„ êµ¬ê¸€ë¡œ ê²€ìƒ‰í•˜ê±°ë‚˜ ìµœì¸ í”¼í‹°ì—ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìžˆê²Œ ë˜ì—ˆëŠ”ë°ìš”. ë§ì´ ë§Žì•˜ë˜ ì´ ë²„íŠ¼, ë“œë””ì–´ ì“¸ëª¨ë¥¼ ì°¾ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìµœì¸ í”¼í‹° ì–˜ê¸°ê°€ ë‚˜ì™”ìœ¼ë‹ˆ ë°”ë¡œ ì–˜ê¸°ë¥¼ í•˜ìžë©´ \n",
      "\n",
      " ì‹œë¦¬ì— ë­”ê°€ ë¬¼ì–´ë³´ê³  ë‚˜ì„œ ìµœì°Œ PTë¥¼ ì‚¬ìš©í•´ì„œ ëŒ€ë‹µí•´ë‹¬ë¼ê³  í•˜ë©´ ìµœì°Œ PTë¥¼ ì´ìš©í•œ ëŒ€ë‹µì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìµœì°Œ PTë¥¼ ìœ ë£Œë¡œ êµ¬ë… ì¤‘ì´ì‹œë¼ë©´ ê³„ì • ì—°ë™ë„ ê°€ëŠ¥í•œë°ìš”. ê³„ì •ì„ ì—°ë™í•˜ê³  ê·¸ë¦¼ì„ ê·¸ë ¤ë‹¬ë¼ê³  ë¶€íƒí•˜ë©´ GPTê°€ ê·¸ë¦¼ë„ ë°”ë¡œ ê·¸ë ¤ì£¼ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ WWDCì—ì„œ ì†Œê°œëœ ë‚´ìš© ì¤‘ ì•„ì§ ì™„ì „ížˆ êµ¬í˜•ë˜ì§€ ì•Šì€ ê¸°ëŠ¥ë“¤ì´ ìžˆëŠ”ë°ìš”. ë°”ë¡œ In-App Actionsì™€ Personal Contextìž…ë‹ˆë‹¤. ì‚¬ì‹¤ ì´ ë‘ ê°€ì§€ ê¸°ëŠ¥ì´ ì‹œë¦¬ì˜ ë³€í™”ì™€ ê´€ë ¨ëœ í•µì‹¬ ê¸°ëŠ¥ì´ë¼ê³  í•  ìˆ˜ ìžˆê² ëŠ”ë°ìš”. \n",
      "\n",
      " ìƒê°í•˜ëŠ” ì§„ì§œ ì‹œë¦¬ëŠ” ë¬´ì—‡ì¼ì§€ ê°œë°œìžì™€ ê´€ë ¨ëœ ì—…ë°ì´íŠ¸ë¥¼ ë˜ì§šì–´ë³´ë©´ ìžì„¸ížˆ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¼ë‹¨ ì´ë²ˆ WWDCì—ì„œ ê°œë°œìžë“¤ì´ ìžì‹ ë“¤ì˜ ì•±ì„ ì‹œë¦¬ì™€ í†µí•©í•  ìˆ˜ ìžˆê²Œ í•´ì£¼ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ìƒˆë¡­ê²Œ ê³µê°œí–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ ì´ì „ë¶€í„° ì‹œë¦¬í‚¥ê³¼ ì•± ì¸í…ì¸  í”„ë ˆìž„ì›Œí¬ë¥¼ í†µí•´ì„œ ê°œë°œìžë“¤ì´ ì‹œë¦¬ì™€ ë³¸ì¸ì˜ ì•±ì„ í†µí•©í•  ìˆ˜ ìžˆì—ˆì§€ë§Œ ì´ë²ˆì— ê³µê°œëœ ì•± ì¸í…ì¸  ë„ë©”ì¸ê³¼ ì¸ë±ìŠ¤íŠ¸ ì—”í‹°í‹° APIë¥¼ í™œìš©í•˜ë©´ ì‹œë¦¬ì™€ ì—¬ëŸ¬ë¶„ì˜ ì•±ì„ ì¢€ ë” ê¸´ë°€í•˜ê²Œ í†µí•©í•  ìˆ˜ ìžˆê²Œ ë˜ëŠ”ë°ìš”. \n",
      "\n",
      " ì•± ì¸í…ì¸ ëŠ” ì•±ì´ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ì„ ì‹œë¦¬ ë° ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ì´í•´í•  ìˆ˜ ìžˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í”„ë ˆìž„ì›Œí¬ì¸ë°ìš”. ì´ë²ˆ ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ì•± ì¸í…ì¸ ì— ì‚¬ì§„, ë©”ì¼ ë“±ì„ í¬í•¨í•œ 12ê°œì˜ ë„ë©”ì¸ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰, ì´ë ‡ê²Œ ìƒˆë¡œìš´ ë„ë©”ì¸ì˜ ê¸°ëŠ¥ë“¤ì„ ì‹œë¦¬ ë° ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ì™€ í†µí•©í•  ìˆ˜ ìžˆê²Œ ëœ ê²ƒì´ì£ . ì´ë¥¼ í†µí•´ ì• í”Œì—ì„œ ì§ì ‘ ë§Œë“  ì•±ì´ ì•„ë‹Œ ì„œë“œ íŒŒí‹° ì•±ì—ì„œë„ ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ì•± ê¸°ëŠ¥ì„ ì§ì ‘ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•´ì§€ëŠ” ì¸ì•± ì•¡ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. \n",
      "\n",
      " ë˜ ë‹¤ë¥¸ APIì¸ Indexed Entity APIë¥¼ í™œìš©í•˜ë©´ ì•± ë‚´ì˜ ë°ì´í„° êµ¬ì¡°ë¥¼ Spotlightì™€ ì‹œë¦¬ê°€ ê²€ìƒ‰í•  ìˆ˜ ìžˆëŠ” í˜•íƒœë¡œ ë§Œë“¤ì–´ì£¼ëŠ”ë°ìš”. ì´ë¥¼ ì¸ë±ì‹±í•œë‹¤ê³  í•©ë‹ˆë‹¤. ì•± ë‚´ì˜ ì»¨í…ì¸ ë¥¼ ì¸ë±ì‹±í•˜ë©´ ì‹œë¦¬ê°€ ì´ê±¸ ë“¤ì—¬ë‹¤ë³¼ ìˆ˜ ìžˆê²Œ ë˜ëŠ” ê²ƒì´ì£ . ê·¸ëŸ° ì¸ë±ì‹±í•œ ì •ë³´ë¥¼ ì´ìš©í•´ ë” ë‹¤ì–‘í•œ ì—…ë¬´ë¥¼ í•  ìˆ˜ë„ ìžˆê²Œ ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ Indexed Entityë¥¼ í†µí•´ ì‹œë©˜í‹± ê²€ìƒ‰, ì¦‰ ì˜ë¯¸ ê²€ìƒ‰ë„ ê°€ëŠ¥í•´ì§€ëŠ”ë°ìš”. ê¸°ì¡´ì—ëŠ” ê³ ì–‘ì´ ì‚¬ì§„ì„ ê²€ìƒ‰í•´ë‹¬ë¼ê³  í•˜ë©´ \n",
      "\n",
      " ì´ì œëŠ” ë°˜ë ¤ë™ë¬¼ì„ ê²€ìƒ‰í•´ë‹¬ë¼ê³  í•˜ë©´ ì‹œë¦¬ê°€ ìžì—°ì–´ì²˜ë¦¬ë¥¼ í†µí•´ ê³ ì–‘ì´, ê°•ì•„ì§€ ë“±ë“±ì„ ëª¨ë‘ ì°¾ì•„ì¤„ ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. ì„¤ëª…ì´ êµ‰ìž¥ížˆ ê¸¸ì—ˆëŠ”ë°ìš”. ê·¸ëŸ¼ ì´ë ‡ê²Œ ì‹œë¦¬ì™€ ì•±ì´ ìž˜ í†µí•©ë˜ë©´ ì–´ë–¤ ê²ƒì´ ê°€ëŠ¥í•´ì¡Œëƒ? ë§Œì•½ì— ì‚¬ìš©ìžê°€ ë‹¤ìŒ ì£¼ ë‰´ìš• ì¶œìž¥ ê³„íšì„ ìš”ì•½í•´ì„œ PDì—ê²Œ ë©”ì¼ë¡œ ë‹µìž¥í•´ì¤˜ ë¼ê³  ìš”ì²­ì„ í•œë‹¤ê³  ê°€ì •ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¼ë‹¨ ì‹œë¦¬ê°€ ë©”ì¼ë¡œ ì£¼ê³ ë°›ì€ ì¶œìž¥ ê´€ë ¨ ì •ë³´, ìº˜ë¦°ë” ì•±ì˜ ì¼ì •, ì—¬í–‰ ì•±ì˜ ì˜ˆì•½ ì •ë³´, ë©”ëª¨ ì•±ì˜ ê´€ë ¨ ë…¸íŠ¸ ë“±ì„ \n",
      "\n",
      " ì´ë•Œ ì—¬í–‰ ì•± ê°œë°œìžê°€ Indexed Entity APIë¥¼ í™œìš©í•´ ë°ì´í„°ë¥¼ ì¸ë±ì‹±í•  ìˆ˜ ìžˆê²Œ í•´ë‘ë©´ ì‹œë¦¬ê°€ ì˜ˆì•½ ì •ë³´ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. ì´ ë¶€ë¶„ì´ WWDCì—ì„œ ì–˜ê¸°í–ˆë˜ Personal Contextì¸ë°ìš”. ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ë‹¤ì–‘í•œ ì•±ì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ í†µí•´ ê°œì¸ì ì¸ ë§¥ë½ì„ ì´í•´í•  ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ ëª¨ì€ ê°œì¸ ì •ë³´ë¥¼ ì‹œë¦¬ê°€ ìš”ì•½í•´ì„œ ë©”ì¼ë¡œ ì „í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ ì• í”Œ ë©”ì¼ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë©”ì¼ ì•±ì„ ì‚¬ìš©í•˜ë”ë¼ë„ \n",
      "\n",
      " Intentsì™€ ì—°ê²°ë˜ì–´ ìžˆë‹¤ë©´ ì‹œë¦¬ê°€ ê·¸ ì•±ì˜ ë©”ì¼ ë‹µìž¥ ê¸°ëŠ¥ì„ ì´í•´í•˜ê³  ì•Œì•„ì„œ ë‹µìž¥ì„ ë³´ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ ê²°êµ­ ì• í”Œì´ ìƒê°í•˜ëŠ” ê¶ê·¹ì ì¸ ì‹œë¦¬ëŠ” ë‹¨ìˆœížˆ ë§ì„ ì•Œì•„ë“£ê³  ë‹µë³€ë§Œ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì‚¬ìš©ìžì˜ ìš”ì²­ì„ ì´í•´í•˜ê³  ì—¬ëŸ¬ ì•±ì˜ ë°ì´í„°ì™€ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‹¤ì œ í•„ìš”í•œ ìž‘ì—…ì„ ì‚¬ëžŒì„ ëŒ€ì‹ í•´ì„œ ìˆ˜í–‰í•´ì£¼ëŠ” AIë¥¼ ì§€í–¥í•˜ê³  ìžˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆëŠ”ë°ìš” ì´ë¥¼ ê°„ë‹¨ížˆ AI ì—ì´ì „íŠ¸ë¼ê³  í•©ë‹ˆë‹¤ ì •ë¦¬í•˜ë©´ ì˜¬í•´ WWDCì—ì„œ ì—…ë°ì´íŠ¸ëœ ë‚´ìš©ë“¤ì´ \n",
      "\n",
      " ì¸ì•± ì•¡ì…˜ìŠ¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³  í¼ìŠ¤ë„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìžˆê²Œ í•´ì£¼ëŠ”ë°ìš” ì¦‰, ì‹œë¦¬ë¥¼ AI ì—ì´ì „íŠ¸ë¡œ ë§Œë“¤ì–´ì¤„ ìˆ˜ ìžˆë„ë¡ ê¼½ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê²Œ ë˜ëŠ” ê²ƒì´ì£  ë‹¤ë§Œ ì•„ì§ì€ ì´ë²ˆ ì—…ë°ì´íŠ¸ë¥¼ ê°œë°œìžë“¤ì´ ê°ê°ì˜ ì•±ì— ë‹¤ ì ìš©í•˜ê¸°ì—ëŠ” ì‹œê°„ë„ ë§Žì´ í•„ìš”í•˜ê³  ì‹œë¦¬ ë˜í•œ ì•„ì§ ê¸°ëŠ¥ì´ ì™„ë²½í•˜ì§€ ì•Šì€ë°ìš” ì•žìœ¼ë¡œ ì‹œë¦¬ê°€ ë” ë§Žì€ ì•±ì˜ ë°ì´í„°ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìžˆê³  ì•± ë‚´ì˜ ë™ìž‘ ìˆ˜í–‰ë„ ê°€ëŠ¥í•´ì§ˆ í…Œë‹ˆ ëª¨ë“  ìž‘ì—…ì„ ì•Œì•„ì„œ ìˆ˜í–‰í•˜ëŠ” ì•„ì´ì–¸ë§¨ì˜ ìžë¹„ìŠ¤ ê°™ì€ ë‚˜ë§Œì˜ ë¹„ì„± \n",
      "\n",
      " AI ì—ì´ì „íŠ¸ ì‹œë¦¬ë¥¼ ê³§ ë§Œë‚˜ë³¼ ìˆ˜ ìžˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì— ì¶”ê°€ëœ ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤. ì•„ì§ì€ ì•ˆíƒ€ê¹ê²Œë„ ë¯¸êµ­ í•œì •ìœ¼ë¡œ ì˜ì–´ë¡œë§Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•œë°ìš”. ëª‡ ê°€ì§€ ê³¼ì •ì„ ê±°ì¹˜ë©´ í•œêµ­ì—ì„œë„ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¼ë‹¨ êµ­ê°€ë¥¼ ë¯¸êµ­ìœ¼ë¡œ ì„¤ì •í•´ì¤˜ì•¼ í•˜ëŠ”ë°ìš”. ì„¤ì •ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ì¼ë°˜, ì–¸ì–´ ë° ì§€ì—­ìœ¼ë¡œ ì´ë™í•œ í›„ ì˜ì–´ë¥¼ ê¸°ë³¸ ì–¸ì–´ë¡œ ì„ íƒí•˜ê³  ì§€ì—­ì„ ë¯¸êµ­ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ë§Œì•½ ì˜ì–´ê°€ ì—†ë‹¤ë©´ ì–¸ì–´ ì¶”ê°€ë¥¼ í†µí•´ ì„¤ì¹˜í•˜ê³  \n",
      "\n",
      " ê¸°ë³¸ìœ¼ë¡œ ì„¤ì •í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤ ë˜ ë² íƒ€ ë²„ì „ì„ ë‹¤ìš´ë°›ìœ¼ë ¤ë©´ ê°œë°œìž ë“±ë¡ì´ í•„ìš”í•œë°ìš” ì• í”Œ ë””ë²¨ë¡œí¼ í™ˆíŽ˜ì´ì§€ ë˜ëŠ” ì•±ì—ì„œ ìžì‹ ì˜ ì• í”Œ ì•„ì´ë””ë¡œ ë¡œê·¸ì¸í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤ ë§ˆì§€ë§‰ìœ¼ë¡œ ë¯¸êµ­ ì•±ìŠ¤í† ì–´ë¥¼ ê°™ì´ ì´ìš©í•˜ë ¤ë©´ ë¯¸êµ­ ì£¼ì†Œê°€ í•„ìš”í•œë°ìš” ë¯¸êµ­ ë°°ì†¡ëŒ€í–‰ì§€ë¥¼ ê²€ìƒ‰í•´ ë‚˜ì˜¤ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ë©´ ê°„ë‹¨í•˜ê²Œ ë¯¸êµ­ ì£¼ì†Œë¥¼ ìƒì„±í•˜ê³  ë“±ë¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ ë‹¤ë§Œ ì§€ê¸ˆ ë§ì”€ë“œë¦° ë°©ë²•ì€ ê³µì‹ì ì¸ ì‚¬ìš©ë²•ì€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë””ë°”ì´ìŠ¤ì—ëŠ” ì ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤ \n",
      "\n",
      " ì§€ê¸ˆê¹Œì§€ ê³µê°œëœ ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ì™€ ì• í”Œì´ ìƒê°í•˜ëŠ” AIì˜ ë¯¸ëž˜ë¥¼ ì†Œê°œí•´ë“œë ¸ëŠ”ë°ìš” ì• í”Œì´ ë‚´ë…„ê¹Œì§€ ê³„ì†í•´ì„œ AI ê´€ë ¨ ì—…ë°ì´íŠ¸ë¥¼ ì˜ˆê³ í•˜ê³  ìžˆëŠ” ë§Œí¼ ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ë‚˜ì˜¤ë©´ ì¶”ê°€ë¡œ ë” ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ì˜ìƒì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒë“œë¦¬ê² ìŠµë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for script in transcript['script']:\n",
    "    print(script['text'],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel download...\n",
      "Download complete!\n",
      "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "transcript = await whisper.transcribe(video_info[\"audio_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì˜¬í•´ WWDCì—ì„œ ê³µê°œëœ ì• í”Œì˜ AI, ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ë“œë””ì–´ iOS 18.1 ì •ì‹ ë²„ì „ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìžˆê²Œ ê³µê°œê°€ ë˜ì—ˆìŠµë‹ˆë‹¤ ë˜ ì¶”ê°€ë¡œ ë” ë§Žì€ AI ê¸°ëŠ¥ë“¤ì´ iOS 18.2 ê°œë°œìž ë² íƒ€ ë²„ì „ì„ í†µí•´ ê³µê°œê°€ ë˜ì—ˆëŠ”ë°ìš” ì—…ë°ì´íŠ¸ëœ AI ê¸°ëŠ¥ë“¤ì„ í•˜ë‚˜ì”© í•¨ê»˜ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤ ì´ë²ˆ iOS 18.1ì— í¬í•¨ëœ AI ê¸°ëŠ¥ë“¤ì€ ê°•ë ¥í•´ì§„ Sirië¶€í„° ê¸€ì“°ê¸° ë„êµ¬, ì•Œë¦¼ ê´€ë ¨ AI, í´ë¦°ì—…ì¸ë°ìš” ê°•ë ¥í•´ì§„ SiriëŠ” ë””ìžì¸ì´ ë³€ê²½ë˜ì—ˆê³  \n",
      "\n",
      " ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ë¡œ ì—…ë°ì´íŠ¸ëœ SiriëŠ” ì‚¬ìš©ìžê°€ í™”ë©´ì—ì„œ ë³´ê³  ìžˆëŠ” ê²ƒì„ íŒŒì•…í•˜ê³  ê·¸ì— ë§žì¶¤ ìž‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆëŠ”ë°ìš” ë¿ë§Œ ì•„ë‹ˆë¼ ë” ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì§€ì›í•´ì„œ ì‚¬ìš©ìžê°€ ë§ì„ ë”ë“¬ê±°ë‚˜ ë©ˆì¶”ë”ë¼ë„ ì´í•´í•˜ê³  ë°˜ì‘í•  ìˆ˜ ìžˆê²Œ ë˜ì—ˆê³  ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•´ ëŒ€í™” ë§¥ë½ë„ ì´í•´í•©ë‹ˆë‹¤ ë‹¤ìŒìœ¼ë¡œ ê¸€ì“°ê¸° ë„êµ¬ëŠ” ì´ë ‡ê²Œ ë²„íŠ¼ë§Œ ë”¸ê¹í•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ êµì •í•˜ê³  ë‹¤ì‹œ ì“°ê³  ìš”ì•½í•´ì£¼ëŠ” ê¸°ëŠ¥ìž…ë‹ˆë‹¤ ë§žì¶¤ë²•ì„ ê³ ì¹˜ê±°ë‚˜ í…ìŠ¤íŠ¸ì˜ ëŠë‚Œì„ ì¢€ ë” ì¹œê·¼í•˜ê²Œ ë˜ëŠ” ì „ë¬¸ì ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤ \n",
      "\n",
      " ë„¤ì´í‹°ë¸Œ ì•±ì€ ë¬¼ë¡  ì„œë“œíŒŒí‹° ì•±ì—ì„œë„ í™œìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë©”ì¼ ì•±ì´ë‚˜ ë©”ì‹œì§€ ì•±ì—ì„œëŠ” ì´ë©”ì¼ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ê³  ì•Œë¦¼ì„ ìš”ì•½í•´ì„œ ë³´ì—¬ì£¼ëŠ” ê¸°ëŠ¥ê³¼ ë‹µë³€ì„ ì¶”ì²œí•´ì£¼ëŠ” ìŠ¤ë§ˆíŠ¸ ë‹µìž¥ ê¸°ëŠ¥ë„ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. Reduce Interruptionì´ë¼ëŠ” ìƒˆë¡œìš´ ë°©í•´ ê¸ˆì§€ ëª¨ë“œë„ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. AIê°€ ì•Œë¦¼ì˜ ì¤‘ìš”ë„ë¥¼ íŒë‹¨í•´ì„œ ì¤‘ìš”í•œ ì•Œë¦¼ë§Œ ë…¸ì¶œì‹œì¼œì¤ë‹ˆë‹¤. ì• í”Œ ì›Œì¹˜ì—ì„œë„ ë™ì¼í•˜ê²Œ ì´ ë°©í•´ ê¸ˆì§€ ëª¨ë“œë¥¼ ì ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì‚¬ì§„ì˜ íŠ¹ì • ë¶€ë¶„ì„ ì§€ìš°ëŠ” \n",
      "\n",
      " ì´ë²ˆ iOS 18.2 ê°œë°œìž ë² íƒ€ ì—…ë°ì´íŠ¸ì—ì„œëŠ” ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ì˜ ë‹¤ë¥¸ ê¸°ëŠ¥ë“¤ë„ ë¯¸ë¦¬ ì²´í—˜í•´ ë³¼ ìˆ˜ ìžˆì—ˆëŠ”ë°ìš” ì´ë²ˆ ì—…ë°ì´íŠ¸ì—ì„œëŠ” ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ìƒì„± AI ê¸°ëŠ¥ì´ í¬í•¨ë˜ì—ˆëŠ”ë°ìš” ë² íƒ€ ë²„ì „ì—ì„œëŠ” ì›¨ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹ ì²­í•˜ê³  ìŠ¹ì¸ì´ ë˜ì–´ì•¼ ì“¸ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ \n",
      "\n",
      " ê·¸ë¦¬ê³  ì›í•˜ëŠ” ì´ëª¨ì§€ì— ê°„ë‹¨í•œ ì„¤ëª…ì„ ìž…ë ¥í•˜ë©´ ì œëª¨ì§€ê°€ ìƒì„±ë˜ëŠ”ë°ìš” ìƒì„±ëœ ì´ëª¨ì§€ ì¤‘ì— ë§ˆìŒì— ë“œëŠ” ê²ƒì„ ì„ íƒí•´ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ë“¯ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ ë‹¤ìŒìœ¼ë¡œ ì´ë¯¸ì§€ í”Œë ˆì´ê·¸ë¼ìš´ë“œëŠ” ì• í”Œì˜ ì´ë¯¸ì§€ ìƒì„± AIë¡œ ìƒˆë¡œ ìƒê¸´ ì•± ë˜ëŠ” ë©”ì‹œì§€ ì•±ê³¼ ë©”ì¼ ì•± ë“±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ”ë°ìš” í…ìŠ¤íŠ¸ë¡œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìž…ë ¥í•˜ë©´ ë§Œí™”ë‚˜ ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë¡œ ë¹ ë¥´ê²Œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ë©° ì¶”ê°€ë¡œ ì•„ì´í…œì´ë‚˜ ì˜ìƒì„ ë§ë¶™ì—¬ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì •í•  ìˆ˜ë„ ìžˆê³  ë‚´ ì‚¬ì§„ì„ ê¸°ë°˜ìœ¼ë¡œë„ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ \n",
      "\n",
      " ì¶”ê°€ë¡œ ì•„ì´íŒ¨ë“œì—ì„œëŠ” Image Wandë¼ëŠ” ê¸°ëŠ¥ë„ ì‚¬ìš© ê°€ëŠ¥í•œë°ìš”. ë©”ëª¨ì—ì„œ ê°„ë‹¨í•œ ìŠ¤ì¼€ì¹˜ë¥¼ í•˜ë©´ ì´ë¥¼ ì •êµí•œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤. ì´ì œ ì•„ì´í° 16 ì‹œë¦¬ì¦ˆì˜ ì¹´ë©”ë¼ ë²„íŠ¼ì„ ê¾¹ ëˆ„ë¥´ë©´ Visual Intelligenceë¥¼ í™œìš©í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤. ì´ ìƒíƒœë¡œ ì‚¬ë¬¼ì„ ì´¬ì˜í•˜ë©´ ê´€ë ¨ëœ ì§ˆë¬¸ì„ êµ¬ê¸€ë¡œ ê²€ìƒ‰í•˜ê±°ë‚˜ ìµœì¸ í”¼í‹°ì—ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìžˆê²Œ ë˜ì—ˆëŠ”ë°ìš”. ë§ì´ ë§Žì•˜ë˜ ì´ ë²„íŠ¼, ë“œë””ì–´ ì“¸ëª¨ë¥¼ ì°¾ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìµœì¸ í”¼í‹° ì–˜ê¸°ê°€ ë‚˜ì™”ìœ¼ë‹ˆ ë°”ë¡œ ì–˜ê¸°ë¥¼ í•˜ìžë©´ \n",
      "\n",
      " ì‹¤ì˜ì— ë­”ê°€ ë¬¼ì–´ë³´ê³  ë‚˜ì„œ ìµœì°ŒPTë¥¼ ì‚¬ìš©í•´ì„œ ëŒ€ë‹µí•´ë‹¬ë¼ê³  í•˜ë©´ ìµœì°ŒPTë¥¼ ì´ìš©í•œ ëŒ€ë‹µì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìµœì°ŒPTë¥¼ ìœ ë£Œë¡œ êµ¬ë… ì¤‘ì´ì‹œë¼ë©´ ê³„ì • ì—°ë™ë„ ê°€ëŠ¥í•œë°ìš”. ê³„ì •ì„ ì—°ë™í•˜ê³  ê·¸ë¦¼ì„ ê·¸ë ¤ë‹¬ë¼ê³  ë¶€íƒí•˜ë©´ GPTê°€ ê·¸ë¦¼ë„ ë°”ë¡œ ê·¸ë ¤ì£¼ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ WWDCì—ì„œ ì†Œê°œëœ ë‚´ìš© ì¤‘ ì•„ì§ ì™„ì „ížˆ êµ¬í˜•ë˜ì§€ ì•Šì€ ê¸°ëŠ¥ë“¤ì´ ìžˆëŠ”ë°ìš”. ë°”ë¡œ In-App Actionsì™€ Personal Contextìž…ë‹ˆë‹¤. ì‚¬ì‹¤ ì´ ë‘ ê°€ì§€ ê¸°ëŠ¥ì´ ì‹¤ì˜ì˜ ë³€í™”ì™€ ê´€ë ¨ëœ í•µì‹¬ ê¸°ëŠ¥ì´ë¼ê³  í•  ìˆ˜ ìžˆê² ëŠ”ë°ìš”. \n",
      "\n",
      " ì œê°€ ìƒê°í•˜ëŠ” ì§„ì§œ ì‹œë¦¬ëŠ” ë¬´ì—‡ì¼ì§€ ê°œë°œìžì™€ ê´€ë ¨ëœ ì—…ë°ì´íŠ¸ë¥¼ ë˜ì§šì–´ë³´ë©´ ìžì„¸ížˆ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ ì¼ë‹¨ ì´ë²ˆ WWDCì—ì„œ ê°œë°œìžë“¤ì´ ìžì‹ ë“¤ì˜ ì•±ì„ ì‹œë¦¬ì™€ í†µí•©í•  ìˆ˜ ìžˆê²Œ í•´ì£¼ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ìƒˆë¡­ê²Œ ê³µê°œí–ˆìŠµë‹ˆë‹¤ ì´ë¯¸ ì´ì „ë¶€í„° ì‹œë¦¬í‚¥ê³¼ ì•± ì¸í…ì¸  í”„ë ˆìž„ì›Œí¬ë¥¼ í†µí•´ì„œ ê°œë°œìžë“¤ì´ ì‹œë¦¬ì™€ ë³¸ì¸ì˜ ì•±ì„ í†µí•©í•  ìˆ˜ ìžˆì—ˆì§€ë§Œ ì´ë²ˆì— ê³µê°œëœ ì•± ì¸í…ì¸  ë„ë©”ì¸ê³¼ ì¸ë±ìŠ¤íŠ¸ ì—”í‹°í‹° APIë¥¼ í™œìš©í•˜ë©´ ì‹œë¦¬ì™€ ì—¬ëŸ¬ë¶„ì˜ ì•±ì„ ì¢€ ë” ê¸´ë°€í•˜ê²Œ í†µí•©í•  ìˆ˜ ìžˆê²Œ ë˜ëŠ”ë°ìš” \n",
      "\n",
      " ì•± ì¸í…ì¸ ëŠ” ì•±ì´ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ì„ Siri ë° ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ì´í•´í•  ìˆ˜ ìžˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í”„ë ˆìž„ì›Œí¬ì¸ë°ìš” ì´ë²ˆ ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ì•± ì¸í…ì¸ ì— ì‚¬ì§„, ë©”ì¼ ë“±ì„ í¬í•¨í•œ 12ê°œì˜ ë„ë©”ì¸ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤ ì¦‰, ì´ë ‡ê²Œ ìƒˆë¡œìš´ ë„ë©”ì¸ì˜ ê¸°ëŠ¥ë“¤ì„ Siri ë° ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ì™€ í†µí•©í•  ìˆ˜ ìžˆê²Œ ëœ ê²ƒì´ì£  ì´ë¥¼ í†µí•´ ì• í”Œì—ì„œ ì§ì ‘ ë§Œë“  ì•±ì´ ì•„ë‹Œ ì„œë“œ íŒŒí‹° ì•±ì—ì„œë„ ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ì•± ê¸°ëŠ¥ì„ ì§ì ‘ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•´ì§€ëŠ” ì¸ì•± ì•¡ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤ \n",
      "\n",
      " ë˜ ë‹¤ë¥¸ APIì¸ Indexed Entity APIë¥¼ í™œìš©í•˜ë©´ ì•± ë‚´ì˜ ë°ì´í„° êµ¬ì¡°ë¥¼ Spotlightì™€ Siriê°€ ê²€ìƒ‰í•  ìˆ˜ ìžˆëŠ” í˜•íƒœë¡œ ë§Œë“¤ì–´ì£¼ëŠ”ë°ìš”. ì´ë¥¼ ì¸ë±ì‹±í•œë‹¤ê³  í•©ë‹ˆë‹¤. ì•± ë‚´ì˜ ì»¨í…ì¸ ë¥¼ ì¸ë±ì‹±í•˜ë©´ Siriê°€ ì´ê±¸ ë“¤ì—¬ë‹¤ë³¼ ìˆ˜ ìžˆê²Œ ë˜ëŠ” ê²ƒì´ì£ . ê·¸ëŸ° ì¸ë±ì‹±í•œ ì •ë³´ë¥¼ ì´ìš©í•´ ë” ë‹¤ì–‘í•œ ì—…ë¬´ë¥¼ í•  ìˆ˜ë„ ìžˆê²Œ ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ Indexed Entityë¥¼ í†µí•´ ì‹œë©˜í‹± ê²€ìƒ‰, ì¦‰ ì˜ë¯¸ ê²€ìƒ‰ë„ ê°€ëŠ¥í•´ì§€ëŠ”ë°ìš”. ê¸°ì¡´ì—ëŠ” ê³ ì–‘ì´ ì‚¬ì§„ì„ ê²€ìƒ‰í•´ë‹¬ë¼ê³  í•˜ë©´ \n",
      "\n",
      " ì´ì œëŠ” ë°˜ë ¤ë™ë¬¼ì„ ê²€ìƒ‰í•´ë‹¬ë¼ê³  í•˜ë©´ ì‹œë¦¬ê°€ ìžì—°ì–´ì²˜ë¦¬ë¥¼ í†µí•´ ê³ ì–‘ì´, ê°•ì•„ì§€ ë“±ë“±ì„ ëª¨ë‘ ì°¾ì•„ì¤„ ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. ì„¤ëª…ì´ êµ‰ìž¥ížˆ ê¸¸ì—ˆëŠ”ë°ìš”. ê·¸ëŸ¼ ì´ë ‡ê²Œ ì‹œë¦¬ì™€ ì•±ì´ ìž˜ í†µí•©ë˜ë©´ ì–´ë–¤ ê²ƒì´ ê°€ëŠ¥í•´ì¡Œëƒ? ë§Œì•½ì— ì‚¬ìš©ìžê°€ ë‹¤ìŒ ì£¼ ë‰´ìš• ì¶œìž¥ ê³„íšì„ ìš”ì•½í•´ì„œ PDì—ê²Œ ë©”ì¼ë¡œ ë‹µìž¥í•´ì¤˜ ë¼ê³  ìš”ì²­ì„ í•œë‹¤ê³  ê°€ì •ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¼ë‹¨ ì‹œë¦¬ê°€ ë©”ì¼ë¡œ ì£¼ê³ ë°›ì€ ì¶œìž¥ ê´€ë ¨ ì •ë³´, ìº˜ë¦°ë” ì•±ì˜ ì¼ì •, ì—¬í–‰ ì•±ì˜ ì˜ˆì•½ ì •ë³´, ë©”ëª¨ ì•±ì˜ ê´€ë ¨ ë…¸íŠ¸ ë“±ì„ \n",
      "\n",
      " ì´ë•Œ ì—¬í–‰ ì•± ê°œë°œìžê°€ ì¸ë±ìŠ¤íŠ¸ ì—”í‹°í‹° APIë¥¼ í™œìš©í•´ ë°ì´í„°ë¥¼ ì¸ë±ì‹±í•  ìˆ˜ ìžˆê²Œ í•´ë‘ë©´ ì‹œë¦¬ê°€ ì˜ˆì•½ ì •ë³´ ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. ì´ ë¶€ë¶„ì´ WWDCì—ì„œ ì–˜ê¸°í–ˆë˜ Personal Contextì¸ë°ìš”. ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ê°€ ë‹¤ì–‘í•œ ì•±ì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ í†µí•´ ê°œì¸ì ì¸ ë§¥ë½ì„ ì´í•´í•  ìˆ˜ ìžˆê²Œ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ ëª¨ì€ ê°œì¸ ì •ë³´ë¥¼ ì‹œë¦¬ê°€ ìš”ì•½í•´ì„œ ë©”ì¼ë¡œ ì „í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ ì• í”Œ ë©”ì¼ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë©”ì¼ ì•±ì„ ì‚¬ìš©í•˜ë”ë¼ë„ \n",
      "\n",
      " Intentsì™€ ì—°ê²°ë˜ì–´ ìžˆë‹¤ë©´ Siriê°€ ê·¸ ì•±ì˜ ë©”ì¼ ë‹µìž¥ ê¸°ëŠ¥ì„ ì´í•´í•˜ê³  ì•Œì•„ì„œ ë‹µìž¥ì„ ë³´ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ ê²°êµ­ ì• í”Œì´ ìƒê°í•˜ëŠ” ê¶ê·¹ì ì¸ SiriëŠ” ë‹¨ìˆœížˆ ë§ì„ ì•Œì•„ë“£ê³  ë‹µë³€ë§Œ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì‚¬ìš©ìžì˜ ìš”ì²­ì„ ì´í•´í•˜ê³  ì—¬ëŸ¬ ì•±ì˜ ë°ì´í„°ì™€ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‹¤ì œ í•„ìš”í•œ ìž‘ì—…ì„ ì‚¬ëžŒì„ ëŒ€ì‹ í•´ì„œ ìˆ˜í–‰í•´ì£¼ëŠ” AIë¥¼ ì§€í–¥í•˜ê³  ìžˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆëŠ”ë°ìš” ì´ë¥¼ ê°„ë‹¨ížˆ AI Agentë¼ê³  í•©ë‹ˆë‹¤ ì •ë¦¬í•˜ë©´ ì˜¬í•´ WWDCì—ì„œ ì—…ë°ì´íŠ¸ëœ ë‚´ìš©ë“¤ì´ \n",
      "\n",
      " ìŠ¤ëƒ… ì•¡ì…˜ìŠ¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³  í¼ìŠ¤ë„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìžˆê²Œ í•´ì£¼ëŠ”ë°ìš” ì¦‰, ì‹œë¦¬ë¥¼ AI ì—ì´ì „íŠ¸ë¡œ ë§Œë“¤ì–´ì¤„ ìˆ˜ ìžˆë„ë¡ ê¼½ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê²Œ ë˜ëŠ” ê²ƒì´ì£  ë‹¤ë§Œ ì•„ì§ì€ ì´ë²ˆ ì—…ë°ì´íŠ¸ë¥¼ ê°œë°œìžë“¤ì´ ê°ê°ì˜ ì•±ì— ë‹¤ ì ìš©í•˜ê¸°ì—ëŠ” ì‹œê°„ë„ ë§Žì´ í•„ìš”í•˜ê³  ì‹œë¦¬ ë˜í•œ ì•„ì§ ê¸°ëŠ¥ì´ ì™„ë²½í•˜ì§€ ì•Šì€ë°ìš” ì•žìœ¼ë¡œ ì‹œë¦¬ê°€ ë” ë§Žì€ ì•±ì˜ ë°ì´í„°ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìžˆê³  ì•± ë‚´ì˜ ë™ìž‘ ìˆ˜í–‰ë„ ê°€ëŠ¥í•´ì§ˆ í…Œë‹ˆ ëª¨ë“  ìž‘ì—…ì„ ì•Œì•„ì„œ ìˆ˜í–‰í•˜ëŠ” ì•„ì´ì–¸ë§¨ì˜ ìžë¹„ìŠ¤ ê°™ì€ ë‚˜ë§Œì˜ ë¹„ì„± \n",
      "\n",
      " AI ì—ì´ì „íŠ¸ ì‹œë¦¬ë¥¼ ê³§ ë§Œë‚˜ë³¼ ìˆ˜ ìžˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ ì´ë ‡ê²Œ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì— ì¶”ê°€ëœ ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ ì•„ì§ì€ ì•ˆíƒ€ê¹ê²Œë„ ë¯¸êµ­ í•œì •ìœ¼ë¡œ ì˜ì–´ë¡œë§Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•œë°ìš” ëª‡ ê°€ì§€ ê³¼ì •ì„ ê±°ì¹˜ë©´ í•œêµ­ì—ì„œë„ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ ì¼ë‹¨ êµ­ê°€ë¥¼ ë¯¸êµ­ìœ¼ë¡œ ì„¤ì •í•´ì¤˜ì•¼ í•˜ëŠ”ë°ìš” ì„¤ì •ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ì¼ë°˜, ì–¸ì–´ ë° ì§€ì—­ìœ¼ë¡œ ì´ë™í•œ í›„ ì˜ì–´ë¥¼ ê¸°ë³¸ ì–¸ì–´ë¡œ ì„ íƒí•˜ê³  ì§€ì—­ì„ ë¯¸êµ­ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤ ë§Œì•½ ì˜ì–´ê°€ ì—†ë‹¤ë©´ ì–¸ì–´ ì¶”ê°€ë¥¼ í†µí•´ ì„¤ì¹˜í•˜ê³  \n",
      "\n",
      " ê¸°ë³¸ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤ ë˜ ë² íƒ€ ë²„ì „ì„ ë‹¤ìš´ë°›ìœ¼ë ¤ë©´ ê°œë°œìž ë“±ë¡ì´ í•„ìš”í•œë°ìš” ì• í”Œ ë””ë²¨ë¡œí¼ í™ˆíŽ˜ì´ì§€ ë˜ëŠ” ì•±ì—ì„œ ìžì‹ ì˜ ì• í”Œ ì•„ì´ë””ë¡œ ë¡œê·¸ì¸ í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤ ë§ˆì§€ë§‰ìœ¼ë¡œ ë¯¸êµ­ ì•±ìŠ¤í† ì–´ë¥¼ ê°™ì´ ì´ìš©í•˜ë ¤ë©´ ë¯¸êµ­ ì£¼ì†Œê°€ í•„ìš”í•œë°ìš” ë¯¸êµ­ ë°°ì†¡ëŒ€í–‰ì§€ë¥¼ ê²€ìƒ‰í•´ ë‚˜ì˜¤ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ë©´ ê°„ë‹¨í•˜ê²Œ ë¯¸êµ­ ì£¼ì†Œë¥¼ ìƒì„±í•˜ê³  ë“±ë¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ ë‹¤ë§Œ ì§€ê¸ˆ ë§ì”€ë“œë¦° ë°©ë²•ì€ ê³µì‹ì ì¸ ì‚¬ìš©ë²•ì€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë””ë°”ì´ìŠ¤ì—ëŠ” ì ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤ \n",
      "\n",
      " ì§€ê¸ˆê¹Œì§€ ê³µê°œëœ ì• í”Œ ì¸í…”ë¦¬ì „ìŠ¤ì™€ ì• í”Œì´ ìƒê°í•˜ëŠ” AIì˜ ë¯¸ëž˜ë¥¼ ì†Œê°œí•´ë“œë ¸ëŠ”ë°ìš” ì• í”Œì´ ë‚´ë…„ê¹Œì§€ ê³„ì†í•´ì„œ AI ê´€ë ¨ ì—…ë°ì´íŠ¸ë¥¼ ì˜ˆê³ í•˜ê³  ìžˆëŠ” ë§Œí¼ ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ë‚˜ì˜¤ë©´ ì¶”ê°€ë¡œ ë” ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ì˜ìƒì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒë“œë¦¬ê² ìŠµë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for script in transcript['script']:\n",
    "    print(script['text'],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ì£¼ì œ: ë ˆê·¸ì˜ ê°œë… ë° êµ¬í˜„ ë°©ë²•\n",
      "\n",
      "- ðŸ“š ë ˆê·¸ ë¹„ë²•ë…¸íŠ¸ë¥¼ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì— ëŒ€í•œ ì´í•´ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "- ðŸ” ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ë°˜ë³µì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ì´í•´ë„ë¥¼ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
      "- â“ ë ˆê·¸ì˜ ì£¼ìš” ëª©ì ì€ ìµœì‹  ì •ë³´ë¥¼ í¬í•¨í•œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
      "- ðŸ†š GPTëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ì˜ì¡´í•˜ì§€ë§Œ, ë ˆê·¸ëŠ” ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "- ðŸ“Š ì˜¤ëž˜ëœ ì •ë³´ëŠ” ì •í™•í•œ ë‹µë³€ì„ ë°©í•´í•˜ë©°, ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ìž…ë‹ˆë‹¤.\n",
      "- ðŸ“‘ ë¬¸ë§¥ì„ í†µí•´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ê³ , ìœ ì‚¬ë„ ê³„ì‚°ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
      "- ðŸ”„ í…ìŠ¤íŠ¸ëŠ” íŠ¹ì • í‚¤ì›Œë“œë¡œ ë¶„í• ë˜ì–´ì•¼ í•˜ë©°, ì²­í¬ ì˜¤ë²„ëž©ì„ í†µí•´ ì •ë³´ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.\n",
      "- ðŸ’¾ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ê° ë‹¨ë½ì„ ìˆ«ìž í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì €ìž¥í•˜ì—¬ ë‚˜ì¤‘ì— ê²€ìƒ‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "- ðŸ“Š ì¸ë² ë”© ì´í•´ í›„, ë°ì´í„°ë¥¼ ì €ìž¥í•´ì•¼ í•˜ë©°, ì´ ê³¼ì •ì—ì„œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.\n",
      "- ðŸ“š ë‹¤ìŒ ì˜ìƒì—ì„œëŠ” ë ˆê·¸ì˜ í›„ë°˜ë¶€ ë‚´ìš©ì„ ë‹¤ë£° ì˜ˆì •ìž…ë‹ˆë‹¤.\n",
      "\n",
      "### ì¶”ì²œ ì§ˆë¬¸:\n",
      "1. ë ˆê·¸ì˜ êµ¬í˜„ ë°©ì‹ì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "2. ì¸ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì€ ì–´ë–»ê²Œ ê´€ë¦¬í•  ìˆ˜ ìžˆë‚˜ìš”?\n",
      "3. ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "print(\"### ì£¼ì œ: ë ˆê·¸ì˜ ê°œë… ë° êµ¬í˜„ ë°©ë²•\\n\\n- ðŸ“š ë ˆê·¸ ë¹„ë²•ë…¸íŠ¸ë¥¼ í†µí•´ ë ˆê·¸ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬í˜„ ë°©ì‹ì— ëŒ€í•œ ì´í•´ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.\\n- ðŸ” ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ë°˜ë³µì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ì´í•´ë„ë¥¼ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.\\n- â“ ë ˆê·¸ì˜ ì£¼ìš” ëª©ì ì€ ìµœì‹  ì •ë³´ë¥¼ í¬í•¨í•œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.\\n- ðŸ†š GPTëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ì˜ì¡´í•˜ì§€ë§Œ, ë ˆê·¸ëŠ” ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n- ðŸ“Š ì˜¤ëž˜ëœ ì •ë³´ëŠ” ì •í™•í•œ ë‹µë³€ì„ ë°©í•´í•˜ë©°, ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ìž…ë‹ˆë‹¤.\\n- ðŸ“‘ ë¬¸ë§¥ì„ í†µí•´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ê³ , ìœ ì‚¬ë„ ê³„ì‚°ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\\n- ðŸ”„ í…ìŠ¤íŠ¸ëŠ” íŠ¹ì • í‚¤ì›Œë“œë¡œ ë¶„í• ë˜ì–´ì•¼ í•˜ë©°, ì²­í¬ ì˜¤ë²„ëž©ì„ í†µí•´ ì •ë³´ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.\\n- ðŸ’¾ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ê° ë‹¨ë½ì„ ìˆ«ìž í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì €ìž¥í•˜ì—¬ ë‚˜ì¤‘ì— ê²€ìƒ‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n- ðŸ“Š ì¸ë² ë”© ì´í•´ í›„, ë°ì´í„°ë¥¼ ì €ìž¥í•´ì•¼ í•˜ë©°, ì´ ê³¼ì •ì—ì„œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.\\n- ðŸ“š ë‹¤ìŒ ì˜ìƒì—ì„œëŠ” ë ˆê·¸ì˜ í›„ë°˜ë¶€ ë‚´ìš©ì„ ë‹¤ë£° ì˜ˆì •ìž…ë‹ˆë‹¤.\\n\\n### ì¶”ì²œ ì§ˆë¬¸:\\n1. ë ˆê·¸ì˜ êµ¬í˜„ ë°©ì‹ì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\\n2. ì¸ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì€ ì–´ë–»ê²Œ ê´€ë¦¬í•  ìˆ˜ ìžˆë‚˜ìš”?\\n3. ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"### KEY TOPIC: ë ˆê·¸ì˜ ê¸°ëŠ¥ê³¼ ì •ë³´ ì ‘ê·¼ ë°©ì‹\\n\\n- ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ì°©í•˜ê¸°ê¹Œì§€ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.  \\n- ðŸ”„ ë ˆê·¸ì— ëŒ€í•œ ì´í•´ë¥¼ ìœ„í•´ ë°˜ë³µ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.  \\n- ðŸŽ¨ ë ˆê·¸ì˜ ëª©ì ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•  ì˜ˆì •ìž…ë‹ˆë‹¤.  \\n- â“ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.  \\n- ðŸ“° ê¸°ì¡´ ì±„ì° PTì™€ ë¹„êµí•˜ì—¬ ì •ë³´ ì ‘ê·¼ ë°©ì‹ì„ ì„¤ëª…í•©ë‹ˆë‹¤.  \\n- âš™ï¸ í”„ë¡¬í”„íŠ¸ì˜ ë³€í™”ë¡œ ë ˆê·¸ì˜ ê¸°ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤.  \\n- ðŸ“„ PDFì™€ ê°™ì€ ìžë£Œë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•¨.  \\n- ðŸ”‘ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ìž„.  \\n- ðŸ“ íŠ¹ì • ë‹¨ë½ë§Œ í•„ìš”í•œ ê²½ìš° ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì„¤ì •í•˜ì—¬ ë¶„í• í•¨.  \\n- ðŸ” ìœ ì‚¬ë„ ê³„ì‚°ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ë½‘ì•„ëƒ…ë‹ˆë‹¤.  \\n- ðŸ“Š ìž„ë² ë”©ì€ ë¬¸ìžì—´ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìž„.  \\n- ðŸ”— ë™ì¼í•œ ìˆ«ìž ê°œìˆ˜ë¡œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥í•¨.  \\n- ðŸ’° ì¸ë² ë”© ê³¼ì •ì—ì„œ ë¹„ìš©ì´ ë°œìƒí•˜ë©°, ë§Žì€ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ ì‹ ì¤‘í•´ì•¼ í•¨.  \\n- ðŸ“½ï¸ ì´ë²ˆ ì˜ìƒì€ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë‹¤ë£¨ì—ˆê³ , ë‹¤ìŒ ì˜ìƒì—ì„œëŠ” í›„ë°˜ë¶€ë¥¼ ë‹¤ë£° ì˜ˆì •.\\n\\n### RECOMMENDED QUESTIONS:\\n1. ë ˆê·¸ì˜ ì •ë³´ ì ‘ê·¼ ë°©ì‹ì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\\n2. ìž„ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì„ ì¤„ì¼ ìˆ˜ ìžˆëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\\n3. ë ˆê·¸ì˜ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë°˜ë³µ í•™ìŠµì˜ í•„ìš”ì„±ì€ ì–´ë–¤ ì ì—ì„œ ì¤‘ìš”í•œê°€ìš”?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### KEY TOPIC: ë ˆê·¸ì˜ ê¸°ëŠ¥ê³¼ ì •ë³´ ì ‘ê·¼ ë°©ì‹\n",
      "\n",
      "- ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ì°©í•˜ê¸°ê¹Œì§€ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.  \n",
      "- ðŸ”„ ë ˆê·¸ì— ëŒ€í•œ ì´í•´ë¥¼ ìœ„í•´ ë°˜ë³µ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.  \n",
      "- ðŸŽ¨ ë ˆê·¸ì˜ ëª©ì ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•  ì˜ˆì •ìž…ë‹ˆë‹¤.  \n",
      "- â“ ë ˆê·¸ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.  \n",
      "- ðŸ“° ê¸°ì¡´ ì±„ì° PTì™€ ë¹„êµí•˜ì—¬ ì •ë³´ ì ‘ê·¼ ë°©ì‹ì„ ì„¤ëª…í•©ë‹ˆë‹¤.  \n",
      "- âš™ï¸ í”„ë¡¬í”„íŠ¸ì˜ ë³€í™”ë¡œ ë ˆê·¸ì˜ ê¸°ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤.  \n",
      "- ðŸ“„ PDFì™€ ê°™ì€ ìžë£Œë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•¨.  \n",
      "- ðŸ”‘ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ìž„.  \n",
      "- ðŸ“ íŠ¹ì • ë‹¨ë½ë§Œ í•„ìš”í•œ ê²½ìš° ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì„¤ì •í•˜ì—¬ ë¶„í• í•¨.  \n",
      "- ðŸ” ìœ ì‚¬ë„ ê³„ì‚°ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ë½‘ì•„ëƒ…ë‹ˆë‹¤.  \n",
      "- ðŸ“Š ìž„ë² ë”©ì€ ë¬¸ìžì—´ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìž„.  \n",
      "- ðŸ”— ë™ì¼í•œ ìˆ«ìž ê°œìˆ˜ë¡œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥í•¨.  \n",
      "- ðŸ’° ì¸ë² ë”© ê³¼ì •ì—ì„œ ë¹„ìš©ì´ ë°œìƒí•˜ë©°, ë§Žì€ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ ì‹ ì¤‘í•´ì•¼ í•¨.  \n",
      "- ðŸ“½ï¸ ì´ë²ˆ ì˜ìƒì€ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë‹¤ë£¨ì—ˆê³ , ë‹¤ìŒ ì˜ìƒì—ì„œëŠ” í›„ë°˜ë¶€ë¥¼ ë‹¤ë£° ì˜ˆì •.\n",
      "\n",
      "### RECOMMENDED QUESTIONS:\n",
      "1. ë ˆê·¸ì˜ ì •ë³´ ì ‘ê·¼ ë°©ì‹ì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "2. ìž„ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì„ ì¤„ì¼ ìˆ˜ ìžˆëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "3. ë ˆê·¸ì˜ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë°˜ë³µ í•™ìŠµì˜ í•„ìš”ì„±ì€ ì–´ë–¤ ì ì—ì„œ ì¤‘ìš”í•œê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Key Topic: RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë° ì´í•´\n",
      "\n",
      "- ðŸŽ‰ ì—¬ëŸ¬ë¶„ì€ RAGì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.\n",
      "- ðŸ”„ RAGì˜ ë‚´ìš©ì„ ë°˜ë³µí•˜ì—¬ ì´í•´ë¥¼ ë†’ì´ì„¸ìš”.\n",
      "- ðŸ“‚ ì‹¤ìŠµ íŒŒì¼ì„ í†µí•´ RAG í”„ë¡œì„¸ìŠ¤ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "- ðŸ§ RAGê°€ ë¬´ì—‡ì¸ì§€ì™€ êµ¬í˜„ ë°©ë²•ì„ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "- ðŸŽ¨ RAG ì‚¬ìš© ëª©ì ì„ ê·¸ë¦¼ìœ¼ë¡œ ì„¤ëª…í•  ì˜ˆì •ìž…ë‹ˆë‹¤.\n",
      "- â“ RAGì˜ í•„ìš”ì„±ì„ ì±„ì° PTì™€ ë¹„êµí•˜ì—¬ ì„¤ëª…í•  ê²ƒìž…ë‹ˆë‹¤.\n",
      "- ðŸ“„ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ RAGì˜ ì£¼ìš” ëª©ì ìž…ë‹ˆë‹¤.\n",
      "- ðŸ“Š GPDëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ì˜ì¡´í•˜ë¯€ë¡œ ì •ë³´ê°€ ì˜¤ëž˜ë˜ë©´ ì •í™•í•œ ë‹µë³€ì„ í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\n",
      "- ðŸ”— RAGëŠ” ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ê°€ ë°”ë€ë‹ˆë‹¤.\n",
      "- ðŸ“š GPDëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ë§Œ ë‹µë³€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "- â³ ì˜¤ëž˜ëœ ì‚¬ì „í•™ìŠµ ì •ë³´ëŠ” ì •í™•í•œ ë‹µë³€ì„ ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤.\n",
      "- ðŸ” í”„ë¡¬í”„íŠ¸ê°€ ë³€ê²½ë˜ì–´ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
      "- ðŸ“„ PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "- âš ï¸ ë§Žì€ ì •ë³´ë¥¼ ìž…ë ¥í•  ê²½ìš° ë¹„ìš©ì´ ì¦ê°€í•˜ê³  ì •ë³´ íƒìƒ‰ì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "- ðŸ”‘ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ìž…ë‹ˆë‹¤.\n",
      "- ðŸ“ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê¸ì–´ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
      "- ðŸ” ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
      "- ðŸ“ˆ ìœ ì‚¬ë„ê°€ ë†’ì€ ë‹¨ë½ì„ ê²€ìƒ‰í•´ ìµœìƒìœ„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "- ðŸ§® ì¸ë² ë”©ì€ ë¬¸ìž¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ì–´ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
      "- ðŸ’¾ ì¸ë² ë”© í›„ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì €ìž¥í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- ðŸ” ì €ìž¥ëœ ë°ì´í„°ëŠ” ê²€ìƒ‰ì–´ë¥¼ í†µí•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "- ðŸ“½ï¸ ì´ë²ˆ ì˜ìƒì€ ì‚¬ì „ ë‹¨ê³„ê¹Œì§€ ì‚´íŽ´ë³´ì•˜ê³ , ë‹¤ìŒ ì˜ìƒì—ì„œ í›„ë°˜ë¶€ë¥¼ ë‹¤ë£° ì˜ˆì •ìž…ë‹ˆë‹¤.\n",
      "\n",
      "### RECOMMENDED QUESTIONS:\n",
      "1. RAG ì‹œìŠ¤í…œì´ ê¸°ì¡´ GPDì™€ ì–´ë–»ê²Œ ì°¨ë³„í™”ë˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìžˆë‚˜ìš”?\n",
      "2. RAGì˜ ì¸ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì€ ì–´ë–¤ ìš”ì†Œì— ì˜í•´ ê²°ì •ë˜ë‚˜ìš”?\n",
      "3. PDF ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ìœ ì‚¬ë„ ê³„ì‚°ì€ ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "print('### Key Topic: RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë° ì´í•´\\n\\n- ðŸŽ‰ ì—¬ëŸ¬ë¶„ì€ RAGì˜ ë¹„ë²•ë…¸íŠ¸ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.\\n- ðŸ”„ RAGì˜ ë‚´ìš©ì„ ë°˜ë³µí•˜ì—¬ ì´í•´ë¥¼ ë†’ì´ì„¸ìš”.\\n- ðŸ“‚ ì‹¤ìŠµ íŒŒì¼ì„ í†µí•´ RAG í”„ë¡œì„¸ìŠ¤ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\\n- ðŸ§ RAGê°€ ë¬´ì—‡ì¸ì§€ì™€ êµ¬í˜„ ë°©ë²•ì„ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.\\n- ðŸŽ¨ RAG ì‚¬ìš© ëª©ì ì„ ê·¸ë¦¼ìœ¼ë¡œ ì„¤ëª…í•  ì˜ˆì •ìž…ë‹ˆë‹¤.\\n- â“ RAGì˜ í•„ìš”ì„±ì„ ì±„ì° PTì™€ ë¹„êµí•˜ì—¬ ì„¤ëª…í•  ê²ƒìž…ë‹ˆë‹¤.\\n- ðŸ“„ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ RAGì˜ ì£¼ìš” ëª©ì ìž…ë‹ˆë‹¤.\\n- ðŸ“Š GPDëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ì˜ì¡´í•˜ë¯€ë¡œ ì •ë³´ê°€ ì˜¤ëž˜ë˜ë©´ ì •í™•í•œ ë‹µë³€ì„ í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\\n- ðŸ”— RAGëŠ” ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ê°€ ë°”ë€ë‹ˆë‹¤.\\n- ðŸ“š GPDëŠ” ì‚¬ì „í•™ìŠµëœ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ë§Œ ë‹µë³€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n- â³ ì˜¤ëž˜ëœ ì‚¬ì „í•™ìŠµ ì •ë³´ëŠ” ì •í™•í•œ ë‹µë³€ì„ ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤.\\n- ðŸ” í”„ë¡¬í”„íŠ¸ê°€ ë³€ê²½ë˜ì–´ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ë„ë¡ í•©ë‹ˆë‹¤.\\n- ðŸ“„ PDF ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n- âš ï¸ ë§Žì€ ì •ë³´ë¥¼ ìž…ë ¥í•  ê²½ìš° ë¹„ìš©ì´ ì¦ê°€í•˜ê³  ì •ë³´ íƒìƒ‰ì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n- ðŸ”‘ ê´€ë ¨ì„± ìžˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ìµœì„ ìž…ë‹ˆë‹¤.\\n- ðŸ“ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê¸ì–´ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\\n- ðŸ” ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\\n- ðŸ“ˆ ìœ ì‚¬ë„ê°€ ë†’ì€ ë‹¨ë½ì„ ê²€ìƒ‰í•´ ìµœìƒìœ„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\\n- ðŸ§® ì¸ë² ë”©ì€ ë¬¸ìž¥ì„ ìˆ˜í•™ì  í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ì–´ ì •ë³´ ê²€ìƒ‰ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\\n- ðŸ’¾ ì¸ë² ë”© í›„ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì €ìž¥í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n- ðŸ” ì €ìž¥ëœ ë°ì´í„°ëŠ” ê²€ìƒ‰ì–´ë¥¼ í†µí•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\\n- ðŸ“½ï¸ ì´ë²ˆ ì˜ìƒì€ ì‚¬ì „ ë‹¨ê³„ê¹Œì§€ ì‚´íŽ´ë³´ì•˜ê³ , ë‹¤ìŒ ì˜ìƒì—ì„œ í›„ë°˜ë¶€ë¥¼ ë‹¤ë£° ì˜ˆì •ìž…ë‹ˆë‹¤.\\n\\n### RECOMMENDED QUESTIONS:\\n1. RAG ì‹œìŠ¤í…œì´ ê¸°ì¡´ GPDì™€ ì–´ë–»ê²Œ ì°¨ë³„í™”ë˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìžˆë‚˜ìš”?\\n2. RAGì˜ ì¸ë² ë”© ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ìš©ì€ ì–´ë–¤ ìš”ì†Œì— ì˜í•´ ê²°ì •ë˜ë‚˜ìš”?\\n3. PDF ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ìœ ì‚¬ë„ ê³„ì‚°ì€ ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ë‚˜ìš”?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://youtu.be/AA621UofTUA?si=gn4XutRMWUDSYLFL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Please summarize the sentence according to the following FINAL REQUEST. \n",
    "FINAL REQUEST:\n",
    "1. The provided summary sections are partial summaries of one document. Please combine them into a single cohesive summary.\n",
    "2. Summarize the main points in bullet points in KOREAN.\n",
    "3. Each summarized sentence must start with a single emoji that fits the meaning of the sentence.\n",
    "4. Use various emojis to make the summary more interesting, but keep it concise and relevant.\n",
    "5. Focus on identifying and presenting only one main topic and one overall summary for the document.\n",
    "6. Avoid redundant or repeated points, and ensure that the summary covers all key ideas without introducing multiple conclusions or topics.\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\n",
    "FINAL SUMMARY:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please summarize the sentence according to the following REQUEST.\n",
      "REQUEST:\n",
      "1. Summarize the main points in bullet points in KOREAN.\n",
      "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
      "3. Use various emojis to make the summary more interesting.\n",
      "4. Translate the summary into KOREAN if it is written in ENGLISH.\n",
      "5. DO NOT translate any technical terms.\n",
      "6. DO NOT include any unnecessary information.\n",
      "\n",
      "CONTEXT:\n",
      "{context}\n",
      "\n",
      "SUMMARY:\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Please summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points in KOREAN.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. Translate the summary into KOREAN if it is written in ENGLISH.\\n5. DO NOT translate any technical terms.\\n6. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please summarize the sentence according to the following FINAL REQUEST. \n",
      "FINAL REQUEST:\n",
      "1. The provided summary sections are partial summaries of one document. Please combine them into a single cohesive summary.\n",
      "2. Summarize the main points in bullet points in KOREAN, but DO NOT translate any technical terms.\n",
      "3. Each summarized sentence must start with a single emoji that fits the meaning of the sentence.\n",
      "4. Use various emojis to make the summary more interesting, but keep it concise and relevant.\n",
      "5. Focus on identifying and presenting only one main topic and one overall summary for the document.\n",
      "6. Avoid redundant or repeated points, and ensure that the summary covers all key ideas without introducing multiple conclusions or topics.\n",
      "7. Please refer to each summary and indicate the key topic.\n",
      "8. If the original text is in English, we have already provided a summary translated into Korean, so please do not provide a separate translation.\n",
      "\n",
      "CONTEXT: \n",
      "{context}\n",
      "\n",
      "FINAL SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print(\"Please summarize the sentence according to the following FINAL REQUEST. \\nFINAL REQUEST:\\n1. The provided summary sections are partial summaries of one document. Please combine them into a single cohesive summary.\\n2. Summarize the main points in bullet points in KOREAN, but DO NOT translate any technical terms.\\n3. Each summarized sentence must start with a single emoji that fits the meaning of the sentence.\\n4. Use various emojis to make the summary more interesting, but keep it concise and relevant.\\n5. Focus on identifying and presenting only one main topic and one overall summary for the document.\\n6. Avoid redundant or repeated points, and ensure that the summary covers all key ideas without introducing multiple conclusions or topics.\\n7. Please refer to each summary and indicate the key topic.\\n8. If the original text is in English, we have already provided a summary translated into Korean, so please do not provide a separate translation.\\n\\nCONTEXT: \\n{context}\\n\\nFINAL SUMMARY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"[FINAL SUMMARY]\\nâ€¢ ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ëŠ” ë°˜ë³µ í•™ìŠµê³¼ ë ˆê·¸ì— ëŒ€í•œ ê¹Šì€ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\\nâ€¢ ðŸ–¼ï¸ RAGì˜ ë„ìž…ì€ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì¤‘ìš”í•˜ë©°, ì¢Œì¸¡ì˜ ë ˆê·¸ì™€ ìš°ì¸¡ì˜ ê¸°ì¡´ ë°©ë²•ì„ ë¹„êµí•´ ì„¤ëª…í•©ë‹ˆë‹¤.\\nâ€¢ ðŸ“ˆ í”„ë¡¬í”„íŠ¸ì˜ ë³€í™”ì™€ ì •ë³´ì˜ ì •í™•ì„±ì´ ì¤‘ìš”í•˜ë©°, ì‚¬ì „í•™ìŠµëœ ì •ë³´ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ ì‹ ë¢°ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.\\nâ€¢ ðŸ”‘ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì°¾ì•„ë‚´ê³ , í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°ì™€ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ì •ë³´ì˜ ì •í™•ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.\\nâ€¢ ðŸ’° ë§Žì€ ìž…ë ¥ ì •ë³´ëŠ” ë¹„ìš© ì¦ê°€ì™€ ì •ë³´ íƒìƒ‰ì˜ ì–´ë ¤ì›€ì„ ì´ˆëž˜í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n\\n[RECOMMEND QUESTIONS]\\n1. RAGì˜ ë„ìž…ì´ ì™œ ì¤‘ìš”í•œê°€ìš”?\\n2. ìœ ì‚¬ë„ ê²€ìƒ‰ì—ì„œ ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ê´€ë ¨ ë‹¨ë½ì„ ì°¾ë‚˜ìš”?\\n3. ìž…ë ¥ ì •ë³´ê°€ ë§Žì„ ë•Œ ë°œìƒí•  ìˆ˜ ìžˆëŠ” ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â€¢ ðŸ“š ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ëŠ” ë°˜ë³µ í•™ìŠµê³¼ ë ˆê·¸ì— ëŒ€í•œ ê¹Šì€ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "â€¢ ðŸ–¼ï¸ RAGì˜ ë„ìž…ì€ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì¤‘ìš”í•˜ë©°, ì¢Œì¸¡ì˜ ë ˆê·¸ì™€ ìš°ì¸¡ì˜ ê¸°ì¡´ ë°©ë²•ì„ ë¹„êµí•´ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
      "â€¢ ðŸ“ˆ í”„ë¡¬í”„íŠ¸ì˜ ë³€í™”ì™€ ì •ë³´ì˜ ì •í™•ì„±ì´ ì¤‘ìš”í•˜ë©°, ì‚¬ì „í•™ìŠµëœ ì •ë³´ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ ì‹ ë¢°ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.\n",
      "â€¢ ðŸ”‘ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ë‹¨ë½ì„ ì°¾ì•„ë‚´ê³ , í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°ì™€ ì¸ë² ë”© ê³¼ì •ì„ í†µí•´ ì •ë³´ì˜ ì •í™•ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.\n",
      "â€¢ ðŸ’° ë§Žì€ ìž…ë ¥ ì •ë³´ëŠ” ë¹„ìš© ì¦ê°€ì™€ ì •ë³´ íƒìƒ‰ì˜ ì–´ë ¤ì›€ì„ ì´ˆëž˜í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAGì˜ ë„ìž…ì´ ì™œ ì¤‘ìš”í•œê°€ìš”?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"[FINAL SUMMARY]\")[1].split(\"[RECOMMEND QUESTIONS]\")[1].split(\"\\n\")[1].split(\".\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = [{'start': 0.0, 'end': 29.42, 'text': ' ì—¬ëŸ¬ë¶„ ì•ˆë…•í•˜ì„¸ìš” ë“œë””ì–´ ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë ˆê·¸ íŒŒíŠ¸ê¹Œì§€ ì˜¤ì‹œëŠë¼ ì •ë§ ê³ ìƒ ë§Žìœ¼ì…¨ìŠµë‹ˆë‹¤ ë ˆê·¸ì˜ ì „ë°˜ì ì¸ ë‚´ìš©ì„ ë¨¼ì € í•œë²ˆ ë“¤ì–´ë³´ì‹œê³ ìš” ê·¸ë¦¬ê³  ìž˜ ì´í•´ê°€ ì•ˆë˜ë©´ ë˜ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹¤ ìˆ˜ ìžˆìœ¼ë‹ˆê¹Œ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹œê³  ê·¸ë¦¬ê³  ë” ì¤‘ìš”í•œ ê±°ëŠ” ì´ ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ì—¬ëŸ¬ë¶„ë“¤ì´ ë°˜ë³µí•´ì„œ ë³´ì‹œë©´ì„œ ê³„ì† ë ˆê·¸ì— ëŒ€í•œ í”„ë¡œì„¸ìŠ¤ ì´í•´ê°€ ìžˆì–´ì•¼ ê·¸ ë‹¤ìŒì— ë‹¤ì‹œ ì—­ìœ¼ë¡œ ëŒì•„ê°€ì„œ ìš°ë¦¬ê°€ ì´ëŸ° ê²ƒë“¤ì„ ì‚´íŽ´ë³¼ ê±°ì—ìš” ì•„í”„íŒŒì„œëž‘ ëª¨ë¸ ë©”ëª¨ë¦¬ ì²´ì¸ë“¤ ì´ëŸ° ê²ƒë“¤ì„ ì­‰ ì‚´íŽ´ë³¼ ë•Œ ì—­ìœ¼ë¡œ ë” ì´í•´ê°€ ìž˜ ë˜ì‹¤ ê±°ë¼ëŠ” ìƒê°ì´ ë“¤ë”ë¼êµ¬ìš”'}, {'start': 30.0, 'end': 42.5, 'text': ' ìš°ë¦¬ê°€ ì—¬ê¸° ì²˜ìŒë¶€í„° ë‹¤ í•˜ê³  ê°€ë ¤ë©´ ë„ˆë¬´ ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦¬ë‹ˆê¹Œ ì´ë²ˆ ì‹œê°„ì—ëŠ” ë ˆê·¸ë¥¼ ì¢€ ê¹Šê²Œ ë‹¤ë¤„ë³´ê¸° ë³´ë‹¤ëŠ” ì¼ë‹¨ì€ ë ˆê·¸ê°€ ë­”ì§€ ê·¸ë¦¬ê³  ì–´ë–¤ ì‹ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ”ì§€ ëŒ€ì¶© ê°ì„ ìž¡ëŠ”ë‹¤ ê·¸ëŸ° ìƒê°ìœ¼ë¡œ ì˜¤ì‹œë©´ ë©ë‹ˆë‹¤.'}, {'start': 43.21, 'end': 60.03, 'text': ' ì €í¬ê°€ ë¨¼ì € ì—¬ê¸° ë ˆê·¸ì˜ ë² ì´ì‹, ì´ ì •ë„ ìˆ˜ì¤€ì—ì„œ ë¨¼ì € ë³¼ ê±´ë°ìš”. ë¨¼ì € ê·¸ëŸ¬ë ¤ë©´ì€ ìš°ë¦¬ê°€ ë ˆê·¸ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•  ê²ƒ ê°™ì•„ìš”. ê·¸ëž˜ì„œ ì œê°€ ì¢€ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë ¤ì™”ì–´ìš”. ì œê°€ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë¦¬ëŠ” ê±¸ ë˜ê²Œ ì¢‹ì•„í•˜ëŠ”ë° ì´ ë ˆê·¸ë¼ëŠ” ê±¸ ë„ëŒ€ì²´ ì™œ ì“°ëŠëƒ, ìš°ë¦¬ê°€ ê·¸ ê°•ì˜ ì´ˆë°˜ì—ë„ ë§ì”€ë“œë ¸ìž–ì•„ìš”.'}, {'start': 60.0, 'end': 74.72, 'text': ' ë ˆê·¸ë¥¼ ì“°ëŠ” ëª©ì ì— ëŒ€í•´ì„œ ë‹¤ì‹œ í•œ ë²ˆë§Œ ì§šê³  ë„˜ì–´ê°€ ë³¼ê²Œìš”. ìš°ë¦¬ê°€ ë ˆê·¸ë¥¼ ì•ˆ ì“°ê³  ì±„ì° PT ê°™ì€ ê±¸ í†µí•´ì„œ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì±„ì° PTì—ì„œ ì“°ëŠ” ê±°ëŠ” ì´ëŸ° ë°©ì‹ì´ê±°ë“ ìš”. ì—¬ê¸°ì— ì—¬ëŸ¬ë¶„ë“¤ì´ ì´ëŸ¬í•œ í€˜ì…˜ë“¤ì„ ë„£ì–´ì¤˜ìš”.'}, {'start': 76.47, 'end': 89.55, 'text': ' í”„ë¡¬í”„íŠ¸ë¡œ ë“¤ì–´ê°€ì£ . ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. ì´ëŸ° ê²ƒë“¤ì´ ë“¤ì–´ê°€ê³ ìš”. ê·¸ ë‹¤ìŒì— ì¢€ ë” í™•ëŒ€í•´ì„œ ë³´ì—¬ë“œë¦¬ë©´ ì´ë ‡ê²Œ ë“¤ì–´ê°€ì£ . ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë‹µë³€ì„ í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸.'}, {'start': 90.82, 'end': 117.02, 'text': ' ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì´ ì—¬ê¸° ë“¤ì–´ì™€ìš”. ê·¸ëŸ¬ë©´ ìš°ë¦¬ê°€ ìŠ¤íŠ¸ë¦¬ë°‹ìœ¼ë¡œ êµ¬í˜„í•œ ê²ƒì²˜ëŸ¼ ìš”ê±°ì— ëŒ€í•´ì„œ í”„ë¡¬í”„íŠ¸ ì™„ì„±ì„ í•´ì„œ ê²°êµ­ì—ëŠ” ì´ LLMí•œí…Œ ì „ë‹¬ì´ ëœë‹¤ëŠ” ê±°ì˜ˆìš”. ìš°ë¦¬ê°€ ê·¸ê±¸ GPTë¥¼ ì“¸ ìˆ˜ë„ ìžˆê³  ì•„ë‹ˆë©´ ë­ í´ë¡œë“œë¼ëŠ” ëª¨ë¸ì„ ì“¸ ìˆ˜ë„ ìžˆê³  ë¼ë§ˆ3ë¼ëŠ” ì˜¤í”ˆëª¨ë¸ì„ ì“¸ ìˆ˜ë„ ìžˆê³ ìš”. ì–´ì¨Œë“  ì´ê±¸ ë„£ì–´ì„œ ìš°ë¦¬ê°€ ì–»ëŠ” ë‹µë³€ì€ ë­ëƒë©´ ì‚¼ì„±ì „ìžê°€ ìžì²´ ê°œë°œí•œ AIì˜ ì´ë¦„ì€ ìš”ê±°ëŠ” ì œê°€ ì±„ì°PTí•œí…Œ ë¬¼ì–´ë³¸ ê±°ê±°ë“ ìš”. ë‹µë³€ì„ ì´ì œ ì´ëŸ° ì‹ìœ¼ë¡œ ì¤€ë‹¤ëŠ” ê±°ì˜ˆìš”.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = [script['text'] for script in scripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ìš°ë¦¬ê°€ ì—¬ê¸° ì²˜ìŒë¶€í„° ë‹¤ í•˜ê³  ê°€ë ¤ë©´ ë„ˆë¬´ ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦¬ë‹ˆê¹Œ ì´ë²ˆ ì‹œê°„ì—ëŠ” ë ˆê·¸ë¥¼ ì¢€ ê¹Šê²Œ ë‹¤ë¤„ë³´ê¸° ë³´ë‹¤ëŠ” ì¼ë‹¨ì€ ë ˆê·¸ê°€ ë­”ì§€ ê·¸ë¦¬ê³  ì–´ë–¤ ì‹ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ”ì§€ ëŒ€ì¶© ê°ì„ ìž¡ëŠ”ë‹¤ ê·¸ëŸ° ìƒê°ìœ¼ë¡œ ì˜¤ì‹œë©´ ë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d4407d216a4cd0b9e725c7f428b03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\",torch_dtype=torch.bfloat16,device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì›ë³¸ ===\n",
      " ì—¬ëŸ¬ë¶„ ì•ˆë…•í•˜ì„¸ìš” ë“œë””ì–´ ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë ˆê·¸ íŒŒíŠ¸ê¹Œì§€ ì˜¤ì‹œëŠë¼ ì •ë§ ê³ ìƒ ë§Žìœ¼ì…¨ìŠµë‹ˆë‹¤ ë ˆê·¸ì˜ ì „ë°˜ì ì¸ ë‚´ìš©ì„ ë¨¼ì € í•œë²ˆ ë“¤ì–´ë³´ì‹œê³ ìš” ê·¸ë¦¬ê³  ìž˜ ì´í•´ê°€ ì•ˆë˜ë©´ ë˜ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹¤ ìˆ˜ ìžˆìœ¼ë‹ˆê¹Œ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹œê³  ê·¸ë¦¬ê³  ë” ì¤‘ìš”í•œ ê±°ëŠ” ì´ ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ì—¬ëŸ¬ë¶„ë“¤ì´ ë°˜ë³µí•´ì„œ ë³´ì‹œë©´ì„œ ê³„ì† ë ˆê·¸ì— ëŒ€í•œ í”„ë¡œì„¸ìŠ¤ ì´í•´ê°€ ìžˆì–´ì•¼ ê·¸ ë‹¤ìŒì— ë‹¤ì‹œ ì—­ìœ¼ë¡œ ëŒì•„ê°€ì„œ ìš°ë¦¬ê°€ ì´ëŸ° ê²ƒë“¤ì„ ì‚´íŽ´ë³¼ ê±°ì—ìš” ì•„í”„íŒŒì„œëž‘ ëª¨ë¸ ë©”ëª¨ë¦¬ ì²´ì¸ë“¤ ì´ëŸ° ê²ƒë“¤ì„ ì­‰ ì‚´íŽ´ë³¼ ë•Œ ì—­ìœ¼ë¡œ ë” ì´í•´ê°€ ìž˜ ë˜ì‹¤ ê±°ë¼ëŠ” ìƒê°ì´ ë“¤ë”ë¼êµ¬ìš”\n",
      "\n",
      "=== êµì •ë³¸ ===\n",
      "ì´ ë¬¸ì„œì˜ ì˜¤íƒˆìžì™€ ì–´ìƒ‰í•œ í‘œí˜„ì„ ì „ë¬¸ êµì •ìžì˜ ìž…ìž¥ì—ì„œ ìžì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
      "ë‹¤ìŒê³¼ ê°™ì€ ì‚¬í•­ì„ ì¤‘ì ì ìœ¼ë¡œ ê²€í† í•´ì£¼ì„¸ìš”:\n",
      "1. ë¬¸ë§¥ì— ë§žì§€ ì•ŠëŠ” ë‹¨ì–´ë¥¼ ìˆ˜ì •\n",
      "2. ì˜ì–´ ë°œìŒì€ ì•ŒíŒŒë²³ìœ¼ë¡œ ë³€ê²½\n",
      "3. ê¸°ìˆ ì ì¸ ìš©ì–´ëŠ” ì›ì–´ë¡œ ë³€ê²½\n",
      "4. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•˜ì§€ ë§ ê²ƒ\n",
      "\n",
      "ì›ë¬¸:  ì—¬ëŸ¬ë¶„ ì•ˆë…•í•˜ì„¸ìš” ë“œë””ì–´ ë ˆê·¸ì˜ ë¹„ë²•ë…¸íŠ¸ì— ë ˆê·¸ íŒŒíŠ¸ê¹Œì§€ ì˜¤ì‹œëŠë¼ ì •ë§ ê³ ìƒ ë§Žìœ¼ì…¨ìŠµë‹ˆë‹¤ ë ˆê·¸ì˜ ì „ë°˜ì ì¸ ë‚´ìš©ì„ ë¨¼ì € í•œë²ˆ ë“¤ì–´ë³´ì‹œê³ ìš” ê·¸ë¦¬ê³  ìž˜ ì´í•´ê°€ ì•ˆë˜ë©´ ë˜ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹¤ ìˆ˜ ìžˆìœ¼ë‹ˆê¹Œ ë°˜ë³µí•´ì„œ ë“¤ì–´ë³´ì‹œê³  ê·¸ë¦¬ê³  ë” ì¤‘ìš”í•œ ê±°ëŠ” ì´ ì‹¤ìŠµ íŒŒì¼ë“¤ì„ ì—¬ëŸ¬ë¶„ë“¤ì´ ë°˜ë³µí•´ì„œ ë³´ì‹œë©´ì„œ ê³„ì† ë ˆê·¸ì— ëŒ€í•œ í”„ë¡œì„¸ìŠ¤ ì´í•´ê°€ ìžˆì–´ì•¼ ê·¸ ë‹¤ìŒì— ë‹¤ì‹œ ì—­ìœ¼ë¡œ ëŒì•„ê°€ì„œ ìš°ë¦¬ê°€ ì´ëŸ° ê²ƒë“¤ì„ ì‚´íŽ´ë³¼ ê±°ì—ìš” ì•„í”„íŒŒì„œëž‘ ëª¨ë¸ ë©”ëª¨ë¦¬ ì²´ì¸ë“¤ ì´ëŸ° ê²ƒë“¤ì„ ì­‰ ì‚´íŽ´ë³¼ ë•Œ ì—­ìœ¼ë¡œ ë” ì´í•´ê°€ ìž˜ ë˜ì‹¤ ê±°ë¼ëŠ” ìƒê°ì´ ë“¤ë”ë¼êµ¬ìš”\n",
      "\n",
      "êµì • ê²°ê³¼: ì—¬ëŸ¬ë¶„ì˜ ìˆ˜ê³ ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤, ì´ì œ 'ë ˆê·¸' ë¶€ë¶„ê¹Œì§€ ë„ë‹¬í•˜ì…¨ìŠµë‹ˆë‹¤! ìš°ì„  ì „ì²´ ê°•ì˜ ë‚´ìš©ì— ìµìˆ™í•´ì§€ì‹  ë‹¤ìŒ, ì´í•´ë˜ì§€ ì•Šìœ¼ë©´ ë°˜ë³µí•´ ë“¤ì„ ìˆ˜ ìžˆìœ¼ë‹ˆ ê·¸ë ‡ê²Œ í•˜ì‹­ì‹œì˜¤. ë˜í•œ ì—°ìŠµ íŒŒì¼ì„ ê³„ì†í•´ì„œ ë³´ë©´ì„œ ë ˆê·¸ ê³¼ì • ì´í•´ë¥¼ í™•ì‹¤ížˆ í•´ì•¼ ë‚˜ì¤‘ì— ë‹¤ì‹œ ëŒì•„ì™€ì„œ ì•± ì„œë¹„ìŠ¤ì™€ ë©”ëª¨ë¦¬ ìºì‹œì™€ ê°™ì€ ì£¼ì œë“¤ì— ëŒ€í•´ ìžì„¸ížˆ ë“¤ì—¬ë‹¤ë³¼ ë•Œ ë„ì›€ì´ ë  ê²ƒìž…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë” ëª…í™•í•œ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt_template = \"\"\"ì´ ë¬¸ì„œì˜ ì˜¤íƒˆìžì™€ ì–´ìƒ‰í•œ í‘œí˜„ì„ ì „ë¬¸ êµì •ìžì˜ ìž…ìž¥ì—ì„œ ìžì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ì‚¬í•­ì„ ì¤‘ì ì ìœ¼ë¡œ ê²€í† í•´ì£¼ì„¸ìš”:\n",
    "1. ë¬¸ë§¥ì— ë§žì§€ ì•ŠëŠ” ë‹¨ì–´ë¥¼ ìˆ˜ì •\n",
    "2. ì˜ì–´ ë°œìŒì€ ì•ŒíŒŒë²³ìœ¼ë¡œ ë³€ê²½\n",
    "3. ê¸°ìˆ ì ì¸ ìš©ì–´ëŠ” ì›ì–´ë¡œ ë³€ê²½\n",
    "4. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•˜ì§€ ë§ ê²ƒ\n",
    "\n",
    "ì›ë¬¸: {prompt}\n",
    "\n",
    "êµì • ê²°ê³¼:\"\"\"\n",
    "\n",
    "# ìž…ë ¥ í…ì„œ ìƒì„± ë° GPU ì´ë™\n",
    "text = scripts[0]\n",
    "model_inputs = tokenizer(prompt_template.format(prompt=text), return_tensors='pt')\n",
    "model_inputs = {k: v.to('cuda') for k, v in model_inputs.items()}\n",
    "\n",
    "# ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "generation_config = {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 0.7,        # ì°½ì˜ì„± ì¡°ì ˆ (0.0-1.0)\n",
    "    \"top_p\": 0.9,             # nucleus sampling\n",
    "    \"do_sample\": True,        # ë‹¤ì–‘í•œ ì¶œë ¥ì„ ìœ„í•´ ìƒ˜í”Œë§ ì‚¬ìš©\n",
    "    \"num_return_sequences\": 1, # ìƒì„±í•  ê²°ê³¼ ìˆ˜\n",
    "    \"top_k\": 50,              # top-k sampling\n",
    "    \"repetition_penalty\": 1.2, # ë°˜ë³µ ë°©ì§€\n",
    "    \"no_repeat_ngram_size\": 3  # n-gram ë°˜ë³µ ë°©ì§€\n",
    "}\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìƒì„±\n",
    "outputs = model.generate(**model_inputs, **generation_config)\n",
    "\n",
    "# ê²°ê³¼ ë””ì½”ë”©\n",
    "output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "# ì›ë³¸ê³¼ êµì •ë³¸ ë¹„êµ ì¶œë ¥\n",
    "print(\"=== ì›ë³¸ ===\")\n",
    "print(text)\n",
    "print(\"\\n=== êµì •ë³¸ ===\")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "\n",
    "yt = YouTube(url)\n",
    "audio_stream = yt.streams.filter(only_audio=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# model = WhisperModel(\n",
    "#     \"large-v3\", device='cuda', compute_type=\"bfloat16\"\n",
    "# )\n",
    "# model = BatchedInferencePipeline(model=model)  # ë°°ì¹˜ ëª¨ë¸ì¼ ê²½ìš°\n",
    "# print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# segments, info = model.transcribe(\n",
    "#     audio_stream.url,\n",
    "#     batch_size=64,  # ë°°ì¹˜ ëª¨ë¸ì¸ ê²½ìš°\n",
    "#     repetition_penalty=1.5,\n",
    "#     beam_size=10,\n",
    "#     patience=2,\n",
    "#     no_repeat_ngram_size=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../miniconda3/envs/youtube/lib/python3.10/site-packages/faster_whisper/assets/pyannote_vad_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "Starting parallel download...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parallel downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.3M/32.3M [00:02<00:00, 11.3MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio chunks:   0%|          | 0/177 [00:00<?, ?it/s]/home/jinu/miniconda3/envs/youtube/lib/python3.10/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jinu/miniconda3/envs/youtube/lib/python3.10/site-packages/torch/nested/__init__.py:220: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  return _nested.nested_tensor(\n",
      "Processing audio chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [03:07<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 -> 29.82:  ê¼¼ê¼¼í•œ ë”¥ëŸ¬ë‹ ë…¼ë¬¸ ë¦¬ë·°ì™€ ì½”ë“œ ì‹¤ìŠµ. ì´ë²ˆ ì‹œê°„ì— ë¦¬ë·°í•  ë…¼ë¬¸ì€ í˜„ëŒ€ ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ìžì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ì˜ í•µì‹¬ ì•„í‚¤í…ì²˜ê°€ ë˜ê³  ìžˆëŠ” íŠ¸ëžœìŠ¤í¬ë¨¸ìž…ë‹ˆë‹¤. íŠ¸ëžœìŠ¤í¬ë¨¸ ë…¼ë¬¸ì˜ ì›ëž˜ ì œëª©ì€ Attention is all you need ìž…ë‹ˆë‹¤. ë…¼ë¬¸ì˜ ì œëª©ì—ì„œ ì•Œ ìˆ˜ ìžˆë“¯ì´ íŠ¸ëžœìŠ¤í¬ë¨¸ë¼ëŠ” ì•„í‚¤í…ì²˜ì—ëŠ” ì´ Attentionì´ë¼ê³  í•˜ëŠ” ê²ƒì´ ê°€ìž¥ ë©”ì¸ ì•„ì´ë””ì–´ë¡œì„œ ì‚¬ìš©ì´ ëœë‹¤ëŠ” ê±¸ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ íŠ¸ëžœìŠ¤í¬ë¨¸ëŠ” Attentionì´ë¼ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ ì „ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ì•„í‚¤í…ì²˜ìž…ë‹ˆë‹¤.\n",
      "30.00 -> 52.40:  íŠ¸ëžœìŠ¤í¬ë¨¸ê°€ ë‚˜ì˜¤ê²Œ ëœ ê³„ê¸°ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ê¸°ê³„ ë²ˆì—­ ë°œì „ ê³¼ì •ì— ëŒ€í•´ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤. 2021ë…„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ìžì—°ì–´ì²˜ë¦¬ ìª½ ê³ ì„±ëŠ¥ ëª¨ë¸ë“¤ì€ ì´ëŸ° íŠ¸ëžœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ìµœê·¼ê¹Œì§€ í™”ì œê°€ ë˜ì—ˆë˜ GPTì™€ BERTëŠ” ëª¨ë‘ ì´ëŸ¬í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì ì ˆížˆ í™œìš©í•˜ì—¬ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "60.00 -> 89.66:  ìžˆë‹¤ëŠ” ì ì´ íŠ¹ì§•ìž…ë‹ˆë‹¤. ìžì—°ì–´ì²˜ë¦¬ íƒœìŠ¤í¬ ì¤‘ì—ì„œ ê°€ìž¥ ëŒ€í‘œì ì´ë©´ì„œ ì¤‘ìš”í•œ íƒœìŠ¤í¬ ì¤‘ í•˜ë‚˜ëŠ” ê¸°ê³„ ë²ˆì—­ìž…ë‹ˆë‹¤. ì‹¤ì œë¡œ ê¸°ê³„ ë²ˆì—­ ê¸°ìˆ ì˜ ë°œì „ ê³¼ì •ì„ í™•ì¸í•´ ë³´ì‹œë©´ 1986ë…„ë„ ì¦ˆìŒì— RNNì´ ì œí•œë˜ì—ˆê³  ê·¸ë¡œë¶€í„° ì•½ 10ë…„ ì •ë„ê°€ ì§€ë‚œ ë’¤ì— LSTMì´ ë“±ìž¥í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ LSTMì„ í™œìš©í•˜ë©´ ë‹¤ì–‘í•œ ì‹œí€€ìŠ¤ ì •ë³´ë¥¼ ëª¨ë¸ë§í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ëŒ€í‘œì ìœ¼ë¡œ ì£¼ê°€ ì˜ˆì¸¡, ì£¼ê¸°í•¨ìˆ˜ ì˜ˆì¸¡ ë“±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ LSTMì„ í™œìš©í•´ì„œ 2014ë…„ë„ì—ëŠ” ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê¸°ìˆ ë¡œ\n",
      "90.00 -> 118.84:  ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ê°€ ë“±ìž¥í•˜ì˜€ìŠµë‹ˆë‹¤. ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ëŠ” í˜„ëŒ€ì˜ ë”¥ëŸ¬ë‹ ê¸°ìˆ ë“¤ì´ ë‹¤ì‹œ ë¹ ë¥´ê²Œ ë‚˜ì˜¤ê¸° ì‹œìž‘í•œ ì‹œì ì¸ 2014ë…„ë„ì— ì´ëŸ¬í•œ LSTMì„ í™œìš©í•´ì„œ ê³ ì •ëœ í¬ê¸°ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ë§Œ ì´ëŸ¬í•œ ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì´ ë‚˜ì™”ì„ ë•Œì˜ ì‹œì ë§Œ í•˜ë”ë¼ë„ ê³ ì •ëœ í¬ê¸°ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ì“°ê³  ìžˆê¸° ë•Œë¬¸ì— ì†ŒìŠ¤ ë¬¸ìž¥ì„ ì „ë¶€ ê³ ì •ëœ í¬ê¸°ì˜ í•œ ë²¡í„°ì—ë‹¤ê°€ ì••ì¶•ì„ í•  í•„ìš”ê°€ ìžˆë‹¤ëŠ” ì ì—ì„œ\n",
      "120.00 -> 141.36:  ì´í›„ì— ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ ì œí•œëœ ë…¼ë¬¸ì´ ë‚˜ì˜¤ë©´ì„œ ì´ëŸ¬í•œ ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì— ì–´í…ì…˜ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë” ëŒì–´ì˜¬ë¦´ ìˆ˜ê°€ ìžˆì—ˆê³ ìš”. ì´ì œ ê·¸ ì´í›„ì— íŠ¸ëžœìŠ¤í¬ë¨¸ ë…¼ë¬¸ì—ì„œëŠ” ê·¸ëƒ¥ RNN ìžì²´ë¥¼ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ë‹¤ëŠ” ì•„ì´ë””ì–´ë¡œ ì˜¤ì§ ì–´í…ì…˜ ê¸°ë²•ì— ì˜ì¡´í•˜ëŠ” ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í–ˆë”ë‹ˆ ì„±ëŠ¥ì´ í›¨ì”¬ ì¢‹ì•„ì§€ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
      "150.00 -> 176.50:  ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë”ìš±ë” ë§Žì´ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ ë“±ìž¥í•œ ì´í›„ë¡œë¶€í„°ëŠ” ìž…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì—°êµ¬ ë°©í–¥ì´ ë°œì „ë˜ì–´ ì™”ë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë¬¼ë¡  ì´í›„ì— ë‚˜ì˜¨ ë…¼ë¬¸ë“¤ ì¤‘ì—ì„œë„ RNNì„ í™œìš©í•˜ëŠ” ì•„í‚¤í…ì³ë„ ë§Žì´ ì¡´ìž¬í•˜ì§€ë§Œ ì „ë°˜ì ì¸ ì¶”ì„¸ ìžì²´ëŠ” ì–´í…ì…˜ ê¸°ë²•ì„ ë”ìš±ë” í™œìš©í•˜ëŠ” ì´ëŸ° íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì•„í‚¤í…ì³ë¥¼ ë”°ë¥´ëŠ” ë°©ì‹ìœ¼ë¡œ ë‹¤ì–‘í•œ ê³ ì„±ëŠ¥ ëª¨ë¸ë“¤ì´ ì œí•œë˜ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "180.00 -> 208.14:  ì–´ë–¤ í•œê³„ì ì´ ì¡´ìž¬í• ê¹Œìš”? ê¸°ì¡´ ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì˜ í•œê³„ì ì´ë¼ê³  í•œë‹¤ë©´ ì´ ì»¨í…ìŠ¤íŠ¸ ë²¡í„° Vì— ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ì •ë³´ë¥¼ ì••ì¶•í•œë‹¤ëŠ” ì ìž…ë‹ˆë‹¤. ì´ë•Œ ë³‘ëª© í˜„ìƒì´ ë°œìƒí•  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— ì„±ëŠ¥ í•˜ë½ì˜ ì›ì¸ì´ ë  ìˆ˜ ìžˆëŠ”ë°ìš”. í˜„ìž¬ ì˜ˆì‹œë¥¼ í™•ì¸í•´ ë³´ì‹œë©´ ëŒ€í‘œì ì¸ ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì„ í™œìš©í•œ ê¸°ê³„ ë²ˆì—­ ì˜ˆì‹œë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì™¼ìª½ì— ìžˆëŠ” ë…ì¼ì–´ ë¬¸ìž¥, ì¦‰ ê°ê°ì˜ ë‹¨ì–´ë“¤ë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ê°€ ë“¤ì–´ì™”ì„ ë•Œ ì´ë ‡ê²Œ ì¤‘ê°„ì—ì„œ í•˜ë‚˜ì˜ ê³ ì •ëœ í¬ê¸°ì˜\n",
      "210.00 -> 236.02:  ë‹¤ì‹œ ì´ëŸ¬í•œ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œë¶€í„° ì¶œë ¥ ë¬¸ìž¥ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¦‰ í•œìª½ì˜ ì‹œí€€ìŠ¤ì—ì„œë¶€í„° ë‹¤ë¥¸ í•œìª½ì˜ ì‹œí€€ìŠ¤ë¥¼ ë§Œë“ ë‹¤ëŠ” ì˜ë¯¸ì—ì„œ ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤ ëª¨ë¸ì´ë¼ê³  ë¶€ë¥¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ì˜ì–´ ì¶œë ¥ ë¬¸ìž¥ì´ ë‚˜ì˜¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ë‹¤ë§Œ ì´ë•Œ ì´ëŸ¬í•œ ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ í™•ì¸í•´ ë³´ì‹œë©´ ë§¤ë²ˆ ë‹¨ì–´ê°€ ìž…ë ¥ë  ë•Œë§ˆë‹¤ ížˆë“  ìŠ¤í…Œì´íŠ¸ ê°’ì„ ê°±ì‹ í•˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "240.00 -> 269.80:  ë‹¨ì–´ë“¤ì— ëŒ€í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìžˆëŠ” ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ë°›ì•„ì„œ ë§¤ë²ˆ ì´ëŸ° ì‹ìœ¼ë¡œ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ìƒˆë¡­ê²Œ ê°±ì‹ í•©ë‹ˆë‹¤. ì¦‰ ì´ëŸ° ì‹ìœ¼ë¡œ ê°ê°ì˜ ë‹¨ì–´ê°€ ì°¨ë¡€ëŒ€ë¡œ ìˆœì„œì— ë§žê²Œ ìž…ë ¥ë  ë•Œë§ˆë‹¤ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì´ ê°±ì‹ ë˜ì–´ ì´ëŸ¬í•œ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì€ ì´ì „ê¹Œì§€ ìž…ë ¥ë˜ì—ˆë˜ ë‹¨ì–´ë“¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°–ê³  ìžˆê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ë“¤ì–´ì™”ì„ ë•Œ ê·¸ë•Œì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì€ ì†ŒìŠ¤ ë¬¸ìž¥ ì „ì²´ë¥¼ ëŒ€í‘œí•˜ëŠ” í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œì„œ ì‚¬ìš©í•  ìˆ˜ê°€ ìžˆë‹¤ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì—\n",
      "270.00 -> 296.02:  ì´ë ‡ê²Œ ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ë“¤ì–´ì™”ì„ ë•Œì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œì„œ ì´ ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ì•ˆì—ëŠ” ì•žì— ë“±ìž¥í–ˆë˜ ì†ŒìŠ¤ ë¬¸ìž¥ì— ëŒ€í•œ ë¬¸ë§¥ì ì¸ ì •ë³´ë¥¼ ë‹´ê³  ìžˆë‹¤ê³  ê°€ì •í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œë¶€í„° ì¶œë°œí•´ì„œ ì´ë ‡ê²Œ ì¶œë ¥ì„ ìˆ˜í–‰í•˜ëŠ” ë””ì½”ë” íŒŒíŠ¸ì—ì„œëŠ” ë§¤ë²ˆ ì¶œë ¥ ë‹¨ì–´ê°€ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ ì´ëŸ¬í•œ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œë¶€í„° ì¶œë°œí•´ì„œ ë§ˆì°¬ê°€ì§€ë¡œ ížˆë“ ìŠ¤í…Œì´íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ ë§¤ë²ˆ ì¶œë ¥ì„ ë‚´ë³´ëƒ…ë‹ˆë‹¤.\n",
      "300.00 -> 328.14:  ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ì™€ì„œ ë°˜ë³µì ìœ¼ë¡œ ì´ì „ê¹Œì§€ ì¶œë ¥í–ˆë˜ ë‹¨ì–´ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìžˆëŠ” ížˆë“ ìŠ¤í…Œì´íŠ¸ì™€ ê°™ì´ ìž…ë ¥ì„ ë°›ì•„ ìƒˆë¡­ê²Œ ížˆë“ ìŠ¤í…Œì´íŠ¸ë¥¼ ê°±ì‹ í•˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ë””ì½”ë” íŒŒíŠ¸ì—ì„œëŠ” ë§¤ë²ˆ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ê°±ì‹ í•˜ë©´ì„œ ì´ë ‡ê²Œ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ìœ¼ë¡œë¶€í„° ì¶œë ¥ ê°’ì´ end of sequenceê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤. ê·¸ëž˜ì„œ end of sequenceê°€ ë‚˜ì™”ì„ ë•Œ ì¶œë ¥ ë¬¸ìž¥ ìƒì„±ì„ ë§ˆì¹˜ê²Œ ë˜ê³ ìš”. ì´ë ‡ê²Œ ì¶œë ¥ëœ ì •ë³´ì¸ good eveningì´ ë‚˜ì˜¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "330.00 -> 356.80:  ì‹œí€€ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ëª¨ë¸ì˜ ë™ìž‘ ì›ë¦¬ìž…ë‹ˆë‹¤. ë‹¤ë§Œ í™•ì¸í•´ ë³´ì‹œë©´ ì´ë ‡ê²Œ ì†ŒìŠ¤ ë¬¸ìž¥ì„ ëŒ€í‘œí•˜ëŠ” í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë§Œë“¤ì–´ì•¼ í•œë‹¤ëŠ” ì ì—ì„œ ì´ë ‡ê²Œ ê³ ì •ëœ í¬ê¸°ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì˜ ì •ë³´ë¥¼ ì••ì¶•í•˜ë ¤ê³  í•˜ë©´ ì´ëŸ¬í•œ ìž…ë ¥ ë¬¸ìž¥ì€ ì–´ë–¨ ë•ŒëŠ” ì§§ê¸°ë„ í•˜ê³  ì–´ë–¨ ë•ŒëŠ” ê¸¸ê¸°ë„ í•˜ê¸° ë•Œë¬¸ì— ê·¸ëŸ¬í•œ ë‹¤ì–‘í•œ ê²½ìš°ì˜ ìˆ˜ì— ëŒ€í•´ì„œ í•­ìƒ ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ì •ë³´ë¥¼ ê³ ì •ëœ í¬ê¸°ë¡œ ê°€ì§€ê³  ìžˆëŠ” ê²ƒì€ ì „ì²´ ì„±ëŠ¥ì—ì„œ ë³‘ëª©í˜„ìƒì˜ ì›ì¸ì´ ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "360.00 -> 388.72:  ì´ ê³ ì •ëœ í¬ê¸°ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ë§¤ë²ˆ ì´ ë””ì½”ë”ì˜ RNN ì…€ì—ì„œ ì°¸ê³ í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì¡°ê¸ˆ ë” ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ê²Œ ë˜ë©´ ì´ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì— ëŒ€í•œ ì •ë³´ê°€ ì´ ë””ì½”ë” íŒŒíŠ¸ì˜ RNN ì…€ì„ ê±°ì¹¨ì— ë”°ë¼ì„œ ì •ë³´ê°€ ì†ì‹¤ë˜ëŠ” ì •ë„ë¥¼ ë” ì¤„ì¼ ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— ì¶œë ¥ë˜ëŠ” ë¬¸ìž¥ì´ ê¸¸ì–´ì§„ë‹¤ê³  í•˜ë”ë¼ë„ ê°ê°ì˜ ì¶œë ¥ë˜ëŠ” ë‹¨ì–´ì— ì´ëŸ¬í•œ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹¤ì‹œ í•œë²ˆ ë„£ì–´ì¤„ ìˆ˜ ìžˆì–´ì„œ ì„±ëŠ¥ì´ ê¸°ì¡´ë³´ë‹¤ ì¡°ê¸ˆ ë” í–¥ìƒë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "390.00 -> 419.52:  ì ‘ê·¼í•œë‹¤ê³  í•˜ë”ë¼ë„ ì—¬ì „ížˆ ì´ ì†ŒìŠ¤ ë¬¸ìž¥ì„ í•˜ë‚˜ì˜ ë²¡í„°ì— ì••ì¶•í•´ì•¼ ëœë‹¤ëŠ” ì ì€ ë™ì¼í•˜ê¸° ë•Œë¬¸ì— ë³‘ëª© í˜„ìƒì€ ì—¬ì „ížˆ ë°œìƒí•©ë‹ˆë‹¤. ì¦‰ í˜„ìž¬ì˜ ë¬¸ì œ ìƒí™©ì´ë¼ê³  í•œë‹¤ë©´ í•˜ë‚˜ì˜ ë¬¸ë§¥ ë²¡í„° ì¦‰ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ê°€ ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ëª¨ë“  ì •ë³´ë¥¼ ê°€ì§€ê³  ìžˆì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìžˆë‹¤ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ë””ì½”ë” íŒŒíŠ¸ì—ì„œëŠ” í•˜ë‚˜ì˜ ë¬¸ë§¥ ë²¡í„°ì— ëŒ€í•œ ì •ë³´ë§Œ ê°€ì§€ê³  ìžˆëŠ” ê²Œ ì•„ë‹ˆë¼ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ ë•Œë§ˆë‹¤ ë§¤ë²ˆ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œì˜ ì¶œë ¥ ê°’ë“¤ ì „ë¶€ë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ìœ¼ë©´ ì–´ë–¨ê¹Œìš”?\n",
      "420.00 -> 448.72:  ì•„ì´ë””ì–´ê°€ ë‚˜ì˜¬ ìˆ˜ ìžˆëŠ” ê±°ì£ . ìµœì‹  GPUëŠ” ë§Žì€ ë©”ëª¨ë¦¬ì™€ ê·¸ë¦¬ê³  ë¹ ë¥¸ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ê¸° ë•Œë¬¸ì— ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ê¸¸ë‹¤ê³  í•˜ë”ë¼ë„ ê·¸ëŸ¬í•œ ì†ŒìŠ¤ ë¬¸ìž¥ì„ êµ¬ì„±í•˜ëŠ” ê°ê°ì˜ ë‹¨ì–´ì— ëŒ€í•œ ì¶œë ¥ê°’ë“¤ ì „ë¶€ë¥¼ íŠ¹ì • í–‰ë ¬ì—ë‹¤ê°€ ê¸°ë¡í•´ ë†“ì•˜ë‹¤ê°€ ì†ŒìŠ¤ ë¬¸ìž¥ì— ëŒ€í•œ ì „ë°˜ì ì¸ ë‚´ìš©ë“¤ì„ ë§¤ë²ˆ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ë°˜ì˜í•  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ê²ƒì„ ê¸°ëŒ€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ í•˜ë‚˜ì˜ ê³ ì •ëœ í¬ê¸°ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì— ë‹´ì§€ ë§ê³  ê·¸ëƒ¥ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ë‚˜ì™”ë˜\n",
      "450.00 -> 479.76:  ë§¤ë²ˆ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ 1ë…„ì˜ ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ë„ë¡ í•˜ë©´ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§ˆ ìˆ˜ ìžˆë‹¤ëŠ” ê²ë‹ˆë‹¤. ì§€ê¸ˆ ë³´ì´ëŠ” ì•„í‚¤í…ì²˜ê°€ ë°”ë¡œ ì‹œí€€ìŠ¤ ì‹œí€€ìŠ¤ì— ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì ìš©í•œ ì•„í‚¤í…ì²˜ì¸ë°ìš”. ì´ë ‡ê²Œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì ìš©í•´ì„œ ì¸ì½”ë” íŒŒíŠ¸ì˜ ëª¨ë“  ì¶œë ¥ì„ ì°¸ê³ í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ê°€ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ íŒŒì´í†¨ì¹˜ì™€ ê°™ì€ í”„ë ˆìž„ì›Œí¬ì—ì„œëŠ” ë‹¨ìˆœížˆ RNNì´ë‚˜ LSTM ê°™ì€ ê±¸ ì‚¬ìš©í•˜ë„ë¡ ë§Œë“¤ë©´ ì´ë ‡ê²Œ ë§¤ë²ˆ ì „ì²´ ì‹œí€€ìŠ¤ ê¸°ì— ë§žëŠ” ì•„ì›ƒí’‹ ê°’ë“¤ì´ ë”°ë¡œ\n",
      "480.00 -> 509.62:  ì¶œë ¥ê°’ë“¤ì´ ë‚˜ì˜¤ê²Œ ë˜ëŠ”ë°ìš”. ì´ì œ ê·¸ê±¸ ê·¸ëŒ€ë¡œ ì´ìš©í•´ì„œ ì‹¤ì œë¡œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤. ì „ë°˜ì ì¸ ë‚´ìš©ì„ í™•ì¸í•´ ë³´ì‹œë©´ ì´ë ‡ê²Œ ë§¤ë²ˆ ë‹¨ì–´ê°€ ì¶œë ¥ë¼ì„œ ížˆë“ ìŠ¤í…Œì´íŠ¸ê°€ ë‚˜ì˜¬ ë•Œë§ˆë‹¤ ê·¸ëƒ¥ ì´ ê°’ë“¤ì„ ì „ë¶€ ë‹¤ ì¶œë ¥ê°’ìœ¼ë¡œì¨ ê·¸ëƒ¥ ë³„ë„ì˜ ë°°ì—´ì—ë‹¤ê°€ ë‹¤ ê¸°ë¡í•´ë†“ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ëŸ° ì‹ìœ¼ë¡œ ê°ê°ì˜ ë‹¨ì–´ë¥¼ ê±°ì¹˜ë©´ì„œ ê°±ì‹ ë˜ëŠ” ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ë“¤ì„ ë§¤ë²ˆ ë‹¤ ê°€ì§€ê³  ìžˆëŠ” ê±°ì˜ˆìš”. ì´ë ‡ê²Œ í•´ì¤Œìœ¼ë¡œì¨ ì´ë ‡ê²Œ ë§¤ ë‹¨ì–´ê°€ ë“¤ì–´ì™”ì„ ë•Œì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ì „ë¶€ ê°€ì§€ê³  ìžˆì„ ìˆ˜ ìžˆê¸° ë•Œë¬¸ì—\n",
      "510.00 -> 536.78:  ì´ëŸ¬í•œ ê°’ë“¤ì„ ì–´ë–»ê²Œë“  ì°¸ê³ í•´ì„œ ì´ë ‡ê²Œ ì¶œë ¥ ë‹¨ì–´ê°€ ë§¤ë²ˆ ìƒì„±ë  ë•Œë§ˆë‹¤ ì´ëŸ¬í•œ ì†ŒìŠ¤ ë¬¸ìž¥ ì „ì²´ë¥¼ ë°˜ì˜í•˜ê² ë‹¤ ë¼ëŠ” ì•„ì´ë””ì–´ë¼ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” ì´ë ‡ê²Œ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ë§¤ë²ˆ ížˆë“ ìŠ¤í…Œì´íŠ¸ë¥¼ ê°±ì‹ í•˜ê²Œ ë˜ëŠ”ë° ì´ë•Œ í˜„ìž¬ ë‹¨ê³„ì—ì„œ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ë§Œë“ ë‹¤ê³  í•˜ë©´ ë°”ë¡œ ì´ì „ì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ì´ìš©í•´ì„œ ì´ ì¶œë ¥ë‹¨ì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ê³¼ ì´ë ‡ê²Œ ì†ŒìŠ¤ ë¬¸ìž¥ë‹¨ì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ì„œë¡œ ë¬¶ì–´ì„œ\n",
      "540.00 -> 551.50:  ì´ì œ ì´ë•Œ ê·¸ ì—ë„ˆì§€ ê°’ì€ ë‚´ê°€ í˜„ìž¬ ì–´ë– í•œ ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ì„œ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ì–´ë–¤ ë‹¨ì–´ì— ì´ˆì ì„ ë‘˜ í•„ìš”ê°€ ìžˆëŠ”ì§€ë¥¼ ìˆ˜ì¹˜í™”í•´ì„œ í‘œí˜„í•œ ê°’ìž…ë‹ˆë‹¤.\n",
      "570.00 -> 598.74:  ë”í•´ì¤€ ë‹¤ìŒì— ì´ì œ ê·¸ëŸ¬í•œ weighted sum ê°’ì„ ë§¤ë²ˆ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë°˜ì˜ì„ í•˜ê² ë‹¤ë¼ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤. ê·¸ëž˜ì„œ ë‹¨ìˆœížˆ ì´ë ‡ê²Œ context vectorë§Œ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì—¬ê¸°ì— ë”ë¶ˆì–´ì„œ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ì¶œë ¥ì´ ë˜ì—ˆë˜ ëª¨ë“  ížˆë“  ìŠ¤í…Œì´íŠ¸ ê°’ë“¤ì„ ì „ë¶€ ë°˜ì˜í•´ì„œ ì´ëŸ¬í•œ ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ë‹¨ì–´ì— ë”ìš± ë” ì£¼ì˜ ì§‘ì¤‘í•´ì„œ ì¶œë ¥ ê²°ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆëŠ”ê°€ë¥¼ ìš°ë¦¬ ëª¨ë¸ì´ ê³ ë ¤í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì„±ëŠ¥ì„ ë”ìš± ë†’ì¼ ìˆ˜ê°€ ìžˆë‹¤ëŠ” ê²ë‹ˆë‹¤.\n",
      "600.00 -> 628.86:  ë§¤ë²ˆ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ì´ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ë‚˜ì™”ë˜ ëª¨ë“  ì¶œë ¥ê°’ë“¤ì„ ì „ë¶€ ì°¸ê³ í•˜ê² ë‹¤ ì´ê²ë‹ˆë‹¤. ì¦‰ ì´ë ‡ê²Œ ì••ì¶•ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„° í•˜ë‚˜ë§Œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì´ëŸ° ì¶œë ¥ê°’ë“¤ì„ ì „ë¶€ ê³ ë ¤í•œ í•˜ë‚˜ì˜ weighted sum ë²¡í„°ë¥¼ êµ¬í•œ ë‹¤ìŒì— ê±”ë¥¼ ì´ë ‡ê²Œ ê°™ì´ ìž…ë ¥ìœ¼ë¡œ ë„£ì–´ì¤˜ì„œ ì†ŒìŠ¤ ë¬¸ìž¥ì— ëŒ€í•œ ì •ë³´ë¥¼ ëª¨ë‘ ê³ ë ¤í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì‹¤ì œë¡œ ì´ attention ê¸°ë²•ì„ ì ìš©í–ˆì„ ë•Œ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ê°ê°ì˜ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“œëŠ” ê³¼ì •ì„\n",
      "630.00 -> 656.54:  ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ê°€ ìžˆëŠ”ë°ìš”. ì´ë•Œ iëŠ” í˜„ìž¬ ë””ì½”ë”ê°€ ì²˜ë¦¬ ì¤‘ì¸ ì¸ë±ìŠ¤ê°€ ë˜ê² ìŠµë‹ˆë‹¤. ì¦‰ ë””ì½”ë”ê°€ ë§¤ë²ˆ í•œ ë²ˆì— í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ë§Œë“œëŠ”ë° ê·¸ ê°ê°ì˜ ì²˜ë¦¬ ì¤‘ì¸ ì¸ë±ìŠ¤ê°€ iê°€ ë˜ê² ê³ ìš”. ì´ë•Œ ì´ j ê°™ì€ ê²½ìš°ëŠ” ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ì¶œë ¥ ì¸ë±ìŠ¤ê°€ ë˜ê² ìŠµë‹ˆë‹¤. ì¦‰ ì—ë„ˆì§€ ê°’ì´ë¼ê³  í•˜ëŠ” ê²ƒì€ ë§¤ë²ˆ ë””ì½”ë”ê°€ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ ë•Œë§ˆë‹¤ ëª¨ë“  jë¥¼ ê³ ë ¤í•˜ëŠ” ê²ë‹ˆë‹¤. ì¦‰ ì¸ì½”ë”ì˜ ëª¨ë“  ì¶œë ¥ë“¤ì„ ê³ ë ¤í•˜ê² ë‹¤ë¼ê³  ë³´ì‹œë©´ ë¼ìš”.\n",
      "660.00 -> 687.72:  ë‹¨ì–´ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì‚¬ìš©í–ˆë˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ê°€ ë˜ê² ê³ ìš”. ì—¬ê¸° HëŠ” ì¸ì½”ë” íŒŒíŠ¸ì˜ ê°ê°ì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ìž…ë‹ˆë‹¤. ì¦‰ ì´ê±¸ ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•˜ìžë©´ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ë‚´ê°€ ì´ì „ì— ì¶œë ¥í–ˆë˜ ì •ë³´ëŠ” ì´ê±°ì¸ë° ì´ ì •ë³´ì™€ ì¸ì½”ë”ì˜ ëª¨ë“  ì¶œë ¥ê°’ê³¼ ë¹„êµë¥¼ í•´ì„œ ì—ë„ˆì§€ê°’ì„ êµ¬í•˜ê² ë‹¤ëŠ” ê²ë‹ˆë‹¤. ì¦‰ ì–´ë–¤ Hê°’ê³¼ ê°€ìž¥ ë§Žì€ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ”ì§€ë¥¼ ì—ë„ˆì§€ê°’ìœ¼ë¡œ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê±°ê³  ì´ì œ ì´ëŸ¬í•œ ì—ë„ˆì§€ê°’ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì·¨í•´ì„œ í™•ë¥ ê°’ì„ êµ¬í•©ë‹ˆë‹¤.\n",
      "690.00 -> 714.62:  ê°ê°ì˜ Hê°’ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ê°’ê³¼ ê°€ìž¥ ì—°ê´€ì„±ì´ ë†’ì€ì§€ë¥¼ êµ¬í•˜ë„ë¡ ë§Œë“¤ê³  ì´ì œ ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ ê°’ì„ ì‹¤ì œë¡œ Hê°’ê³¼ ê³±í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ê°€ ë°˜ì˜ëœ ê°ê°ì˜ ì¸ì½”ë”ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë”í•´ì„œ ê·¸ê²ƒì„ í™œìš©í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ ê·¸ë¦¼ì€ ì‹¤ì œë¡œ ì´ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•œ ë…¼ë¬¸ì—ì„œ ë³´ì—¬ì£¼ê³  ìžˆëŠ” ê·¸ë¦¼ì¸ë°ìš”. ë³´ì‹œë©´ ë§ˆì°¬ê°€ì§€ë¡œ ì—ë„ˆì§€ëž‘ ê°€ì¤‘ì¹˜ì˜ ê³µì‹ì€ ë™ì¼í•©ë‹ˆë‹¤.\n",
      "720.00 -> 746.54:  ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ì´ìš©í•´ì„œ ë§Œë“¤ ìˆ˜ê°€ ìžˆëŠ”ë°ìš”. í˜„ìž¬ ížˆë“ ìŠ¤í…Œì´íŠ¸, ì¦‰ STë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ ì´ì „ì— ì‚¬ìš©í–ˆë˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ê³¼ ì´ ì¸ì½”ë” íŒŒíŠ¸ì˜ ëª¨ë“  ê°ê°ì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ê°™ì´ ë¬¶ì–´ì„œ ì—ë„ˆì§€ ê°’ì„ êµ¬í•œ ë’¤ì— ì´ì œ ê±°ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì·¨í•´ì„œ ì´ë ‡ê²Œ ë¹„ìœ¨ ê°’ì„ êµ¬í•  ìˆ˜ ìžˆëŠ” ê±°ì˜ˆìš”. ì¦‰ ê·¸ëŸ¬í•œ ë¹„ìœ¨ì´ ê°ê° ì´ Aê°€ ë˜ê² ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ì„œ ë§Œì•½ì— ìž…ë ¥ ë¬¸ìž¥ì´ I am a teacherë¼ê³  í•´ë³¼ê²Œìš”.\n",
      "750.00 -> 777.64:  ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ê±¸ ê°€ìž¥ ë§Žì´ ì°¸ê³ í•˜ë©´ ë˜ëŠ”ì§€ë¥¼ ê·¸ ë¹„ìœ¨ê°’ì„ ì´ë ‡ê²Œ í¼ì„¼í…Œì´ì§€ë¡œ êµ¬í•´ì£¼ëŠ” ê²ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ì„œ iëŠ” 70%, mì€ 20%, ì–´ëŠ” 5%, í‹°ì³ë„ 5% ì´ëŸ° ì‹ìœ¼ë¡œ ë‹¤ ë”í–ˆì„ ë•Œ 100ì´ ë  ìˆ˜ ìžˆë„ë¡ ê·¸ í™•ë¥ ê°’ì„ êµ¬í•´ì„œ ê·¸ ë¹„ìœ¨ë§Œí¼ ì‹¤ì œë¡œ ì´ hê°’ì„ ê³±í•œ ê²ƒì„ ì´ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ì²˜ëŸ¼ ì‚¬ìš©ì„ í•  ìˆ˜ ìžˆë‹¤ëŠ” ê²ë‹ˆë‹¤. ê·¸ëž˜ì„œ ë§¤ë²ˆ ì¶œë ¥ì„ í•  ë•Œë§ˆë‹¤ ì´ë ‡ê²Œ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ì¶œë ¥ë˜ì—ˆë˜\n",
      "780.00 -> 809.28:  ì´ë ‡ê²Œ ë‹¤ìŒì— ë­˜ ì¶œë ¥í• ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆë‹¤ë¼ëŠ” ê²ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë ‡ê²Œ ë§¤ë²ˆ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ ë•Œë§ˆë‹¤ ì´ë ‡ê²Œ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ë“±ìž¥í–ˆë˜ ëª¨ë“  ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ë“¤ì„ ì „ë¶€ ë°˜ì˜í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì¦‰ ë‹¤ì‹œ í•œë²ˆ ìš©ì–´ë¥¼ ì •ë¦¬í•´ë“œë¦¬ìžë©´ ì´ ì—ë„ˆì§€ ê°’ì€ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œ ë‚˜ì™”ë˜ ëª¨ë“  ì¶œë ¥ ê°’ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ê°’ê³¼ ê°€ìž¥ ì—°ê´€ì„±ì´ ìžˆëŠ”ì§€ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œ ê·¸ ìˆ˜ì¹˜ë¥¼ êµ¬í•œ ê²ƒì´ê³ ìš”. ì´ì œ ê·¸ ê°’ë“¤ì„ ì†Œí”„íŠ¸ë§¥ìŠ¤ì— ë„£ì–´ì„œ ìƒëŒ€ì ì¸ í™•ë¥  ê°’ì„ êµ¬í•œ ê²ƒì´\n",
      "810.00 -> 838.86:  ê·¸ëŸ¬í•œ ê°€ì¤‘ì¹˜ ê°’ë“¤ì„ ì‹¤ì œë¡œ ê°ê°ì˜ ê·¸ ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ížˆë“ ìŠ¤í…Œì´íŠ¸ì™€ ê³±í•´ì¤˜ì„œ ì „ë¶€ ë”í•´ì¤€ ê°’ì„ ì‹¤ì œë¡œ ë””ì½”ë”ì˜ ìž…ë ¥ìœ¼ë¡œ ê°™ì´ ë„£ì–´ì£¼ê² ë‹¤ë¼ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ì´ì œ ì´ëŸ° ì‹ìœ¼ë¡œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì“°ê²Œ ë˜ë©´ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ë¿ë§Œ ì•„ë‹ˆë¼ ë˜ ì¶”ê°€ì ì¸ ìž¥ì ìœ¼ë¡œëŠ” ì´ëŸ¬í•œ ì–´í…ì…˜ì€ ì‹œê°í™”í•  ìˆ˜ë„ ìžˆë‹¤ëŠ” ê±´ë°ìš”. ì´ëŸ° ì‹ìœ¼ë¡œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì¦‰ êµ¬í•´ì§„ í™•ë¥  ê°’ì„ ì´ìš©í•´ì„œ ë§¤ë²ˆ ì¶œë ¥ì´ ë‚˜ì˜¬ ë•Œë§ˆë‹¤ ê·¸ ì¶œë ¥ì´ ìž…ë ¥ì—ì„œ ì–´ë–¤ ì •ë³´ë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ë¥¼ êµ¬í•  ìˆ˜ê°€ ìžˆìŠµë‹ˆë‹¤.\n",
      "840.00 -> 869.10:  ì´ê±°ëŠ” ì˜ì–´ë¥¼ ë¶ˆì–´ë¡œ ë²ˆì—­í•œ ì˜ˆì‹œì¸ë°ìš”. ì—¬ê¸°ì„œ the arrangement on the European ì´ë ‡ê²Œ ë‚˜ì˜¤ì£ . ê°ê°ì˜ ë‹¨ì–´ë“¤ì´ ìžˆì„ ë•Œ ì´ì œ ë§¤ë²ˆ ì´ ë¶ˆì–´ì— ë‹¨ì–´ë“¤ì„ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ì´ëŸ¬í•œ ìž…ë ¥ ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ë‹¨ì–´ì— ê°€ìž¥ ë§Žì€ ì´ˆì ì„ ë’€ëŠ”ì§€ë¥¼ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì§€ê¸ˆ ì´ëŸ° ì‹ìœ¼ë¡œ ë°ê²Œ í‘œì‹œëœ ë¶€ë¶„ì´ í™•ë¥ ê°’ì´ ë†’ì€ ë¶€ë¶„ì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ë§¤ë²ˆ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ì´ ì¶œë ¥í•˜ëŠ” ë‹¨ì–´ê°€ ìž…ë ¥ ë‹¨ì–´ ì¤‘ì—ì„œ ì–´ë–¤ ë‹¨ì–´ì— ë”ìš± ë§Žì€ ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ì„œ\n",
      "871.44 -> 899.40:  ê¸°ë³¸ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì€ ë§¤ìš° ë§Žì€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ê³  ìžˆê¸° ë•Œë¬¸ì— ê·¸ëŸ¬í•œ ì„¸ë¶€ì ì¸ íŒŒë¼ë¯¸í„°ë¥¼ ì¼ì¼ì´ ë¶„ì„í•˜ë©´ì„œ ì–´ë–¤ ì›ë¦¬ë¡œ ë™ìž‘ì„ í–ˆëŠ”ì§€ë¥¼ ì•Œì•„ë‚´ê¸°ëŠ” ì‰½ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ ì‹¤ì œë¡œ ë”¥ëŸ¬ë‹ì´ ì–´ë–¤ ìš”ì†Œì— ë”ìš±ë” ë§Žì€ ì´ˆì ì„ ë‘ì–´ì„œ ë¶„ë¥˜ë¥¼ í–ˆëŠ”ê°€ í˜¹ì€ ì–´ë– í•œ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ëƒˆëŠ”ê°€ ê°™ì€ ê³¼ì •ì„ ë¶„ì„í•  ë•Œ ìš©ì´í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì˜¤ëŠ˜ ë¦¬ë·°í•˜ê³  ìžˆëŠ” íŠ¸ëžœìŠ¤í¬ë¨¸ ë…¼ë¬¸ì€ ì–´ë–¤ ì›ë¦¬ë¡œ ë™ìž‘í• ê¹Œìš”?\n",
      "905.44 -> 927.78:  ê·¸ëž˜ì„œ ë…¼ë¬¸ì˜ ì›ëž˜ ì œëª©ì€ attention is all you need ì´ê³ ìš”. ë§ ê·¸ëŒ€ë¡œ attention ê¸°ë²•ë§Œ ìž˜ í™œìš©í•´ë„ ë‹¤ì–‘í•œ ìžì—°ì–´ì²˜ë¦¬ íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìžˆë‹¤ëŠ” ì˜ë¯¸ìž…ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ attention ê¸°ë²•ë§Œ ì“°ê¸° ë•Œë¬¸ì— RNN, CNN ë“±ì„ ì „í˜€ í•„ìš”ë¡œ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì§„ì§œ ë§ ê·¸ëŒ€ë¡œ attention ê¸°ë²•ë§Œ ì‚¬ìš©í•´ì„œ ê¸°ê³„ ë²ˆì—­ë¶€í„° ì‹œìž‘í•´ì„œ ë‹¤ì–‘í•œ ìžì—°ì–´ì²˜ë¦¬ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìžˆëŠ” ê²ë‹ˆë‹¤.\n",
      "930.00 -> 955.82:  ë…¼ë¬¸ì—ì„œ ë³´ì—¬ì£¼ê³  ìžˆëŠ” íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì•„í‚¤í…ì²˜ì¸ë°ìš”. ì—¬ê¸° ë³´ì´ëŠ” ê²ƒê³¼ ê°™ì´ ì‹¤ì œë¡œ RNNê³¼ CNNì„ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬¼ë¡  ì´ëŸ° ì‹ìœ¼ë¡œ RNN, CNN ë“±ì„ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ë¬¸ìž¥ ì•ˆì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ ë‹¨ì–´ë“¤ì˜ ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ì£¼ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— íŠ¸ëžœìŠ¤í¬ë¨¸ëŠ” ë¬¸ìž¥ ë‚´ ê°ê°ì˜ ë‹¨ì–´ë“¤ì— ëŒ€í•œ ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ê¸° ìœ„í•´ì„œ ë³„ë„ë¡œ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ ì´ìš©í•´ì„œ ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ì¤„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "960.00 -> 988.88:  ë”ìš± í–¥ìƒëœ ë„¤íŠ¸ì›Œí¬ì—ì„œë„ ì±„íƒì´ ë˜ì—ˆê³ ìš”. ë˜í•œ ì°¸ê³ ë¡œ RNNì„ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ë§ˆì°¬ê°€ì§€ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë” íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ëŠ” ê±´ ë™ì¼í•©ë‹ˆë‹¤. ë˜í•œ ì–´í…ì…˜ ê³¼ì •ì„ í•œ ë²ˆë§Œ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ ê±°ì³ì„œ ë°˜ë³µí•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì¦‰ ì´ëŸ¬í•œ ì¸ì½”ë”ê°€ ì—¬ëŸ¬ ë²ˆ ì¤‘ì²©ë˜ì–´ ì¦‰ Në²ˆë§Œí¼ ì¤‘ì²©ë˜ì–´ ì‚¬ìš©í•˜ë„ë¡ ë§Œë“ ë‹¤ëŠ” ê±´ë°ìš”. ì°¸ê³ ë¡œ ì§€ê¸ˆ ë³´ì´ëŠ” ê·¸ë¦¼ì—ì„œ ì´ ì™¼ìª½ íŒŒíŠ¸ëŠ” ì¸ì½”ë”ê°€ ë˜ê³  ì´ ì˜¤ë¥¸ìª½ íŒŒíŠ¸ëŠ” ë””ì½”ë”ê°€ ë˜ê² ìŠµë‹ˆë‹¤. í•œë²ˆ ìžì„¸í•œ ë‚´ìš©ì„ ì§€ê¸ˆë¶€í„° ì•Œì•„ë³¼ê²Œìš”.\n",
      "990.00 -> 1018.50:  ì–´ë– í•œ ë‹¨ì–´ ì •ë³´ë¥¼ ë„¤íŠ¸ì›Œí¬ì— ë„£ê¸° ìœ„í•´ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë³´í†µ ì¸ë² ë”© ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ê·¸ë ‡ê²Œ í•´ì£¼ëŠ” ì´ìœ ëŠ” ì¼ë‹¨ ë§¨ ì²˜ìŒì— ìž…ë ¥ ì°¨ì› ìžì²´ëŠ” íŠ¹ì • ì–¸ì–´ì—ì„œ ì¡´ìž¬í•  ìˆ˜ ìžˆëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ì™€ ê°™ê¸° ë•Œë¬¸ì— ë˜í•œ ê·¸ë ‡ê²Œ ì°¨ì›ì´ ë§Žì„ ë¿ë§Œ ì•„ë‹ˆë¼ ê°ê°ì˜ ì •ë³´ë“¤ì€ ì›í•« ì¸ì½”ë”© í˜•íƒœë¡œ í‘œí˜„ì´ ë˜ê¸° ë•Œë¬¸ì— ì¼ë°˜ì ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì— ë„£ì„ ë•ŒëŠ” ë¨¼ì € ì¸ë² ë”© ê³¼ì •ì„ ê±°ì³ì„œ ë”ìš±ë” ì ì€ ì°¨ì›ì˜ ì»¨í‹°ë‰´ì–´ìŠ¤í•œ ê°’ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ì¦‰ ì–´ë– í•œ ì‹¤ìˆ˜ ê°’ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ê°€ ìžˆë‹¤ëŠ” ê±´ë°ìš”.\n",
      "1020.00 -> 1046.74:  ì´ëŸ° ì‹ìœ¼ë¡œ I am a teacherì™€ ê°™ì€ í•˜ë‚˜ì˜ ë¬¸ìž¥ì´ ë“¤ì–´ì™”ì„ ë•Œ ì–˜ë„¤ëŠ” ì‹¤ì œë¡œ input embedding matrixë¡œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤. ì´ë•Œ ì¼ë°˜ì ìœ¼ë¡œ ì´ matrixëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ë§Œí¼ í–‰ì˜ í¬ê¸°ë¥¼ ê°€ì§€ê³ ìš”. ì¦‰ ì´ëŸ° ì‹ìœ¼ë¡œ I am a teacherë¼ëŠ” ê°’ì´ ì´ë ‡ê²Œ í–‰ í˜•íƒœë¡œ ë“¤ì–´ì˜¤ê²Œ ë˜ê³  ì´ ê°ê°ì˜ ì—´ ë°ì´í„°ëŠ” embedding ì°¨ì›ê³¼ ê°™ì€ í¬ê¸°ì˜ ë°ì´í„°ê°€ ë‹´ê¸´ ë°°ì—´ì„ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤. í˜„ìž¬ ê·¸ë¦¼ì—ì„  ì´ëŸ° ì‹ìœ¼ë¡œ ì´ 4ê°œì˜ ë‹¨ì–´ê°€ ì¡´ìž¬í•˜ê¸° ë•Œë¬¸ì—\n",
      "1050.00 -> 1079.68:  ë¥¼ í¬í•¨í•˜ê³  ìžˆëŠ” ì¸ë² ë”© ê°’ë“¤ì„ ê°ê° êµ¬í•  ìˆ˜ê°€ ìžˆë‹¤ëŠ” ê±°ì£ . ì´ëŸ° ì‹ìœ¼ë¡œ ë‹¤ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¸ë² ë”© ë””ë©˜ì €ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ë§Œë“œëŠ” ì‚¬ëžŒì´ ìž„ì˜ë¡œ ì„¤ì •í•´ ì¤„ ìˆ˜ ìžˆëŠ”ë°ìš”. ì›ë³¸ ë…¼ë¬¸ì—ì„œëŠ” 512 ì •ë„ì˜ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë¬¼ë¡  ì´ ê°’ì€ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ë¥¼ ë§Œë“œëŠ” ì‚¬ëžŒë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì„¤ì •í•  ìˆ˜ê°€ ìžˆëŠ” ê±°ì˜ˆìš”. ì•„ë¬´íŠ¼ ê·¸ëž˜ì„œ ì´ëŸ° ì‹ìœ¼ë¡œ ì „í†µì ì¸ ì¸ë² ë”©ì€ ë„¤íŠ¸ì›Œí¬ì— ë„£ê¸° ì „ì— ìž…ë ¥ ê°’ë“¤ì„ ì¸ë² ë”© í˜•íƒœë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•˜ëŠ” ë ˆì´ì–´ë¼ê³  ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ ìš°ë¦¬ê°€ ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤ì™€ ê°™ì€\n",
      "1080.00 -> 1109.94:  RNN ê¸°ë°˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•œë‹¤ê³  í•˜ë©´ RNNì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ê°ê°ì˜ ë‹¨ì–´ê°€ RNNì— ë“¤ì–´ê°ˆ ë•Œ ìˆœì„œì— ë§žê²Œ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— ìžë™ìœ¼ë¡œ ê°ê°ì˜ ížˆë“ ìŠ¤í…”íŠ¸ ê°’ì€ ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì§€ê²Œ ë˜ëŠ”ë°ìš”. ë§Œì•½ì— íŠ¸ëžœìŠ¤í¬ë¨¸ì™€ ê°™ì´ RNN ìžì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì£¼ê¸° ìœ„í•´ì„œ ì¦‰ í•˜ë‚˜ì˜ ë¬¸ìž¥ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ ë‹¨ì–´ ì¤‘ì—ì„œ ì–´ë–¤ ë‹¨ì–´ê°€ ì•žì— ì˜¤ëŠ” ê²ƒì´ê³  ì–´ë– í•œ ë‹¨ì–´ê°€ ë’¤ì— ì˜¤ëŠ” ê²ƒì¸ì§€ ê·¸ëŸ¬í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ê¸° ìœ„í•´ì„œëŠ” ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìžˆëŠ” ì¸ë² ë”©ì„ ì‚¬ìš©í•  í•„ìš”ê°€ ìžˆìŠµë‹ˆë‹¤.\n",
      "1110.00 -> 1133.84:  ì´ì œ ì´ë¥¼ ìœ„í•´ íŠ¸ëžœìŠ¤í¬ë¨¸ì—ì„œëŠ” ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¸ì½”ë”©í•˜ê³  ìžˆëŠ” ìœ„ì¹˜ ì¸ì½”ë”©, ì¦‰ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¦‰ ì´ëŸ° ì‹ìœ¼ë¡œ ì¸í’‹ ìž„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì™€ ê°™ì€ í¬ê¸°, ì¦‰ ê°™ì€ ë””ë©˜ì „ì„ ê°€ì§€ëŠ” ë³„ë„ì˜ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìžˆëŠ” ì¸ì½”ë”© ì •ë³´ë¥¼ ë„£ì–´ì¤˜ì„œ ê°ê° ì—˜ëŸ¬ë¨¼íŠ¸ ì™€ì´ì¦ˆë¡œ ë”í•´ì¤Œìœ¼ë¡œì¨ ê°ê°ì˜ ë‹¨ì–´ê°€ ì–´ë–¤ ìˆœì„œë¥¼ ê°€ì§€ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ë„¤íŠ¸ì›Œí¬ê°€ ì•Œ ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
      "1140.00 -> 1162.08:  ì¦‰ ì´ë ‡ê²Œ attentionì´ ë°›ëŠ” ê°’ì€ ìž…ë ¥ ë¬¸ìž¥ì— ëŒ€í•œ ì •ë³´ì—ë‹¤ê°€ ì‹¤ì œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ê¹Œì§€ ê°™ì´ í¬í•¨ë˜ì–´ ìžˆëŠ” ìž…ë ¥ ê°’ìž…ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ê·¸ëŸ¬í•œ ìž…ë ¥ì„ ë°›ì•„ì„œ ê°ê°ì˜ ë‹¨ì–´ë“¤ì„ ì´ìš©í•´ì„œ attentionì„ ìˆ˜í–‰í•˜ê³ ìš”. ì´ì œ ì´ë ‡ê²Œ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ìˆ˜í–‰í•˜ëŠ” attentionì€ self-attentionì´ë¼ê³  í•´ì„œ ê°ê°ì˜ ë‹¨ì–´ê°€ ì„œë¡œì—ê²Œ ì–´ë–¤ ì—°ê´€ì„±ì„ ê°€ì§€ê³  ìžˆëŠ”ì§€ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "1170.00 -> 1197.58:  ì‹œì²˜ê°€ ê°ê° ì„œë¡œì—ê²Œ attention ìŠ¤ì½”ì–´ë¥¼ êµ¬í•´ì„œ ê°ê°ì˜ ë‹¨ì–´ëŠ” ë‹¤ë¥¸ ì–´ë– í•œ ë‹¨ì–´ì™€ ë†’ì€ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ì´ëŸ¬í•œ attentionì€ ì´ ì „ë°˜ì ì¸ ìž…ë ¥ ë¬¸ìž¥ì— ëŒ€í•œ ë¬¸ë§¥ì— ëŒ€í•œ ì •ë³´ë¥¼ ìž˜ í•™ìŠµí•˜ë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤. ë˜í•œ ì—¬ê¸°ì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ residual learningê³¼ ê°™ì€ í…Œí¬ë‹‰ì´ ì‚¬ìš©ë˜ëŠ”ë°ìš”. ì´ëŸ° residual learning ê°™ì€ ê²½ìš°ëŠ” ëŒ€í‘œì ì¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ë„¤íŠ¸ì›Œí¬ì¸ ë ˆì§€ë„¥ê³¼ ê°™ì€ ë„¤íŠ¸ì›Œí¬ì—ì„œ ì‚¬ìš©ë˜ê³  ìžˆëŠ” ê¸°ë²•ìœ¼ë¡œ\n",
      "1200.00 -> 1226.68:  ë°˜ë³µì ìœ¼ë¡œ ë‹¨ìˆœí•˜ê²Œ ê°±ì‹ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ íŠ¹ì • ë ˆì´ì–´ë¥¼ ê±´ë„ˆë›°ì–´ì„œ ë³µì‚¬ê°€ ëœ ê°’ì„ ê·¸ëŒ€ë¡œ ë„£ì–´ì£¼ëŠ” ê¸°ë²•ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ íŠ¹ì • ë ˆì´ì–´ë¥¼ ê±´ë„ˆë›°ì–´ì„œ ìž…ë ¥í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒì„ ì¼ë°˜ì ìœ¼ë¡œ ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜ì´ë¼ê³  ë¶€ë¥´ê³ ìš”. ì´ë ‡ê²Œ í•´ì¤Œìœ¼ë¡œì¨ ì „ì²´ ë„¤íŠ¸ì›Œí¬ëŠ” ê¸°ì¡´ ì •ë³´ë¥¼ ìž…ë ¥ ë°›ìœ¼ë©´ì„œ ì¶”ê°€ì ìœ¼ë¡œ ìž”ì—¬ëœ ë¶€ë¶„ë§Œ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ê¸° ë•Œë¬¸ì— ì „ë°˜ì ì¸ í•™ìŠµ ë‚œì´ë„ê°€ ë‚®ê³  ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ˆê¸°ì˜ ëª¨ë¸ ìˆ˜ë ´ ì†ë„ê°€ ë†’ê²Œ ë˜ê³ \n",
      "1230.00 -> 1258.86:  ì „ë°˜ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•´ì„œ residual learningì„ ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ëŠ” ê±¸ ë§Žì´ ëª©ê²©í•  ìˆ˜ ìžˆê³ ìš”. íŠ¸ëžœìŠ¤í¬ë¨¸ ë˜í•œ ë§ˆì°¬ê°€ì§€ë¡œ ê·¸ëŸ° ì•„ì´ë””ì–´ë¥¼ ì „ì ìœ¼ë¡œ ìž¬íƒí•´ì„œ ì„±ëŠ¥ì„ ë†’ì˜€ë‹¤ê³  í•  ìˆ˜ ìžˆëŠ” ê²ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë ‡ê²Œ attentionì„ ìˆ˜í–‰í•´ì£¼ê³  ë‚˜ì˜¨ ê°’ê³¼ ì´ë ‡ê²Œ residual connectionì„ ì´ìš©í•´ì„œ ë°”ë¡œ ë”í•´ì§„ ê°’ì„ ê°™ì´ ë°›ì•„ì„œ ë…¸ë©€ë¼ì´ì œì´ì…˜ê¹Œì§€ ìˆ˜í–‰í•œ ë’¤ì— ê·¸ ê²°ê³¼ë¥¼ ë‚´ë³´ë‚¼ ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì´ê²ƒì´ ì¸ì½”ë”ì˜ ë™ìž‘ ê³¼ì •ì´ê³ ìš”. ê·¸ëž˜ì„œ ì‹¤ì œë¡œ ì´ë ‡ê²Œ ìž…ë ¥ê°’ì´ ë“¤ì–´ì˜¨ ì´í›„ë¡œë¶€í„°\n",
      "1260.00 -> 1289.88:  ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜ ì´í›„ì— ë…¸ë©€ë¼ì´ì œì´ì…˜, ê·¸ ë‹¤ìŒì— ë‹¤ì‹œ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ë¥¼ ê±°ì¹œ ë‹¤ìŒì— ë§ˆì°¬ê°€ì§€ë¡œ ë ˆì§€ë“€ì–¼ ëŸ¬ë‹, ê·¸ë¦¬ê³  ë…¸ë©€ë¼ì´ì œì´ì…˜ì„ ì¶”ê°€í•´ì„œ ê²°ê³¼ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ì¸ì½”ë” ë ˆì´ì–´ì—ì„œ ê·¸ ê²°ê³¼ê°’ì„ ë½‘ì•„ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ì–´í…ì…˜ê³¼ ì •êµí™” ê³¼ì •ì„ ë°˜ë³µí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¥¼ ì¤‘ì²©í•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë•Œ í•œ ê°€ì§€ ìœ ì˜í•  ì ì€ ê°ê°ì˜ ë ˆì´ì–´ëŠ” ì„œë¡œ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë ˆì´ì–´ 1ë²ˆê³¼ ë ˆì´ì–´ 2ë²ˆì— í¬í•¨ë˜ì–´ ìžˆëŠ” ì–´í…ì…˜ ë° í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ì— ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„°ëŠ”\n",
      "1290.00 -> 1319.56:  ì„œë¡œ ë‹¤ë¦…ë‹ˆë‹¤. ë˜í•œ ì´ë•Œ ì´ë ‡ê²Œ ë ˆì´ì–´ë¥¼ ì¤‘ì²©í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ëŠ” ì ì—ì„œ ìœ ì¶”í•  ìˆ˜ ìžˆê² ì§€ë§Œ ì´ë ‡ê²Œ ìž…ë ¥ë˜ëŠ” ê°’ê³¼ ì¶œë ¥ë˜ëŠ” ê°’ì˜ ë””ë©˜ì €ëŠ” ë™ì¼í•©ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ì‹¤ì œë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì „ì²´ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì•„í‚¤í…ì²˜ë¥¼ ê·¸ë ¤ë³¼ ìˆ˜ ìžˆëŠ”ë°ìš”. ì´ë ‡ê²Œ ìž…ë ¥ê°’ì´ ë“¤ì–´ì˜¨ ë‹¤ìŒì— ì—¬ëŸ¬ ê°œì˜ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ ë°˜ë³µí•´ì„œ ê°€ìž¥ ë§ˆì§€ë§‰ì˜ ì¸ì½”ë”ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ê·¸ ì¶œë ¥ê°’ì€ ì´ë ‡ê²Œ ë””ì½”ë”ì— ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•´ì£¼ëŠ” ì´ìœ ëŠ” ìš°ë¦¬ê°€ ì•žì„œ ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤ ëª¨ë¸ì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í–ˆì„ ë•Œì™€ ë§ˆì°¬ê°€ì§€ë¡œ\n",
      "1320.00 -> 1348.42:  ë””ì½”ë” íŒŒíŠ¸ì—ì„œëŠ” ë§¤ë²ˆ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ìž…ë ¥ ì†ŒìŠ¤ ë¬¸ìž¥ ì¤‘ì—ì„œ ì–´ë–¤ ë‹¨ì–´ì—ê²Œ ê°€ìž¥ ë§Žì€ ì´ˆì ì„ ë‘¬ì•¼ ë˜ëŠ”ì§€ë¥¼ ì•Œë ¤ì£¼ê¸° ìœ„í•¨ìž…ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ì´ë ‡ê²Œ ë””ì½”ë” íŒŒíŠ¸ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ì´ ë˜ê³  ì´ ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ì¶œë ¥ ê°’ì´ ë°”ë¡œ ì‹¤ì œë¡œ ìš°ë¦¬ê°€ ë²ˆì—­ì„ ìˆ˜í–‰í•œ ê²°ê³¼ ê·¸ ì¶œë ¥ ë‹¨ì–´ê°€ ë˜ëŠ” ê±°ê³ ìš”. ì´ë•Œ ê°ê°ì˜ ë ˆì´ì–´ëŠ” ì´ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ì¶œë ¥ ê°’ì„ ìž…ë ¥ìœ¼ë¡œ ë°›ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ê°€ìž¥ ê¸°ë³¸ì ì¸ ë™ìž‘ ë°©ì‹ì´ê³ ìš”.\n",
      "1350.00 -> 1376.32:  ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì¶œë ¥ê°’ë§Œ ë°›ëŠ” ê²Œ ì•„ë‹ˆë¼ ì´ë ‡ê²Œ ê°ê°ì˜ ë ˆì´ì–´ë§ˆë‹¤ ì¶œë ¥ê°’ì„ ë°›ëŠ” ê¸°ë²•ë„ ì¡´ìž¬í•˜ê¸´ í•˜ì§€ë§Œìš”. ì•„ë¬´íŠ¼ ê¸°ë³¸ì ì¸ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì•„í‚¤í…ì…˜ì€ ì´ëŸ° ì‹ìœ¼ë¡œ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ì¶œë ¥ê°’ì„ ë§¤ë²ˆ ë””ì½”ë”ì˜ ë ˆì´ì–´ì— ë„£ì–´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë•Œ ë””ì½”ë” ë˜í•œ ë§ˆì°¬ê°€ì§€ë¡œ ê°ê° ë‹¨ì–´ ì •ë³´ë¥¼ ë°›ì•„ì„œ ì´ì–´ì„œ ê° ë‹¨ì–´ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ê¸° ìœ„í•´ ì¸ì½”ë”© ê°’ì„ ì¶”ê°€í•œ ë’¤ì— ìž…ë ¥ì„ ë„£ê²Œ ë˜ê³ ìš”.\n",
      "1380.00 -> 1405.00:  ì²« ë²ˆì§¸ë¡œ ë³´ì´ëŠ” attentionì€ self-attentionìœ¼ë¡œ ì¸ì½”ë” íŒŒíŠ¸ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ê°ê°ì˜ ë‹¨ì–´ë“¤ì´ ì„œë¡œê°€ ì„œë¡œì—ê²Œ ì–´ë– í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ëŠ”ì§€ë¥¼ êµ¬í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì´ ì¶œë ¥ë˜ê³  ìžˆëŠ” ë¬¸ìž¥ì— ëŒ€í•œ ì „ë°˜ì ì¸ í‘œí˜„ì„ í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê³ ìš”. ì´ë ‡ê²Œ ì´ì–´ì„œ ë””ì½”ë” ë ˆì´ì–´ì˜ ë‘ ë²ˆì§¸ attentionì—ì„œëŠ” ì¸ì½”ë”ì— ëŒ€í•œ ì •ë³´ë¥¼ attentioní•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ê°ê°ì˜ ì¶œë ¥ ë‹¨ì–´ê°€ ì¸ì½”ë”ì˜ ì¶œë ¥ ì •ë³´ë¥¼ ë°›ì•„ì™€ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤.\n",
      "1410.00 -> 1437.46:  ì–´ë–¤ ë‹¨ì–´ì™€ ì—°ê´€ì„±ì´ ìžˆëŠ”ì§€ë¥¼ êµ¬í•´ì£¼ëŠ” ê²ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì—¬ê¸° ë³´ì´ëŠ” attentionì€ ì¼ë°˜ì ìœ¼ë¡œ ì¸ì½”ë” ë””ì½”ë” attentionì´ë¼ê³  ë¶€ë¥´ê³ ìš”. ê·¸ ë™ìž‘ ì›ë¦¬ë¥¼ ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ ì„¤ëª…ë“œë¦¬ìžë©´ ì˜ˆë¥¼ ë“¤ì–´ ìž…ë ¥ ë¬¸ìž¥ì´ I am a teacherë¼ê³  í•œë‹¤ë©´ ì´ë ‡ê²Œ ì¶œë ¥ê°’ì€ ì°¨ë¡€ëŒ€ë¡œ ë‚˜ëŠ” ì„ ìƒë‹˜ì´ë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ì¶œë ¥ì„ ë‚´ë±‰ê²Œ ë  ê±´ë°ìš”. ì´ë•Œ ì¶œë ¥ë˜ê³  ìžˆëŠ” ë‹¨ì–´ë“¤ ì˜ˆë¥¼ ë“¤ì–´ì„œ ì„ ìƒë‹˜ì´ë¼ê³  ë‹¨ì–´ë¥¼ ë²ˆì—­í•œë‹¤ê³  í•˜ë©´ ê·¸ ì„ ìƒë‹˜ì´ë¼ëŠ” ë‹¨ì–´ëŠ” I am a teacher ì¤‘ì—ì„œ\n",
      "1440.00 -> 1468.76:  ê·¸ëŸ¬í•œ ì •ë³´ë¥¼ ë§¤ë²ˆ ì–´í…ì…˜ì„ í†µí•´ì„œ ê³„ì‚°í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì´ë ‡ê²Œ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ë‚˜ì™”ë˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ì „ì ìœ¼ë¡œ í™œìš©í•˜ë„ë¡ ë„¤íŠ¸ì›Œí¬ë¥¼ ì„¤ê³„í•  ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì¦‰ ê·¸ëž˜ì„œ ë””ì½”ë¡œ ë˜í•œ ë§ˆì°¬ê°€ì§€ë¡œ ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ìž…ë ¥ ë””ë©˜ì „ê³¼ ì´ ì¶œë ¥ ë””ë©˜ì „ì´ ê°™ë„ë¡ ë§Œë“¤ì–´ì„œ ê°ê°ì˜ ë””ì½”ë” ë ˆì´ì–´ëŠ” ì—¬ëŸ¬ ë²ˆ ì¤‘ì²©í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¦‰ ë‹¤ì‹œ ë§í•´ ì´ íŠ¸ëžœìŠ¤í¬ë¨¸ì—ì„œëŠ” ë§ˆì§€ë§‰ ì¸ì½”ë”ì˜ ë ˆì´ì–´ì˜ ì¶œë ¥ì´ ëª¨ë“  ë””ì½”ë”ì˜ ë ˆì´ì–´ì— ìž…ë ¥ë˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë™ìž‘í•˜ê³ ìš”.\n",
      "1470.00 -> 1488.52:  ë ˆì´ì–´ì˜ ê°œìˆ˜ê°€ 4ê°œì¼ ë•Œì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì´ ë ˆì´ì–´ì˜ ê°œìˆ˜ëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ê°€ ë™ì¼í•˜ë„ë¡ ë§žì¶°ì£¼ëŠ” ê²½ìš°ê°€ ë§Žê³ ìš”. ì¦‰ ì´ë ‡ê²Œ ì¸ì½”ë”ëž‘ ë””ì½”ë” ë‘˜ ë‹¤ 4ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìžˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³  ì´ë ‡ê²Œ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì¶œë ¥ê°’ì´ ê°ê°ì˜ ë””ì½”ë” ë ˆì´ì–´ì— ìž…ë ¥ë˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "1500.00 -> 1527.64:  ë°”ë¡œ ì—¬ê¸° ë¶€ë¶„ì—ì„œ ì‚¬ìš©ëœë‹¤ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ë˜í•œ ë§ì”€ë“œë ¸ë“¯ì´ íŠ¸ëžœìŠ¤í¬ë¨¸ì—ì„œë„ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ êµ¬ì¡°ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ì¦‰ RNNì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì´ í° ì°¨ì´ì ì´ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ë‹¤ìˆ˜ ì‚¬ìš©í•œë‹¤ëŠ” ì ì´ íŠ¹ì§•ìž…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìž¬ë¯¸ìžˆëŠ” ì ì€ ì›ëž˜ ê¸°ë³¸ì ìœ¼ë¡œ RNNì„ ì‚¬ìš©í•  ë•ŒëŠ” ì¸ì½”ë” ì¦‰ LSTMì´ë‚˜ RNN ë“±ì€ ê³ ì •ëœ í¬ê¸°ë¡œ ì‚¬ìš©í•˜ê³  ì´ ìž…ë ¥ ë‹¨ì–´ì˜ ê°œìˆ˜ë§Œí¼ ë°˜ë³µì ìœ¼ë¡œ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ ê±°ì³ì„œ ë§¤ë²ˆ ížˆë“  ìŠ¤í…Œì´íŠ¸ë¥¼ ë§Œë“¤ì—ˆë‹¤ê³  í•˜ë©´\n",
      "1530.00 -> 1558.96:  ìžì²´ê°€ í•˜ë‚˜ë¡œ ì­‰ ì—°ê²°ë˜ì–´ì„œ í•œ ë²ˆì— ìž…ë ¥ì´ ë˜ê³  í•œ ë²ˆì— ê·¸ì— ëŒ€í•œ ì–´í…ì…˜ ê°’ì„ êµ¬í•œë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¦‰ ë‹¤ì‹œ ë§í•´ RNNì„ ì‚¬ìš©í–ˆì„ ë•Œì™€ ë‹¤ë¥´ê²Œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ í•œêº¼ë²ˆì— ë„£ì–´ì„œ í•œ ë²ˆì— ì¸ì½”ë”ë¥¼ ê±°ì¹  ë•Œë§ˆë‹¤ ë³‘ë ¬ì ìœ¼ë¡œ ì¶œë ¥ ê°’ì„ êµ¬í•´ë‚¼ ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— RNNì„ ì‚¬ìš©í–ˆì„ ë•Œì™€ ë¹„êµí•˜ì—¬ ì¼ë°˜ì ìœ¼ë¡œ ê³„ì‚° ë³µìž¡ë„ê°€ ë” ë‚®ê²Œ í˜•ì„±ë©ë‹ˆë‹¤. ë˜í•œ ì‹¤ì œë¡œ í•™ìŠµì„ ìˆ˜í–‰í•  ë•ŒëŠ” ì´ëŸ¬í•œ ìž…ë ¥ ê°’ë“¤ ì „ë¶€ë¥¼ í•œêº¼ë²ˆì— ë„£ì„ ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— RNNì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìžˆë‹¤ëŠ” ì ì´ ìž¥ì ì¸ë°ìš”.\n",
      "1560.00 -> 1585.34:  ì‹¤ì œë¡œ ëª¨ë¸ì—ì„œ ì¶œë ¥ê°’ì„ ë‚´ë³´ë‚¼ ë•ŒëŠ” ë§ˆì°¬ê°€ì§€ë¡œ ì´ ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš©í•´ì„œ ì´ë ‡ê²Œ EOSê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µí•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì¶œë ¥ê°’ì„ êµ¬í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë³´ì‹œë©´ ì´ë ‡ê²Œ ì¤‘ê°„ì— ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ì••ì¶•í•˜ëŠ” ê³¼ì • ë“±ì´ ì™„ì „ížˆ ìƒëžµì´ ë˜ì–´ ìžˆê¸° ë•Œë¬¸ì— ë„¤íŠ¸ì›Œí¬ ìžì²´ì—ì„œ LSTMê³¼ ê°™ì€ RNN êµ¬ì¡°ë¥¼ ì•„ì˜ˆ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ë‹¤ëŠ” ì ì´ ìž¥ì ì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ì‹¤ì œë¡œ ì´ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì´ ë­”ì§€ í•œë²ˆ ì•Œì•„ë³´ë„ë¡ í• ê²Œìš”.\n",
      "1590.00 -> 1617.70:  ë¼ê³  í•´ì„œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì´ë¼ê³  ë¶€ë¥´ëŠ”ë°ìš”. ê·¸ ì‹¤ì œ êµ¬ì¡°ëŠ” ë°”ë¡œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ë°”ë¡œ ì˜¤ë¥¸ìª½ì— ë³´ì´ëŠ” ê·¸ë¦¼ì´ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì„ ë³´ì—¬ì£¼ê³  ìžˆëŠ” ê·¸ë¦¼ì´ê³ ìš”. ì´ë•Œ ì´ë ‡ê²Œ ì¤‘ê°„ì— scaled.product.attentionì´ ì‚¬ìš©ë˜ëŠ”ë°ìš”. ì´ëŸ¬í•œ scaled.product.attentionì€ ë°”ë¡œ ì™¼ìª½ ê·¸ë¦¼ê³¼ ê°™ì´ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ë•Œ ì´ëŸ¬í•œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” Queryì™€ Key, Valueê°€ ë¬´ì—‡ì¸ì§€ ì•Œ í•„ìš”ê°€ ìžˆëŠ”ë°ìš”. ì´ë•Œ QueryëŠ” ë¬´ì–¸ê°€ë¥¼ ë¬¼ì–´ë³´ëŠ” ì£¼ì²´ìž…ë‹ˆë‹¤. ì¦‰, ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê°„ë‹¨ížˆ ì„¤ëª…í•˜ë©´\n",
      "1620.00 -> 1649.34:  ì–´ë– í•œ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ”ì§€ë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ë¼ í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ì´ë•Œ ë¬¼ì–´ë³´ëŠ” ì£¼ì²´ê°€ ì¿¼ë¦¬ì´ê³  ê·¸ ë¬¼ì–´ë³´ëŠ” ëŒ€ìƒì´ í‚¤ìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ I am a teacherë¼ëŠ” í•˜ë‚˜ì˜ ë¬¸ìž¥ì´ ìžˆì„ ë•Œ I am a teacherì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë‹¨ì–´ì™€ ì–¼ë§ˆë‚˜ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ”ì§€ ì¸¡ì •í•˜ê¸° ìœ„í•´ì„œ ì…€í”„ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆëŠ”ë° ì´ë•Œ Ië¼ëŠ” ë‹¨ì–´ê°€ I am a teacher ê°ê°ì— ëŒ€í•´ì„œ ì–¼ë§ˆë‚˜ ì—°ê´€ì„±ì´ ìžˆëŠ”ì§€ êµ¬í•œë‹¤ê³  ì¹˜ë©´ ê·¸ë•Œ Iê°€ ì¿¼ë¦¬ê°€ ë˜ëŠ” ê±°ê³ ìš”. I am a teacher ê°ê° ë‹¨ì–´ë“¤ì€ í‚¤ê°€ ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
      "1650.00 -> 1675.00:  ì–´ë– í•œ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ì–´ë– í•œ ë‹¨ì–´ë“¤ì— ê´€í•´ì„œ ì–´ë– í•œ ê°€ì¤‘ì¹˜ ê°’ì„ ê°€ì§€ëŠ”ì§€ êµ¬í•˜ê³ ìž í•œë‹¤ë©´ ì´ëŸ° ì‹ìœ¼ë¡œ ê°ê°ì˜ í‚¤ì— ëŒ€í•´ì„œ ì–´í…ì…˜ ìŠ¤ì½”ì–´ë¥¼ êµ¬í•´ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ë•Œ ê·¸ë ‡ê²Œ ìŠ¤ì½”ì–´ë¥¼ êµ¬í•œ ë’¤ì—ëŠ” ì‹¤ì œë¡œ ë°¸ë¥˜ ê°’ë“¤ê³¼ ê³±í•´ì„œ ê²°ê³¼ì ì¸ ì–´í…ì…˜ ë°¸ë¥˜ ê°’ì„ êµ¬í•  ìˆ˜ ìžˆëŠ” ê²ë‹ˆë‹¤. ë‚´ìš©ì„ í™•ì¸í•´ ë³´ì‹œë©´ ì´ëŸ° ì‹ìœ¼ë¡œ ë¬¼ì–´ë³´ëŠ” ì£¼ì²´, ì¦‰ í€„ì´ê°€ ë“¤ì–´ì˜¤ê³  ê°ê°ì˜ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ë‹¨ì–´ë“¤, ê·¸ ì •ë³´ê°€ Kë¡œ ë“¤ì–´ê°€ëŠ” ê²ë‹ˆë‹¤.\n",
      "1680.00 -> 1709.80:  ì†Œí”„íŠ¸ ë§¥ìŠ¤ë¥¼ ì·¨í•´ì„œ ê°ê°ì˜ í‚¤ ì¤‘ì—ì„œ ì–´ë–¤ ë‹¨ì–´ì™€ ê°€ìž¥ ë†’ì€ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ”ì§€ë¥¼ ê·¸ ë¹„ìœ¨ì„ êµ¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì•žì—ì„œ ê³µë¶€í–ˆì—ˆë˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ê³¼ ê°™ë‹¤ê³  í•  ìˆ˜ ìžˆì£ . ê·¸ë ‡ê²Œ êµ¬í•´ì§„ í™•ë¥ ê°’ê³¼ ì‹¤ì œë¡œ ë°¸ë¥˜ê°’ì„ ê³±í•´ì„œ ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ê²°ê³¼ì ì¸ ì–´í…ì…˜ ë°¸ë¥˜ë¥¼ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì´ì œ ê·¸ëŸ¬í•œ ê³¼ì •ì´ ì´ë ‡ê²Œ ìŠ¤ì¼€ì¼ë“œ ë‹· íŒŒë¼ë• ì–´í…ì…˜ì—ì„œ ìˆ˜í–‰ë˜ëŠ” ê²ƒì´ê³ ìš”. ë˜í•œ ì—¬ê¸°ì—ì„œ ì°¸ê³ ë¡œ ì‹¤ì œë¡œ ìž…ë ¥ê°’ì´ ë“¤ì–´ì™”ì„ ë•Œ ê·¸ëŸ¬í•œ ìž…ë ¥ê°’ë“¤ì€ A ì²´ê³„ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. ì¦‰ ì–´ë– í•œ ìž…ë ¥ ë¬¸ìž¥ì´ ë“¤ì–´ì™”ì„ ë•Œ\n",
      "1710.00 -> 1735.44:  ì´ì œ ê·¸ê²ƒì€ Value, Key, Queryë¡œ êµ¬ë¶„ë˜ëŠ”ë° ì´ë•Œ Hê³„ì˜ ì„œë¡œ ë‹¤ë¥¸ Valueì™€ Key, Queryë¡œ êµ¬ë¶„ë  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•´ì£¼ëŠ” ì´ìœ ëŠ” Hê³„ì˜ ì„œë¡œ ë‹¤ë¥¸ Attention ì»¨ì…‰ì„ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ë”ìš±ë” êµ¬ë¶„ëœ ë‹¤ì–‘í•œ íŠ¹ì§•ë“¤ì„ í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ ìœ ë„í•´ì¤€ë‹¤ëŠ” ìž¥ì ì´ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ê°’ì€ 3ê°œë¡œ ë³µì œê°€ ë˜ì–´ì„œ ê°ê° Value, Key, Queryë¡œ ë“¤ì–´ê°€ê²Œ ë˜ê³ \n",
      "1740.00 -> 1769.56:  Hê³„ë¡œ êµ¬ë¶„ëœ ê°ê°ì˜ ì¿¼ë¦¬ ìŒë“¤ì„ ë§Œë“¤ì–´ë‚´ê²Œ ë˜ê³  ì´ë•Œ ì—¬ê¸°ì—ì„œ HëŠ” í—¤ë“œì˜ ê°œìˆ˜ì´ê¸° ë•Œë¬¸ì— ê°ê° ì„œë¡œ ë‹¤ë¥¸ í—¤ë“œë¼ë¦¬ ì´ë ‡ê²Œ Value, Key, Queryì˜ ìŒì„ ë°›ì•„ì„œ Attentionì„ ìˆ˜í–‰í•´ì„œ ê²°ê³¼ë¥¼ ë‚´ë³´ëƒ…ë‹ˆë‹¤. ì´ì œ ê·¸ ë‹¤ìŒì— ì•žì„œ ë§ì”€ë“œë ¸ë“¯ì´ ì´ Attention ë©”ì»¤ë‹ˆì¦˜ì˜ ìž…ë ¥ê°’ê³¼ ì´ ì¶œë ¥ê°’ì˜ ë””ë©˜ì €ëŠ” ê°™ì•„ì•¼ ë˜ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ê°ê°ì˜ í—¤ë“œë¡œë¶€í„° ë‚˜ì˜¤ê²Œ ëœ Attention ê°’ë“¤ì„ ë‹¤ì‹œ ì´ë ‡ê²Œ ì»¨ì¼“ì„ ìˆ˜í–‰í•´ì„œ ì¼ìžë¡œ ì­‰ ë¶™ì¸ ë’¤ì— ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ Linear ë ˆì´ì–´ë¥¼ ê±°ì³ì„œ Output ê°’ì„ ë‚´ë³´ë‚´ê²Œ ë©ë‹ˆë‹¤.\n",
      "1770.00 -> 1797.54:  ì´ë•Œ ê²°ê³¼ì ìœ¼ë¡œ ì´ ìž…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì˜ ë””ë©˜ì „ì´ ê°™ë„ë¡ ë§Œë“¤ì–´ì„œ ì´ëŸ¬í•œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•œ ë’¤ì—ë„ ë””ë©˜ì „ì´ ì¤„ì–´ë“¤ì§€ ì•Šë„ë¡ ë§Œë“­ë‹ˆë‹¤. ë°”ë¡œ ì´ëŸ° ì‹ìœ¼ë¡œ ê°ê°ì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ê³ ìš”. ì´ëŸ¬í•œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ì´ ì „ì²´ ì•„í‚¤í…ì²˜ì—ì„œ ë‹¤ ë™ì¼í•œ í•¨ìˆ˜ë¡œì„œ ë™ìž‘í•©ë‹ˆë‹¤. ì´ë•Œ ë‹¤ë¥¸ ì ì´ë¼ê³  í•œë‹¤ë©´ ì´ë ‡ê²Œ ì‚¬ìš©ë˜ëŠ” ìœ„ì¹˜ë§ˆë‹¤ í€„ì´ëž‘ í‚¤ëž‘ ë°¸ë¥˜ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆëŠ” ê±´ë° ê·¸ëŸ° ì ì„ ì œì™¸í•˜ê³  ê¸°ë³¸ì ì¸ ê°ê°ì˜ ì–´í…ì…˜ ë ˆì´ì–´ì˜ ë™ìž‘ ë°©ì‹ì€ ê°™ìŠµë‹ˆë‹¤.\n",
      "1800.00 -> 1827.82:  ì¸ì½”ë” ì–´í…ì…˜ì—ì„œëŠ” ë””ì½”ë”ì˜ ì¶œë ¥ ë‹¨ì–´ê°€ ì¿¼ë¦¬ê°€ ë˜ëŠ” ê²ƒì´ê³  ê°ê°ì˜ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œì˜ ì–´ë–¤ ë‹¨ì–´ë¥¼ ì°¸ê³ í•˜ë©´ ì¢‹ì€ì§€ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œ ì´ í‚¤ëž‘ ë°¸ë¥˜ì˜ ê°’ìœ¼ë¡œëŠ” ì¸ì½”ë”ì˜ ì¶œë ¥ ê°’ì„ ì“°ê² ë‹¤ëŠ” ê²ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ê°ê°ì˜ ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ì„œ ì–´ë–¤ ì •ë³´ë¥¼ ì°¸ê³ í•´ì•¼ í•´ ë¼ê³  ì´ë ‡ê²Œ ì¸ì½”ë”í•œí…Œ ë¬¼ì–´ë³´ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ì´ ë””ì½”ë” íŒŒíŠ¸ì— ìžˆëŠ” ë‹¨ì–´ê°€ ì¿¼ë¦¬ê°€ ë˜ê³  ì¸ì½”ë” íŒŒíŠ¸ì— ìžˆëŠ” ê°ê°ì˜ ê°’ë“¤ì´ í‚¤ì™€ ë°¸ë¥˜ê°€ ëœë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "1830.00 -> 1858.34:  ë”ìš± ë” ìžì„¸í•˜ê²Œ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ë°ìš”. ìž ì´ë ‡ê²Œ í•˜ë‚˜ì˜ ì–´í…ì…˜ì€ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ë¥¼ ë´¤ê³ ìš”. ì´ë•Œ ì¿¼ë¦¬ëž‘ í‚¤ëž‘ ê³±í•´ì„œ ê° ì¿¼ë¦¬ì— ëŒ€í•´ì„œ ê°ê°ì˜ í‚¤ì— ëŒ€í•œ ì—ë„ˆì§€ ê°’ì„ êµ¬í•  ìˆ˜ ìžˆê² ì£ . ì´ì œ ê·¸ëŸ° ì—ë„ˆì§€ ê°’ì— ëŒ€í•´ì„œ í™•ë¥  ê°’ìœ¼ë¡œ í‘œí˜„í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ì‹¤ì œë¡œ ì–´ë–¤ í‚¤ì— ëŒ€í•´ì„œ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ëŠ”ì§€ ê³„ì‚°í•  ìˆ˜ê°€ ìžˆê³ ìš”. ì´ë•Œ ì´ë ‡ê²Œ ìŠ¤ì¼€ì¼ ì„¹í„°ë¡œì„œ ë£¨íŠ¸ DKë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë•Œ DKëŠ” ê°ê°ì˜ í‚¤ ë””ë©˜ì „ì´ ë˜ê² ê³ ìš”. ì´ë ‡ê²Œ íŠ¹ì •í•œ ìŠ¤ì¼€ì¼ë¡œ ë‚˜ëˆ ì£¼ëŠ” ì´ìœ ëŠ”\n",
      "1860.00 -> 1887.94:  ê°€ì§€ëŠ” íŠ¹ì„±ì„ ìƒê°í•´ë³´ì‹œë©´ 0 ê·¼ì²˜ì˜ ìœ„ì¹˜ì—ì„œëŠ” ê·¸ëž˜ë””ì–¸íŠ¸ê°€ ë†’ê²Œ í˜•ì„±ë˜ëŠ” ê²ƒì— ë°˜í•´ ê°’ì´ ë“¤ì­‰ë‚ ì­‰ ì¡°ê¸ˆì”© ì™¼ìª½ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™í•˜ê²Œ ë˜ë©´ êµìœ¡ì˜ ê°’ì´ ë§Žì´ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì— ê·¸ëž˜ë””ì–¸ ë² ë‹ˆì‹± ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ì´ëŸ¬í•œ ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë¥¼ ë„£ì–´ì¤„ ìˆ˜ ìžˆë‹¤ê³  ë…¼ë¬¸ì—ì„  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ê°ê°ì˜ ì¿¼ë¦¬ê°€ ê°ê°ì˜ í‚¤ì— ëŒ€í•´ì„œ ì–´ë– í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ëŠ”ì§€ ìŠ¤ì½”ì–´ ê°’ì„ êµ¬í•œ ë’¤ì— ì´ì œ ê±”ë¥¼ ì‹¤ì œë¡œ ë°¸ë¥˜ ê°’ê³¼ ê³±í•´ì„œ ì–´í…Œì…˜ ë°¸ë¥˜ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
      "1890.00 -> 1919.16:  ë“¤ì–´ì˜¤ëŠ” ê°ê°ì˜ ê°’ì— ëŒ€í•´ì„œ ì„œë¡œ ë‹¤ë¥¸ ë¦¬ë‹ˆì–´ ë ˆì´ì–´ë¥¼ ê±°ì¹˜ë„ë¡ ë§Œë“¤ì–´ì„œ Aì¸¡ì˜ ì„œë¡œ ë‹¤ë¥¸ ê°ê° ì¿¼ë¦¬ í‚¤ ë°¸ë¥˜ ê°’ì„ ë§Œë“¤ ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ Aì¸¡ì˜ ì„œë¡œ ë‹¤ë¥¸ ì»¨ì…‰ì„ ë„¤íŠ¸ì›Œí¬ê°€ êµ¬ë¶„í•´ì„œ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ë¯€ë¡œì¨ ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ í”¼ì²˜ë“¤ì„ í•™ìŠµí•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì‹¤ì œë¡œ ë‚˜ì¤‘ì— ìš°ë¦¬ê°€ ì–´í…ì…˜ ìŠ¤ì½”ì–´ë¥¼ ì‹œê°í™”í•´ ë³¼ ë•ŒëŠ” ì´ Hì˜ ê°œìˆ˜ë§Œí¼ ì–´í…ì…˜ ìŠ¤ì½”ì–´ì˜ ê·¸ë¦¼ì´ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ê° í—¤ë“œì— ëŒ€í•œ ì¶œë ¥ê°’ë“¤ì„ êµ¬í•  ìˆ˜ ìžˆê³ \n",
      "1920.00 -> 1948.56:  ì¼ìžë¡œ ì­‰ ë¶™ì¸ ë‹¤ìŒì— ë§ˆì§€ë§‰ìœ¼ë¡œ ì•„ì›ƒí’‹ ë§¤íŠ¸ë¦­ìŠ¤ëž‘ ê³±í•´ì„œ ê²°ê³¼ì ì¸ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì˜ ê°’ì„ êµ¬í•´ë‚¼ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ë§¤ë²ˆ ìž…ë ¥ ê°’ì´ ë“¤ì–´ì™”ì„ ë•Œ ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì´ëŸ° ì‹ìœ¼ë¡œ valueì™€ keyì™€ queryì˜ ê°’ìœ¼ë¡œ ê°ê° ë“¤ì–´ê°€ê²Œ ë˜ê³  ì´ë ‡ê²Œ ë‚˜ì˜¬ ë•ŒëŠ” ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ì™”ë˜ ê°’ê³¼ ë™ì¼í•œ ë””ë©˜ì €ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ê°€ í¬í•¨ëœ í•˜ë‚˜ì˜ ì¸ì½”ë” í˜¹ì€ ë””ì½”ë” ë ˆì´ì–´ëŠ” ì¤‘ì²©í•´ì„œ ì‚¬ìš©ë  ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì œ í•œë²ˆ ìžì„¸í•˜ê²Œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ë™ìž‘ ì›ë¦¬ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "1950.00 -> 1978.10:  í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ìžˆë‹¤ê³  ê°€ì •ì„ í•´ë³¼ê²Œìš”. ì´ë•Œ attentionì„ ìœ„í•´ì„œ ê°ê°ì˜ headë§ˆë‹¤ queryì™€ key value ê°’ì„ ë§Œë“¤ í•„ìš”ê°€ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë ‡ê²Œ í•˜ë‚˜ì˜ ë‹¨ì–´ê°€ embedding ì°¨ì›ìœ¼ë¡œ í‘œí˜„ë˜ê³  ìžˆëŠ” ìƒíƒœì—ì„œ ì´ì œ ì—¬ê¸°ì—ì„œ linear ë ˆì´ì–´ë¥¼ ê±°ì³ì„œ ê°ê° queryëž‘ keyëž‘ value ê°’ì„ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ embedding ì°¨ì›ì„ deep modelì´ë¼ê³  ë¶€ë¥¼ ìˆ˜ ìžˆê³ ìš”. ì›ë³¸ ë…¼ë¬¸ì—ì„œëŠ” embedding ì°¨ì›ì„ 512 ì°¨ì›ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ê³  ì–¸ê¸‰ì„ í–ˆê³ ìš”. ì´ë•Œ ë§Œì•½ì— headì˜ ê°œìˆ˜ê°€ 8ê°œë¼ê³  í•˜ë©´\n",
      "1980.00 -> 2009.56:  64ë§Œí¼ ê°ê°ì˜ Query Key Valueì˜ ì°¨ì›ì´ êµ¬ì„±ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì—¬ê¸° ë³´ì´ëŠ” ê·¸ë¦¼ì€ ê·¸ëƒ¥ ê°„ë‹¨í•˜ê²Œ ì¸ë² ë”© ì°¨ì›ì´ 4ì°¨ì›ì´ê³  í—¤ë“œê°€ 2ê°œë¼ê³  ê°€ì •í•œ ìƒí™©ìž…ë‹ˆë‹¤. ì¦‰ ì´ì œ ì´ëŸ´ ë•ŒëŠ” 4 ê³±í•˜ê¸° 2ì§œë¦¬ ë§¤íŠ¸ë¦­ìŠ¤ê°€ ë§Œë“¤ì–´ì§€ê² ì£ . ì™œëƒí•˜ë©´ ì´ 4ì°¨ì›ì˜ ë°ì´í„°ë¥¼ 2ì°¨ì›ì˜ ë°ì´í„°ë¡œ ë§µí•‘í•´ì•¼ ë˜ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ 4 ê³±í•˜ê¸° 2 ê°€ì¤‘ì¹˜ ë§¤íŠ¸ë¦­ìŠ¤ê°€ ì‚¬ìš©ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ëŸ° ì‹ìœ¼ë¡œ Loveë¼ëŠ” ë‹¨ì–´ê°€ 4ì°¨ì›ìœ¼ë¡œ í‘œí˜„ë˜ì–´ ìžˆë‹¤ê³  í•˜ë©´ ì´ì œ ì´ê²ƒì€ Query Key Value ê°ê° 2ì°¨ì›ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆëŠ” ë°ì´í„°ë¡œ í‘œí˜„ë  ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
      "2010.00 -> 2037.20:  ì´ì œ ì´ëŸ° ì‹ìœ¼ë¡œ í‚¤ëž‘ ì¿¼ë¦¬ëž‘ ë°¸ë¥˜ë¥¼ ë‹¤ êµ¬í–ˆë‹¤ê³  ì¹˜ë©´ ë°”ë¡œ ë‹¤ìŒì˜ ê³µì‹ìœ¼ë¡œ ì´ìš©í•´ì„œ ì‹¤ì œë¡œ attention valueë¥¼ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ”ë°ìš”. ì´ë•Œ ì´ ì¿¼ë¦¬ëŠ” ê°ê°ì˜ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ ì´ í‚¤ì™€ í–‰ë ¬ê¸‰ì„ ìˆ˜í–‰í•´ì„œ ì´ë ‡ê²Œ í•˜ë‚˜ì˜ attention energy ê°’ì„ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ I love youë¼ê³  í•˜ë‚˜ì˜ ë¬¸ìž¥ì´ ë“¤ì–´ì™”ë‹¤ê³  í•˜ë©´ ì´ Ië¼ëŠ” ë‹¨ì–´ëŠ” Iì— í•´ë‹¹í•˜ëŠ” í‚¤, loveì— í•´ë‹¹í•˜ëŠ” í‚¤, youì— í•´ë‹¹í•˜ëŠ” í‚¤ ê°’ê³¼ ê°ê° ê³±í•´ì ¸ì„œ í•˜ë‚˜ì˜ attention energy ê°’ì„ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê±°ê³ ìš”.\n",
      "2040.00 -> 2068.60:  ë“¤ì–´ê°€ëŠ” ê°’ì˜ í¬ê¸°ë¥¼ ë…¸ë©€ë¼ì´ì œì´ì…˜ í•´ì£¼ê¸° ìœ„í•´ì„œ ê°ê° ìŠ¤ì¼€ì¼ë§ íŒ©í„°ë¡œ ë‚˜ëˆ„ì–´ì¤ë‹ˆë‹¤. ì´ì œ ì´í›„ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì·¨í•´ì„œ ì‹¤ì œë¡œ ê°ê°ì˜ í‚¤ ê°’ì— ëŒ€í•´ì„œ ì–´ë– í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ëŠ”ì§€ë¥¼ êµ¬í•´ë‚¼ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì—¬ê¸° ë³´ì´ëŠ” ê·¸ë¦¼ì—ì„œëŠ” ì´ ië¼ëŠ” ë‹¨ì–´ëŠ” ië¼ëŠ” ë‹¨ì–´ì™€ 72%ë§Œí¼ì˜ ë†’ì€ ì—°ê´„ì„±ì„ ê°€ì§€ê³  ì´ loveë¼ëŠ” ë‹¨ì–´ì™€ëŠ” 15% ê·¸ ë‹¤ìŒì— uë¼ëŠ” ë‹¨ì–´ì™€ëŠ” 13% ì´ë ‡ê²Œ ê°ê°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ë‹¤ê³  í‘œí˜„í•  ìˆ˜ê°€ ìžˆëŠ” ê±°ê³ ìš”. ì´ë ‡ê²Œ ê°ê°ì˜ ê°€ì¤‘ì¹˜ ê°’ì—ë‹¤ê°€\n",
      "2070.00 -> 2099.46:  ê°ê° ê³±í•œ ë’¤ì— ì „ë¶€ ë”í•´ì¤˜ì„œ ê²°ê³¼ì ì¸ attention value ê°’ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì¦‰ ë§ˆì°¬ê°€ì§€ë¡œ weighted sumì„ êµ¬í•  ìˆ˜ê°€ ìžˆë‹¤ëŠ” ê±°ê³ ìš”. ë°”ë¡œ ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ì„œ ì‹¤ì œë¡œ attentionì´ ìˆ˜í–‰ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ í•œë²ˆ ì‹¤ì œë¡œ ì „ì²´ ë¬¸ìž¥ì´ í•œêº¼ë²ˆì— ìž…ë ¥ë˜ëŠ” ì´ëŸ° í–‰ë ¬ê³¼ ê°™ì€ ìƒí™©ì—ì„œ ì˜ˆì‹œë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” ì´ëŸ° ì‹ìœ¼ë¡œ í–‰ë ¬ ê³¡ì…ˆ ì—°ì‚°ì„ ì´ìš©í•´ì„œ í•œêº¼ë²ˆì— ì—°ì‚°ì´ ê°€ëŠ¥í•˜ê³ ìš”. I love youë¼ëŠ” í•˜ë‚˜ì˜ ë¬¸ìž¥ì´ ìžˆê³  ê·¸ ë‹¤ìŒì— ì¸ë² ë”© ì°¨ì›ì´ 4ì°¨ì›ì´ë¼ê³  í–ˆì„ ë•Œ ë°”ë¡œ ì´ë ‡ê²Œ 3x4ì§œë¦¬ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ êµ¬ì„±ë˜ëŠ”ë°ìš”.\n",
      "2100.00 -> 2126.50:  ì´ë•Œ ë§ˆì°¬ê°€ì§€ë¡œ í•˜ë‚˜ì˜ í—¤ë“œì— ìžˆëŠ” ì´ Query Key Valueë¥¼ êµ¬í•˜ê¸° ìœ„í•œ ê°€ì¤‘ì²´ ê°’ì´ ì´ë ‡ê²Œ ìžˆë‹¤ê³  í•´ë³¼ê²Œìš”. í˜„ìž¬ í—¤ë“œì—ì„œëŠ” ë°”ë¡œ ì´ëŸ° ì‹ìœ¼ë¡œ I Love Youì— ëŒ€í•œ ê°ê°ì˜ Query ê°’, Key ê°’, Value ê°’ì´ ë§Œë“¤ì–´ì§€ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ì´ë ‡ê²Œ Queryì™€ Keyì™€ Valueì˜ ê°’ì´ êµ¬í•´ì¡Œê¸° ë•Œë¬¸ì— Attention Valueë¥¼ êµ¬í•  ìˆ˜ ìžˆê²Œ ë˜ëŠ” ê±´ë°ìš”. ì´ë ‡ê²Œ Iì™€ Loveì™€ You, Query ê°’ë“¤ì„ í•œêº¼ë²ˆì— ì´ë ‡ê²Œ ê° Key ê°’ê³¼ ê³±í•´ì¤˜ì„œ Attention Energyë¥¼ ì´ë ‡ê²Œ 3x3ìœ¼ë¡œ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "2130.00 -> 2159.06:  ê°ê°ì˜ í‚¤ ê°’ì— ëŒ€í•´ì„œ ì–¼ë§ˆë‚˜ ë†’ì€ ê·¸ ì—°ê´€ì„±ì„ í‘œí˜„í•˜ëŠ” ìˆ˜ì¹˜ë¥¼ ë¶€ì—¬í–ˆëŠ”ì§€ë¥¼ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì¦‰ ì´ëŸ° ì‹ìœ¼ë¡œ Attention Energy ê°’ì€ I love you ê°ê°ì— ëŒ€í•´ì„œ êµ¬í•´ì§€ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë ‡ê²Œ í–‰ê³¼ ì—´ì€ ëª¨ë‘ ë‹¨ì–´ì˜ ê°œìˆ˜ì™€ ë™ì¼í•œ í¬ê¸°ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ê°ê°ì˜ ë‹¨ì–´ê°€ ì„œë¡œì—ê²Œ ì–´ë– í•œ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ”ì§€ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ƒì´ê³ ìš”. ì´ì œ ì—¬ê¸°ì— Softnessë¥¼ ì·¨í•´ì„œ ê°ê°ì˜ í–‰ë§ˆë‹¤ ê° í‚¤ì— ëŒ€í•œ ê°’ë“¤ì„ í™•ë¥  ê°’ìœ¼ë¡œ êµ¬í•´ë‚¼ ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê±°ê³ ìš”. ì´ì œ ê·¸ëŸ¬í•œ ê°€ì¤‘ì¹˜ ê°’ë“¤ê³¼ Value ê°’ì„ ê³±í•´ ì£¼ì–´ì„œ\n",
      "2160.00 -> 2187.16:  ì–´í…ì…˜ ë°¸ë¥˜ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ êµ¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë³´ì‹œë©´ ì´ì œ ì´ë ‡ê²Œ ì–´í…ì…˜ ë°¸ë¥˜ ê°’ ìžì²´ëŠ” ìž…ë ¥ë˜ì—ˆë˜ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ì™€ ëª¨ë‘ ë™ì¼í•œ ì°¨ì›ì„ ê°€ì§‘ë‹ˆë‹¤. ë˜í•œ í•œ ê°€ì§€ ì•Œì•„ë‘ì‹œë©´ ì¢‹ì€ ì ì€ ë§ˆìŠ¤í¬ í–‰ë ¬ì„ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ëŠ” ì ì¸ë°ìš”. ì´ ë§ˆìŠ¤í¬ í–‰ë ¬, ì¦‰ ë§ˆìŠ¤í¬ ë§¤íŠ¸ë¦­ìŠ¤ëŠ” íŠ¹ì •í•œ ë‹¨ì–´ë¥¼ ë¬´ì‹œí•  ìˆ˜ ìžˆë„ë¡ í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ì–´í…ì…˜ ì—ë„ˆì§€ ê°’ì´ ìžˆì„ ë•Œ ì–´í…ì…˜ ì—ë„ˆì§€ì™€ ê°™ì€ ì°¨ì›ì˜ ë§ˆìŠ¤í¬ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ë§Œë“¤ì–´ì„œ ì–˜ë¥¼ ì—˜ëŸ¬ë¨¼íŠ¸ ì™€ì´ì¦ˆë¡œ, ì¦‰ ê°ê°ì˜ ì›ì†Œ ë‹¨ìœ„ë¡œ ê³±í•´ ì£¼ì–´ì„œ\n",
      "2190.00 -> 2214.42:  ì˜ˆë¥¼ ë“¤ì–´ì„œ ì´ë ‡ê²Œ ì´ Ië¼ëŠ” ë‹¨ì–´ëŠ” ì´ ëŸ¬ë¸Œì™€ Uì— í•´ë‹¹í•˜ëŠ” í‚¤ ê°’ì€ ë¬´ì‹œí•˜ë„ë¡, ì¦‰ ì´ ëŸ¬ë¸Œì™€ UëŠ” ê·¸ëƒ¥ ì–´í…ì…˜ í•˜ì§€ ì•Šë„ë¡ ë¬´ì‹œí•˜ê³ ìž í•œë‹¤ë©´ ì´ë ‡ê²Œ ì–´í…ì…˜ ì—ë„ˆì§€ ê°’ì„ ì „ë¶€ ë‹¤ ë§ˆì´ë„ˆìŠ¤ ë¬´í•œì´ë¼ê³  í•  ìˆ˜ ìžˆëŠ” ê°€ëŠ¥í•œ ìµœëŒ€ë¡œ ìž‘ì€ ê°’ì„ ë„£ì–´ì£¼ê²Œ ë˜ë©´ ì‹¤ì œë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì·¨í•´ì„œ ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê°’ì´ êµ¬í•´ì¡Œì„ ë•Œ ê³ ë ¤í•˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬ê°€ ëœ ê·¸ëŸ° ë‹¨ì–´ë“¤ì— ëŒ€í•´ì„œëŠ” ëª¨ë‘ 0%ì˜ ê°€ì¤‘ì¹˜ ê°’ì„ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤.\n",
      "2220.00 -> 2249.32:  ì´ì™€ ê°™ì´ ë§ˆìŠ¤í¬ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì´ìš©í•´ì„œ ì´ëŸ¬í•œ ì–´í…ì…˜ ì—ë„ˆì§€ ê°’ì— ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•¨ìœ¼ë¡œì¨ íŠ¹ì • ë‹¨ì–´ëŠ” ê·¸ëƒ¥ ë¬´ì‹œí•´ì„œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ì§€ ì•Šë„ë¡ ë§Œë“¤ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ê°ê°ì˜ í—¤ë“œë§ˆë‹¤ ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ì™€ ê°™ì€ ì°¨ì›ì˜ ë²¡í„°ë¥¼ ë§Œë“¤ì–´ë‚´ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ê° í—¤ë“œë§ˆë‹¤ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ì˜ ê°’ë“¤ì„ ê°ê° ë„£ì–´ì„œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•œ ê°’ë“¤ì„ ì´ë ‡ê²Œ ë‹¤ í—¤ë“œ 1ë¶€í„° í—¤ë“œ Hê¹Œì§€ë¼ê³  í–ˆì„ ë•Œ ì´ëŸ¬í•œ ì •ë³´ë“¤ì„ ë‹¤ ì¼ìžë¡œ ì­‰ ì—°ê²°í•˜ê²Œ ë˜ë©´\n",
      "2250.00 -> 2277.22:  ë§¨ ì²˜ìŒì— ìž…ë ¥ì´ ë˜ì—ˆë˜ ì´ëŸ° ìž…ë ¥ ë””ë©˜ì „ê³¼ ê°™ì€ ë””ë©˜ì „ì„ ê°€ì§€ê²Œ ë˜ëŠ”ë°ìš”. ë‹¤ì‹œ ë§í•´ ì´ëŸ° ì‹ìœ¼ë¡œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ê°ê°ì˜ í—¤ë“œì— ëŒ€í•´ì„œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•œ ë’¤ì— ê·¸ëŸ¬í•œ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì­‰ ì´ì–´ë¶™ì´ê¸° ë•Œë¬¸ì— ê²°ê³¼ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ë§¤íŠ¸ë¦­ìŠ¤ì˜ ì´ ì—´ì˜ ê°œìˆ˜ëŠ” ì›ëž˜ ìž…ë ¥ì˜ ìž„ë² ë”© ì°¨ì›ê³¼ ë™ì¼í•œ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ì œ ë§ˆì§€ë§‰ì— ì´ Wê°€ì¤‘ì¹˜ ê°’ìœ¼ë¡œ Dëª¨ë¸ ê³±í•˜ê¸° Dëª¨ë¸ ì°¨ì›ì„ ê°€ì§€ëŠ” ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê³±í•´ì¤Œìœ¼ë¡œì¨ ê²°ê³¼ì ì¸ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì˜ ê°’ì„ êµ¬í•  ìˆ˜ ìžˆê³ ìš”.\n",
      "2280.00 -> 2307.64:  ì •í™•ížˆ ë™ì¼í•˜ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•œ ë’¤ì—ë„ ì°¨ì›ì´ ë™ì¼í•˜ê²Œ ìœ ì§€ê°€ ëœë‹¤ëŠ” ì ì´ íŠ¹ì§•ìž…ë‹ˆë‹¤. ë˜í•œ ì•žì„œ ê°„ë‹¨í•˜ê²Œ ë§ì”€ë“œë ¸ë“¯ì´ ì´ íŠ¸ëžœìŠ¤í¬ë¨¸ì—ëŠ” ì„¸ ê°€ì§€ ì¢…ë¥˜ì˜ ì–´í…ì…˜ì´ ì‚¬ìš©ë˜ëŠ”ë°ìš”. íŠ¸ëžœìŠ¤í¬ë¨¸ì— ì“°ì´ëŠ” ì–´í…ì…˜ì€ í•­ìƒ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ìœ¼ë¡œ í—¤ë“œê°€ ì—¬ëŸ¬ ê°œì¸ ì–´í…ì…˜ì´ë¼ ë³¼ ìˆ˜ ìžˆëŠ”ë° ì´ì œ ê·¸ëŸ¬í•œ ì–´í…ì…˜ì´ ì‚¬ìš©ë˜ëŠ” ìœ„ì¹˜ì— ë”°ë¼ì„œ ì¸ì½”ë” ì…€í”„ ì–´í…ì…˜ ê·¸ë¦¬ê³  ë§ˆìŠ¤íŠ¸ ë””ì½”ë” ì…€í”„ ì–´í…ì…˜ ì¸ì½”ë¡œ ë””ì½”ë” ì–´í…ì…˜ ì´ ì„¸ ê°€ì§€ ì¢…ë¥˜ê°€ ì¡´ìž¬í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ ì¸ì½”ë”ì˜ ì…€í”„ ì–´í…ì…˜ì€ ë§ì”€ë“œë ¸ë“¯ì´\n",
      "2310.00 -> 2336.82:  ê°€ì§€ëŠ”ì§€ë¥¼ ì–´í…ì…˜ì„ í†µí•´ì„œ êµ¬í•˜ë„ë¡ ë§Œë“¤ê³  ì „ì²´ ë¬¸ìž¥ì— ëŒ€í•œ ë ˆí”„ë ˆì  í…Œì´ì…˜ì„ ëŸ¬ë‹í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“ ë‹¤ëŠ” ì ì´ íŠ¹ì§•ì´ê³ ìš”. ë‹¤ë§Œ ì´ì œ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ì…€í”„ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ë•ŒëŠ” ì´ë ‡ê²Œ ê°ê°ì˜ ì¶œë ¥ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ëª¨ë“  ì¶œë ¥ ë‹¨ì–´ë¥¼ ì „ë¶€ ì°¸ê³ í•˜ë„ë¡ ë§Œë“¤ì§„ ì•Šê³  ì•žìª½ì— ë“±ìž¥í–ˆë˜ ë‹¨ì–´ë“¤ë§Œ ì°¸ê³ í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì¶œë ¥ ë¬¸ìž¥ì´ ë‚˜ëŠ” ì¶•êµ¬ë¥¼ í–ˆë‹¤ ë¼ê³  í•˜ë©´ì€ ìš°ë¦¬ê°€ ì¶•êµ¬ë¥¼ ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì¶œë ¥í•  ë•Œ ìžˆì–´ì„œ í–ˆë‹¤ ë¼ê³  ì´ë ‡ê²Œ ë’¤ìª½ì— ë‚˜ì˜¤ëŠ” ë‹¨ì–´ê°€ ë¬´ì—‡ì¸ì§€\n",
      "2340.00 -> 2368.78:  ì¹˜íŒ…ì²˜ëŸ¼ ë™ìž‘ì„ í•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ í•™ìŠµì´ ë˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ attentionì„ ìˆ˜í–‰í•  ë•ŒëŠ” ì´ë ‡ê²Œ ê°ê°ì˜ ë‹¨ì–´ì— ëŒ€í•´ì„œ ì´ ì•žìª½ ë‹¨ì–´ë“¤ë§Œ ì°¸ê³ í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ë¯€ë¡œì¨ ì¹˜íŒ…ì„ í•˜ì§€ ì•Šê³  ì •ìƒì ìœ¼ë¡œ ëª¨ë¸ì´ í•™ìŠµë  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì¸ì½”ë” ë””ì½”ë” attentionì€ ì¿¼ë¦¬ê°€ ë””ì½”ë”ì— ìžˆê³  ê°ê°ì˜ í‚¤ì™€ ë°¸ë¥˜ëŠ” ì¸ì½”ë”ì— ìžˆëŠ” ìƒí™©ì„ ì˜ë¯¸í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‚œ ë„ ì¢‹ì•„í•´ë¼ê³  I like youë¼ê³  ë¬¸ìž¥ì´ ë“¤ì–´ì™”ì„ ë•Œ ì¶œë ¥ ë¬¸ìž¥ì´ ë‚œ ë„ ì¢‹ì•„í•´ë¼ê³  ë‚˜ì˜¨ë‹¤ê³  í•˜ë©´\n",
      "2370.00 -> 2396.48:  ë‹¨ì–´ë“¤ì´ ì´ëŸ¬í•œ ìž…ë ¥ ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ì •ë³´ì— ë”ìš± ë” ë§Žì€ ê°€ì¤‘ì¹˜ë¥¼ ë‘ëŠ”ì§€ë¥¼ êµ¬í•  ìˆ˜ ìžˆì–´ì•¼ ë˜ëŠ”ë°ìš”. ì´ì œ ê·¸ëŸ¬í•œ ê³¼ì •ì—ì„œ ì´ ë””ì½”ë” íŒŒíŠ¸ì— ìžˆëŠ” ì¿¼ë¦¬ ê°’ì´ ì´ë ‡ê²Œ ì¸ì½”ë” íŒŒíŠ¸ì— ìžˆëŠ” í‚¤ì™€ ë°¸ë¥˜ ê°’ì„ ì°¸ì¡°í•œë‹¤ê³  í•´ì„œ ì¸ì½”ë” ë””ì½”ë” ì–´í…ì…˜ì´ë¼ê³  ë¶€ë¥´ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë˜í•œ ì´ì–´ì„œ ì…€í”„ ì–´í…ì…˜ì— ëŒ€í•´ì„œ ì•Œì•„ë³¼ ê±´ë°ìš”. ì‹¤ì œë¡œ ì´ëŸ¬í•œ ì…€í”„ ì–´í…ì…˜ì€ ë§ì”€ë“œë ¸ë“¯ì´ ì¸ì½”ë”ì™€ ë””ì½”ë” ëª¨ë‘ì—ì„œ ì‚¬ìš©ë˜ê³ ìš”. ì‹œê°í™” ê³¼ì •ì„ í†µí•´ì„œ ì–´í…ì…˜ ìŠ¤ì½”ì–´ë¡œ ë‚˜ì˜¨ ê°’ì„ ê·¸ë ¤ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "2400.00 -> 2428.38:  êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê±´ë°ìš”. ì˜ˆë¥¼ ë“¤ì–´ ì´ëŸ° ì‹ìœ¼ë¡œ í•˜ë‚˜ì˜ ìž…ë ¥ ë¬¸ìž¥ì´ ë“¤ì–´ì™”ì„ ë•Œ ê°ê°ì˜ ë‹¨ì–´ë“¤ì€ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•´ì„œ attention score ê°’ì„ êµ¬í•  ìˆ˜ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì´ë ‡ê²Œ a boy who is looking at the tree is surprised. ì´ëŸ° ì‹ìœ¼ë¡œ ë¬¸ìž¥ì´ ìžˆë‹¤ê³  í–ˆì„ ë•Œ ê°ê°ì˜ ë‹¨ì–´ë“¤ì€ ë‹¤ë¥¸ ë‹¨ì–´ ëª¨ë‘ì— ëŒ€í•´ì„œ ì–¼ë§ˆë‚˜ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í• ì§€ë¥¼ attentionì„ í†µí•´ì„œ ê³„ì‚°í•  ìˆ˜ê°€ ìžˆëŠ” ê±´ë°ìš”. ì˜ˆë¥¼ ë“¤ì–´ ì´ë ‡ê²Œ itì´ëž€ ë‹¨ì–´ë¥¼ ì¶œë ¥í•œë‹¤ê³  í•˜ë©´ ì´ëŸ¬í•œ itì´ ì˜ë¯¸í•˜ëŠ” ë‹¨ì–´ëŠ” ì•žìª½ì— ìžˆëŠ” treeì™€ ì´ë ‡ê²Œ ë™ì¼í•œ itì´ ë˜ê² ì£ .\n",
      "2444.10 -> 2458.48:  ìž ì´ì œ ê²°ê³¼ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì•žì—ì„œ í™•ì¸í–ˆë˜ ì´ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì „ì²´ ì•„í‚¤í…ì²˜ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ë‚´ìš©ë“¤ì„ í•˜ë‚˜ì”© í™•ì¸í•´ ë³´ì•˜ëŠ”ë°ìš”. ì´ë ‡ê²Œ ì¸ì½”ë” íŒŒíŠ¸ì—ì„  ìž…ë ¥ê¹Œì§€ ë“¤ì–´ì™€ì„œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜ì˜í•´ ì¤€ ìž…ë ¥ì„ ì‹¤ì œë¡œ ì²« ë²ˆì§¸ ë ˆì´ì–´ì— ë„£ì–´ì£¼ê²Œ ë˜ê³ ìš”.\n",
      "2460.00 -> 2487.50:  në²ˆë§Œí¼ ë°˜ë³µì´ ë˜ì–´ì„œ ì¤‘ì²©ì— ì‚¬ìš©ì´ ë˜ê³  ì´ì œ ê·¸ë ‡ê²Œ ë‚˜ì˜¨ ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì¸ì½”ë”ì˜ ì¶œë ¥ ê°’ì´ ê°ê°ì˜ ë””ì½”ë” ë ˆì´ì–´ì— ë“¤ì–´ê°„ë‹¤ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ë§ˆì°¬ê°€ì§€ë¡œ ë””ì½”ë” ë ˆì´ì–´ë„ në²ˆë§Œí¼ ì¤‘ì²©ì´ ë˜ì–´ì„œ ê°€ìž¥ ë§ˆì§€ë§‰ì— ë‚˜ì˜¨ ê·¸ ì¶œë ¥ ê°’ì— Linear Layerì™€ Softmaxë¥¼ ì·¨í•´ì„œ ê°ê°ì˜ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ë‹¤ë§Œ ì´ì œ ìš°ë¦¬ê°€ í•œ ê°€ì§€ ì–˜ê¸° ì•ˆ í•œ ê²Œ ìžˆë‹¤ê³  í•˜ë©´ ë°”ë¡œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì–´ë–¤ ì‹ìœ¼ë¡œ ë„£ì„ì§€ì— ëŒ€í•œ ì¸ì½”ë”© í•¨ìˆ˜ìž…ë‹ˆë‹¤. ì›ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í•˜ë‚˜ì˜ ë¬¸ìž¥ì— í¬í•¨ë˜ì–´ ìžˆëŠ”\n",
      "2490.00 -> 2518.40:  ëª¨ë¸ì—ê²Œ ì•Œë ¤ì£¼ê¸° ìœ„í•´ì„œ ë°”ë¡œ ì£¼ê¸°í•¨ìˆ˜ë¥¼ í™œìš©í•œ ê³µì‹ì„ ì‚¬ìš©í•˜ëŠ”ë°ìš”. ì‹¤ì œ ê³µì‹ì€ ë°”ë¡œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì´ë•Œ p2ëŠ” í¬ì§€ì…”ë„ ì¸ì½”ë”©ì˜ ì•½ìžê³ ìš”. ì´ë•Œ ì´ í¬ìŠ¤ëŠ” ê°ê°ì˜ ë‹¨ì–´ ë²ˆí˜¸ê°€ ë˜ê² ê³ ìš”. ì´ë•Œ ì´ iëŠ” ê°ê°ì˜ ë‹¨ì–´ì— ëŒ€í•œ ì¸ë² ë”© ê°’ì˜ ìœ„ì¹˜ í•˜ë‚˜í•˜ë‚˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ì´ëŸ° ì‹ìœ¼ë¡œ siní•¨ìˆ˜ì™€ ê°™ì€ ì£¼ê¸°í•¨ìˆ˜ ê°’ì„ ì¸ì½”ë”©ì„ ìœ„í•´ì„œ ì‚¬ìš©í•˜ëŠ”ë°ìš”. ì´ë ‡ê²Œ íŒŒë¼ë¯¸í„°ë¡œ ë“¤ì–´ì™€ ìžˆëŠ” ë§Œê³¼ ê°™ì€ ê°’ì´ë‚˜ ì´ëŸ° sinê³¼ cosí•¨ìˆ˜ëŠ” ì´ë ‡ê²Œ ê¸°ë³¸ì ì¸ siní•¨ìˆ˜ì™€ cosí•¨ìˆ˜ ë§ê³ \n",
      "2520.00 -> 2549.98:  ì•„ë¬´íŠ¼ ìš°ë¦¬ ë„¤íŠ¸ì›Œí¬ê°€ ê°ê°ì˜ ìž…ë ¥ ë¬¸ìž¥ì´ í¬í•¨ë˜ì–´ ìžˆëŠ” ê° ë‹¨ì–´ë“¤ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œ ìˆ˜ ìžˆë„ë¡ ì´ëŸ¬í•œ ì£¼ê¸°ì„±ì„ í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê¸°ë§Œ í•œë‹¤ë©´ ì–´ë–¤ í•¨ìˆ˜ê°€ ë“¤ì–´ì™€ë„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì›ë³¸ ë…¼ë¬¸ì—ì„œë„ ì´ë ‡ê²Œ sine í•¨ìˆ˜ì™€ cosine í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ì •í•´ì§„ ê·¸ëŸ° í•¨ìˆ˜ ê°’ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìžˆì§€ë§Œ ìš°ë¦¬ê°€ ìœ„ì¹˜ì— ëŒ€í•œ ì¸ë² ë”© ê°’ì„ ë”°ë¡œ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ë„¤íŠ¸ì›Œí¬ì— ë„£ì„ ìˆ˜ ìžˆë‹¤ê³  ë§í•˜ê³  ìžˆê³  ì‹¤ì œë¡œ ê·¸ë ‡ê²Œ ë„£ì—ˆì„ ë•Œë„ ì´ë ‡ê²Œ sine í•¨ìˆ˜ì™€ cosine í•¨ìˆ˜ë¥¼ ì´ìš©í–ˆì„ ë•Œì™€ ì‹¤ì œ ì„±ëŠ¥ìƒì˜ ì°¨ì´ëŠ” ê±°ì˜ ì—†ì—ˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "2550.00 -> 2575.18:  ê·¸ëž˜ì„œ ì‹¤ì œë¡œ íŠ¸ëžœìŠ¤í¬ë¨¸ ì´í›„ì— ë‚˜ì˜¨ ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ì—ì„œëŠ” ì´ëŸ¬í•œ ì£¼ê¸°í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê·¸ëƒ¥ í•™ìŠµì´ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³„ë„ì˜ ì¸ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ê¸°ë„ í•©ë‹ˆë‹¤. ë”ìš±ë” ìžì„¸í•˜ê²Œ ì‹¤ì œë¡œ ì´ëŸ¬í•œ ìœ„ì¹˜ ì¸ì½”ë”©ì´ ì–´ë–¤ ì‹ìœ¼ë¡œ ë“¤ì–´ê°ˆ ìˆ˜ ìžˆëŠ”ì§€ë¥¼ í™•ì¸í•´ ë³´ì‹œë©´ìš”. ì˜ˆë¥¼ ë“¤ì–´ ì´ë ‡ê²Œ ìž…ë ¥ ë¬¸ìž¥ì´ we are the oneì´ë¼ê³  í•œë²ˆ í•´ë³¼ê²Œìš”. ì´ë•Œ ê°ê°ì˜ ë‹¨ì–´ë“¤ì€ ë”¥ ë§ˆë”ë§Œí¼ì˜ ì¸ë² ë”© ì°¨ì›ì„ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. ì§€ê¸ˆ ê·¸ë¦¼ì—ì„œëŠ” ì´ ì¸ë² ë”© ì°¨ì›ì´ 8ì´ ë˜ê² ì£ .\n",
      "2580.00 -> 2606.76:  ê°ê°ì˜ ê°’ì—ì„œì˜ ê°ê°ì˜ ì¸ë±ìŠ¤ ê°’ê³¼ ë™ì¼í•˜ê²Œ ë“¤ì–´ê°€ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì—¬ê¸°ëŠ” 0,3ì´ ë˜ëŠ”ë°ìš”. ì²« ë²ˆì§¸ ë‹¨ì–´ì— ë„¤ ë²ˆì§¸ ì¸ë² ë”©ì´ê¸° ë•Œë¬¸ì´ì£ . ê·¸ëž˜ì„œ ì´ì œ ê°ê°ì˜ ê°’ë“¤ì´ ì´ëŸ° í•¨ìˆ˜ì— ë“¤ì–´ê°€ê²Œ ë¼ì„œ ë°”ë¡œ ìž…ë ¥ ê°’ê³¼ ì •í™•ížˆ ë™ì¼í•œ ë””ë©˜ì „ì„ ê°€ì§€ëŠ” ìœ„ì¹˜ ì¸ì½”ë”©ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ì œ ì´ ê°’ì„ ì—˜ëŸ¬ë¨¼íŠ¸ ì™€ì´ì €ë¡œ ë‹¤ ë”í•´ì¤˜ì„œ ì›ì†Œ ë°”ì´ ì›ì†Œë¡œ ë‹¤ ë”í•´ì¤€ ë’¤ì— ê·¸ ê°’ì„ ì‹¤ì œë¡œ ê° ì¸ì½”ë”ì™€ ë””ì½”ë” ë ˆì´ì–´ì˜ ìž…ë ¥ ê°’ìœ¼ë¡œ ì‚¬ìš©ì„ í•œë‹¤ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤.\n",
      "2610.00 -> 2620.16:  ì‹¤ì¡°ë¡œ ì–´ë–¤ ì‹ìœ¼ë¡œ ê° ë‹¨ì–´ì˜ ìœ„ì¹˜ì— ëŒ€í•œ ì¸ì½”ë”© ì •ë³´ê°€ ë“¤ì–´ê°€ëŠ”ì§€ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒì¸ë°ìš”. ë°”ë¡œ ì´ë ‡ê²Œ ê°„ë‹¨í•˜ê²Œ ë§µí”ŒëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ê·¸ë¦¼ì„ ê·¸ë ¤ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "2620.46 -> 2640.04:  ìž ë§ˆì°¬ê°€ì§€ë¡œ ì „ì²´ ì‹¤ìŠµ ì½”ë“œëŠ” ì œ Github ì €ìž¥ì†Œì— ì˜¬ë ¤ë†“ì•˜ìœ¼ë‹ˆê¹Œìš”. í™•ì¸í•˜ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ì•„ëž˜ìª½ì— ë‚´ë ¤ì™€ ë³´ì‹œë©´ Attention is all you need ì½”ë“œ í”„ëž™í‹°ìŠ¤ ë³´ì´ì‹œì£ ? ì—¬ê¸° ë“¤ì–´ì˜¤ì…”ì„œ ì „ì²´ ì½”ë“œë¥¼ í™•ì¸í•´ ë³´ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì „ì²´ ì½”ë“œëŠ” ì—¬ëŸ¬ë¶„ë“¤ì˜ ê°œì¸ ê°œë°œ í™˜ê²½ì´ ì•„ë‹Œ ë¬´ë£Œ ë”¥ëŸ¬ë‹ ê°œë°œ í™˜ê²½ì¸ ì½”ëž©ì—ì„œ íŒŒì†ë©ë‹ˆë‹¤.\n",
      "2640.00 -> 2668.20:  ë°”ë¡œ ì‹¤í–‰í•´ë³¼ ìˆ˜ ìžˆë„ë¡ ì¤€ë¹„ë¥¼ í•´ë†“ì•˜ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì—¬ëŸ¬ë¶„ë“¤ì€ êµ¬ê¸€ ì•„ì´ë””ë§Œ ìžˆìœ¼ì‹œë©´ ë°”ë¡œ ì—¬ê¸° ë§í¬ ë“¤ì–´ì˜¤ì…”ì„œ ì½”ëž©ì—ì„œ ì¦‰ì‹œ ì‹¤í–‰í•´ë³´ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì „ì²´ ì½”ë“œë¥¼ í™•ì¸í•´ë³¼ ìˆ˜ ìžˆëŠ”ë°ìš”. ë‚´ìš©ì„ í™•ì¸í•´ë³´ì‹œë©´ ê¸°ë³¸ì ìœ¼ë¡œ ë³¸ ì½”ë“œëŠ” íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ë…¼ë¬¸ ë‚´ìš©ì„ ìµœëŒ€í•œ ë”°ë¥´ë©´ì„œ êµ¬í˜„ëœ ì½”ë“œìž…ë‹ˆë‹¤. ì‹¤ì œë¡œ íŠ¸ëžœìŠ¤í¬ë¨¸ ë…¼ë¬¸ì€ ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ìžì—°í•œ ì²˜ë¦¬ ê¸°ë²•ì˜ ëŒ€í‘œì ì¸ ê¸°ë³¸ì ì¸ êµ¬ì„±ì„ ì´í•´í•˜ê³  ê³µë¶€í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ê·¸ëž˜ì„œ ìµœê·¼ ê°€ìž¥ ë›°ì–´ë‚œ ë²ˆì—­ ëª¨ë¸ë“¤ì€\n",
      "2671.48 -> 2698.36:  ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê¸° ì „ì— ëŸ°íƒ€ìž„ì—ì„œ ëŸ°íƒ€ìž„ ìœ í˜• ë³€ê²½ì— ë“¤ì–´ì˜¤ì‹  ë’¤ì— GPUë¡œ ì„¤ì •ì´ ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ë˜í•œ ë³¸ ì½”ë“œì—ì„œëŠ” ë…ì¼ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ì„ ìˆ˜í–‰í•´ ë³¼ ê±´ë°ìš”. ì´ì œ ë²ˆì—­ëœ ì˜ì–´ ë¬¸ìž¥ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ì²™ë„ë¡œ ë¸”ë£¨ìŠ¤ì½”ì–´ë¥¼ ì‚¬ìš©í•  ì˜ˆì •ìž…ë‹ˆë‹¤. ì´ ë¸”ë£¨ìŠ¤ì½”ì–´ëŠ” Ngram ê¸°ë°˜ìœ¼ë¡œ ë²ˆì—­í•œ ë¬¸ìž¥ì´ ì‹¤ì œ ì •ë‹µ ë¬¸ìž¥ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ í‰ê°€í•´ì£¼ëŠ” í‰ê°€ ì²™ë„ ì¤‘ í•˜ë‚˜ìž…ë‹ˆë‹¤.\n",
      "2703.94 -> 2729.00:  ì´ì œ ì´ì–´ì„œ ë°ì´í„°ì˜ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ê²Œ ë  ê±´ë°ìš”. ë¬¸ìž¥ì˜ í† í°í™”ë¥¼ ì§„í–‰í•  ê²ë‹ˆë‹¤. ì´ë•Œ ìš°ë¦¬ëŠ” ë…ì¼ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í…ŒìŠ¤í¬ë¥¼ ì§„í–‰í•  ê²ƒì´ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ì˜ì–´ì™€ ë…ì¼ì–´ì— ëŒ€í•´ì„œ ì „ì²˜ë¦¬ ëª¨ë“ˆì„ ì„¤ì¹˜í•  ìˆ˜ ìžˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ê°ê° ì˜ì–´ì™€ ë…ì¼ì–´ì— ëŒ€í•´ì„œ ì–´ë– í•œ ë¬¸ìž¥ì´ ìžˆì„ ë•Œ ê·¸ëŸ¬í•œ ë¬¸ìž¥ì„ í† í°ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸° ìœ„í•´ì„œ í† í°ìœ¼ë¡œ ë°”ê¿”ì¤„ ìˆ˜ ìžˆëŠ” ê°ê°ì˜ ìŠ¤íŽ˜ì´ì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì²´ë¥¼ ì„ ì–¸í•´ì£¼ê³ ìš”.\n",
      "2730.00 -> 2753.04:  ê°„ë‹¨í•˜ê²Œ I am a graduate studentë¼ëŠ” ë‚´ìš©ì˜ ë¬¸ìž¥ì´ ìžˆì„ ë•Œ í•œë²ˆ ì´ê±¸ í† í°ìœ¼ë¡œ ê°ê° ë°”ê¾¸ì–´ì„œ ì¶œë ¥ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì´ëŸ° ì‹ìœ¼ë¡œ ì˜ì–´ ë¬¸ìž¥ì´ ì •ìƒì ìœ¼ë¡œ I am a graduate studentë¼ê³  ìž˜ í† í°í™” í•´ì œê°€ ëœ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì œ ìš°ë¦¬ëŠ” ì‹¤ì œë¡œ ë‹¤ìˆ˜ì˜ ë¬¸ìž¥ì„ ë¶ˆëŸ¬ì™€ì„œ ê° ë¬¸ìž¥ë§ˆë‹¤ ì „ë¶€ë‹¤ ì´ëŸ¬í•œ í† í°í™”ë¥¼ ì§„í–‰í•´ì„œ ìš°ë¦¬ ë„¤íŠ¸ì›Œí¬ì˜ ìž…ë ¥ê°’ìœ¼ë¡œ ë„£ì„ ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ ê²ë‹ˆë‹¤.\n",
      "2760.00 -> 2789.48:  ì´ë ‡ê²Œ ë§ˆì°¬ê°€ì§€ë¡œ í•¨ìˆ˜ë¥¼ ì •ì˜í•´ ì£¼ì‹œê³  ë˜ ì¶”ê°€ì ìœ¼ë¡œ í•„ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ì–´ë– í•œ ë°ì´í„°ì…‹ì´ ìžˆì„ ë•Œ ê·¸ëŸ¬í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•  ê±´ì§€ ëª…ì‹œí•  ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤. ë²ˆì—­ ëª¨ë¸ì— ìž…ë ¥ì„ ë„£ì„ ë•ŒëŠ” ê°ê°ì˜ ë¬¸ìž¥ë“¤ì˜ ì•žë¶€ë¶„ì—ëŠ” sos í† í°ì„ ë¶™ì´ê³  ê°€ìž¥ ë’·ë¶€ë¶„ì—ëŠ” eos í† í°ì„ ë¶™ì´ëŠ” ê²ƒì´ ì¼ë°˜ì ìž…ë‹ˆë‹¤. ë˜í•œ ê°ê°ì˜ ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ì†Œë¬¸ìžë¡œ ë°”ê¿”ì£¼ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ê³ ìš”. ë˜í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ì— ìž…ë ¥ì„ ë„£ì„ ë•ŒëŠ” í…ì„œì˜ ì°¨ì›ì—ì„œ ì‹œí€€ìŠ¤ë³´ë‹¤ëŠ” ë°°ì¹˜ê°€\n",
      "2790.00 -> 2818.42:  ë¨¼ì € ì˜¤ë„ë¡ ë§Œë“œëŠ” ê²½ìš°ê°€ ë§Žê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ë°°ì¹˜ í¼ìŠ¤íŠ¸ì˜ ê°’ìœ¼ë¡œëŠ” íŠ¸ë£¨ ê°’ì„ ë„£ì–´ì£¼ê² ìŠµë‹ˆë‹¤. ì´ì œ ì´ì–´ì„œ ì•½ 3ë§Œê°œ ì •ë„ì˜ ì˜ì–´, ë…ì–´, ìŒì„ ê°€ì§€ê³  ìžˆëŠ” ë²ˆì—­ ë°ì´í„°ì…‹ì¸ ë©€í‹° 30kë¥¼ ë¶ˆëŸ¬ì™€ì„œ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìžˆë„ë¡ í•´ì¤„ê²Œìš”. ì´ë•Œ ê°ê° ì´ í•„ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ë…ì¼ì–´ë¥¼ ì˜ì–´ë¡œ ë°”ê¾¸ëŠ” í…ŒìŠ¤í¬ì— ëŒ€í•´ì„œ ê°ê° ì•žì„œ ì •ì˜í–ˆë˜ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì œ í•™ìŠµ ë°ì´í„°ì…‹ê³¼ í‰ê°€ ë°ì´í„°ì…‹, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œ ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ì–´ ë³´ì‹œë©´\n",
      "2820.00 -> 2849.54:  2ë§Œ 9ì²œ ê°œ ê·¸ë¦¬ê³  í‰ê°€ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ê°ê° ì•½ ì²œ ê°œ ì •ë„ ë¬¸ìž¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ì´ë•Œ í•œë²ˆ ê°„ë‹¨í•˜ê²Œ ì¸ë±ìŠ¤ 30ë²ˆì— í•´ë‹¹í•˜ëŠ” í•™ìŠµ ë¬¸ìž¥ì„ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ì–´ ë³´ì‹œë©´ ë°”ë¡œ ì´ëŸ¬í•œ ë…ì¼ì–´ ë¬¸ìž¥ì´ ë“¤ì–´ì™”ì„ ë•Œ ì´ëŸ¬í•œ ì˜ì–´ ë¬¸ìž¥ì„ ì¶œë ¥í•˜ë„ë¡ í•™ìŠµ ë°ì´í„°ê°€ êµ¬ì„±ë˜ì–´ ìžˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ìž ê·¸ëž˜ì„œ ì´ì œ ì‹¤ì œë¡œ vocabulary ì„¸íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ vocabularyë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ì´ìœ ëŠ” ë…ì¼ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•  ë•Œ ê°ê°ì˜ ì´ˆê¸° input dimensionì˜ ì–¼ë§ˆì¸ì§€ë¥¼ êµ¬í•  ìˆ˜ê°€ ìžˆê¸° ë•Œë¬¸ìž…ë‹ˆë‹¤.\n",
      "2850.00 -> 2876.06:  ê·¸ëž˜ì„œ ì „ì²´ ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ ìµœì†Œ 2ë²ˆ ì´ìƒ ë“±ìž¥í•œ ë‹¨ì–´ë“¤ë§Œì„ ì„ íƒí•˜ë„ë¡ ë§Œë“¤ì–´ì„œ vocabulary ì„¸íŠ¸ë¥¼ ë§Œë“  ë’¤ì— ê°ê°ì˜ lengthë¥¼ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ì–´ ë³´ì‹œë©´ ë…ì¼ì–´ëŠ” 7,855ê°œì˜ ìœ ì˜ë¯¸í•œ ë‹¨ì–´ê°€ ìžˆê³  ê·¸ë¦¬ê³  ì˜ì–´ëŠ” 5,893ê°œì˜ ê°ê°ì˜ ë‹¨ì–´ë“¤ì´ ì¡´ìž¬í•œë‹¤ê³  ë³¼ ìˆ˜ ìžˆëŠ” ê±°ì˜ˆìš”. ê·¸ëž˜ì„œ ì´ëŸ° vocabulary ê°ì²´ì—ì„œ string2i í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ê°€ì§€ê³  ê°ê°ì˜ ë‹¨ì–´ê°€ ì–´ë– í•œ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ”ì§€ë¥¼ êµ¬í•´ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "2880.00 -> 2909.02:  ì´ì œ í™•ì¸í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ì´ë•Œ ë§Œì•½ì— ì´ëŸ° ì‹ìœ¼ë¡œ ì• ì´ˆì— ë“±ìž¥í•˜ì§€ ì•Šì•˜ë˜ ì—†ëŠ” ë‹¨ì–´ë¼ë©´ 0ì´ë¼ê³  ë±‰ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ì´ë ‡ê²Œ ì•„ì˜ˆ ì˜ë¯¸ê°€ ì—†ëŠ” ê·¸ëŸ° ê³µê°„ì— í•´ë‹¹í•˜ëŠ” íŒ¨ë”© ê°’ì€ 1ë¡œ ë“¤ì–´ê°€ ìžˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ì´ì œ ì´ë ‡ê²Œ sosì™€ eosëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 2ë²ˆê³¼ 3ë²ˆì— í•´ë‹¹í•©ë‹ˆë‹¤. ë˜í•œ ì´ë ‡ê²Œ ì‹¤ì œë¡œ ì¡´ìž¬í•˜ëŠ” ë‹¨ì–´ ê°™ì€ ê²½ìš°ëŠ” ê·¸ ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ê°€ ë‚˜ì˜¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ì´ì œ ì´ì™€ ê°™ì´ ì•žìª½ì— ë¶™ëŠ” 4ê°œì˜ í† í°ë“¤ì´ ì°¨ë¡€ëŒ€ë¡œ unknown í† í°, ê·¸ ë‹¤ìŒ íŒ¨ë”© í† í°, sos í† í°, eos í† í°ì´ë¼ê³  ë¶ˆë¦¬ê³ ìš”.\n",
      "2910.00 -> 2939.42:  ì‹¤ì œë¡œ ì¡´ìž¬í•˜ëŠ” ë‹¨ì–´ëŠ” ì•„ë‹ˆì§€ë§Œ ë„¤íŠ¸ì›Œí¬ê°€ ê°ê°ì˜ ë¬¸ìž¥ë“¤ì„ ì ì ˆí•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” í† í°ë“¤ìž…ë‹ˆë‹¤. ì´ì–´ì„œ í•œ ë¬¸ìž¥ì— í¬í•¨ëœ ë‹¨ì–´ë“¤ì´ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´ëœ ìƒíƒœë¡œ ë„¤íŠ¸ì›Œí¬ì— ìž…ë ¥ì´ ë˜ëŠ”ë°ìš”. ì´ë•Œ í•˜ë‚˜ì˜ ë°°ì¹˜ì— í¬í•¨ëœ ë¬¸ìž¥ë“¤ì´ ê°€ì§€ëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ìœ ì‚¬í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ bucket iteratorë¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë•Œ ì´ëŸ° ì‹ìœ¼ë¡œ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì •í•´ì¤„ ìˆ˜ ìžˆëŠ”ë°ìš”. í•˜ë‚˜ì˜ ë°°ì¹˜ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ ë¬¸ìž¥ë“¤ì˜ ê·¸ ì‹œí€€ìŠ¤ ëž­ìŠ¤ê°€ ê°€ëŠ¥í•œ ìœ ì‚¬ë„ë¡ ë§Œë“¤ì–´ì„œ ê¸¸ì´ê°€ ì§§ì€ ë¬¸ìž¥ë“¤ì— ëŒ€í•´ì„œ\n",
      "2940.00 -> 2966.56:  íŒ¨ë”© í† í°ì´ ìµœëŒ€í•œ ì ê²Œ ë“¤ì–´ê°ˆ ìˆ˜ ìžˆë„ë¡ í•˜ì—¬ ì‹¤ì œë¡œ í•™ìŠµì„ ìœ„í•´ ë„¤íŠ¸ì›Œí¬ì— ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë°ì´í„°ì˜ ì°¨ì›ì„ ì¤„ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë ‡ê²Œ ê°ê° í•™ìŠµìš©, í‰ê°€ìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ì„ ì´í„°ë ˆì´í„°ë¡œ ë§Œë“¤ì–´ì£¼ê³ ìš”. í•œë²ˆ ê°„ë‹¨í•˜ê²Œ ì´ íŠ¸ëžœ ì´í„°ë ˆì´í„°ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ì²« ë²ˆì§¸ ë°°ì¹˜ë¥¼ í™•ì¸í•œ ë’¤ì— í•˜ë‚˜ì˜ ë¬¸ìž¥ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶œë ¥í•´ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. í™•ì¸í•´ ë³´ì‹œë©´ í˜„ìž¬ ë°°ì¹˜ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ë¬¸ìž¥ë“¤ ì¤‘ì—ì„œ ê°€ìž¥ ê¸´ ë¬¸ìž¥ì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ 35ê°€ ë˜ê² ê³ ìš”.\n",
      "2970.00 -> 2994.72:  ì´ëŸ° ì‹ìœ¼ë¡œ ì–´ë–¤ ë¬¸ìž¥ì´ ë“¤ì–´ê°€ ìžˆëŠ”ë° ì—¬ê¸° 2ë²ˆ ê°™ì€ ê²½ìš°ëŠ” SOSê°€ ë˜ê³  3ë²ˆì€ EOSë¼ê³  í–ˆì£ . ê·¸ëž˜ì„œ ì´ì œ SOSì™€ EOS ì•ˆì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ ë°ì´í„°ê°€ ì‹¤ì œ í•˜ë‚˜í•˜ë‚˜ì”© ë‹¨ì–´ë¥¼ ì˜ë¯¸í•˜ëŠ” ê±°ê³ ìš”. ì´ì œ ì´ë ‡ê²Œ EOSê°€ ë‚˜ì˜¨ ë’¤ì—ëŠ” ë’¤ìª½ì— ë‹¤ íŒ¨ë”© í† í°ì´ ë¶™ì–´ê°€ì§€ê³  ì˜ë¯¸ê°€ ì—†ëŠ” í† í°ì´ë¼ëŠ” ê²ƒì„ ì•Œë ¤ì¤„ ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì œ ì´ëŸ° ì‹ìœ¼ë¡œ í˜„ìž¬ ë°°ì¹˜ì— ìžˆëŠ” í•˜ë‚˜ì˜ ë¬¸ìž¥ì— í¬í•¨ëœ ì •ë³´ë¥¼ ì¶œë ¥í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "3000.00 -> 3028.80:  ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ì‹¤ì œë¡œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ë…¼ë¬¸ê³¼ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ê°ê°ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•´ì„œ ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ê°€ ìžˆëŠ”ë°ìš”. ê°€ìž¥ ë¨¼ì € ë©€í‹°í—¤ë“œ ì–´í…ì…˜ìž…ë‹ˆë‹¤. í™•ì¸í•´ë³´ì‹œë©´ ì´ë ‡ê²Œ ì–´í…ì…˜ì˜ ì„¸ ê°€ì§€ ìš”ì†Œë¥¼ ìž…ë ¥ìœ¼ë¡œ ë´¤ê³ ìš”. ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ìž…ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ì˜ ì°¨ì›ë“¤ì€ ëª¨ë‘ d ëª¨ë¸ì„ hë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ ì°¨ì›ì„ ëª¨ë‘ ê°™ë„ë¡ ë§Œë“¤ë©´ ê°„ë‹¨í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ íŒŒë¼ë¯¸í„°ë¡œ ì„¸ ê°œë¥¼ ë´¤ëŠ”ë° ë¨¼ì € ížˆë“  ë””ë„¨ì €ëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ì— ëŒ€í•œ ì¸ë² ë”©ì´ ë˜ê² ê³ ìš”.\n",
      "3030.00 -> 3059.34:  í•´ì§€ëŠ” ë§ ê·¸ëŒ€ë¡œ hê°€ ë˜ê² ìŠµë‹ˆë‹¤. ì¦‰ í—¤ë“œì˜ ê°œìˆ˜ê°€ ë˜ëŠ” ê±°ê³  ê·¸ ë‹¤ìŒì— ë“œëžì•„ì›ƒ ë ˆì´ì…”ëŠ” ë³„ë„ì˜ ì •êµí™” í…Œí¬ë‹‰ìœ¼ë¡œ ë“œëžì•„ì›ƒì„ ì ìš©í•  ë•Œì˜ ë¹„ìœ¨ì„ ì„¤ì •í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì°¸ê³ ë¡œ ì—¬ê¸°ì—ì„œ ìš°ë¦¬ê°€ ì•žì„œ ê³µë¶€í–ˆì„ ë•ŒëŠ” ê°ê°ì˜ ì¿¼ë¦¬ì™€ í‚¤ ë©œë¥˜ë“¤ì€ ížˆë“  ë””ë©˜ì „ì—ì„œ ì´ í‚¤ì˜ ì°¨ì›ìœ¼ë¡œ ë°”ë€Œì–´ì§„ë‹¤ê³  ë§ì”€ì„ ë“œë ¸ëŠ”ë°ìš”. ì‹¤ì œë¡œ êµ¬í˜„í•  ë•ŒëŠ” ì´ì™€ ê°™ì´ ê·¸ëƒ¥ ížˆë“  ë””ë©˜ì „ì„ ížˆë“  ë””ë©˜ì „ìœ¼ë¡œ ë§µí•‘í•˜ë„ë¡ ë§Œë“  ë‹¤ìŒì— ì´ ê²°ê³¼ ë””ë©˜ì „ì„ hë¡œ ìª¼ê°œì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ê²ë‹ˆë‹¤. ê·¸ëž˜ì„œ í™•ì¸í•´ ë³´ì‹œë©´ ê° í—¤ë“œì— í¬í•¨ë˜ì–´ ìžˆëŠ”\n",
      "3060.00 -> 3089.70:  ì¸ë² ë”© ì°¨ì›ì€ í—¤ë“œ ë””ë©˜ì „ì´ë¼ê³  í•´ì„œ ì´ ë‹¨ì–´ë“¤ì˜ ì¸ë² ë”© ì°¨ì›ì„ hë¡œ ë‚˜ëˆˆ ê°’ì„ ì‚¬ìš©í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤. ë˜í•œ ìŠ¤ì¼€ì¼ ê°’ë„ ì•žì„œ ì„¤ëª…í–ˆë˜ ë‚´ìš©ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ê°ê°ì˜ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ì— í•´ë‹¹í•˜ëŠ” ê·¸ ê°’ì— ë£¨íŠ¸ë¥¼ ì”Œìš´ ê°’ì„ ë‚˜ì¤‘ì— ë‚˜ëˆ ì£¼ì–´ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ì— ë„£ì–´ì¤„ ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë•Œ ê°ê° ì¿¼ë¦¬ì™€ í‚¤ ë°¸ë¥˜ê°€ ë“¤ì–´ì˜¤ëŠ”ë°ìš”. ì´ë•Œ ì¿¼ë¦¬ ëž­ìŠ¤ëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ë˜ê² ì£ . ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ê°ê° ì¿¼ë¦¬ì™€ í‚¤ ë°¸ë¥˜ë¡œ ê·¸ëŒ€ë¡œ ë‹¤ ë§µí•‘ì„ í•´ì£¼ê³ ìš”. ì´ë•Œ ì—¬ê¸°ì—ì„œ ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ì¿¼ë¦¬ì™€ í‚¤ì˜ ë°¸ë¥˜ì—\n",
      "3090.00 -> 3115.94:  ê²°ê³¼ê°’ë“¤ì„ Aì¸¡ìœ¼ë¡œ ë‚˜ëˆ  ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì¦‰ Aì¸¡ì˜ ê°ê°ë§ˆë‹¤ í—¤ë“œ ë””ë©˜ì ë§Œí¼ì˜ í¬ê¸°ë¡œ ì°¨ì›ì„ ê°€ì§€ë„ë¡ ë§Œë“¤ì–´ì„œ ì•žì„œ í™•ì¸í–ˆë˜ ê·¸ë¦¼ì—ì„œ ì´ë ‡ê²Œ ë¦¬ë‹ˆì–´ë¥¼ ê°ê° ê±°ì¹œ ê°’ì„ ë½‘ì•„ë‚¼ ìˆ˜ê°€ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ê°ê° Aì¸¡ì˜ Value, Key, Queryë“¤ì„ ë§Œë“  ê²ƒê³¼ ë§ˆì°¬ê°€ì§€ìž…ë‹ˆë‹¤. ì´ì œ ê·¸ë ‡ê²Œ ë‚˜ëˆ„ì–´ì§„ ìƒíƒœì—ì„œ ê°ê°ì˜ í—¤ë“œë§ˆë‹¤ Queryì™€ Keyë¥¼ ì„œë¡œ ê³±í•˜ë„ë¡ ë§Œë“¤ì–´ì£¼ê³  ìŠ¤ì¼€ì¼ë¡œ ë‚˜ëˆ ì¤ë‹ˆë‹¤.\n",
      "3120.00 -> 3145.10:  ì´ë•Œ ë§ˆìŠ¤í¬ ê°’ì´ 0ì¸ ë¶€ë¶„ì„ ì „ë¶€ ë‹¤ ë§ˆì´ë„ˆìŠ¤ ë¬´í•œì— ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ ë„£ì–´ì£¼ì–´ì„œ ì‹¤ì œë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ì— ë“¤ì–´ê°„ ê²°ê³¼ ê°’ì´ ê±°ì˜ 0%ê°€ ë  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê±°ê³ ìš”. ê·¸ëž˜ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì·¨í•œ ë‹¤ìŒì— ê·¸ë ‡ê²Œ ë‚˜ì˜¤ê²Œ ëœ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê°’ë“¤ì„ ì‹¤ì œë¡œ vê°’ê³¼ ê³±í•´ì„œ ì–´í…ì…˜ ë°¸ë¥˜ ê°’ë“¤ì„ ê²°ê³¼ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¤„ ìˆ˜ê°€ ìžˆëŠ” ê±°ê³ ìš”. ì´ì œ ì–˜ë¥¼ ë‹¤ì‹œ ì¼ìžë¡œ ì­‰ ëŠ˜ì–´ëœ¨ë ¤ì„œ ì»¨ì¼“ì„ ìˆ˜í–‰í•œ ê²ƒê³¼ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë½‘ì„ ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤.\n",
      "3150.00 -> 3176.56:  ê·¸ë¦¬ê³  ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê°’ì€ ë”°ë¡œ ë˜ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ë‚˜ì¤‘ì— ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì´ì–´ì„œ í¬ì¸íŠ¸ì™€ì´ì¦ˆ í”¼ë“œí¬ì›Œë“œ ì•„í‚¤í…ì²˜ì¸ë°ìš”. ë§ˆì°¬ê°€ì§€ë¡œ ì´ë ‡ê²Œ ížˆë“  ë””ë©˜ì ¼ë§Œí¼ì˜ ì°¨ì›ì´ ë“¤ì–´ì™”ì„ ë•Œ ížˆë“  ë””ë©˜ì ¼ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ë‚´ë³´ë‚¸ë‹¤ëŠ” ì ì´ íŠ¹ì§•ì´ê³ ìš”. ì¦‰ ìž…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì›ì´ ë™ì¼í•©ë‹ˆë‹¤. ì´ì œ ì´ì–´ì„œ ì•žì— ì •ì˜í–ˆë˜ ì–´í…ì…˜ê³¼ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ì— ëŒ€í•œ í´ëž˜ìŠ¤ë¥¼ ì´ìš©í•´ì„œ ì‹¤ì œë¡œ í•˜ë‚˜ì˜ ì¸ì½”ë” ë ˆì´ì–´ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•  ìˆ˜ê°€ ìžˆëŠ”ë°ìš”. ë§ˆì°¬ê°€ì§€ë¡œ ìž…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì›ì´ ê°™ê³ ìš”.\n",
      "3180.00 -> 3207.44:  ì—¬ëŸ¬ ë²ˆ ì¤‘ì²©í•´ì„œ í•˜ë‚˜ì˜ ì „ì²´ ì¸ì½”ë”ì— ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ í™•ì¸í•´ ë³´ì‹œë©´ì€ 4ê°œì˜ ì‹¤ì§ˆì ì¸ ë ˆì´ì–´ê°€ ë“¤ì–´ê°€ ìžˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ì—¬ê¸° ê·¸ë¦¼ì„ í™•ì¸í•´ ë³´ì‹œë©´ ì‹¤ì œ ì¸ì½”ë” ë ˆì´ì–´ëŠ” ë§ì”€ë“œë ¸ë“¯ì´ attention ì´í›„ì— residual connectionê³¼ normalization ê·¸ ë‹¤ìŒì— feed for layerì™€ ë‹¤ì‹œ í•œë²ˆ residual connectionê³¼ normalization ìˆ˜í–‰ì„ í•œë‹¤ê³  ë§ì”€ì„ ë“œë ¸ì£ . ê·¸ëž˜ì„œ ê°ê°ì˜ ë ˆì´ì–´ê°€ ì´ë ‡ê²Œ 4ê°œ ì°¨ë¡€ëŒ€ë¡œ ë“¤ì–´ê°€ ìžˆëŠ” ê±°ê³ ìš”. ê°€ìž¥ ë¨¼ì € í•˜ë‚˜ì˜ ìž…ë ¥ê°’ì´ ë“¤ì–´ì™”ì„ ë•Œ\n",
      "3210.00 -> 3239.98:  ê·¸ëŒ€ë¡œ ë³µì œí•´ì„œ ê°™ì€ ê°’ë“¤ì„ ë„£ì–´ì£¼ë„ë¡ ë§Œë“¤ê³ ìš”. ìš°ë¦¬ê°€ íŠ¹ì • ë‹¨ì–´ì— ëŒ€í•´ì„œëŠ” ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ì„œ ë§ˆìŠ¤í¬ ë²¡í„°ë¥¼ ì”Œìš¸ ìˆ˜ ìžˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ê·¸ëŒ€ë¡œ ê±´ë„ˆì˜¨ ìž…ë ¥ ì¸ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì™€ ë§ˆìŠ¤í¬ë¥¼ ê·¸ëŒ€ë¡œ ë„£ì„ ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” ê±°ê³ ìš”. ê·¸ëž˜ì„œ ê°€ìž¥ ë¨¼ì € ì´ë ‡ê²Œ ì…€í”„ ì–´í…ì…˜ì„ ìˆ˜í–‰í•´ì„œ ê²°ê³¼ë¥¼ ë½‘ì•„ë‚¸ ë’¤ì— êµ¬í•´ì§„ ê°’ì„ ë”í•´ì¤˜ì„œ ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜ì„ ìˆ˜í–‰í•œ ë’¤ì— ì‹¤ì œë¡œ ë…¸ë©€ë¼ì´ì œì´ì…˜ì„ ìˆ˜í–‰í•œ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìžˆë„ë¡ í•˜ê³ ìš”. ì´ì œ ë§ˆì°¬ê°€ì§€ë¡œ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ë¥¼ ê±°ì¹œ ë‹¤ìŒì— ë‹¤ì‹œ í•œë²ˆ ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜ì„ ê±°ì³ì„œ ë§Œë“¤ì–´ì§„ ì•„ì›ƒí’‹ì„ ë‚´ë³´ë‚´ì£¼ê³ \n",
      "3240.00 -> 3267.34:  ê·¸ëž˜ì„œ ì‹¤ì œ ì¸ì½”ë” ì•„í‚¤í…ì²˜ì—ì„œëŠ” ì´ë ‡ê²Œ ì•žì„œ ì •ì˜í–ˆë˜ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ ì´ n ë ˆì´ì–´ë§Œí¼ ë°˜ë³µí•´ì„œ ìŒ“ë„ë¡ ë§Œë“­ë‹ˆë‹¤. í™•ì¸í•´ë³´ì‹œë©´ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œëŠ” ì‹¤ì œ ë‹¨ì–´ë“¤ì˜ ê°œìˆ˜ì— í•´ë‹¹í•˜ëŠ” ì¸í’‹ ë””ë©˜ì „ì— í•´ë‹¹í•˜ëŠ” ë§¤íŠ¸ë¦­ìŠ¤ê°€ ë“¤ì–´ì™”ì„ ë•Œ ì „ë¶€ ë‹¤ ì¸ë² ë”© ì°¨ì›ìœ¼ë¡œ ë°”ê¿”ì£¼ê³ ìš”. ê·¸ ë‹¤ìŒ ë˜ ì¶”ê°€ì ìœ¼ë¡œ ì—¬ê¸°ì—ì„œ ë°”ë¡œ ì´ ë¶€ë¶„ì´ ì‹¤ì œ ë…¼ë¬¸ê³¼ëŠ” ë‹¤ë¥´ê²Œ êµ¬í˜„ëœ ë¶€ë¶„ì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. í˜„ìž¬ ì½”ë“œì—ì„œëŠ” ì›ë³¸ ë…¼ë¬¸ê³¼ ë‹¤ë¥´ê²Œ ìœ„ì¹˜ ì¸ë² ë”©ì„ ì§ì ‘ í•™ìŠµí•˜ëŠ” í˜•íƒœë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
      "3270.00 -> 3296.28:  ì‚¬ì¸ê³¼ ì½”ì‚¬ì¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì´ëŸ° ìœ„ì¹˜ ìž„ë² ë”©ì„ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ì–´ë„ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ë‚´ë³´ë‚¼ ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— ë³¸ ì½”ë“œì—ì„  ì´ë ‡ê²Œ ìž„ë² ë”© ê°’ì„ í•™ìŠµí•˜ëŠ” ë ˆì´ì–´ë¡œì„œ ë³„ë„ì˜ í•™ìŠµ ë ˆì´ì–´ë¡œì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  ë³´ì—¬ì£¼ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë˜í•œ ì´ì œ ì‹¤ì œë¡œ ë§ˆìŠ¤í¬ ê°’ì€ ì´ íŒ¨ë”© í† í°ì— ëŒ€í•´ì„œ 0ê°’ì´ ë“¤ì–´ê°€ëŠ” í˜•íƒœë¡œ ë§Œë“¤ì–´ì§€ëŠ”ë°ìš”. ë§ì”€ë“œë ¸ë“¯ì´ í•˜ë‚˜ì˜ ë°°ì¹˜ ì•ˆì—ëŠ” ì—¬ëŸ¬ ê°œì˜ ìž…ë ¥ ë¬¸ìž¥ì´ ë“¤ì–´ê°€ ìžˆëŠ”ë° ì´ë•Œ ì§§ì€ ë¬¸ìž¥ì— ëŒ€í•´ì„œëŠ” ë’¤ìª½ì— íŒ¨ë”© í† í°ìœ¼ë¡œ ì±„ì›Œì§„ë‹¤ê³  í–ˆìŠµë‹ˆë‹¤.\n",
      "3300.00 -> 3326.86:  ë‹¨ì–´ë“¤ë¼ë¦¬ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ë•Œ íŒ¨ë”© í† í°ì€ ë¬´ì‹œí•˜ë„ë¡ ë§Œë“¤ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ íŒ¨ë”© í† í°ì— ëŒ€í•´ì„œ ë§ˆìŠ¤í¬ë¥¼ ì”Œì›Œì¤€ë‹¤ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ë¨¼ì € ë§¨ ì²˜ìŒì— ì¸í’‹ ë””ë©˜ì „ìœ¼ë¡œ ìž…ë ¥ì´ ë“¤ì–´ì™”ì„ ë•Œ ì‹¤ì œ ì¸ë² ë”© ì°¨ì›ìœ¼ë¡œ ë°”ê¿”ì£¼ê³  ê±°ê¸°ë‹¤ê°€ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ ê°’ì„ ë”í•´ì£¼ë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë³„ë„ì˜ í¬ìŠ¤ ì¸ë² ë”© ë ˆì´ì–´ë¥¼ ì¶”ê°€í•´ ì¤€ ê±°ê³ ìš”. ì´ì œ ì¸ì½”ë” ë ˆì´ì–´ëŠ” ë°˜ë³µì ìœ¼ë¡œ ì¤‘ì²©ë¼ì„œ ì‚¬ìš©ì´ ë˜ê¸° ë•Œë¬¸ì— ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ìš©í•´ì„œ N ë ˆì´ì–´ë§Œí¼ ë°˜ë³µí•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤.\n",
      "3330.00 -> 3358.78:  ë§ ê·¸ëŒ€ë¡œ ë¬¸ìž¥ì˜ ê°œìˆ˜ê°€ ë˜ê² ê³ ìš”. ì´ source lengthëŠ” ê° ë¬¸ìž¥ë“¤ ì¤‘ì—ì„œ ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ê°€ìž¥ ë§Žì€ ë¬¸ìž¥ì˜ ë‹¨ì–´ ê°œìˆ˜ê°€ ë˜ê² ìŠµë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ í¬ì§€ì…”ëŸ´ ì¸ì½”ë”©ì€ ì°¨ë¡€ëŒ€ë¡œ 0ë¶€í„° ê°€ìž¥ ê¸´ ë¬¸ìž¥ì— í•´ë‹¹í•˜ëŠ” ë²ˆí˜¸ê¹Œì§€ ë“¤ì–´ê°ˆ ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê³  ì´ì œ ê·¸ê²ƒì„ ê°ê°ì˜ ë¬¸ìž¥ë§ˆë‹¤ ì ìš©í•˜ë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë¦¬í•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ìž…ë ¥ ì¸ë² ë”© ê°’ì— ê·¸ëŸ¬í•œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ì‹¤ì œ ìž…ë ¥ ê°’ìœ¼ë¡œ ì‚¬ìš©ì„ í•´ì£¼ëŠ” ê±°ê³ ìš”. ê·¸ëž˜ì„œ ê·¸ëŸ¬í•œ ìž…ë ¥ ê°’ì´ ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê±°ì¹˜ë©´ì„œ\n",
      "3360.00 -> 3388.60:  forwardë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ë§ˆì§€ë§‰ ì¸ì½”ë” ë ˆì´ì–´ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ê·¸ ì¶œë ¥ê°’ì„ ê²°ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì–´ì„œ ë””ì½”ë” ë ˆì´ì–´ì˜ ì•„í‚¤í…ì²˜ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ìž…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì›ì´ ê°™ê³ ìš”. ê·¸ëž˜ì„œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë”ëŠ” ì´ëŸ¬í•œ ë””ì½”ë” ë ˆì´ì–´ë¥¼ ì—¬ëŸ¬ ë²ˆ ì¤‘ì²©í•´ì„œ ì‚¬ìš©í•œë‹¤ê³  ë§ì”€ë“œë ¸ì£ . ë˜í•œ ë‚´ë¶€ì ìœ¼ë¡œ ë‘ ê°œì˜ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì´ ì‚¬ìš©ëœë‹¤ê³  ë§ì”€ë“œë ¸ìŠµë‹ˆë‹¤. í•˜ë‚˜ëŠ” ì…€í”„ ì–´í…ì…˜ì´ê³ ìš”. ê·¸ë¦¬ê³  í•˜ë‚˜ëŠ” ì¸ì½”ë”ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°›ì•„ì˜¤ê¸° ìœ„í•œ ì¸ì½”ë” ë””ì½”ë” ì–´í…ì…˜ì´ë¼ê³  ë§ì”€ë“œë ¸ìŠµë‹ˆë‹¤.\n",
      "3390.00 -> 3417.34:  ì´ 6ê°œì˜ ë ˆì´ì–´ê°€ ì‚¬ìš©ë˜ëŠ” ê±¸ ì•Œ ìˆ˜ ìžˆê³ ìš”. ì´ëŠ” ì—¬ê¸° ê·¸ë¦¼ê³¼ ë§ˆì°¬ê°€ì§€ìž…ë‹ˆë‹¤. ì…€í”„ ì–´í…ì…˜ ì´í›„ì— ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜, ê·¸ ë‹¤ìŒì— ì¸ì½”ë” ë””ì½”ë” ì–´í…ì…˜ ì´í›„ì— ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜ ì´í›„ì— í“¨ë“œ í¬ì›Œë“œ ë ˆì´ì–´ì™€ ë ˆì§€ë“€ì–¼ ì»¤ë„¥ì…˜ì„ í•œ ë²ˆ ë” ê±°ì³ì„œ ê²°ê³¼ë¥¼ ë½‘ì•„ë‚¼ ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì´ì œ ì´ëŸ¬í•œ ë ˆì´ì–´ê°€ Në²ˆë§Œí¼ ì¤‘ì²©ë˜ì–´ ì“°ì´ê³ ìš”. ê·¸ë ‡ê²Œ ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ì¶œë ¥ê°’ì´ ì‹¤ì œ ì¶œë ¥ ë¬¸ìž¥ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìžˆë‹¤ê³  í–ˆì£ . ë”°ë¼ì„œ ì´ì™€ ê°™ì´ 6ê°€ì§€ ë ˆì´ì–´ë¥¼ ì „ë¶€ ì´ˆê¸°í™”í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì£¼ì—ˆê³ ìš”.\n",
      "3420.00 -> 3449.48:  ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì¿¼ë¦¬ì™€ í‚¤ ë°¸ë¥˜ëŠ” ëª¨ë‘ ìžê¸° ìžì‹ ì„ ë„£ì„ ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì£¼ê³ ìš”. ê·¸ ë‹¤ìŒ ì´í›„ì— ë ˆì§€ë“ˆëŸ¬ ì»¤ë„¥ì…˜ì„ ìˆ˜í–‰í•œ ë’¤ì— ê·¸ ë‹¤ìŒ ì¸ì½”ë”ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¸ì½”ë” ë””ì½”ë” ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ëŠ”ë°ìš”. ì´ë•Œ ì¿¼ë¦¬ëŠ” ë°”ë¡œ ë””ì½”ë”ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ì¶œë ¥ ë‹¨ì–´ë“¤ì— ëŒ€í•œ ì •ë³´ê°€ ë˜ê² ê³ ìš”. ì¸ì½”ë”ì—ì„œ ê°€ìž¥ ë§ˆì§€ë§‰ ì¶œë ¥ ê°’ìœ¼ë¡œ ë‚˜ì˜¨ ê·¸ ê°’ì„ í‚¤ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ì •ì˜ëœ ë””ì½”ë” ë ˆì´ì–´ ì•„í‚¤í…ì²˜ë¥¼ ì´ìš©í•´ì„œ ì „ì²´ ë””ì½”ë” ì•„í‚¤í…ì²˜ì—ì„œëŠ” ê·¸ëŸ¬í•œ ë””ì½”ë” ë ˆì´ì–´ë¥¼ ì—¬ëŸ¬ ë²ˆ ì¤‘ì²©í•´ì„œ ì‚¬ìš©í•˜ê³ ìš”.\n",
      "3450.00 -> 3478.58:  ì›ë³¸ ë…¼ë¬¸ê³¼ëŠ” ë‹¤ë¥´ê²Œ ë§ˆì°¬ê°€ì§€ë¡œ ìœ„ì¹˜ ìž„ë² ë”©ì„ ìš°ë¦¬ê°€ ë³„ë„ë¡œ í•™ìŠµí•˜ëŠ” í˜•íƒœë¡œ êµ¬í˜„ì„ í•´ì„œ ì‚¬ì¸í•¨ìˆ˜ì™€ ì½”ì‚¬ì¸í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ë§Œë“¤ ê²ƒìž…ë‹ˆë‹¤. ë˜í•œ ì°¸ê³ ë¡œ ë§ì”€ë“œë ¸ë“¯ì´ íƒ€ê²Ÿ ë¬¸ìž¥ì—ì„œ ê°ê°ì˜ ë‹¨ì–´ëŠ” ë‹¤ìŒ ë‹¨ì–´ê°€ ë¬´ì—‡ì¸ì§€ ì•Œ ìˆ˜ ì—†ë„ë¡ ì¦‰ ì´ì „ì— ì¶œë ¥í•œ ë‹¨ì–´ë§Œ ë³¼ ìˆ˜ ìžˆë„ë¡ í•˜ê¸° ìœ„í•´ì„œ ë³„ë„ì˜ ë§ˆìŠ¤í¬ ë²¡í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì•„ê¹Œëž‘ ë™ì¼í•˜ê²Œ ë‹¨ì–´ì˜ ê°œìˆ˜ì™€ ê°™ì€ ê·¸ ë””ë©˜ì „ì„ ìž„ë² ë”© ì°¨ì›ìœ¼ë¡œ ë°”ê¾¸ì–´ ì£¼ê³ ìš”. ë§ˆì°¬ê°€ì§€ë¡œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì£¼ê¸° ìœ„í•´ì„œ ì „ì²´ ì‹œí€€ìŠ¤ì˜ ëž­ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë””ë©˜ì „ì„\n",
      "3480.00 -> 3509.18:  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ë˜í•œ ì´ì–´ì„œ ì´ëŸ¬í•œ ë””ì½”ë” ë ˆì´ì–´ëŠ” ë°˜ë³µì ìœ¼ë¡œ ì¤‘ì²©í•´ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  ë§ì”€ë“œë ¸ìŠµë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì‹¤ì œë¡œ forwardë¥¼ ìˆ˜í–‰í•  ë•Œ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ ë‚˜ì˜¤ê²Œ ëœ ì¶œë ¥ê°’ê³¼ ì‹¤ì œë¡œ íƒ€ê²Ÿ ë¬¸ìž¥ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°›ê³ ìš”. ë§ˆì°¬ê°€ì§€ë¡œ íƒ€ê²Ÿ ë¬¸ìž¥ ë˜í•œ ì¦‰ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë¬¸ìž¥ ë˜í•œ 0ë¶€í„° ê·¸ ë‹¨ì–´ì˜ ê°œìˆ˜ê¹Œì§€ì— ëŒ€í•œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê²¨ì•¼ í•˜ê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜ í…ì„œë¥¼ ì´ˆê¸°í™”í•œ ë’¤ì— ê° ë¬¸ìž¥ì— ëŒ€í•´ì„œ ëª¨ë‘ ë™ì¼í•˜ê²Œ ì ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ê·¸ëž˜ì„œ ë¬¸ìž¥ì´ ìž„ë°°ëœ ê°’ì— ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ë”í•œ ê²ƒì„\n",
      "3510.00 -> 3535.88:  ê·¸ëž˜ì„œ ë””ì½”ë” ë ˆì´ì–´ë¥¼ ì—¬ëŸ¬ ë²ˆ ê±°ì¹œ ë‹¤ìŒì— ë§ˆì§€ë§‰ì— ë‚˜ì˜¤ê²Œ ëœ ì•„ì›ƒí’‹ ê°’ì— ì¶œë ¥ì„ ìœ„í•œ ë¦¬ë‹ˆì–´ ë ˆì´ì–´ë¥¼ ê±°ì¹˜ë„ë¡ ë§Œë“¤ì–´ì„œ ê²°ê³¼ì ì¸ ì•„ì›ƒí’‹ ê°’ì„ ë½‘ì•„ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ì¸ íŠ¸ëžœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ëŠ” ì´ë ‡ê²Œ ì „ì²´ ì¸ì½”ë” ì•„í‚¤í…ì²˜ì™€ ì „ì²´ ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ë°›ì•„ì„œ ìž…ë ¥ ë¬¸ìž¥ì— ë”°ë¼ì„œ ë§ˆìŠ¤í¬ë¥¼ ë¶™ì—¬ì„œ ì‹¤ì œ ê²°ê³¼ë¥¼ ë½‘ì•„ë‚¼ ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì´ë•Œ ì†ŒìŠ¤ ë¬¸ìž¥ ê°™ì€ ê²½ìš°ëŠ” íŒ¨ë”© í† í°ì— ëŒ€í•´ì„œë§Œ ë§ˆìŠ¤í¬ ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •í•´ì„œ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ê³ ìš”.\n",
      "3540.00 -> 3568.02:  ë¬´ì—‡ì¸ì§€ ì•Œ ìˆ˜ ì—†ë„ë¡ í•˜ê¸° ìœ„í•´ì„œ ë§ˆì°¬ê°€ì§€ë¡œ ë§ˆìŠ¤í¬ í–‰ë ¬ì„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì—¬ê¸° ë³´ì´ëŠ” íŒ¨ë”© ë§ˆìŠ¤í¬ëŠ” ì†ŒìŠ¤ ë¬¸ìž¥ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ íŒ¨ë”© í† í°ì— ëŒ€í•´ì„œ ì ìš©í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ í•™ìŠµí•  ë•Œ ì´ëŸ¬í•œ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ í•˜ê³ ìš”. ì¶”ê°€ì ìœ¼ë¡œ ì•žìª½ì— ìžˆëŠ” ë‹¨ì–´ë“¤ë§Œ ë³¼ ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë³„ë„ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ ë” ë§Œë“  ë‹¤ìŒì— ì´ ë‘ ë§ˆìŠ¤í¬ì— ëŒ€í•´ì„œ ì—˜ëŸ¬ë¨¼íŠ¸ YGë¡œ ì—”ë“œ ì—°ì‚°ì„ ìˆ˜í–‰í•œ ë’¤ì— ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ë‘ ë§ˆìŠ¤í¬ì— ëŒ€í•´ì„œ ë‘˜ ë‹¤ 1ì˜ ê°’ì„ ê°€ì§€ëŠ” ê·¸ëŸ° ìœ„ì¹˜ì— ëŒ€í•´ì„œë§Œ ì‹¤ì œ ì–´í…ì…˜ ìŠ¤ì½”ì–´ë¥¼ êµ¬í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì„œ\n",
      "3570.00 -> 3599.18:  ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ì†ŒìŠ¤ì™€ íƒ€ê²Ÿì´ ë“¤ì–´ì™”ì„ ë•Œ ë§ˆìŠ¤í¬ë¥¼ ê°ê° ë§Œë“  ë’¤ì— ë¨¼ì € ì¸ì½”ë”ì— ì´ëŸ¬í•œ ì†ŒìŠ¤ ë¬¸ìž¥ì„ ë„£ì–´ì„œ ì¸ì½”ë”ì˜ ì¶œë ¥ê°’ë“¤ì„ ë½‘ì€ ë’¤ì— ì´ì œ ë””ì½”ë”ëŠ” ë§¤ë²ˆ ê·¸ëŸ¬í•œ ì¸ì½”ë”ì˜ ì¶œë ¥ê°’ì„ ì–´íƒœì…˜í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì„œ ê²°ê³¼ì ìœ¼ë¡œ ë§ˆì§€ë§‰ì— ë‚˜ì˜¨ ì•„ì›ƒí’‹ ê°’ì´ ìš°ë¦¬ ë„¤íŠ¸ì›Œí¬ì˜ ë²ˆì—­ ê²°ê³¼ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ì‹¤ì œë¡œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìžˆëŠ”ë°ìš”. í•™ìŠµí•  ë• ì´ì™€ ê°™ì´ ì¸í’‹ ë””ë©˜ì „ê³¼ ì•„ì›ƒí’‹ ë””ë©˜ì „ì€ ê°ê° ì†ŒìŠ¤ ì–¸ì–´ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ì–¸ì–´ì˜ ê°œìˆ˜, ê·¸ ë‹¤ìŒì— íƒ€ê²Ÿ ì–¸ì–´ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ì–¸ì–´ì˜ ê°œìˆ˜ê°€ ë  ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "3600.00 -> 3625.58:  ê°ê°ì˜ ë‹¨ì–´ì— ëŒ€í•œ ì¸ë² ë”© ì°¨ì›ì€ 256ìœ¼ë¡œ ì„¤ì •í•˜ê³  ë ˆì´ê°€ ì´ 3ë²ˆì”© ì¤‘ì²©ë˜ì–´ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì—¬ê¸° ë³´ì´ëŠ” íŒŒë¼ë¯¸í„°ëŠ” ì‹¤ì œ ë…¼ë¬¸ì—ì„œ ì œí•œëœ íŒŒë¼ë¯¸í„°ì— ë¹„í•˜ë©´ í¬ê¸°ê°€ ë§Žì´ ìž‘ì€ íŽ¸ì´ì§€ë§Œ ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì¶©ë¶„ížˆ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ íŠ¸ëžœìŠ¤í¬ë¨¸ ê°ì²´ë¥¼ ë§Œë“¤ì–´ ì¤€ ë’¤ì— íŒŒë¼ë¯¸í„°ê¹Œì§€ ë‹¤ ì´ˆê¸°í™”ë¥¼ ì§„í–‰í•´ ì£¼ì‹œê³ ìš”. ì´ë ‡ê²Œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•´ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ì œ í•œë²ˆ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìžˆëŠ”ë°ìš”.\n",
      "3630.00 -> 3659.80:  ëª¨ë¸ í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ í•™ìŠµí•¨ìˆ˜ì™€ í‰ê°€í•¨ìˆ˜ë¥¼ ë”°ë¡œ ì •ì˜í•´ì„œ í•™ìŠµì„ ì§„í–‰í•˜ë©´ìš”. ì´ë ‡ê²Œ í•™ìŠµì´ ì§„í–‰ë˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. í•™ìŠµì„ ì§„í–‰í•  ë•Œë§ˆë‹¤ validation lossê°€ ë” ê°ì†Œí•˜ëŠ” ê²½ìš°ì—ë§Œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ìƒˆë¡œìš´ íŒŒì¼ë¡œ ê¸°ë¡í•˜ë„ë¡ ë§Œë“œëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì´ì™€ ê°™ì´ í•™ìŠµì´ ì™„ë£Œëœ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ì´ë ‡ê²Œ í•™ìŠµëœ ê²°ê³¼ë¥¼ ì—¬ëŸ¬ë¶„ë“¤ì˜ ì»´í“¨í„°ì— ê¸°ë¡í•˜ê³ ìž í•œë‹¤ë©´ ì´ë ‡ê²Œ íŒŒì¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ í•™ìŠµì´ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "3660.00 -> 3684.36:  ìž ì´í›„ì— ì´ì™€ ê°™ì´ í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ì„ ì´ìš©í•´ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œ ì´ë²¨ë ˆì´ì…˜ì„ ì§„í–‰í•˜ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ë¡œìŠ¤ ê°’ì„ êµ¬í•´ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì œ ì´ì–´ì„œ ì—¬ëŸ¬ë¶„ë“¤ë§Œì˜ ë¬¸ìž¥ì„ ë„£ì–´ì„œ ì‹¤ì œë¡œ ìš°ë¦¬ ëª¨ë¸ì„ ì‚¬ìš©í•´ë³¼ ìˆ˜ ìžˆëŠ”ë°ìš”. ì´ë ‡ê²Œ íŠ¸ëžœìŠ¬ëŸ¬ì˜ ì„¼í…ìŠ¤ í•¨ìˆ˜ ì•ˆì— ë‚´ìš©ì´ ì •ì˜ë˜ì–´ ìžˆëŠ” ê±¸ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë¨¼ì € í•˜ë‚˜ì˜ ë¬¸ìž¥ì´ ë“¤ì–´ì™”ì„ ë•Œ í† í°ì„ ì§„í–‰í•œ ë’¤ì— ì•žë’¤ë¡œ sosì™€ eos í† í°ì„ ë¶™ìž…ë‹ˆë‹¤.\n",
      "3690.00 -> 3712.38:  ì´ì–´ì„œ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“  ë’¤ì— ì‹¤ì œë¡œ ì¸ì½”ë”ì— ì´ëŸ¬í•œ ì†ŒìŠ¤ ë¬¸ìž¥ì„ ë„£ì–´ì„œ ì¶œë ¥ê°’ì„ êµ¬í•  ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒì— ì´ì œ ì‹¤ì œ ì¶œë ¥ ë¬¸ìž¥ì€ sos í† í°ë¶€í„° ì¶œë°œí•´ì„œ max lengthê¹Œì§€ í•œ ë²ˆì”© ë°˜ë³µì ìœ¼ë¡œ ëª¨ë¸ì˜ ë””ì½”ë”ì— ë„£ì–´ì„œ ì¶œë ¥ê°’ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ë•Œ ë§¤ë²ˆ ë””ì½”ë”ì— ë„£ì—ˆì„ ë•Œ ê°€ìž¥ ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ì¶œë ¥ ë¬¸ìž¥ìœ¼ë¡œì„œ í•˜ë‚˜ì”© ì¶”ê°€ê°€ ë˜ëŠ” ê±°ê³ ìš”.\n",
      "3720.00 -> 3748.56:  ëª¨ë“  ë‹¨ì–´ë“¤ì´ ì „ì²´ ì¶œë ¥ ë¬¸ìž¥ì´ ë˜ê² ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì‹¤ì œ ê²°ê³¼ë¡œ ë½‘ê¸° ìœ„í•´ì„œ ê°ê°ì˜ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ë¬¸ìžì—´ë¡œ ë°”ê¾¸ì–´ì„œ ë¦¬í„´í•´ì£¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ê°„ë‹¨í•˜ê²Œ í•œë²ˆ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ì—ì„œ 10ë²ˆì§¸ ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ë„ë¡ í• ê²Œìš”. ë‚´ìš© í™•ì¸í•´ë³´ì‹œë©´ ì–˜ê°€ ë…ì¼ì–´ ë¬¸ìž¥ì´ ë˜ê² ìŠµë‹ˆë‹¤. ì´ ë‚´ìš©ì´ ì›ëž˜ ì˜ë¯¸í•˜ëŠ” ë‚´ìš©ì€ í•œ ëª…ì˜ ì–´ë¨¸ë‹ˆì™€ ê·¸ì˜ ìžì‹ì€ ë…¸ëž˜ë¥¼ ë¶€ë¥¸ë‹¤. ì•¼ì™¸ì—ì„œ ì¢‹ì€ ë‚ ì„ ì¦ê¸°ë©° ë¼ëŠ” ë‚´ìš©ì´ì£ . ì´ê²Œ ì‹¤ì œë¡œ ì¶œë ¥ëœ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ë©´\n",
      "3750.00 -> 3779.18:  ì–´ë¨¸ë‹ˆì™€ ê·¸ì˜ ì–´ë¦° ì•„ë“¤ì´ ì•¼ì™¸ì—ì„œ ìž‘ì€ ë‚˜ë‚ ì„ ì¦ê¸°ê³  ìžˆë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ë²ˆì—­ë˜ì–´ ìžˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì™„ì „ížˆ ë™ì¼í•œ ë¬¸ìž¥ì€ ì•„ë‹ˆë”ë¼ë„ ì´ëŸ° ì „ë°˜ì ì¸ ì˜ë¯¸ ìžì²´ê°€ ìž˜ ì „ë‹¬ë˜ë„ë¡ ë²ˆì—­ì´ ì´ë£¨ì–´ì§„ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ë ‡ê²Œ ì¶œë ¥ëœ attention ê°’ì€ ì´ 8ê°œì˜ í—¤ë“œë¡œ êµ¬ì„±ëœ attention ìŠ¤ì½”ì–´ë“¤ì˜ ì§‘í•©ì´ë¼ê³  í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ì „ì²´ ê·¸ë¦¼ì—ë‹¤ê°€ ê°ê°ì˜ í—¤ë“œì— ëŒ€í•œ attention ìŠ¤ì½”ì–´ ê°’ì„ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ì‹¤ì œ ê·¸ë¦¼ê¹Œì§€ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ì–´ ë³´ì‹œë©´\n",
      "3780.00 -> 3805.40:  ì´ë ‡ê²Œ ê°ê°ì˜ ë‹¨ì–´ê°€ ì¶œë ¥ë˜ê¸° ìœ„í•´ì„œ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œì˜ ì–´ë–¤ ì •ë³´ë¥¼ ë§Žì´ ì°¸ê³ í–ˆëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ ì˜ì–´ ë¬¸ìž¥ìœ¼ë¡œ motherì™€ ì´ ë…ì¼ì–´ ë¬¸ìž¥ì— í•´ë‹¹ ë‹¨ì–´ëŠ” ë§ˆì°¬ê°€ì§€ë¡œ ì–´ë¨¸ë‹ˆë¼ëŠ” ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìžˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ motherë¼ëŠ” ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ì„œ ë…ì¼ì–´ ë¬¸ìž¥ì— ì´ëŸ¬í•œ ë‹¨ì–´ë¥¼ ì°¸ê³ í–ˆë‹¤ëŠ” ê²ƒì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì™€ ê°™ì´ ì´ 8ê°œì˜ í—¤ë“œ ê°ê°ì— ëŒ€í•´ì„œ attention score ê°’ì´ ë§¤ê²¨ì§€ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”.\n",
      "3810.00 -> 3838.46:  í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ì–´ì§€ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ê°ê° attention score ê°’ì´ êµ¬í•´ì§„ ê²°ê³¼ê°€ ì¡°ê¸ˆì”© ë‹¤ë¥¼ ìˆ˜ ìžˆë‹¤ëŠ” ì  ë˜í•œ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ì œ ë§ˆì§€ë§‰ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ blue scoreë¥¼ ê³„ì‚°í•´ì„œ í•™ìŠµì´ ì™„ë£Œëœ íŠ¸ëžœìŠ¤í¬ë¨¼ ëª¨ë¸ì˜ ìŠ¤ì½”ì–´ë¥¼ êµ¬í•´ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì˜ˆì‹œì—ì„œëŠ” ê°ê°ì˜ ìž…ë ¥ ë¬¸ìž¥ì´ ìžˆì„ ë•Œ ê·¸ ì •ë‹µ ë¬¸ìž¥ ë˜í•œ í•˜ë‚˜ì”©ë§Œ ì¡´ìž¬í•˜ê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜ ì˜ˆì¸¡ ê°’ì— ëŒ€í•´ì„œ ê·¸ ì •ë‹µ ê°’ì´ 1ëŒ€ 1ë¡œ ë§¤ì¹­ë  ìˆ˜ ìžˆë„ë¡ ë°”ë¡œ ê·¸ ì •ë‹µ ë¬¸ìž¥ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ í•˜ë‚˜ì”© ë‚˜ì—´í•˜ëŠ” ê±¸ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "3840.00 -> 3867.00:  ë¬¸ìž¥ 100ê°œë‹¹ í•œ ë²ˆì”© ì˜ˆì¸¡ê³¼ ì •ë‹µ ê°’ì„ ì¶œë ¥í•˜ë„ë¡ ë§Œë“¤ì–´ ë³¸ ê±°ê³ ìš”. ìž ì´ë ‡ê²Œ ì‹¤ì œë¡œ ë¬¸ìž¥ì„ ë³´ì‹œë©´ ê½¤ ìœ ì‚¬í•˜ê²Œ ì˜ˆì¸¡ì´ ì´ë£¨ì–´ì§„ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë§ˆì§€ë§‰ ë¬¸ìž¥ ê°™ì€ ê²½ìš°ëŠ” ë‚˜ì´ê°€ ë§Žì€ í•œ ë‚¨ìžëŠ” ë¯¸ë””ì–´ ê²Œìž„ì„ í”Œë ˆì´í•˜ê³  ìžˆë‹¤ë¼ê³  ë²ˆì—­ì„ í–ˆëŠ”ë°ìš”. ì‹¤ì œ ì •ë‹µ ê°’ê³¼ ë¹„êµí–ˆì„ ë•Œ ê±°ì˜ ìœ ì‚¬í•˜ê²Œ ë²ˆì—­ì„ ìˆ˜í–‰í•œ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì—¬ê¸° ë³´ì´ëŠ” ì´ ë¸”ë£¨4 ìŠ¤ì½”ì–´ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìžˆëŠ” ë¸”ë£¨ ìŠ¤ì½”ì–´ì™€ ê°™ì€ ê°’ì„ ê°€ì§€ëŠ”ë°ìš”.\n",
      "3871.02 -> 3874.76:  ì´ì–´ì„œ ê°™ì´ í•œë²ˆ ë…¼ë¬¸ ë¦¬ë”© ì§„í–‰í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "3900.00 -> 3928.70:  ì–´í…ì…˜ ê¸°ë²•ë§Œ ì‚¬ìš©í•´ì„œ ê¸°ê³„ ë²ˆì—­ íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì—ˆìŠµë‹ˆë‹¤. ë°”ë¡œ í•œë²ˆ abstractë¶€í„° ì½ì–´ë³¼ê²Œìš”. ë³´ì‹œëŠ” ë°”ì™€ ê°™ì´ ì´ì „ê¹Œì§€ëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ í¬í•¨í•œ í˜•íƒœë¡œ ë³µìž¡í•œ RNN í˜¹ì€ CNN ê¸°ë°˜ì˜ ì‹œí€€ìŠ¤ ê°„ ë³€í˜•ì´ ì´ë£¨ì–´ì§€ëŠ” RNN ë° CNNì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ëª¨ë¸ì„ ë§Žì´ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ transductionì€ ë³€í™” í˜¹ì€ í˜•ì§ˆì˜ ë³€í˜•ê³¼ ê°™ì€ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìžˆëŠ”ë°ìš”. ë§ ê·¸ëŒ€ë¡œ ì–´ë– í•œ ì‹œí€€ìŠ¤ ê°„ ë³€í˜•ì„ ì˜ë¯¸í•˜ëŠ” ê²ë‹ˆë‹¤. ëŒ€í‘œì ì¸ ì˜ˆì‹œê°€ ê¸°ê³„ ë²ˆì—­ì´ ìžˆê² ì£ .\n",
      "3930.00 -> 3959.74:  ê·¸ëž˜ì„œ ì´ë ‡ê²Œ RNN í˜¹ì€ CNNì„ ì „ì ìœ¼ë¡œ í™œìš©í•œ ëª¨ë¸ë“¤ì´ ë§Žì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ê·¸ëŸ¬í•œ ì¸ì½”ë” ë””ì½”ë” ì•„í‚¤í…ì²˜ì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í–ˆì„ ë•Œ ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ìˆ˜ ìžˆì—ˆë‹¤ëŠ” ê·¸ëŸ° ê²°ê³¼ë¥¼ ì´ì „ ë…¼ë¬¸ì—ì„œ í™•ì¸í•´ ë³¼ ìˆ˜ê°€ ìžˆì—ˆì£ . ê·¸ëž˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„  ì´ë ‡ê²Œ íŠ¸ëžœìŠ¤í¬ë¨¸ë¼ëŠ” ì´ë¦„ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•˜ê³  ì´ ì•„í‚¤í…ì²˜ëŠ” ì „ì ìœ¼ë¡œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì— ê¸°ë°˜ì„ í•˜ê³  ìžˆëŠ” ì•„í‚¤í…ì²˜ìž…ë‹ˆë‹¤. ì´ë•Œ ë§ ê·¸ëŒ€ë¡œ ë¦¬ì»¤ëŸ°ìŠ¤ë‚˜ ì»¨ë³¼ë£¨ì…˜ ìžì²´ë¥¼ ì œê±°í•œ í˜•íƒœë¡œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ë§Œ í™œìš©ì„ í–ˆë‹¤ëŠ” ê±°ê³ ìš”.\n",
      "3960.00 -> 3988.14:  ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦ˆë§Œ í™œìš©í•¨ìœ¼ë¡œì¨ ë¦¬ì»¤ëŸ°ìŠ¤í•˜ê²Œ ê°ê°ì˜ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ì–´ì§€ê¸° ë•Œë¬¸ì— ê·¸ëƒ¥ í–‰ë ¬ ê³¡ì„ ì´ìš©í•´ì„œ ì™„ì „ížˆ ë³‘ë ¬ì ìœ¼ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— í›¨ì”¬ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì ì´ ìž¥ì ìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ êµ‰ìž¥ížˆ ìœ ëª…í•œ ë‘ ê°€ì§€ íƒœìŠ¤í¬ì¸ WMT-14ìš©ë„ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ ì˜ì–´ë¥¼ ë…ì¼ì–´ë¡œ ë²ˆì—­í•˜ëŠ” íƒœìŠ¤í¬ ê·¸ë¦¬ê³  ì˜ì–´ë¥¼ ë¶ˆì–´ë¡œ ë²ˆì—­í•˜ëŠ” íƒœìŠ¤í¬ì—ì„œ ê°ê° í›¨ì”¬ ê°œì„ ëœ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "3990.00 -> 4019.92:  í…ŒìŠ¤í¬ì— ëŒ€í•´ì„œ ì™„ì „ížˆ state-of-the-artì˜ ì„±ëŠ¥ì„ ë³´ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ì™€ ê°™ì´ 8ê°œì˜ PBAC GPUë¥¼ ì´ìš©í•´ì„œ ìƒëŒ€ì ìœ¼ë¡œ ë” ì ì€ ì‹œê°„ì„ ë“¤ì—¬ì„œ í•™ìŠµì„ ë§ˆì¹  ìˆ˜ ìžˆì—ˆë‹¤ê³  í•˜ê³ ìš”. ì´ëŠ” ì´ì „ê¹Œì§€ ì œí•œë˜ì—ˆë˜ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ í›¨ì”¬ ë” í•™ìŠµ íš¨ìœ¨ì´ ë†’ë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ëŠ” ë¹„ë‹¨ ê¸°ê³„ ë²ˆì—­ ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‹¤ì–‘í•œ í…ŒìŠ¤í¬ì— ëŒ€í•´ì„œ ì¼ë°˜í™”ê°€ ê°€ëŠ¥í•˜ê³  ì„±ëŠ¥ì´ ìž˜ ë‚˜ì˜¤ëŠ” ê²ƒ ë˜í•œ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ êµ¬ë¬¸ ë¶„ì„ ë¶„ì•¼ì—ì„œì˜ ì´ëŸ¬í•œ ì»¨ìŠ¤í‹°íŠœì–¸ì‹œ\n",
      "4020.00 -> 4049.64:  íŽ„ì‹±í…ŒìŠ¤í¬ì— ëŒ€í•´ì„œë„ ìž˜ ë™ìž‘í•˜ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ì´ì „ì— ì´ì™€ ê°™ì´ RNN ê·¸ë¦¬ê³  LSTM ê·¸ë¦¬ê³  GRLUì™€ ê°™ì€ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì´ ì œì•ˆì´ ë˜ì—ˆê³ ìš”. ì´ëŸ¬í•œ ë„¤íŠ¸ì›Œí¬ë“¤ì€ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì„ ìœ„í•´ì„œ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©ì´ ë˜ê³  ìžˆì—ˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ ê¸°ë³¸ì ìœ¼ë¡œ ì´ëŸ¬í•œ ë¦¬ì»¤ëŸ°íŠ¸ ëª¨ë¸ë“¤ì€ í•œ ë²ˆì— í•œ ë‹¨ì–´ì”© ë„£ëŠ” ë°©ì‹ì²˜ëŸ¼ ì‹œí€€ìŠ¤ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ í† í°ë“¤ì— ëŒ€í•œ ìˆœì„œ ì •ë³´ë¥¼ ë¨¼ì € ì •ë ¬ì‹œí‚¨ ë’¤ì— ì´ê²ƒì„ ë°˜ë³µì ìœ¼ë¡œ ìž…ë ¥ìœ¼ë¡œ ë„£ì–´ì„œ ì´ëŸ¬í•œ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ê°±ì‹ ì‹œí‚¤ëŠ” ë°©ë²•ìœ¼ë¡œ\n",
      "4050.00 -> 4078.96:  ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ëŸ° ì‹ìœ¼ë¡œ ë¦¬ì»¤ëŸ°íŠ¸í•˜ê²Œ ë™ìž‘í•˜ëŠ” ëª¨ë¸ì¸ ê²½ìš° ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ ì¦‰ í† í°ì˜ ê°œìˆ˜ë§Œí¼ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ì— ìž…ë ¥ì„ ë„£ì–´ì•¼ ë˜ê¸° ë•Œë¬¸ì— ë‹¹ì—°ížˆ ë³‘ë ¬ì ì¸ ì²˜ë¦¬ê°€ ì–´ë µë‹¤ëŠ” ë¬¸ì œê°€ ì¡´ìž¬í•˜ê³ ìš”. ë‹¤ì‹œ ë§í•´ ë ˆì´ì–´ì˜ ì•„ì›ƒí’‹ì„ í–‰ë ¬ê¸‰ìœ¼ë¡œ ë°”ë¡œ êµ¬í•  ìˆ˜ ìžˆëŠ” ê²Œ ì•„ë‹ˆë¼ ì¦‰ ë²ˆì—­ì—ì„œëŠ” ë¬¸ìž¥ì˜ ê¸¸ì´ë§Œí¼ ìž…ë ¥ì„ ìˆ˜í–‰í•  í•„ìš”ê°€ ìžˆê¸° ë•Œë¬¸ì— ì´ëŠ” ë©”ëª¨ë¦¬ ë° ì†ë„ ì¸¡ë©´ì—ì„œ ë¹„íš¨ìœ¨ì„±ì„ ì•¼ê¸°í•  ìˆ˜ ìžˆë‹¤ê³  ì§€ì í•˜ê³  ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ì´ì–´ì„œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì´ ë“±ìž¥ì„ í–ˆì—ˆëŠ”ë°ìš”.\n",
      "4080.00 -> 4107.46:  ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ë©´ì„œ ë§¤ë²ˆ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ì–´ë‚¼ ë•Œë§ˆë‹¤ ì†ŒìŠ¤ ë¬¸ìž¥ì˜ ì¶œë ¥ ì •ë³´ ì¤‘ì—ì„œ ì–´ë–¤ ì •ë³´ê°€ ê°€ìž¥ ì¤‘ìš”í•œì§€ì— ëŒ€í•´ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ë„ë¡ í•´ì„œ ê·¸ëŸ¬í•œ ê°€ì¤‘ì¹˜ê°€ ì ìš©ë˜ì–´ ê³±í•´ì§„ ížˆë“ ìŠ¤í…Œì´íŠ¸ ê°’ì„ ì´ìš©í•˜ë„ë¡ í•´ì„œ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ ìˆ˜ ìžˆë‹¤ê³  í–ˆì£ . ë‹¤ë§Œ ì´ëŸ¬í•œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ë„ ê¸°ë³¸ì ìœ¼ë¡œ ì–´ë¢°ëŠ”ê³¼ ê°™ì´ ì‚¬ìš©ë˜ëŠ” ê²½ìš°ê°€ ë§Žì•˜ê³ ìš”. ê·¸ëž˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê·¸ëƒ¥ ë¦¬ì»¤ëŸ°ìŠ¤í•œ íŠ¹ì„± ìžì²´ë¥¼ ì™„ì „í•˜ê²Œ ì œê±°í•´ë²„ë¦° ê²ë‹ˆë‹¤.\n",
      "4110.00 -> 4139.88:  ì „ì ìœ¼ë¡œ ì˜ì¡´í•´ì„œ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë‚´ë³´ë‚¼ ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ê¸° ë•Œë¬¸ì— í•œ ë²ˆì˜ í–‰ë ¬ ê³¡ìœ¼ë¡œ ìœ„ì¹˜ ì •ë³´ê°€ í¬í•¨ëœ ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìžˆë‹¤ëŠ” ì ì—ì„œ ë‹¤ì‹œ ë§í•´ ìˆœì°¨ì ìœ¼ë¡œ ìž…ë ¥ì„ ë„£ì§€ ì•Šì•„ë„ ë˜ê¸° ë•Œë¬¸ì— ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ëŸ¬í•œ íŠ¹ì§•ì„ í™œìš©í–ˆë”ë‹ˆ ì„±ëŠ¥ì´ í›¨ì”¬ ì¢‹ì•„ì§„ ê±¸ í™•ì¸í•  ìˆ˜ê°€ ìžˆê³  8ê°œì˜ P100 GPUë¥¼ ì´ìš©í•´ì„œ í•™ìŠµì„ í•´ë³¸ ê²°ê³¼ í˜„ì‹¤ì ì¸ ì‹œê°„, ì¦‰ 12ì‹œê°„ ë§Œì— ìƒë‹¹ížˆ ì¢‹ì€ ë² ì´ìŠ¤ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìžˆì—ˆë‹¤ê³ \n",
      "4140.00 -> 4160.52:  ìž ê·¸ëž˜ì„œ ê¸°ë°˜ì´ ë˜ê³  ìžˆëŠ” ë‹¤ì–‘í•œ ë°±ê·¸ë¼ìš´ë“œ ë…¼ë¬¸ì„ ì†Œê°œí•˜ê³  ìžˆê³ ìš”. ì´ ì¤‘ì—ì„œ ì…€í”„ ì–´í…ì…˜ì´ë¼ê³  í•˜ëŠ” ê²ƒì€ íƒ€ê²Ÿ ë¬¸ìž¥ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œ ì†ŒìŠ¤ ë¬¸ìž¥ì—ì„œì˜ ížˆë“  ì •ë³´ë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì–´ë– í•œ ë¬¸ìž¥ì´ ìžˆì„ ë•Œ ìžê¸° ìžì‹ ì˜ ë¬¸ìž¥ ìŠ¤ìŠ¤ë¡œì—ê²Œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•´ì„œ ë ˆí”„ë ˆì  í…Œì´ì…˜ì„ ëŸ¬ë‹í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” ê²Œ ì…€í”„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ìž…ë‹ˆë‹¤.\n",
      "4170.00 -> 4198.14:  ì‹œí€€ìŠ¤ì— ëŒ€í•œ ë ˆí”„ë ˆì  í…Œì´ì…˜ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  í‘œí˜„í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” ê²ƒìž…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ I am a teacherë¼ëŠ” í•˜ë‚˜ì˜ ë¬¸ìž¥ì´ ìžˆì„ ë•Œ 4ê°œì˜ ë‹¨ì–´ë“¤ì€ ì„œë¡œê°€ ì„œë¡œì—ê²Œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•´ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ë„ë¡ í•  ìˆ˜ ìžˆë‹¤ëŠ” ê±°ì£ . ê·¸ëž˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ì™€ ê°™ì´ íŠ¸ëžœìŠ¤í¬ë¨¸ëŠ” ì „ì ìœ¼ë¡œ ì´ëŸ¬í•œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì— ê¸°ë°˜í•˜ëŠ” ì‚¬ì‹¤ìƒ ìµœì´ˆì˜ ì‹œí€€ìŠ¤ ê°„ ë³€í˜•ì´ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“¤ì–´ì¤€ ë„¤íŠ¸ì›Œí¬ë¼ê³  í•  ìˆ˜ ìžˆê³  ë³¸ ë…¼ë¬¸ì€ ì´ëŸ¬í•œ ì•„ì´ë””ì–´ë¥¼ í†µí•´ì„œ ë§¤ìš° ì¢‹ì€ ì„±ëŠ¥ì„ ì´ëŒì–´ë‚¼ ìˆ˜ê°€ ìžˆì—ˆê³ ìš”.\n",
      "4200.00 -> 4229.66:  ìµœê·¼ì— ë‚˜ì˜¨ GPTë‚˜ BERTì™€ ê°™ì€ ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ë“¤ì€ ì´ëŸ¬í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ì—ì„œ ì œí•œë˜ì—ˆë˜ ì•„í‚¤í…ì²˜ë¥¼ ë§Žì´ ë”°ë¥´ê³  ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì‹œí€€ìŠ¤ ê°„ ë³€í˜• ëª¨ë¸ì— ëŒ€í•´ì„œ ë§Žì€ ì•„í‚¤í…ì²˜ëŠ” ì¸ì½”ë”, ë””ì½”ë” êµ¬ì¡°ë¥¼ ë”°ë¥´ê³  ìžˆê³ ìš”. ì—¬ê¸°ì—ì„œ 35ë²ˆ ë…¼ë¬¸ ê°™ì€ ê²½ìš°ëŠ” ì›ë³¸ ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤ ë…¼ë¬¸ì„ ì˜ë¯¸í•˜ê³ ìš”. ì´ëŸ° ì‹ìœ¼ë¡œ X1ë¶€í„° Xnê¹Œì§€ ì´ Nê°œì˜ í† í°ìœ¼ë¡œ êµ¬ì„±ëœ ìž…ë ¥ ì‹œí€€ìŠ¤ê°€ ìžˆì„ ë•Œ ì´ê²ƒì„ ì»¨í‹°ë‰´ì–´ìŠ¤í•œ ì–´ë– í•œ ì¸ë² ë”© ë²¡í„°ë¡œì„œ ë°”ê¾¸ì–´ì£¼ê³  ì´ëŸ¬í•œ ì¸ë² ë”© ë²¡í„°ì¸\n",
      "4230.00 -> 4258.16:  ì´ ë””ì½”ë”ëŠ” Y1ë¶€í„° YMê¹Œì§€ ì´ Mê°œì˜ í† í°ìœ¼ë¡œ êµ¬ì„±ëœ ì¶œë ¥ ë¬¸ìž¥ì„ ë§Œë“œëŠ” ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤. ì´ë•Œ ê¸°ë³¸ì ìœ¼ë¡œ RNN êµ¬ì¡°ë¥¼ ë”°ë¥´ê³  ìžˆëŠ” ëª¨ë¸ë“¤ì€ ì˜¤í†  ë¦¬ê·¸ë ˆì‹œë¸Œí•˜ê²Œ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ë§Œí¼ ë„¤íŠ¸ì›Œí¬ì— ìž…ë ¥í•´ ì£¼ì–´ì§€ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ë˜ì—ˆë˜ ì‹¬ë³¼ì„ ì´ìš©í•´ì„œ ë‹¤ìŒë²ˆì— ë‚˜ì˜¬ ì¶œë ¥ê°’ì„ ë§Œë“œëŠ” ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•œë‹¤ëŠ” ê±°ì£ . ì—„ë°€ížˆ ë§í•˜ë©´ íŠ¸ëžœìŠ¤í¬ë¨¸ ë˜í•œ ë§ˆì°¬ê°€ì§€ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë” íŒŒíŠ¸ë¡œ êµ¬ì„±ì´ ë˜ì–´ ìžˆìœ¼ë©°\n",
      "4260.00 -> 4289.92:  í™œìš©í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë‹¨ì§€ ë‹¤ë¥¸ ì ì´ë¼ê³  í•œë‹¤ë©´ ëª¨ë¸ì„ ë¦¬ì»¤ëŸ°íŠ¸í•˜ê²Œ ì´ìš©í•˜ì§„ ì•Šê³  ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ë§Œ í™œìš©í•´ì„œ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì •ë³´ë¥¼ í•œ ë²ˆì— ìž…ë ¥ìœ¼ë¡œ ì¤€ë‹¤ëŠ” ì ì´ ê·¸ íŠ¹ì§•ì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì—¬ê¸° ë³´ì´ëŠ” ê·¸ë¦¼ì´ ì „ì²´ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì•„í‚¤í…ì²˜ë¼ê³  í•  ìˆ˜ ìžˆëŠ”ë°ìš”. ìž ì´ì™€ ê°™ì´ ì–´ë¥¸ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ëŒ€ì‹ ì— ë¬¸ìž¥ ë‚´ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê°ê°ì˜ ë‹¨ì–´ë“¤ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì¸ì½”ë”©í•´ì„œ ìž…ë ¥í•˜ê¸° ìœ„í•´ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ê³ ìš”. ì´ë ‡ê²Œ ìž…ë ¥ ì¸ë² ë”©ê³¼ ê°™ì€ ë””ë©˜ì „ìœ¼ë¡œ í•©ì¹˜ê¸°ë¥¼ ìˆ˜í–‰í•´ì„œ ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ ê²°ê³¼ë¥¼\n",
      "4290.00 -> 4318.86:  ì‹¤ì œ ì¸ë² ë”© ë²¡í„°ë¡œì„œ ì‚¬ìš©ì„ í•˜ê³ ìš”. ì´ì œ ì–˜ê°€ ì´ë ‡ê²Œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ì˜ ê°’ìœ¼ë¡œ ê°ê° ë³µì œê°€ ë˜ì–´ ìž…ë ¥ë©ë‹ˆë‹¤. ì—¬ê¸° ë³´ì´ëŠ” ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ì…€í”„ ì–´í…ì…˜ìœ¼ë¡œ ë™ìž‘ì„ í•˜ë©° ë³´ì‹œëŠ” ë°”ì™€ ê°™ì´ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ì˜ ê°’ì´ ëª¨ë‘ ë™ì¼í•©ë‹ˆë‹¤. ë˜í•œ ì–´í…ì…˜ì€ ìž…ë ¥ê³¼ ì¶œë ¥ì´ ì°¨ì›ì´ ê°™ë‹¤ê³  ë§ì”€ë“œë ¸ì£ . ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ì´ë ‡ê²Œ ë“¤ì–´ê°ˆ ë•Œì˜ ì°¨ì›ê³¼ ì´ ì–´í…ì…˜ì„ ë‚˜ì™”ì„ ë•Œì˜ ì°¨ì›ì€ ë™ì¼í•˜ê³ ìš”. ë§ˆì°¬ê°€ì§€ë¡œ ë ˆì§€ëŒ ì»¤ë„¥ì…˜ì„ ìˆ˜í–‰í•œ ë’¤ì— ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•´ì£¼ê³  ì´ë ‡ê²Œ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ë¥¼ ê±°ì¹˜ê³  ë‹¤ì‹œ í•œë²ˆ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•  ë•Œê¹Œì§€\n",
      "4320.00 -> 4349.90:  ë ˆì´ì–´ì— ëŒ€í•œ ìž…ë ¥ê³¼ ì¶œë ¥ì˜ ë””ë©˜ì €ëŠ” ê°™ë‹¤ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ì œ ì´ëŸ¬í•œ ê³¼ì • ìžì²´ë¥¼ ì´ në²ˆë§Œí¼ ë°˜ë³µí•´ì„œ ì´ nê°œì˜ ì¸ì½”ë” ë ˆì´ì–´ê°€ ì°¨ê³¡ì°¨ê³¡ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰ì´ ë¼ì„œ ë§ˆì§€ë§‰ì— ë‚˜ì˜¨ ê·¸ ì¶œë ¥ê°’ì„ ì´ì™€ ê°™ì´ ë§¤ ì¸ì½”ë” ë””ì½”ë” ì–´í…ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“ ë‹¤ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ë˜í•œ ì´ë ‡ê²Œ ë””ì½”ë” íŒŒíŠ¸ì—ì„œëŠ” ì§€ê¸ˆê¹Œì§€ ì¶œë ¥ëœ ë‹¨ì–´ë§Œ ì–´í…ì…˜ í•  ìˆ˜ ìžˆë„ë¡ í•˜ê¸° ìœ„í•´ì„œ í•™ìŠµì„ ìˆ˜í–‰í•  ë•Œ ì´ë ‡ê²Œ ë§ˆìŠ¤í¬ë¥¼ ì”Œì›Œì„œ ë’¤ìª½ì— ìžˆëŠ” ë‹¨ì–´ëŠ” ë¯¸ë¦¬ ì•Œì§€ ëª»í•˜ë„ë¡ ë§‰ëŠ” ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì´ ì •ìƒì ì¸ ë°ì´í„°ë§Œì„ í•™ìŠµí• \n",
      "4350.00 -> 4379.88:  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì£¼ê³ ìš”. ë§ˆì°¬ê°€ì§€ë¡œ ì—¬ê¸° ë³´ì´ëŠ” ì´ ë””ì½”ë”ì˜ ì²« ë²ˆì§¸ attentionì—ì„œëŠ” queryì™€ key valueì˜ ê°’ì´ ê°™ê¸° ë•Œë¬¸ì— self-attentionì´ ìˆ˜í–‰ëœë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ë‘ ë²ˆì§¸ attentionì—ì„œëŠ” ì´ queryì˜ ê°’ì´ ë””ì½”ë”ì— ìžˆê¸° ë•Œë¬¸ì— ê°ê°ì˜ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ ì´ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ì–´ë– í•œ ì •ë³´ë¥¼ ì°¸ê³ í•˜ë©´ ì¢‹ì€ì§€ë¥¼ attentionì´ ìˆ˜í–‰í•œë‹¤ê³  í•  ìˆ˜ ìžˆëŠ” ê²ë‹ˆë‹¤. ì¦‰ ë‹¤ì‹œ ë§í•´ ì´ keyì™€ valueì˜ ê°’ë“¤ì€ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ë°›ìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ë§ˆì°¬ê°€ì§€ë¡œ feedforward ë ˆì´ì–´ë¥¼ ê±°ì¹œ ë’¤ì— ë§ˆì§€ë§‰ì— linear ë ˆì´ì–´ë¥¼ ê±°ì¹˜ê³  softmaxë¥¼ ì·¨í•´ì„œ ì‹¤ì œë¡œ ê°ê°ì˜ ì¶œë ¥ ë¬¸ìž¥ì˜\n",
      "4380.00 -> 4407.04:  í¬í•¨ëœ ë‹¨ì–´ë“¤ì´ ì‹¤ì œë¡œ ì–´ë–¤ ë‹¨ì–´ì— í•´ë‹¹í•˜ëŠ”ì§€ êµ¬í•  ìˆ˜ ìžˆë„ë¡ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜ ì´ì œ ì—¬ê¸°ì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ ë ˆì´ë¸” ìŠ¤ë¬´ì‹±ì„ ì ìš©í•´ì„œ ì •ê·œí™” íš¨ê³¼ë¥¼ ë”í•´ì„œ ì„±ëŠ¥ì„ ë” ë†’ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ëŸ¬í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ ì•„í‚¤í…ì²˜ëŠ” í–¥í›„ ë§Žì€ ë…¼ë¬¸ì— ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì„¤ëª…í–ˆë˜ ë‚´ìš©ê³¼ ë™ì¼í•˜ê²Œ ì¸ì½”ë” íŒŒíŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ ì¸ì½”ë” ë ˆì´ì–´ê°€ ì¤‘ì²©ì´ ë˜ì–´ ì‚¬ìš©ì´ ë˜ê³ ìš”. ë³´ì‹œëŠ” ë°”ì™€ ê°™ì´ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ 6ë²ˆ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ ì¤‘ì²©í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  ë§í–ˆê³ ìš”.\n",
      "4410.00 -> 4435.02:  ê±°ì¹˜ê¸° ì „ì— ê·¸ ìž…ë ¥ ê°’ìœ¼ë¡œ ì•„ì´ë´í‹°í‹° ë§µí•‘ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ ì£¼ì—ˆê³ ìš”. ë˜í•œ ì´ì™€ ê°™ì´ ì¸ë² ë”© ë²¡í„°ì˜ ì°¨ì›ì€ 512ì°¨ì›ìœ¼ë¡œ ì„¤ì •í–ˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ë””ì½”ë”ì—ì„œë„ ì´ 6ê°œì˜ ë””ì½”ë” ë ˆì´ì–´ë¥¼ ìŒ“ì„ ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì—ˆê³  ì‹¤ì œ êµ¬í˜„ìƒì—ì„œ ì´ì™€ ê°™ì´ ì¸ì½”ë”ì™€ ê°™ì€ ë ˆì´ì–´ì˜ ê°œìˆ˜ë¥¼ ê°€ì§€ë„ë¡ ë§Œë“œëŠ” ê²½ìš°ê°€ ë§ŽìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ë•Œ ì¸ì½”ë”ì˜ ì•„ì›ƒí’‹ ê°’ì— ëŒ€í•´ì„œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“ ë‹¤ê³  í–ˆê³ ìš”.\n",
      "4440.00 -> 4469.46:  ì¢‹ì€ ê¸€ë¡œë²Œ ì˜µí‹°ë§ˆë¥¼ ì°¾ì„ ìˆ˜ ìžˆë„ë¡ ëª¨ë¸ì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ì“°ì´ëŠ” ì…€í”„ ì–´í…ì…˜ì—ì„œëŠ” ì´ì „ì— ë“±ìž¥í•œ ë‹¨ì–´ë“¤ë§Œ ì°¸ê³ í•  ìˆ˜ ìžˆëŠ” í˜•íƒœë¡œ ë§ˆìŠ¤í¬ë¥¼ ì”Œì›Œì„œ ë§ˆìŠ¤í¬ê°€ ë¶™ì€ í˜•íƒœì˜ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì—¬ê¸°ì—ì„œëŠ” ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•´ ì„¤ëª…í•˜ê³  ìžˆëŠ”ë°ìš”. ì´ë•Œ í•˜ë‚˜ì˜ ì¿¼ë¦¬ëŠ” ë§ ê·¸ëŒ€ë¡œ ì–´ë– í•œ ì§ˆë¬¸ì„ ë‚ ë¦¬ëŠ” ê²ë‹ˆë‹¤. íŠ¹ì • í‚¤ì—ê²Œ ë¬¼ì–´ë³´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ì¦‰ ì´ë•Œ ì¿¼ë¦¬ë¼ê³  í•˜ëŠ” ê²ƒì€ ë§ì”€ë“œë ¸ë“¯ì´ ì§ˆë¬¸ì„ í•˜ëŠ” ì£¼ì²´ë¼ê³  í•  ìˆ˜ ìžˆê³ ìš”. ì´ë•Œ ì´ í‚¤ëŠ” ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ëŒ€ìƒì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "4470.00 -> 4498.16:  ì˜ˆë¥¼ ë“¤ì–´ì„œ ì‚¬ëž‘í•´ë¼ëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ê°€ ìƒì„±ë˜ê¸° ìœ„í•´ì„œ I love youë¼ëŠ” ë¬¸ìž¥ì— í¬í•¨ëœ ë‹¨ì–´ë“¤ ì¤‘ì— ì–´ë–¤ ë‹¨ì–´ê°€ ê°€ìž¥ ì¤‘ìš”í–ˆëŠ”ì§€ë¥¼ ë¬¼ì–´ë³´ëŠ” ë°©ì‹ìœ¼ë¡œ ê°ê°ì˜ ì¿¼ë¦¬ê°€ í‚¤ì— ëŒ€í•´ì„œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì—¬ê¸° ë³´ì´ëŠ” ê·¸ë¦¼ì´ ì‹¤ì œë¡œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì„ ìž˜ ì„¤ëª…í•˜ê³  ìžˆëŠ” ê·¸ë¦¼ì´ê³ ìš”. ì´ëŸ¬í•œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ê°ê°ì˜ ì¸ì½”ë”ì™€ ë””ì½”ë” ë ˆì´ì–´ì—ì„œ ì‚¬ìš©ëœë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ë‚´ë¶€ì ìœ¼ë¡œ scaled.product ì–´í…ì…˜ì„ ê°€ì§€ê³  ìžˆëŠ”ë°ìš”.\n",
      "4500.00 -> 4529.94:  ê°™ì´ ìƒê²¼ìŠµë‹ˆë‹¤. ìž ì´ë•Œ ì´ë ‡ê²Œ ì¿¼ë¦¬ì™€ í‚¤ì™€ ë°¸ë¥˜ê°€ ë“¤ì–´ì˜¤ê²Œ ë˜ë©´ ê°ê°ì˜ ì¿¼ë¦¬ê°€ ì´ í‚¤ì— ëŒ€í•´ì„œ ì§ˆë¬¸ì„ í•˜ëŠ” ë‚´ìš©ì´ ë°”ë¡œ ì´ë ‡ê²Œ í–‰ë ¬ ê³ ë¶€ë¡œ ì´ë£¨ì–´ì§€ê³ ìš”. ë˜í•œ ì†Œí”„íŠ¸ë§¥ìŠ¤ì— ë“¤ì–´ê°€ëŠ” ê°’ì— ëŒ€í•´ì„œ ìŠ¤ì¼€ì¼ë§ì„ í•˜ê¸° ìœ„í•´ ìŠ¤ì¼€ì¼ ë ˆì´ì–´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ë•Œ ìŠ¤ì¼€ì¼ ë ˆì´ì–´ëŠ” ì—¬ê¸° ë“¤ì–´ì˜¤ëŠ” í‚¤ì˜ ì°¨ì›ì— ë£¨íŠ¸ë¥¼ ì”Œìš´ ê°’ì„ ë‚˜ëˆ ì¤„ ìˆ˜ ìžˆëŠ” í˜•íƒœë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë˜í•œ ì´ë ‡ê²Œ ë§ˆìŠ¤í¬ ë²¡í„° ê°™ì€ ê²½ìš°ëŠ” í•„ìš”í•  ë•Œ ì‚¬ìš©ì„ í•˜ê³ ìš”. ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì·¨í•´ì„œ ê°ê°ì˜ í‚¤ì— ëŒ€í•´ì„œ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ì— ëŒ€í•œ ê°’ì„ í™•ë¥  í˜•íƒœë¡œ í‘œí˜„í•  ìˆ˜ ìžˆë„ë¡\n",
      "4530.00 -> 4559.20:  ì´ì œ ê·¸ëŸ¬í•œ í™•ë¥  ê°’ì„ ê°ê° ì‹¤ì œ valueì™€ ê³±í•´ì„œ attention value ê°’ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìžˆëŠ” ê²ë‹ˆë‹¤. ì´ì œ ì´ëŸ¬í•œ ê³¼ì •ë“¤ì´ ê°ê°ì˜ headë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥´ê²Œ ì´ë£¨ì–´ì§„ ë’¤ì— ë‹¤ì‹œ ì´ë ‡ê²Œ ê²°ê³¼ë¥¼ í•©ì³ì„œ linear layerë¥¼ ê±°ì¹œ ë’¤ì— output ê°’ì„ ë‚´ë³´ë‚¸ë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ìž ì´ë•Œ ì‹¤ì œ êµ¬í˜„ìƒìœ¼ë¡œëŠ” ì´ë ‡ê²Œ ìž…ë ¥ ê°’ì´ ë“¤ì–´ì™”ì„ ë•Œ ìž…ë ¥ ê°’ì€ ì´ vì™€ kì™€ keyì— ëŒ€í•´ì„œ ê°ê° ë³µì œê°€ ë˜ì–´ì„œ ë“¤ì–´ê°€ë„ë¡ í•  ìˆ˜ ìžˆê³  ì´ë•Œ ê°ê°ì˜ linear layerëŠ” embedding ì°¨ì›ì„ key, query, valueì˜ ì°¨ì›ìœ¼ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.\n",
      "4560.00 -> 4589.94:  ë‚˜ì˜¨ ê°’ë“¤ì„ ê°ê° ì–´ë–¤ ì°¨ì›ì„ ìˆ˜í–‰í•œ ë’¤ì— ë™ì¼í•œ ì°¨ì›ì´ ë‚˜ì˜¤ê²Œ ë˜ë©´ ë‹¤ì‹œ ì–˜ë„¤ë“¤ì„ ë¬¶ì–´ì£¼ì–´ì„œ ê¸°ì¡´ì˜ ì¸ë² ë”© ì°¨ì›ê³¼ ê²°ê³¼ì ìœ¼ë¡œ ê°™ì€ ì°¨ì›ì´ ë  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì–´ì¤€ë‹¤ëŠ” ê±°ì£ . ë˜í•œ ì—¬ê¸°ì—ì„œ ì‹¤ì œë¡œ êµ¬í˜„í•  ë•ŒëŠ” ì˜ˆë¥¼ ë“¤ì–´ì„œ ì´ë ‡ê²Œ ìž…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì¸ë² ë”© ì°¨ì›ì´ 512ë¼ê³  í•˜ê³  ì´ hê°€ 8ì´ë¼ê³  í•œë‹¤ë©´ ê°ê°ì˜ ë¦¬ë‹ˆì–¼ ë ˆì´ì–´ëŠ” 64ì°¨ì›ìœ¼ë¡œ ë§µí•‘ì„ í•´ì£¼ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë‹¤ë§Œ ì—¬ê¸°ì—ì„œ ì‹¤ì œë¡œ êµ¬í˜„í•  ë•ŒëŠ” ê·¸ëƒ¥ 512 ê³±í•˜ê¸° 512ë¡œ ë³‘ë ¬ì ìœ¼ë¡œ ê·¸ëƒ¥ í•œ ë²ˆì˜ í–‰ë ¬ê¸‰ì„ êµ¬í•œ ë’¤ì— ê·¸ ê²°ê³¼ ê°’ì„ 8ê°œë¡œ ìª¼ê°œì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤.\n",
      "4590.00 -> 4618.82:  ìž ê·¸ëž˜ì„œ ì‹¤ì œë¡œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ í•µì‹¬ì´ ë˜ëŠ” ìŠ¤ì¼€ì¼ë¦¬ë‹· í”„ë¡œë• ì–´í…ì…˜ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ê³  ìžˆëŠ”ë°ìš”. ìž í™•ì¸í•´ë³´ì‹œë©´ ì´ë ‡ê²Œ ì‹¤ì œë¡œëŠ” í–‰ë ¬ í˜•íƒœë¡œ í•œ ë²ˆì— ì¿¼ë¦¬ì™€ í‚¤ë“¤ì„ ë¬¶ì–´ì„œ ë³‘ë ¬ì ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ê°€ ìžˆê³ ìš”. ë§ì”€ë“œë¦° ë‚´ìš©ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë¨¼ì € ì¿¼ë¦¬ëž‘ í‚¤ëž‘ ê³±í•˜ê³ ìš”. ì´ë•Œ ì¿¼ë¦¬ì™€ í‚¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì°¨ì›ì´ ê°™ë„ë¡ ë§Œë“¤ì–´ì„œ ì´ì™€ ê°™ì´ ê³±ì…ˆì´ ìˆ˜í–‰ë  ìˆ˜ ìžˆë„ë¡ ë§Œë“­ë‹ˆë‹¤. ì´ì œ ê·¸ëž˜ì„œ ìŠ¤ì¼€ì¼ íŒ©í„°ë§Œí¼ ë‚˜ëˆ ì¤€ ë’¤ì— í™•ë¥ ê°’ì„ êµ¬í•˜ê³  ì–˜ë¥¼ ì‹¤ì œë¡œ ì´ ë°¸ë¥˜ê°’ê³¼ í–‰ë ¬ê¸‰ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆì£ .\n",
      "4620.00 -> 4647.68:  ì´ëŸ¬í•œ ë°©ì‹ì€ additive attentionê³¼ëŠ” ì•½ê°„ êµ¬ë³„ë˜ëŠ” ë°©ì‹ì¸ë°ìš”. ë°”ë¡œ ì—¬ê¸° í™•ì¸í•´ë³´ì‹œë©´ ì´ë ‡ê²Œ í‚¤ëž‘ ì¿¼ë¦¬ë¥¼ ê·¸ëƒ¥ ê³±í•´ê°€ì§€ê³  í•œ ë²ˆì— attentionì„ êµ¬í•  ìˆ˜ê°€ ìžˆìŠµë‹ˆë‹¤. ì‚¬ì‹¤ ìš°ë¦¬ê°€ ì•žì„œ í™•ì¸í–ˆë˜ sequence to sequenceì˜ attention ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í–ˆì„ ë•ŒëŠ” ì´ ì¿¼ë¦¬ì™€ í‚¤ê°€ íŠ¹ì •í•œ í–‰ë ¬ ê³±ì— í•¨ê»˜ ìž…ë ¥ë˜ëŠ” í˜•íƒœë¡œ ë™ìž‘ì„ í–ˆì—ˆëŠ”ë°ìš”. ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ ì¿¼ë¦¬ì™€ í‚¤ë¥¼ ë°”ë¡œ ì„œë¡œ ê³±í•˜ë„ë¡ ë§Œë“¤ì–´ì„œ not product attention í˜•íƒœë¡œ ì‚¬ìš©í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìžˆê³ ìš”. ë…¼ë¬¸ì—ì„  ì´ì™€ ê°™ì´ not product attentionì„ ì‚¬ìš©í–ˆì„ ë•Œ\n",
      "4650.00 -> 4677.34:  ê²ƒì´ í”„ëž™í‹°ì»¬ë¦¬ ë¹ ë¥´ê³  ê³µê°„ íš¨ìœ¨ì ì´ì—ˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ë ‡ê²Œ ë‚´ì ì„ ì´ìš©í•˜ëŠ” ë°©ì‹ì¸ ê²½ìš° ìŠ¤ì¼€ì¼ë§ì„ í•˜ì§€ ì•Šìœ¼ë©´ ê²°ê³¼ê°€ ë§Žì´ ì•ˆ ì¢‹ì•˜ë‹¤ê³  í•˜ëŠ”ë°ìš”. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê·¸ëŸ¬í•œ ì´ìœ ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¶”ì¸¡í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë°”ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ê°™ì€ ê²½ìš°ëŠ” ì´ ì¤‘ê°„ ë¶€ë¶„ì´ ê·¸ëž˜ë””ì–¸íŠ¸ê°€ ìƒëŒ€ì ìœ¼ë¡œ í¬ê³  ì‚¬ì´ë“œë¡œ ê°€ë©´ ê°ˆìˆ˜ë¡ ê·¸ëž˜ë””ì–¸íŠ¸ê°€ ìž‘ì•„ì§€ëŠ” íŠ¹ì§•ì„ ê°€ì§€ê³  ìžˆëŠ”ë°ìš”. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ê°’ì´ ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ í•˜ë©´ ë„ˆë¬´ ê·¸ëž˜ë””ì–¸íŠ¸ê°€ ìž‘ì•„ì§ˆ ìˆ˜ ìžˆì–´ì„œ í•™ìŠµì´ ìž˜ ì•ˆë  ìˆ˜ê°€ ìžˆê² ì£ .\n",
      "4680.00 -> 4707.78:  ê³±í•´ì£¼ì–´ì„œ ê°’ì„ ìž‘ê²Œ ë§Œë“¤ì–´ í•™ìŠµì´ ìž˜ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤. ë˜í•œ ë§ì”€ë“œë ¸ë“¯ì´ ê¸°ì¡´ì˜ ì¸ë² ë”© ì°¨ì›ì„ Dëª¨ë¸ì´ë¼ê³  í–ˆì„ ë•Œ ì–˜ë¥¼ Hë§Œí¼ ì¦‰ í—¤ë“œì˜ ê°œìˆ˜ë§Œí¼ ë‚˜ëˆ„ì–´ì„œ ê°ê° í‚¤ë‚˜ ë°¸ë¥˜, ì½”ë¦¬ì•„ ê°™ì€ ì°¨ì›ë“¤ì„ ê²°ì •í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆê³ ìš”. ì´ëŸ¬í•œ ë²¡í„°ë“¤ì€ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì´ì–´ë¶™ì—¬ì§€ê¸° ë•Œë¬¸ì— ê²°ê³¼ì ìœ¼ë¡œëŠ” ìž…ë ¥ê³¼ ì¶œë ¥ì˜ ë””ë©˜ì „ì´ ê°™ë„ë¡ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì€ ë§ ê·¸ëŒ€ë¡œ í—¤ë“œê°€ ì—¬ëŸ¬ê°œë¼ëŠ” ì˜ë¯¸ë¼ì„œ ì´ë ‡ê²Œ ë©€í‹°í—¤ë“œë¼ê³  ì´ë¦„ì´ ë¶™ì€ ê±°ê³ ìš”.\n",
      "4710.00 -> 4739.94:  ì „ë¶€ ë‹¤ attentionì„ ìˆ˜í–‰í•œ ê°’ì„ ë‹¤ì‹œ ì´ë ‡ê²Œ ì´ì–´ë¶™ì¸ ë’¤ì— out ê°’ì„ ë‚´ë³´ë‚´ê¸° ìœ„í•´ì„œ í–‰ë ¬ê¸‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ì œ ì—¬ê¸°ì—ì„œ ì´ i ê°’ì€ ê°ê°ì˜ headì— ëŒ€í•œ ì¸ë±ìŠ¤ë¼ê³  í•  ìˆ˜ ìžˆê³ ìš”. ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ì‹¤ì œë¡œ callì´ë‚˜ keyë¥¼ ë§Œë“¤ê¸° ìœ„í•œ í–‰ë ¬ì˜ í¬ê¸°ëŠ” dmodel ê³±í•˜ê¸° dkê°€ ì‚¬ìš©ì´ ë˜ê³ ìš”. ë‹¤ì‹œ ë§í•´ì„œ dmodel ì°¨ì›ì˜ embedding vectorë¥¼ dk ì°¨ì›ì˜ callì´ì•¼ key vectorì˜ ì°¨ì›ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë¬¼ë¡  ë§ì”€ë“œë ¸ë“¯ì´ ì‹¤ì œë¡œ êµ¬í˜„í•  ë•ŒëŠ” ê·¸ëƒ¥ dmodel ê³±í•˜ê¸° dmodelë§Œí¼ì˜ í–‰ë ¬ì„ ê³±í•œ ë’¤ì—\n",
      "4740.00 -> 4767.84:  ê·¸ëƒ¥ ê²°ê³¼ ê°’ ìžì²´ë¥¼ ë‚˜ëˆ„ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìžˆëŠ” ê±°ì˜ˆìš”. ê·¸ëž˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” D ëª¨ë¸ì„ 512 ê·¸ë¦¬ê³  Hë¥¼ 8ë¡œ ì„¤ì •í•´ì„œ ì¿¼ë¦¬ ë²¡í„°ì˜ ì°¨ì›ì„ 64ë¼ê³  ì„¤ì •ì„ í–ˆê³ ìš”. ë˜í•œ ì—„ë°€ížˆ ë§í•˜ë©´ ì´ ë°¸ë¥˜ ê°’ ê°™ì€ ê²½ìš°ëŠ” ì°¨ì›ì„ ì¿¼ë¦¬ í˜¹ì€ í‚¤ì™€ ë˜‘ê°™ì´ ë§žì¶œ í•„ìš”ëŠ” ì—†ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì´ë ‡ê²Œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ì „ë¶€ ë‹¤ ê°™ì€ ì°¨ì›ì¸ 64ì°¨ì›ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ì œ ì´ëŸ¬í•œ ì–´í…ì…˜ì´ ì‹¤ì œë¡œ ì–´ë””ì— ì“°ì´ëŠ”ì§€ í™•ì¸í•´ ë³´ì‹œë©´ ì•žì„œ ë§ì”€ë“œë ¸ë“¯ì´ ì´ 3ê°€ì§€ ìœ„ì¹˜ì—ì„œ ì‚¬ìš©ì´ ë˜ëŠ”ë°ìš”.\n",
      "4770.00 -> 4796.82:  í—¤ë“œê°€ ì—¬ëŸ¬ê°œì¸ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì´ë©° ì‚¬ìš©ë˜ëŠ” ìœ„ì¹˜ì— ë”°ë¼ì„œ 3ê°€ì§€ë¡œ êµ¬ë¶„ë˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë¨¼ì € ì¸ì½”ë” ë””ì½”ë” ì–´í…ì…˜ì€ ë””ì½”ë” íŒŒíŠ¸ì—ì„œ ì‚¬ìš©ì´ ë˜ëŠ” ê±°ê³ ìš”. ì´ë•Œ ì´ ì¿¼ë¦¬ëŠ” ì´ ë””ì½”ë”ì—ì„œ ì˜¤ëŠ” ê²ƒì´ê³  ì´ë•Œ ì´ í‚¤ì™€ ë°¸ë¥˜ ê°’ì€ ì¸ì½”ë”ì˜ ì¶œë ¥ íŒŒíŠ¸ì—ì„œ ê°€ì ¸ì˜¨ë‹¤ê³  í–ˆì–´ìš”. ì´ ë‚´ìš©ì€ ë‹¤ì‹œ ë§í•˜ë©´ ìš°ë¦¬ê°€ ì¶œë ¥ ë‹¨ì–´ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ ì†ŒìŠ¤ ë¬¸ìž¥ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ ì–´ë–¤ ì •ë³´ì— ë³´ë‹¤ ì´ˆì ì„ ë§žì¶”ë©´ ë˜ëŠ”ì§€ë¥¼ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì´ë¼ê³  ë¹„ìœ í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆì£ .\n",
      "4800.00 -> 4828.06:  í‚¤ì™€ ë°¸ë¥˜ê°€ ëª¨ë‘ ê°™ì€ í˜•íƒœë¥¼ ì˜ë¯¸í•˜ê³ ìš”. ë°”ë¡œ ì¸ì½”ë” íŒŒíŠ¸ì—ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©ì´ ë©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë””ì½”ë” íŒŒíŠ¸ ë˜í•œ ë§ˆì°¬ê°€ì§€ë¡œ ë§¨ ì²˜ìŒì— ìž…ë ¥ ìž„ë² ë”©ì´ ë“¤ì–´ì™”ì„ ë•Œ ì…€í”„ ì–´í…ì…˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆëŠ”ë°ìš”. ì´ì œ ì—¬ê¸°ì„œëŠ” ë§ˆìŠ¤í¬ë¥¼ ì”Œì›Œì„œ ë‹¤ì‹œ ë§í•´ ì†Œí”„íŠ¸ë§¥ìŠ¤ì— ë“¤ì–´ê°€ëŠ” ê°’ì´ ë§ˆì´ë„ˆìŠ¤ ë¬´í•œì´ ë  ìˆ˜ ìžˆë„ë¡ í•´ì„œ 0%ê°€ ë¶€ì—¬ë  ìˆ˜ ìžˆë„ë¡ í•˜ì—¬ ê°ê°ì˜ ë‹¨ì–´ê°€ ì•žë¶€ë¶„ì— ìžˆëŠ” ë‹¨ì–´ì— ëŒ€í•œ ì •ë³´ë§Œ ì°¸ê³ í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì—ˆë‹¤ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ë˜í•œ ì´ì™€ ê°™ì´ í¬ì§€ì…˜ ì™€ì´ì¦ˆ í”¼ë“œí´ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆëŠ”ë°ìš”.\n",
      "4830.00 -> 4859.14:  í„°ë¬´ëŠ” ë ë£¨ ì•¡í‹°ë² ì´ì…˜ì— ëŒ€í•œ ë‚´ìš©ì„ ë³´ì—¬ì£¼ê³  ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ìž…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì€ ëª¨ë‘ ê°™ì€ ì°¨ì›ì„ ê°€ì§€ê²Œ ë˜ê³ ìš”. ì´ë ‡ê²Œ ì¤‘ê°„ì— ížˆë“¬ ë””ë©˜ì „ìœ¼ë¡œ ì•½ê°„ ê³ ì°¨ì› ê³µê°„ì— ë§µí•‘ì´ ë˜ì—ˆë‹¤ê°€ ì¶œë ¥ ë ˆì´ì–´ë¥¼ í†µí•´ì„œ í”¼ë“œí´ë“œê°€ ìˆ˜í–‰ë  ìˆ˜ ìžˆë„ë¡ ë§Œë“ ë‹¤ê³  ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤. ë˜í•œ ë§ˆì°¬ê°€ì§€ë¡œ ì¸ë² ë”©ê³¼ ì†Œí”„íŠ¸ë§¥ìŠ¤ê°€ ì‚¬ìš©ì´ ë˜ì—ˆëŠ”ë°ìš”. ì´ê±´ ì´ì œ ê¸°ë³¸ì ìœ¼ë¡œ ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤ ëª¨ë¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‚´ìš©ê³¼ ê°™ë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëƒ¥ ì¸í’‹ ë””ë©˜ì „, ì¦‰ íŠ¹ì •í•œ ì–¸ì–´ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ì™€ ë¹„ë¡€í•˜ëŠ”\n",
      "4865.16 -> 4889.98:  ë˜í•œ ì´ì–´ì„œ íŠ¸ëžœìŠ¤í¬ë¨¸ì—ì„œëŠ” ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ë§Œ ì „ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ë•Œë¬¸ì— ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ê°’ì„ ê°™ì´ ì£¼ê¸° ìœ„í•´ì„œ ì¸ì½”ë”© ì •ë³´ë¥¼ ê°™ì´ ë”í•´ì„œ ë„£ì–´ì¤„ ìˆ˜ ìžˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ë¦¬ì»¤ëŸ°ìŠ¤ ë° ì»¨ë³¼ë£¨ì…˜ ë‘˜ ë‹¤ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°™ì´ ë„£ì–´ì¤„ í•„ìš”ê°€ ìžˆëŠ” ê²ë‹ˆë‹¤. ê·¸ëž˜ì„œ ë²• ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ì¸ê³¼ ì½”ì‚¬ì¸ê³¼ ê°™ì€ ì£¼ê¸°í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ìž…ë ¥ì„ ë„£ì—ˆë‹¤ê³  í•˜ê³ ìš”. ë§ì”€ë“œë ¸ë“¯ì´ ìš°ë¦¬ê°€ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ë„£ì–´ì¤„ ë•Œ\n",
      "4890.00 -> 4919.86:  ê¼­ ì‚¬ì¸ì´ë‚˜ ì½”ì‚¬ì¸ í•¨ìˆ˜ë¥¼ ì´ëŸ¬í•œ í˜•íƒœë¡œ ì‚¬ìš©í•  í•„ìš”ëŠ” ì—†ê³ ìš”. ì´ëŸ° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì´ëŸ¬í•œ ì¸ë² ë”© ë ˆì´ì–´ ë˜í•œ ìš°ë¦¬ê°€ ë³„ë„ë¡œ í•™ìŠµí•˜ë„ë¡ ë§Œë“¤ì–´ì„œ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•  ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë ‡ê²Œ í•™ìŠµì´ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¸ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•´ë´¤ë‹¤ê³  í•˜ëŠ”ë°ìš”. ì‹¤ì œë¡œ ì„±ëŠ¥ìƒì—ëŠ” ì°¨ì´ê°€ ì—†ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ì‚¬ì‹¤ ê·¸ë ‡ê¸° ë•Œë¬¸ì— ìš°ë¦¬ê°€ íŒŒì´í†¨ì¹˜ì™€ ê°™ì€ í”„ë ˆìž„ì›ì„ ì‚¬ìš©í•  ë•Œ ê·¸ëƒ¥ í•™ìŠµí•˜ë„ë¡ í•˜ëŠ” ê²Œ êµ¬í˜„ì´ ë” ì‰¬ìš¸ ìˆ˜ë„ ìžˆê¸° ë•Œë¬¸ì— ì‹¤ì œë¡œ ìš°ë¦¬ê°€ ì•„ê¹Œ ì‹¤ìŠµì„ ì§„í–‰í–ˆì„ ë•Œ ë³„ë„ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ì¸ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©ì„ í–ˆë˜ ê²ë‹ˆë‹¤.\n",
      "4920.00 -> 4946.72:  ë‹¤ë§Œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ì •ì—°íŒŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ë³´ë‹¤ ê¸´ ì‹œí€€ìŠ¤ê°€ ë“¤ì–´ì™”ì„ ë•Œ ì„±ëŠ¥ì´ ë” ìž˜ ë‚˜ì˜¬ ìˆ˜ ìžˆë‹¤ê³  ì–¸ê¸‰í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ì´ì–´ì„œ ì„¹ì…˜ 4ì—ì„œëŠ” ì´ëŸ¬í•œ ì…€í”„ì–´í…ì…˜ì´ ì™œ ë” ìœ ë¦¬í•œê°€ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ê³  ìžˆëŠ”ë°ìš”. ë³¸ ë…¼ë¬¸ì˜ ì €ìžë“¤ì€ ì„¸ ê°€ì§€ì˜ ì–´ë– í•œ ì—´ë§í•˜ëŠ” ê·¸ëŸ¬í•œ ìž¥ì ë“¤ì„ ëª©í‘œë¡œ ë‘ê³  ì´ëŸ¬í•œ ì…€í”„ì–´í…ì…˜ì„ ê³ ì•ˆí–ˆë‹¤ê³  ë§í•˜ê³  ìžˆëŠ”ë°ìš”. ì²« ë²ˆì§¸ë¡œëŠ” ê°ê°ì˜ ë ˆì´ì–´ë§ˆë‹¤ ê³„ì‚° ë³µìž¡ë„ê°€ ì¤„ì–´ë“ ë‹¤ëŠ” ìž¥ì ì´ ìžˆìŠµë‹ˆë‹¤.\n",
      "4950.00 -> 4979.26:  ë§ˆì§€ë§‰ìœ¼ë¡œ ë¡± ë ˆì¸ì§€ ë””íŽœë˜ì‹œì— ëŒ€í•´ì„œë„ ìž˜ ì²˜ë¦¬í•  ìˆ˜ ìžˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ìž ê·¸ëž˜ì„œ ì´ë ‡ê²Œ ìœ„ìª½ì— ë³´ì´ëŠ” í…Œì´ë¸”ì´ RNNì„ ì‚¬ìš©í–ˆì„ ë•Œì™€ ì»¨ë³¼ë£¨ì…˜ì„ ì‚¬ìš©í–ˆì„ ë•Œ ê·¸ë¦¬ê³  ì´ë ‡ê²Œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í–ˆì„ ë•Œì— ëŒ€í•œ íš¨ìœ¨ì„±ì„ ë¶„ì„í•˜ê³  ìžˆëŠ” ê±´ë°ìš”. ì´ë•Œ Nì€ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ ì¦‰ ë‹¨ì–´ì˜ ê°œìˆ˜ë¼ê³  í•  ìˆ˜ ìžˆê³ ìš”. ì´ë•Œ í™•ì¸í•´ ë³´ì‹œë©´ ì´ëŸ° ì–´í…ì…˜ ê¸°ë²•ì„ ì‚¬ìš©í•  ë•Œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë‹¨ í•œ ë²ˆì— ë³‘ë ¬ì ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— RNNê³¼ ë¹„êµí–ˆì„ ë•Œ í›¨ì”¬ ë„¤íŠ¸ì›Œí¬ì— ë“¤ì–´ê°€ëŠ” ìž…ë ¥ì˜ íšŸìˆ˜ê°€ ì ë‹¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”.\n",
      "4980.00 -> 5004.10:  ê·¸ë ‡ì§€ ë³µìž¡ë„ë¥¼ ë¹„êµí–ˆì„ ë•Œì—ë„ ì´ nì€ ë‹¨ì–´ì˜ ê°œìˆ˜ì´ê¸° ë•Œë¬¸ì— ì¼ë°˜ì ìœ¼ë¡œ ì´ dë³´ë‹¤ëŠ” ì¡°ê¸ˆ ë” ìž‘ê²Œ í˜•ì„±ë˜ëŠ” ê²½ìš°ê°€ ë§ŽìŠµë‹ˆë‹¤. n ì œê³± ê³±í•˜ê¸° dê°€ n ê³±í•˜ê¸° d ì œê³±ë³´ë‹¤ëŠ” ë” ë‚®ì„ í™•ë¥ ì´ ë†’ê¸° ë•Œë¬¸ì— ë³´ë‹¤ ìœ ë¦¬í•œ ë³µìž¡ë„ë¥¼ ê°€ì§„ë‹¤ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ì´ë ‡ê²Œ ë³¸ë¬¸ì—ì„œë„ ë‚´ìš©ì´ ì„¤ëª…ë˜ê³  ìžˆëŠ”ë°ìš”. ë³´í†µ ì´ n ì¦‰ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ ì´ dë³´ë‹¤ëŠ” ì§§ì€ ê²½ìš°ê°€ ë§Žê¸° ë•Œë¬¸ì— í›¨ì”¬ íš¨ìœ¨ì ì¼ ìˆ˜ ìžˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "5010.00 -> 5038.26:  ê°™ë‹¤ê³  í•  ìˆ˜ ìžˆì£ . ê·¸ëŸ° ê²½ìš°ë¥¼ ìƒê°í•´ ë³´ì•˜ì„ ë•Œ í™•ì‹¤ížˆ ì´ nì´ ì¼ë°˜ì ìœ¼ë¡œ dë³´ë‹¤ëŠ” ìž‘ê²Œ í˜•ì„±ë˜ëŠ” ê²½ìš°ê°€ ë§ŽìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ë‹¤ì–‘í•œ ë²ˆì—­ ë°ì´í„°ì…‹ì„ í™•ì¸í•´ ë³´ì‹œë©´ í•œ ë¬¸ìž¥ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ê·¸ë ‡ê²Œ ë§Žì§€ ì•Šê¸° ë•Œë¬¸ì— ê·¸ëŸ° ì¸¡ë©´ì„ ë³´ì•˜ì„ ë•Œ ë‹¨ì–´ì˜ ê°œìˆ˜ê°€ ì´ëŸ¬í•œ nì´ ë˜ê¸° ë•Œë¬¸ì— ê·¸ëŸ¬í•œ ì¸¡ë©´ì—ì„œ íš¨ê³¼ì ì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì¶”ê°€ì ìœ¼ë¡œ attention ë©”ì»¤ë‹ˆì¦˜ ìžì²´ê°€ ìš°ë¦¬ ë‰´ëŸ° ë„¤íŠ¸ì›Œí¬ë¥¼ ë³´ë‹¤ ì„¤ëª… ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“¤ì–´ì¤€ë‹¤ëŠ” ì ì´ ìž¥ì ì´ë¼ê³  í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ìš°ë¦¬ëŠ” ê° ë‹¨ì–´ë¥¼ ì¶œë ¥í•  ë•Œ\n",
      "5040.00 -> 5067.54:  ê°€ìž¥ ë§Žì´ ì°¸ê³ í•´ì„œ ë§Œë“¤ì—ˆëŠ”ì§€ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì¶œë ¥í•´ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë‹¨ìˆœížˆ ê·¸ëƒ¥ ê°ê°ì˜ í—¤ë“œì— í¬í•¨ë˜ì–´ ìžˆëŠ” ê·¸ ì…€í”„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ê°’ì„ ì¶œë ¥í•´ ë³´ë©´ ë˜ê² ì£ . ë˜í•œ íŠ¸ë ˆì´ë‹ì„ ì§„í–‰í•  ë•Œ ì„¤ì •í–ˆë˜ ë‚´ìš©ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì€ë°ìš”. ë§ì”€ë“œë ¸ë“¯ì´ ì˜ì–´ ë…ì¼ì–´ ê·¸ë¦¬ê³  ì˜ì–´ í”„ëž‘ìŠ¤ì–´ ì´ ë‘ ê°€ì§€ ëŒ€í‘œì ì¸ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ì„œ ì‹¤í—˜í–ˆë‹¤ê³  í•˜ê³ ìš”. WMT 2014ë…„ë„ ì˜ì–´ ë…ì–´ ë°ì´í„° ì„¸íŠ¸ëŠ” ì•½ 450ë§Œ ê°œ ì •ë„ì˜ ë¬¸ìž¥ ìŒì´ ì¡´ìž¬í•˜ê³ ìš”.\n",
      "5070.00 -> 5096.34:  3600ë§Œê°œ ì •ë„ì˜ ë¬¸ìž¥ìƒì´ ì¡´ìž¬í•˜ëŠ” ë°ì´í„°ì…‹ì„ ì´ìš©í–ˆê³ ìš”. í•™ìŠµì„ ìœ„í•œ í•˜ë“œì›¨ì–´ë¡œëŠ” 8ê°œì˜ NVIDIA P100 GPUë¥¼ ì‚¬ìš©í–ˆê³ ìš”. ë² ì´ìŠ¤ ëª¨ë¸ë§Œìœ¼ë¡œë„ State of the Artì˜ ì„±ëŠ¥ì´ ë‚˜ì˜¤ê³  í•™ìŠµì‹œê°„ ë˜í•œ ë§¤ìš° ë¹ ë¥¸ 12ì‹œê°„ë°–ì— ê±¸ë¦¬ì§€ ì•Šì•˜ë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ì™€ ê°™ì´ Adam Optimizerë¥¼ ì‚¬ìš©í•˜ê³  ì„¸ë¶€ì ì¸ íŒŒë¼ë¯¸í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ë˜í•œ ì •êµí™” íš¨ê³¼ë¥¼ ìœ„í•´ì„œ ë ˆì§€ë“€ì–¼ ëŸ¬ë‹ì„ ìˆ˜í–‰í•  ë•Œ ì´ ë“œëžì•„ì›ƒë„ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ë§Œë“¤ì—ˆê³ ìš”.\n",
      "5100.00 -> 5129.12:  ìš°ë¦¬ ëª¨ë¸ì´ íŠ¹ì • ì¶œë ¥ê°’ì— ëŒ€í•´ì„œ í™•ì‹ ì„ ê°€ì§€ì§€ ì•Šë„ë¡ í•¨ìœ¼ë¡œì¨ ì •ê·œí™” íš¨ê³¼ë¥¼ ë”í•  ìˆ˜ ìžˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ì‚¬ì‹¤ ì´ê²ƒë„ êµ‰ìž¥ížˆ ìž˜ ì•Œë ¤ì§„ ì •ê·œí™” ê¸°ë²•ì´ê³  ì´ë¯¸ì§€ ë¶„ë¥˜ ë“±ì—ì„œë„ ì´ë¯¸ ë§Žì´ ì‚¬ìš©ë˜ê³  ìžˆëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ì£ . ê·¸ëž˜ì„œ ì´ì™€ ê°™ì´ ì–´íëŸ¬ì‹œì™€ ë¸”ë£¨ìŠ¤ì½”ì–´ë¥¼ ë†’ì¼ ìˆ˜ ìžˆì—ˆë‹¤ê³  ë§í•˜ê³  ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ì—¬ê¸° ë³´ì´ëŠ” í‘œê°€ ì‹¤ì œ íŠ¸ëžœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ ì„±ëŠ¥ì„ ìž˜ ë³´ì—¬ì£¼ê³  ìžˆëŠ”ë°ìš”. ì´ì™€ ê°™ì´ ê¸°ë³¸ì ì¸ ë² ì´ìŠ¤ ëª¨ë¸ë§Œ ê°€ì§€ê³ ë„ ê¸°ì¡´ State-of-the-Art ë„¤íŠ¸ì›Œí¬ì™€ í•„ì í•˜ëŠ” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆì—ˆê³ ìš”.\n",
      "5130.00 -> 5156.56:  í•™ìŠµ ì‹œê°„ì€ í›¨ì”¬ ì§§ì•˜ë‹¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ëŸ¬í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ í›¨ì”¬ ëŠ˜ë ¤ì„œ í° ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ ë•Œì—ë„ ì´ì „ ì—°êµ¬ì™€ ë¹„êµí–ˆì„ ë•Œ í•™ìŠµ íš¨ìœ¨ì´ ë†’ì•˜ìœ¼ë©° ì„±ëŠ¥ì€ í›¨ì”¬ ë” ê°œì„ ëœ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ëŸ° íŠ¸ëžœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì—ì„œ ì–´ë–¤ ì»´í¬ë„ŒíŠ¸ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì¤‘ìš”í•œì§€ì— ëŒ€í•œ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ëª¨ë¸ ë² ë¦¬ì—ì´ì…˜ ì‹¤í—˜ ë˜í•œ ì§„í–‰ì„ í–ˆëŠ”ë°ìš”. ê°„ë‹¨í•˜ê²Œ í—¤ë“œì˜ ìˆ˜ë¥¼ ì¤„ì—¬ë³´ê±°ë‚˜ íŠ¹ì • íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ê±°ë‚˜ ì¤„ì—¬ë³´ê±°ë‚˜ ì´ëŸ° ì‹¤í—˜ë“¤ì„ í•´ë³¸ ê²ë‹ˆë‹¤.\n",
      "5160.00 -> 5188.54:  ì´ë ‡ê²Œ ì—¬ê¸° ë³´ì´ëŠ” ì´ ë² ì´ìŠ¤ ëª¨ë¸ì´ ê°€ìž¥ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¼ê³  í•  ìˆ˜ ìžˆê³ ìš”. ì—¬ê¸°ì„œ A ê°™ì€ ê²½ìš°ëŠ” ì´ í—¤ë“œì˜ ë””ë©˜ì „ì„ ë°”ê¿”ê°€ì§€ê³  ê·¸ì— ë”°ë¼ì„œ ì´ í‚¤ì™€ ë°¸ë¥˜ì˜ ë””ë©˜ì „ ë˜í•œ ë°”ë€” ìˆ˜ ìžˆë„ë¡ í•œ ê²ë‹ˆë‹¤. ë§ì”€ë“œë ¸ë“¯ì´ D ëª¨ë¸ì„ Hë¡œ ë‚˜ëˆˆ ê°’ì´ í‚¤ì™€ ë°¸ë¥˜ì˜ ë””ë©˜ì „ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìžˆë‹¤ê³  í–ˆì£ . ê·¸ëž˜ì„œ í™•ì¸í•´ ë³´ì‹œë©´ ì´ë ‡ê²Œ í—¤ë“œë¥¼ 8ê°œ ì‚¬ìš©í–ˆì„ ë•Œ ê°€ìž¥ ì„±ëŠ¥ì´ ì¢‹ì€ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ë˜í•œ B ê°™ì€ ê²½ìš°ëŠ” ë³„ë„ë¡œ í—¤ë“œì™€ ìƒê´€ì—†ì´ ì´ í‚¤ ë°¸ë¥˜ì˜ ë””ë©˜ì „ì„ ë” ì¤„ì—¬ë³¸ ê²ë‹ˆë‹¤.\n",
      "5190.00 -> 5219.50:  ë‹¹ì—°ížˆ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ê°€ ì¤„ì–´ì„œ ëª¨ë¸ì˜ ìºí¼ì‹œí‹° ë˜í•œ ê°ì†Œí•˜ê²Œ ë˜ê² ì£ . ì‹¤ì œë¡œ ê²°ê³¼ ë˜í•œ ë” ì•ˆ ì¢‹ì•„ì§€ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ê°€ ìžˆì—ˆê³ ìš”. ê·¸ëž˜ì„œ ì´ë ‡ê²Œ 64ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œê°€ 16ì´ë‚˜ 32ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œë³´ë‹¤ ë” ì¢‹ì€ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ë ‡ê²Œ ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ë” í‚¤ì› ì„ ë•Œ ë” ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ ê²ƒë„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë³´ì‹œë©´ ì´ëŸ° ì‹ìœ¼ë¡œ ì¸ë² ë”© ì°¨ì›ì„ ë†’ì´ê±°ë‚˜ ì´ Feed Forward ë ˆì´ì–´ì— í¬í•¨ë˜ì–´ ìžˆëŠ” ì°¨ì›ì„ ë†’ì˜€ì„ ë•Œ ë” ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆê³ ìš”. ë˜í•œ ë“œëžì•„ì›ƒ ê¸°ë²•ì€ ì´ì²˜ëŸ¼ ì˜¤ë²„í”¼íŒ… ë°©ì§€ì— ë§¤ìš° íš¨ê³¼ì ì¸ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "5220.00 -> 5248.52:  ê·¸ëž˜ì„œ ì´ë ‡ê²Œ ë“œëžì•„ì›ƒì„ ì¼ì„ ë•Œ ë” ì„±ëŠ¥ì´ ë§Žì´ ì¢‹ì•„ì§„ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì£¼ê¸° ìœ„í•´ ì‚¬ì¸ê³¼ ì½”ì‚¬ì¸ í•¨ìˆ˜ë¥¼ ì´ìš©í•œ ì¸ì½”ë”© ëŒ€ì‹ ì— ë³„ë„ì˜ ì¸ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ì´ë•ŒëŠ” ë² ì´ìŠ¤ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ ì„±ëŠ¥ì˜ ì°¨ì´ëŠ” ê±°ì˜ ì—†ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ëŸ¬í•œ íŠ¸ëžœìŠ¤í¬ë¨¸ëŠ” ë¹„ëŒ€í•œ ê¸°ê³„ ë²ˆì—­ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ìžì—°ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©ì´ ê°€ëŠ¥í•œë°ìš”. ëŒ€í‘œì ìœ¼ë¡œ êµ¬ë¬¸ ë¶„ì„ ë¶„ì•¼ì— ëŒ€í•´ì„œ ì‹¤í—˜í•œ ê²°ê³¼ ë˜í•œ ë³´ì—¬ì£¼ê³  ìžˆìŠµë‹ˆë‹¤. ì—¬ê¸° í…Œì´ë¸” 4ë²ˆì´ ê·¸ ë‚´ìš©ì„ ê°„ë‹¨í•˜ê²Œ ë³´ì—¬ì£¼ê³  ìžˆê³ ìš”.\n",
      "5250.00 -> 5279.26:  ì´ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë‹¤ë¥¸ State of the Art ë„¤íŠ¸ì›Œí¬ì™€ ë¹„êµí–ˆì„ ë•Œ ë” ì„±ëŠ¥ì´ ì¢‹ì€ ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. Semi-supervised caseì— ëŒ€í•´ì„œë„ ë§ˆì°¬ê°€ì§€ë¡œ ë” ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ê²°ê³¼ì ìœ¼ë¡œ ì´ì™€ ê°™ì´ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” íŠ¸ëžœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí–ˆê³ ìš”. ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ê¹Œì§€ì˜ ë…¼ë¬¸ê³¼ ë‹¤ë¥´ê²Œ ì „ì ìœ¼ë¡œ Attention Mechanismë§Œ í™œìš©ì„ í•´ì„œ Recurrentí•œ ë„¤íŠ¸ì›Œí¬ ìžì²´ë¥¼ ì „ë¶€ ë‹¤ ì•„í‚¤í…ì²˜ì—ì„œ ë¹¼ë²„ë ¸ê³ ìš”. ì´ë¡œ ì¸í•´ ë³´ë‹¤ ë†’ì€ ë³‘ë ¬ì„±ì„ ì–»ê²Œ ë˜ê³  ì„±ëŠ¥ ë˜í•œ ë§Žì´ ê°œì„ ë  ìˆ˜ ìžˆì—ˆìŠµë‹ˆë‹¤.\n",
      "5280.00 -> 5296.18:  ì‹¤ì œë¡œ ê¸°ê³„ ë²ˆì—­ íƒœìŠ¤í¬ì— ëŒ€í•´ì„œ ê¸°ì¡´ê¹Œì§€ ì¡´ìž¬í–ˆë˜ ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ì— ë¹„í•´ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤„ ìˆ˜ê°€ ìžˆì—ˆê³  ë¹„ë‹¨ ê¸°ê³„ ë²ˆì—­ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ëŒ€í•´ì„œë„ ì ìš© ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ëŠ” ê²ƒê¹Œì§€ ìž˜ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ìƒìœ¼ë¡œ ì´ë²ˆ ì‹œê°„ì—ëŠ” íŠ¸ëžœìŠ¤í¬ë¨¸ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import math\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import concurrent.futures\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import threading\n",
    "import ffmpeg\n",
    "\n",
    "class ProgressBar:\n",
    "    def __init__(self, total_size, desc=\"Downloading\"):\n",
    "        self.pbar = tqdm(total=total_size, unit='iB', unit_scale=True, desc=desc)\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def update(self, size):\n",
    "        with self.lock:\n",
    "            self.pbar.update(size)\n",
    "\n",
    "    def close(self):\n",
    "        self.pbar.close()\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=0.1,\n",
    "        status_forcelist=[500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(\n",
    "        max_retries=retry,\n",
    "        pool_connections=100,\n",
    "        pool_maxsize=100\n",
    "    )\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def download_chunk(args):\n",
    "    url, start, end, chunk_number, temp_dir, progress_bar = args\n",
    "    \n",
    "    headers = {'Range': f'bytes={start}-{end}'}\n",
    "    session = create_session()\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, headers=headers, stream=True)\n",
    "        chunk_path = os.path.join(temp_dir, f'chunk_{chunk_number:04d}')\n",
    "        \n",
    "        with open(chunk_path, 'wb') as f:\n",
    "            for data in response.iter_content(chunk_size=8192):\n",
    "                size = f.write(data)\n",
    "                progress_bar.update(size)\n",
    "        \n",
    "        return chunk_path, chunk_number\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading chunk {chunk_number}: {str(e)}\")\n",
    "        return None, chunk_number\n",
    "\n",
    "def parallel_download(url, temp_dir, num_chunks=10):\n",
    "    session = create_session()\n",
    "    response = session.head(url)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    if total_size == 0:\n",
    "        raise ValueError(\"Could not determine file size\")\n",
    "    \n",
    "    chunk_size = total_size // num_chunks\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = start + chunk_size - 1 if i < num_chunks - 1 else total_size - 1\n",
    "        chunks.append((start, end))\n",
    "    \n",
    "    progress_bar = ProgressBar(total_size, \"Parallel downloading\")\n",
    "    \n",
    "    download_args = [\n",
    "        (url, start, end, i, temp_dir, progress_bar)\n",
    "        for i, (start, end) in enumerate(chunks)\n",
    "    ]\n",
    "    \n",
    "    chunk_paths = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_chunks) as executor:\n",
    "        futures = executor.map(download_chunk, download_args)\n",
    "        chunk_paths = [(path, num) for path, num in futures if path is not None]\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    chunk_paths.sort(key=lambda x: x[1])\n",
    "    output_path = os.path.join(temp_dir, \"complete_audio.mp4\")\n",
    "    \n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        for chunk_path, _ in chunk_paths:\n",
    "            with open(chunk_path, 'rb') as infile:\n",
    "                outfile.write(infile.read())\n",
    "            os.remove(chunk_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def convert_to_wav(input_path, output_path):\n",
    "    \"\"\"MP4ë¥¼ WAVë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        stream = ffmpeg.input(input_path)\n",
    "        stream = ffmpeg.output(stream, output_path, \n",
    "                             acodec='pcm_s16le', \n",
    "                             ar='16000',\n",
    "                             ac='1')\n",
    "        ffmpeg.run(stream, capture_stdout=True, capture_stderr=True)\n",
    "        return True\n",
    "    except ffmpeg.Error as e:\n",
    "        print('FFmpeg error:', e.stderr.decode())\n",
    "        return False\n",
    "\n",
    "def process_audio_chunk(chunk_data):\n",
    "    \"\"\"ê°œë³„ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬\"\"\"\n",
    "    model, audio_path, start_time, duration = chunk_data\n",
    "    try:\n",
    "        segments, info = model.transcribe(\n",
    "            audio_path,\n",
    "            beam_size=5,\n",
    "            batch_size=32,\n",
    "            word_timestamps=True,\n",
    "            initial_prompt=None\n",
    "        )\n",
    "        \n",
    "        # segmentsë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ì‹œê°„ ì¡°ì •\n",
    "        chunk_segments = []\n",
    "        for segment in segments:\n",
    "            segment_dict = {\n",
    "                'start': segment.start + start_time,\n",
    "                'end': segment.end + start_time,\n",
    "                'text': segment.text,\n",
    "                'words': [\n",
    "                    {\n",
    "                        'start': word.start + start_time,\n",
    "                        'end': word.end + start_time,\n",
    "                        'word': word.word,\n",
    "                        'probability': word.probability\n",
    "                    }\n",
    "                    for word in segment.words\n",
    "                ]\n",
    "            }\n",
    "            chunk_segments.append(segment_dict)\n",
    "        \n",
    "        return chunk_segments\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk at {start_time}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_with_progress(url, model, chunk_duration=30, num_download_chunks=10):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        print(\"Starting parallel download...\")\n",
    "        mp4_path = parallel_download(url, temp_dir, num_download_chunks)\n",
    "        print(\"Download complete!\")\n",
    "        \n",
    "        # MP4ë¥¼ WAVë¡œ ë³€í™˜\n",
    "        wav_path = os.path.join(temp_dir, \"audio.wav\")\n",
    "        if not convert_to_wav(mp4_path, wav_path):\n",
    "            raise Exception(\"Failed to convert audio to WAV format\")\n",
    "        \n",
    "        # WAV íŒŒì¼ ì •ë³´ ì½ê¸°\n",
    "        wav_info = sf.info(wav_path)\n",
    "        total_duration = wav_info.duration\n",
    "        \n",
    "        # ì²­í¬ ê³„ì‚°\n",
    "        total_chunks = math.ceil(total_duration / chunk_duration)\n",
    "        \n",
    "        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        pbar = tqdm(total=total_chunks, desc=\"Processing audio chunks\")\n",
    "        \n",
    "        # ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "        chunks_data = []\n",
    "        for i in range(total_chunks):\n",
    "            start_time = i * chunk_duration\n",
    "            chunk_wav_path = os.path.join(temp_dir, f\"chunk_{i}.wav\")\n",
    "            \n",
    "            # ì²­í¬ ì¶”ì¶œ\n",
    "            duration = min(chunk_duration, total_duration - start_time)\n",
    "            stream = ffmpeg.input(wav_path, ss=start_time, t=duration)\n",
    "            stream = ffmpeg.output(stream, chunk_wav_path, \n",
    "                                 acodec='pcm_s16le', \n",
    "                                 ar='16000',\n",
    "                                 ac='1')\n",
    "            ffmpeg.run(stream, quiet=True)\n",
    "            \n",
    "            chunks_data.append((model, chunk_wav_path, start_time, duration))\n",
    "        \n",
    "        # ì²­í¬ ì²˜ë¦¬ ë° ê²°ê³¼ ìˆ˜ì§‘\n",
    "        all_segments = []\n",
    "        for chunk_data in chunks_data:\n",
    "            segments = process_audio_chunk(chunk_data)\n",
    "            all_segments.extend(segments)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # ì‚¬ìš©í•œ ì²­í¬ íŒŒì¼ ì‚­ì œ\n",
    "            if os.path.exists(chunk_data[1]):\n",
    "                os.remove(chunk_data[1])\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "    return all_segments\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = WhisperModel(\n",
    "    \"large-v3\", \n",
    "    device='cuda', \n",
    "    compute_type=\"float16\"  # bfloat16 ëŒ€ì‹  float16 ì‚¬ìš©\n",
    ")\n",
    "print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "model = BatchedInferencePipeline(model=model)\n",
    "\n",
    "# íŠ¸ëžœìŠ¤í¬ë¦½ì…˜ ì‹¤í–‰\n",
    "segments = process_with_progress(\n",
    "    audio_stream.url,\n",
    "    model,\n",
    "    chunk_duration=30,\n",
    "    num_download_chunks=10\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì €ìž¥\n",
    "for i, segment in enumerate(segments):\n",
    "    print(f\"{segment['start']:.2f} -> {segment['end']:.2f}: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio chunks:   0%|          | 0/177 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 157\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# íŠ¸ëžœìŠ¤í¬ë¦½ì…˜ ì‹¤í–‰\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m segments \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_stream_with_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ìœ íŠœë¸Œ URL\u001b[39;49;00m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_duration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[1;32m    161\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# ê²°ê³¼ ì¶œë ¥\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segments:\n",
      "Cell \u001b[0;32mIn[1], line 76\u001b[0m, in \u001b[0;36mprocess_stream_with_progress\u001b[0;34m(url, model, chunk_duration)\u001b[0m\n\u001b[1;32m     72\u001b[0m chunk_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# ì²­í¬ ì½ê¸°\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     audio_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m audio_chunk:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# url = \"https://youtu.be/AA621UofTUA?si=gn4XutRMWUDSYLFL\"\n",
    "\n",
    "# from faster_whisper import WhisperModel\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "# import tempfile\n",
    "# import os\n",
    "# import ffmpeg\n",
    "# import subprocess\n",
    "# from yt_dlp import YoutubeDL\n",
    "# import io\n",
    "\n",
    "# def get_audio_stream(url):\n",
    "#     \"\"\"URLì—ì„œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "#     ydl_opts = {\n",
    "#         'format': 'bestaudio/best',\n",
    "#         'quiet': True,\n",
    "#         'no_warnings': True,\n",
    "#         'extract_audio': True\n",
    "#     }\n",
    "    \n",
    "#     with YoutubeDL(ydl_opts) as ydl:\n",
    "#         info = ydl.extract_info(url, download=False)\n",
    "#         audio_url = info['url']\n",
    "#         duration = info.get('duration', 0)\n",
    "        \n",
    "#         return audio_url, duration\n",
    "\n",
    "# def process_stream_with_progress(url, model, chunk_duration=30):\n",
    "#     \"\"\"\n",
    "#     ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - url: ì˜¤ë””ì˜¤ URL\n",
    "#     - model: WhisperModel ì¸ìŠ¤í„´ìŠ¤\n",
    "#     - chunk_duration: ê° ì²­í¬ì˜ ê¸¸ì´(ì´ˆ)\n",
    "#     \"\"\"\n",
    "#     # ìŠ¤íŠ¸ë¦¼ URL ê°€ì ¸ì˜¤ê¸°\n",
    "#     audio_url, total_duration = get_audio_stream(url)\n",
    "    \n",
    "#     # ffmpeg ëª…ë ¹ì–´ ì„¤ì •\n",
    "#     ffmpeg_cmd = [\n",
    "#         'ffmpeg',\n",
    "#         '-i', audio_url,\n",
    "#         '-f', 'wav',\n",
    "#         '-ar', '16000',\n",
    "#         '-ac', '1',\n",
    "#         '-hide_banner',\n",
    "#         '-loglevel', 'error',\n",
    "#         'pipe:1'\n",
    "#     ]\n",
    "    \n",
    "#     # ì§„í–‰ë¥  í‘œì‹œ ì„¤ì •\n",
    "#     total_chunks = int(np.ceil(total_duration / chunk_duration))\n",
    "#     pbar = tqdm(total=total_chunks, desc=\"Processing audio chunks\")\n",
    "    \n",
    "#     # ê²°ê³¼ ì €ìž¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "#     all_segments = []\n",
    "    \n",
    "#     try:\n",
    "#         # ffmpeg í”„ë¡œì„¸ìŠ¤ ì‹œìž‘\n",
    "#         process = subprocess.Popen(\n",
    "#             ffmpeg_cmd,\n",
    "#             stdout=subprocess.PIPE,\n",
    "#             bufsize=10**8  # ë²„í¼ í¬ê¸° ì„¤ì •\n",
    "#         )\n",
    "        \n",
    "#         # ìž„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "#         with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#             chunk_size = int(16000 * chunk_duration * 2)  # 16000Hz * seconds * 2 bytes per sample\n",
    "#             chunk_number = 0\n",
    "            \n",
    "#             while True:\n",
    "#                 # ì²­í¬ ì½ê¸°\n",
    "#                 audio_chunk = process.stdout.read(chunk_size)\n",
    "#                 if not audio_chunk:\n",
    "#                     break\n",
    "                \n",
    "#                 # ì²­í¬ë¥¼ ìž„ì‹œ íŒŒì¼ë¡œ ì €ìž¥\n",
    "#                 chunk_path = os.path.join(temp_dir, f'chunk_{chunk_number}.wav')\n",
    "#                 with open(chunk_path, 'wb') as f:\n",
    "#                     # WAV í—¤ë” ìž‘ì„±\n",
    "#                     f.write(b'RIFF')\n",
    "#                     f.write((chunk_size + 36).to_bytes(4, 'little'))\n",
    "#                     f.write(b'WAVE')\n",
    "#                     f.write(b'fmt ')\n",
    "#                     f.write((16).to_bytes(4, 'little'))\n",
    "#                     f.write((1).to_bytes(2, 'little'))  # PCM\n",
    "#                     f.write((1).to_bytes(2, 'little'))  # Mono\n",
    "#                     f.write((16000).to_bytes(4, 'little'))  # Sample rate\n",
    "#                     f.write((32000).to_bytes(4, 'little'))  # Byte rate\n",
    "#                     f.write((2).to_bytes(2, 'little'))  # Block align\n",
    "#                     f.write((16).to_bytes(2, 'little'))  # Bits per sample\n",
    "#                     f.write(b'data')\n",
    "#                     f.write(len(audio_chunk).to_bytes(4, 'little'))\n",
    "#                     f.write(audio_chunk)\n",
    "                \n",
    "#                 try:\n",
    "#                     # ì²­í¬ ì²˜ë¦¬\n",
    "#                     segments, _ = model.transcribe(\n",
    "#                         chunk_path,\n",
    "#                         beam_size=5,\n",
    "#                         batch_size=32,\n",
    "#                         word_timestamps=True,\n",
    "#                         condition_on_previous_text=True\n",
    "#                     )\n",
    "                    \n",
    "#                     # ì‹œê°„ ì˜¤í”„ì…‹ ì¡°ì • ë° ì„¸ê·¸ë¨¼íŠ¸ ì €ìž¥\n",
    "#                     time_offset = chunk_number * chunk_duration\n",
    "#                     for segment in segments:\n",
    "#                         segment_dict = {\n",
    "#                             'start': segment.start + time_offset,\n",
    "#                             'end': segment.end + time_offset,\n",
    "#                             'text': segment.text,\n",
    "#                             'words': [\n",
    "#                                 {\n",
    "#                                     'start': word.start + time_offset,\n",
    "#                                     'end': word.end + time_offset,\n",
    "#                                     'word': word.word,\n",
    "#                                     'probability': word.probability\n",
    "#                                 }\n",
    "#                                 for word in segment.words\n",
    "#                             ]\n",
    "#                         }\n",
    "#                         all_segments.append(segment_dict)\n",
    "                \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing chunk {chunk_number}: {str(e)}\")\n",
    "                \n",
    "#                 finally:\n",
    "#                     # ìž„ì‹œ íŒŒì¼ ì‚­ì œ\n",
    "#                     if os.path.exists(chunk_path):\n",
    "#                         os.remove(chunk_path)\n",
    "                \n",
    "#                 # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "#                 pbar.update(1)\n",
    "#                 chunk_number += 1\n",
    "    \n",
    "#     finally:\n",
    "#         pbar.close()\n",
    "#         if process.poll() is None:\n",
    "#             process.terminate()\n",
    "#             process.wait()\n",
    "    \n",
    "#     return all_segments\n",
    "\n",
    "# # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = WhisperModel(\n",
    "#     \"large-v3\", \n",
    "#     device='cuda', \n",
    "#     compute_type=\"float16\"\n",
    "# )\n",
    "# print(\"Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# # íŠ¸ëžœìŠ¤í¬ë¦½ì…˜ ì‹¤í–‰\n",
    "# segments = process_stream_with_progress(\n",
    "#     url,  # ìœ íŠœë¸Œ URL\n",
    "#     model,\n",
    "#     chunk_duration=30\n",
    "# )\n",
    "\n",
    "# # ê²°ê³¼ ì¶œë ¥\n",
    "# for segment in segments:\n",
    "#     print(f\"{segment['start']:.2f} -> {segment['end']:.2f}: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"script.json\",\"r\",encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "            Document(page_content=\"\\n\".join([t[\"text\"] for t in data]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the last chapter, you and I started to step through the internal workings of a transformer.\\nThis is one of the key pieces of technology inside large language models, and a lot of\\nother tools in the modern wave of AI.\\nIt first hit the scene in a now-famous 2017 paper called Attention is All You Need, and\\nin this chapter, you and I will dig into what this attention mechanism is, visualizing how\\nit processes data.\\nAs a quick recap, here's the important context I want you to have in mind.\\nThe goal of the model that you and I are studying is to take in a piece of text and predict\\nwhat word comes next.\\nThe input text is broken up into little pieces that we call tokens, and these are very often\\nwords or pieces of words, but just to make the examples in this video easier for you\\nand me to think about, let's simplify by pretending that tokens are always just words.\\nThe first step in a transformer is to associate each token with a high-dimensional vector,\\nwhat we call its embedding.\\nNow the most important idea I want you to have in mind is how directions in this high-dimensional\\nspace of all possible embeddings can correspond with semantic meaning.\\nIn the last chapter we saw an example for how direction can correspond to gender, in\\nthe sense that adding a certain step in this space can take you from the embedding of a\\nmasculine noun to the embedding of the corresponding feminine noun.\\njust one example, you could imagine how many other directions in this high-dimensional space\\ncould correspond to numerous other aspects of a word's meaning. The aim of a transformer is to\\nprogressively adjust these embeddings so that they don't merely encode an individual word,\\nbut instead they bake in some much, much richer contextual meaning. I should say up front that a\\nlot of people find the attention mechanism, this key piece in a transformer, very confusing, so\\ndon't worry if it takes some time for things to sink in. I think that before we dive into the\\ncomputational details and all the matrix multiplications, it's worth thinking about a\\ncouple examples for the kind of behavior that we want attention to enable. Consider the phrases\\nAmerican true mole, one mole of carbon dioxide, and take a biopsy of the mole. You and I know\\nthat the word mole has different meanings in each one of these, based on the context.\\nBut after the first step of a transformer, the one that breaks up the text and associates each\\ntoken with a vector, the vector that's associated with mole would be the same in all three of these\\ncases, because this initial token embedding is effectively a lookup table with no reference to\\nthe context. It's only in the next step of the transformer that the surrounding embeddings have\\nthe chance to pass information into this one. The picture you might have in mind is that there\\nare multiple distinct directions in this embedding space encoding the multiple distinct meanings of\\nthe word mole, and that a well-trained attention block calculates what you need to add to the\\ngeneric embedding to move it to one of these more specific directions, as a function of the context.\\nTo take another example, consider the embedding of the word tower. This is presumably some very\\ngeneric, non-specific direction in the space, associated with lots of other large, tall nouns.\\nIf this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update\\nthis vector so that it points in a direction that more specifically encodes the Eiffel Tower,\\nmaybe correlated with vectors associated with Paris and France and things made of steel.\\nIf it was also preceded by the word miniature, then the vector should be updated even further\\nso that it no longer correlates with large tall things. More generally than just refining the\\nmeaning of a word, the attention block allows the model to move information encoded in one\\nembedding to that of another, potentially ones that are quite far away, and potentially\\nwith information that's much richer than just a single word.\\nWhat we saw in the last chapter was how after all of the vectors flow through the network,\\nincluding many different attention blocks, the computation that you perform to produce\\na prediction of the next token is entirely a function of the last vector in the sequence.\\nSo imagine, for example, that the text you input is most of an entire mystery novel,\\nway up to a point near the end which reads, therefore the murderer was, if the model is\\ngoing to accurately predict the next word, that final vector in the sequence which began its life\\nsimply embedding the word was will have to have been updated by all of the attention blocks\\nto represent much much more than any individual word, somehow encoding all of the information\\nfrom the full context window that's relevant to predicting the next word. To step through the\\nthe computations though let's take a much simpler example. Imagine that the input includes the\\nphrase a fluffy blue creature roamed the verdant forest and for the moment suppose that the only\\ntype of update that we care about is having the adjectives adjust the meanings of their\\ncorresponding nouns. What I'm about to describe is what we would call a single head of attention\\nand later we will see how the attention block consists of many different heads run in parallel.\\nAgain, the initial embedding for each word is some high-dimensional vector\\nthat only encodes the meaning of that particular word with no context.\\nActually, that's not quite true. They also encode the position of the word.\\nThere's a lot more to say about the specific way that positions are encoded,\\nbut right now all you need to know is that the entries of this vector are enough to tell you\\nboth what the word is and where it exists in the context. Let's go ahead and denote these\\nembeddings with the letter E, the goal is to have a series of computations produce a\\nnew refined set of embeddings where, for example, those corresponding to the nouns have ingested\\nthe meaning from their corresponding adjectives.\\nAnd playing the deep learning game, we want most of the computations involved to look\\nlike matrix-vector products where the matrices are full of tunable weights, things that the\\nmodel will learn based on data.\\nTo be clear, I'm making up this example of adjectives updating nouns just to illustrate\\nthe type of behavior that you could imagine an intention had doing.\\nAs with so much deep learning, the true behavior is much harder to parse, because it's based\\non tweaking and tuning a huge number of parameters to minimize some cost function.\\nIt's just that as we step through all of the different matrices filled with parameters\\nthat are involved in this process, I think it's really helpful to have an imagined example\\nof something that it could be doing to help keep it all more concrete.\\nFor the first step of this process, you might imagine each noun, like creature, asking the\\nquestion, hey, are there any adjectives sitting in front of me, and for the words fluffy and\\nblue to each be able to answer, yeah, I'm an adjective and I'm in that position.\\nThat question is somehow encoded as yet another vector, another list of numbers, which we\\ncall the query for this word.\\nThis query vector, though, has a much smaller dimension than the embedding vector, say 128.\\nComputing this query looks like taking a certain matrix, which I'll label wq, and multiplying\\nit by the embedding.\\nCompressing things a bit, let's write that query vector as q, and then anytime you see\\nme put a matrix next to an arrow like this one, it's meant to represent that multiplying\\nthis matrix by the vector at the arrow's start gives you the vector at the arrow's end.\\nIn this case, you multiply this matrix by all of the embeddings in the context, producing\\none query vector for each token.\\nThe entries of this matrix are parameters of the model, which means the true behavior\\nis learned from data, and in practice what this matrix does in a particular attention\\nhead is challenging to parse.\\nBut for our sake, imagining an example that we might hope it would learn, we'll suppose\\nthat this query matrix maps the embeddings of nouns to certain directions in this smaller\\nquery space that somehow encodes the notion of looking for adjectives in preceding positions.\\nAs to what it does to other embeddings, who knows, maybe it simultaneously tries to accomplish\\nsome other goal with those, right now we're laser focused on the nouns.\\nAt the same time, associated with this is a second matrix called the key matrix, which\\nyou also multiply by every one of the embeddings.\\nThis produces a second sequence of vectors that we call the keys.\\nConceptually you want to think of the keys as potentially answering the queries.\\nThis key matrix is also full of tunable parameters, and just like the query matrix it maps the\\nembedding vectors to that same smaller dimensional space.\\nYou think of the keys as matching the queries whenever they closely align with each other.\\nIn our example, you would imagine that the key matrix maps the adjectives, like fluffy\\nand blue, to vectors that are closely aligned with the query produced by the word creature.\\nTo measure how well each key matches each query, you compute a dot product between each\\npossible key-query pair.\\nI like to visualize a grid full of a bunch of dots, where the bigger dots correspond\\nthe larger dot products, the places where the keys and queries align. For our adjective-noun example,\\nthat would look a little more like this, where if the keys produced by fluffy and blue really do\\nalign closely with the query produced by creature, then the dot products in these two spots would be\\nsome large positive numbers. In the lingo, machine learning people would say that this means the\\nembeddings of fluffy and blue attend to the embedding of creature. By contrast to the dot\\nproduct between the key for some other word like the and the query for creature would be some small\\nor negative value that reflects that these are unrelated to each other. So we have this grid of\\nvalues that can be any real number from negative infinity to infinity giving us a score for how\\nrelevant each word is to updating the meaning of every other word. The way we're about to use these\\nscores is to take a certain weighted sum along each column weighted by the relevance. So instead\\nInstead of having values range from negative infinity to infinity, what we want is for\\nthe numbers in these columns to be between 0 and 1, and for each column to add up to\\n1, as if they were a probability distribution.\\nIf you're coming in from the last chapter, you know what we need to do then.\\nWe compute a softmax along each one of these columns to normalize the values.\\nIn our picture, after you apply softmax to all of the columns, we'll fill in the grid\\nwith these normalized values.\\nAt this point, you're safe to think about each column as giving weights\\naccording to how relevant the word on the left is to the corresponding value at the top.\\nWe call this grid an attention pattern.\\nNow, if you look at the original Transformer paper,\\nthere's a really compact way that they write this all down.\\nHere, the variables q and k represent the full arrays of query and key vectors respectively,\\nthose little vectors you get by multiplying the embeddings by the query and the key matrices.\\nThis expression up in the numerator is a really compact way to represent the grid of all possible\\ndot products between pairs of keys and queries. A small technical detail that I didn't mention\\nis that for numerical stability it happens to be helpful to divide all of these values by the\\nsquare root of the dimension in that key query space. Then this softmax that's wrapped around\\nthe full expression, is meant to be understood to apply column by column.\\nAs to that V term, we'll talk about it in just a second.\\nBefore that, there's one other technical detail that so far I've skipped.\\nDuring the training process, when you run this model on a given text example, and all\\nof the weights are slightly adjusted and tuned to either reward or punish it based on how\\nhigh a probability it assigns to the true next word in the passage, it turns out to\\nmake the whole training process a lot more efficient if you simultaneously have it predict\\nevery possible next token following each initial sub-sequence of tokens in this passage.\\nFor example, with the phrase that we've been focusing on, it might also be predicting what\\nwords follow creature, and what words follow the.\\nThis is really nice, because it means what would otherwise be a single training example\\neffectively acts as many.\\nFor the purposes of our attention pattern, it means that you never want to allow later\\nwords to influence earlier words, since otherwise they could kind of give away the answer for\\nwhat comes next. What this means is that we want all of these spots here, the ones representing\\nlater tokens influencing earlier ones, to somehow be forced to be zero. The simplest thing you might\\nthink to do is to set them equal to zero, but if you did that the columns wouldn't add up to one\\nanymore, they wouldn't be normalized. So instead a common way to do this is that before applying\\nsoftmax you set all of those entries to be negative infinity. If you do that then after\\nAfter applying softmax, all of those get turned into zero, but the columns stay normalized.\\nThis process is called masking.\\nThere are versions of attention where you don't apply it, but in our GPT example, even\\nthough this is more relevant during the training phase than it would be, say, running it as\\na chatbot or something like that, you do always apply this masking to prevent later tokens\\nfrom influencing earlier ones.\\nAnother fact that's worth reflecting on about this attention pattern is how its size is\\nequal to the square of the context size.\\nSo this is why context size can be a really huge bottleneck for large language models,\\nand scaling it up is non-trivial.\\nAs you might imagine, motivated by a desire for bigger and bigger context windows, recent\\nyears have seen some variations to the attention mechanism aimed at making context more scalable.\\nBut right here, you and I are staying focused on the basics.\\nOkay, great, computing this pattern lets the model deduce which words are relevant to which\\nother words.\\nNow you need to actually update the embeddings, allowing words to pass information to whichever\\nother words they're relevant to.\\nFor example, you want the embedding of fluffy to somehow cause a change to creature that\\nmoves it to a different part of this 12,000 dimensional embedding space that more specifically\\nencodes a fluffy creature.\\nWhat I'm going to do here is first show you the most straightforward way that you could\\ndo this, though there's a slight way that this gets modified in the context of multi-headed\\nattention.\\nThis most straightforward way would be to use a third matrix, what we call the value\\nmatrix, which you multiply by the embedding of that first word, for example fluffy.\\nThe result of this is what you would call a value vector, and this is something that\\nyou add to the embedding of the second word, in this case something you add to the embedding\\nof creature.\\nSo, this value vector lives in the same very high dimensional space as the embeddings.\\nWhen you multiply this value matrix by the embedding of a word, you might think of it\\nas saying if this word is relevant to adjusting the meaning of something else, what exactly should\\nbe added to the embedding of that something else in order to reflect this? Looking back in our\\ndiagram, let's set aside all of the keys and the queries, since after you compute the attention\\npattern you're done with those, then you're going to take this value matrix and multiply it by every\\none of those embeddings to produce a sequence of value vectors. You might think of these value\\nvectors as being kind of associated with the corresponding keys.\\nFor each column in this diagram, you multiply each of the value vectors by the corresponding\\nweight in that column.\\nFor example, here, under the embedding of creature, you would be adding large proportions\\nof the value vectors for fluffy and blue, while all of the other value vectors get zeroed\\nout, or at least nearly zeroed out.\\nAnd then finally, the way to actually update the embedding associated with this column,\\npreviously encoding some context-free meaning of creature, you add together all of these\\nrescaled values in the column, producing a change that you want to add that I'll label\\ndelta E, and then you add that to the original embedding.\\nHopefully what results is a more refined vector encoding the more contextually rich meaning,\\nlike that of a fluffy blue creature.\\nAnd of course you don't just do this to one embedding, you apply the same weighted sum\\nacross all of the columns in this picture, producing a sequence of changes.\\nAdding all of those changes to the corresponding embeddings produces a full sequence of more\\nrefined embeddings popping out of the attention block.\\nZooming out, this whole process is what you would describe as a single head of attention.\\nAs I've described things so far, this process is parameterized by three distinct matrices,\\nall filled with tunable parameters, the key, the query, and the value.\\nI want to take a moment to continue what we started in the last chapter with the scorekeeping\\nwhere we count up the total number of model parameters using the numbers from GPT-3.\\nThese key and query matrices each have 12,288 columns, matching the embedding dimension,\\nand 128 rows, matching the dimension of that smaller key query space.\\nThis gives us an additional 1.5 million or so parameters for each one.\\nIf you look at that value matrix by contrast, the way I've described things so far would\\nsuggest that it's a square matrix that has 12,288 columns and 12,288 rows, since both\\nits inputs and its outputs live in this very large embedding space.\\nIf true, that would mean about 150 million added parameters.\\nAnd to be clear, you could do that, you could devote orders of magnitude more parameters\\nto the value map than to the key and query.\\nBut in practice, it is much more efficient if instead you make it so that the number\\nof parameters devoted to this value map is the same as the number devoted to the key\\nin the query.\\nThis is especially relevant in the setting of running multiple attention heads in parallel.\\nThe way this looks is that the value map is factored as a product of two smaller matrices.\\nConceptually, I would still encourage you to think about the overall linear map, one\\nwith inputs and outputs both in this larger embedding space, for example taking the embedding\\nof blue to this blueness direction that you would add to nouns.\\nIt's just that it's broken up into two separate steps.\\nThe first matrix on the right here has a smaller number of rows, typically the same size as\\nthe key query space.\\nWhat this means is you can think of it as mapping the large embedding vectors down to\\na much smaller space.\\nThis is not the conventional naming, but I'm going to call this the value down matrix.\\nThe second matrix maps from this smaller space back up to the embedding space, producing\\nthe vectors that you use to make the actual updates.\\nI'm going to call this one the value-up matrix, which, again, is not conventional.\\nThe way that you would see this written in most papers looks a little different.\\nI'll talk about it in a minute.\\nIn my opinion, it tends to make things a little more conceptually confusing.\\nTo throw in linear algebra jargon here, what we're basically doing is constraining the\\noverall value map to be a low-rank transformation.\\nTurning back to the parameter count, all four of these matrices have the same size, and\\nThen adding them all up, we get about 6.3 million parameters for one attention head.\\nAs a quick side note, to be a little more accurate, everything described so far is what\\npeople would call a self-attention head, to distinguish it from a variation that comes\\nup in other models that's called cross-attention.\\nThis isn't relevant to our GPT example, but if you're curious, cross-attention involves\\nmodels that process two distinct types of data, like text in one language and text in\\nanother language that's part of an ongoing generation of a translation.\\nOr maybe audio input of speech, and an ongoing transcription.\\nA cross-attention head looks almost identical.\\nThe only difference is that the key and query maps act on different datasets.\\nIn a model doing translation, for example, the keys might come from one language, while\\nthe queries come from another, and the attention pattern could describe which words from one\\nlanguage correspond to which words in another.\\nAnd in this setting there would typically be no masking, since there's not really any\\nnotion of later tokens affecting earlier ones.\\nStaying focused on self-attention though, if you understood everything so far, and if\\nyou were to stop here, you would come away with the essence of what attention really\\nis.\\nAll that's really left to us is to lay out the sense in which you do this many, many\\ndifferent times.\\nIn our central example we focused on adjectives updating nouns, but of course there are lots\\nof different ways that context can influence the meaning of a word.\\nIf the words they crashed the preceded the word car, it has implications for the shape\\nand the structure of that car, and a lot of associations might be less grammatical.\\nIf the word wizard is anywhere in the same passage as Harry, it suggests that this might\\nbe referring to Harry Potter, whereas if instead the words Queen, Sussex, and William were\\nin that passage, then perhaps the embedding of Harry should instead be updated to refer\\nto the prince.\\nFor every different type of contextual updating that you might imagine, the parameters of\\nthese key and query matrices would be different to capture the different attention patterns,\\nand the parameters of our value map would be different based on what should be added to the\\nembeddings. And again, in practice the true behavior of these maps is much more difficult\\nto interpret, where the weights are set to do whatever the model needs them to do to best\\naccomplish its goal of predicting the next token. As I said before, everything we described is a\\nsingle head of attention, and a full attention block inside a transformer consists of what's\\ncalled multi-headed attention where you run a lot of these operations in parallel each with its own\\ndistinct key query and value maps. GPT-3 for example uses 96 attention heads inside each block.\\nConsidering that each one is already a bit confusing it's certainly a lot to hold in your\\nhead. Just to spell it all out very explicitly this means you have 96 distinct key and query\\nmatrices producing 96 distinct attention patterns. Then each head has its own distinct value matrices\\nused to produce 96 sequences of value vectors. These are all added together using the\\ncorresponding attention patterns as weights. What this means is that for each position in the\\ncontext, each token, every one of these heads produces a proposed change to be added to the\\nembedding in that position. So what you do is you sum together all of those proposed changes,\\none for each head, and you add the result to the original embedding of that position.\\nThis entire sum here would be one slice of what's outputted from this multi-headed attention block,\\na single one of those refined embeddings that pops out the other end of it.\\nAgain, this is a lot to think about, so don't worry at all if it takes some time to sink in.\\nThe overall idea is that by running many distinct heads in parallel,\\nyou're giving the model the capacity to learn many distinct ways that context changes meaning.\\nPulling up our running tally for parameter count with 96 heads, each including its own variation\\nof these four matrices, each block of multi-headed attention ends up with around 600 million\\nparameters. There's one added slightly annoying thing that I should really mention for any of you\\nwho go on to read more about transformers. You remember how I said that the value map is factored\\nout into these two distinct matrices, which I labeled as the value down and the value up\\nmatrices. The way that I framed things would suggest that you see this pair of matrices\\ninside each attention head, and you could absolutely implement it this way. That would\\nbe a valid design. But the way that you see this written in papers and the way that it's\\nimplemented in practice looks a little different. All of these value up matrices for each head\\nappear stapled together in one giant matrix that we call the output matrix, associated with\\nthe entire multi-headed attention block. And when you see people refer to the value matrix for a\\ngiven attention head, they're typically only referring to this first step, the one that I\\nwas labeling as the value down projection into the smaller space. For the curious among you,\\nI've left an on-screen note about it. It's one of those details that runs the risk of distracting\\nfrom the main conceptual points, but I do want to call it out just so that you know if you read\\nabout this in other sources. Setting aside all the technical nuances, in the preview from the\\nlast chapter, we saw how data flowing through a transformer doesn't just flow through a single\\nattention block. For one thing, it also goes through these other operations called multi-layer\\nperceptrons. We'll talk more about those in the next chapter. And then it repeatedly goes through\\nmany, many copies of both of these operations. What this means is that after a given word imbibes\\nsome of its context, there are many more chances for this more nuanced embedding to be influenced\\nby its more nuanced surroundings. The further down the network you go, with each embedding\\ntaking in more and more meaning from all the other embeddings, which themselves are getting\\nmore and more nuanced, the hope is that there's the capacity to encode higher level and more\\nabstract ideas about a given input beyond just descriptors and grammatical structure.\\nThings like sentiment and tone and whether it's a poem and what underlying scientific truths are\\nare relevant to the piece, and things like that.\\nTurning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the\\ntotal number of key, query, and value parameters is multiplied by another 96, which brings\\nthe total sum to just under 58 billion distinct parameters devoted to all of the attention\\nheads.\\nThat is a lot, to be sure, but it's only about a third of the 175 billion that are\\nin the network in total.\\nSo even though attention gets all of the attention, the majority of parameters come from the blocks\\nsitting in between these steps.\\nIn the next chapter, you and I will talk more about those other blocks and also a lot more\\nabout the training process.\\nA big part of the story for the success of the attention mechanism is not so much any\\nspecific kind of behavior that it enables, but the fact that it's extremely parallelizable,\\nmeaning that you can run a huge number of computations in a short time using GPUs.\\nthat one of the big lessons about deep learning in the last decade or two has been that scale\\nalone seems to give huge qualitative improvements in model performance. There's a huge advantage to\\nparallelizable architectures that let you do this. If you want to learn more about this stuff, I've\\nleft lots of links in the description. In particular, anything produced by Andre Karpathy or Chris Ola\\ntend to be pure gold. In this video, I wanted to just jump into attention in its current form,\\nbut if you're curious about more of the history for how we got here and how you might reinvent\\nthis idea for yourself, my friend Vivek just put up a couple videos giving a lot more of\\nthat motivation. Also, Britt Cruz from the channel The Art of the Problem\\nhas a really nice video about the history of large language models.\\nyou\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def calculate_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5728"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_tokens(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "summarize_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000, chunk_overlap=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = summarize_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(split_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5574/723517548.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7, streaming=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import hub\n",
    "summary_prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7, streaming=True)\n",
    "summary_chain = create_stuff_documents_chain(llm, summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "sumaries = []\n",
    "for split_doc in split_docs:\n",
    "    print(type(split_doc.page_content))\n",
    "    partial_summary = summary_chain.invoke({\"context\": [split_doc]})\n",
    "    sumaries.append(partial_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_summary = Document(page_content= \"\\n\".join(sumaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_RESULT = summary_chain.invoke(\n",
    "                {\"context\": partial_summaries_doc}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SUMMARY_RESULT.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_qa_with_sources_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pytubefix import YouTube\n",
    "import asyncio\n",
    "import torch\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì •\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(url):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    return {\n",
    "        \"title\": yt.title,\n",
    "        \"audio_url\": audio_stream.url if audio_stream else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Title: ê°€ìž¥ ì‰¬ìš´ ê¹Œë¥´ë³´ë‚˜ë¼\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/shorts/a--NSC19MXM\"\n",
    "video_info = get_video_info(video_url)\n",
    "print(f\"Video Title: {video_info['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = WhisperModel(\"large-v3\", device=device, compute_type=compute_type)\n",
    "\n",
    "def transcribe_audio(audio_url):\n",
    "    segments, info = whisper_model.transcribe(audio_url)\n",
    "    transcript = [{\"text\": segment.text, \"start\": segment.start, \"end\": segment.end} for segment in segments]\n",
    "    return {\"script\": transcript, \"language\": info.language}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transcribe.py       :324  2024-10-12 11:30:14,287 Processing audio with duration 00:59.118\n",
      "transcribe.py       :425  2024-10-12 11:30:19,512 Detected language 'ko' with probability 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript Language: ko\n",
      "First few lines of transcript: [{'text': ' í•œ ë‚¨ìžê°€ ë² ì´ì»¨ì„ ê°€ì ¸ì˜¤ëŠ”ë°ìš”', 'start': 0.0, 'end': 10.46}, {'text': ' ê°‘ìžê¸° ê³„ëž€ì„ ê°€ì ¸ì™€ ê¹¨ë¶€ìˆ˜ê¸° ì‹œìž‘í•©ë‹ˆë‹¤', 'start': 10.46, 'end': 12.74}, {'text': ' ë…¸ë¥¸ìžë¥¼ ê±´ì ¸ë‚´ ë”°ë¡œ ë‹´ì•„ì¤ë‹ˆë‹¤', 'start': 12.74, 'end': 14.74}]\n"
     ]
    }
   ],
   "source": [
    "transcript = transcribe_audio(video_info['audio_url'])\n",
    "print(f\"Transcript Language: {transcript['language']}\")\n",
    "print(f\"First few lines of transcript: {transcript['script'][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/0f7nfvt16ln8630csjtkk_1w0000gn/T/ipykernel_41602/2953908480.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "summary_prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            streaming=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader, TextLoader\n",
    "docs = TextLoader(\"script.txt\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'script.txt'}, page_content=\"In the last chapter, you and I started to step through the internal workings of a transformer.\\nThis is one of the key pieces of technology inside large language models, and a lot of\\nother tools in the modern wave of AI.\\nIt first hit the scene in a now-famous 2017 paper called Attention is All You Need, and\\nin this chapter, you and I will dig into what this attention mechanism is, visualizing how\\nit processes data.\\nAs a quick recap, here's the important context I want you to have in mind.\\nThe goal of the model that you and I are studying is to take in a piece of text and predict\\nwhat word comes next.\\nThe input text is broken up into little pieces that we call tokens, and these are very often\\nwords or pieces of words, but just to make the examples in this video easier for you\\nand me to think about, let's simplify by pretending that tokens are always just words.\\nThe first step in a transformer is to associate each token with a high-dimensional vector,\\nwhat we call its embedding.\\nNow the most important idea I want you to have in mind is how directions in this high-dimensional\\nspace of all possible embeddings can correspond with semantic meaning.\\nIn the last chapter we saw an example for how direction can correspond to gender, in\\nthe sense that adding a certain step in this space can take you from the embedding of a\\nmasculine noun to the embedding of the corresponding feminine noun.\\njust one example, you could imagine how many other directions in this high-dimensional space\\ncould correspond to numerous other aspects of a word's meaning. The aim of a transformer is to\\nprogressively adjust these embeddings so that they don't merely encode an individual word,\\nbut instead they bake in some much, much richer contextual meaning. I should say up front that a\\nlot of people find the attention mechanism, this key piece in a transformer, very confusing, so\\ndon't worry if it takes some time for things to sink in. I think that before we dive into the\\ncomputational details and all the matrix multiplications, it's worth thinking about a\\ncouple examples for the kind of behavior that we want attention to enable. Consider the phrases\\nAmerican true mole, one mole of carbon dioxide, and take a biopsy of the mole. You and I know\\nthat the word mole has different meanings in each one of these, based on the context.\\nBut after the first step of a transformer, the one that breaks up the text and associates each\\ntoken with a vector, the vector that's associated with mole would be the same in all three of these\\ncases, because this initial token embedding is effectively a lookup table with no reference to\\nthe context. It's only in the next step of the transformer that the surrounding embeddings have\\nthe chance to pass information into this one. The picture you might have in mind is that there\\nare multiple distinct directions in this embedding space encoding the multiple distinct meanings of\\nthe word mole, and that a well-trained attention block calculates what you need to add to the\\ngeneric embedding to move it to one of these more specific directions, as a function of the context.\\nTo take another example, consider the embedding of the word tower. This is presumably some very\\ngeneric, non-specific direction in the space, associated with lots of other large, tall nouns.\\nIf this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update\\nthis vector so that it points in a direction that more specifically encodes the Eiffel Tower,\\nmaybe correlated with vectors associated with Paris and France and things made of steel.\\nIf it was also preceded by the word miniature, then the vector should be updated even further\\nso that it no longer correlates with large tall things. More generally than just refining the\\nmeaning of a word, the attention block allows the model to move information encoded in one\\nembedding to that of another, potentially ones that are quite far away, and potentially\\nwith information that's much richer than just a single word.\\nWhat we saw in the last chapter was how after all of the vectors flow through the network,\\nincluding many different attention blocks, the computation that you perform to produce\\na prediction of the next token is entirely a function of the last vector in the sequence.\\nSo imagine, for example, that the text you input is most of an entire mystery novel,\\nway up to a point near the end which reads, therefore the murderer was, if the model is\\ngoing to accurately predict the next word, that final vector in the sequence which began its life\\nsimply embedding the word was will have to have been updated by all of the attention blocks\\nto represent much much more than any individual word, somehow encoding all of the information\\nfrom the full context window that's relevant to predicting the next word. To step through the\\nthe computations though let's take a much simpler example. Imagine that the input includes the\\nphrase a fluffy blue creature roamed the verdant forest and for the moment suppose that the only\\ntype of update that we care about is having the adjectives adjust the meanings of their\\ncorresponding nouns. What I'm about to describe is what we would call a single head of attention\\nand later we will see how the attention block consists of many different heads run in parallel.\\nAgain, the initial embedding for each word is some high-dimensional vector\\nthat only encodes the meaning of that particular word with no context.\\nActually, that's not quite true. They also encode the position of the word.\\nThere's a lot more to say about the specific way that positions are encoded,\\nbut right now all you need to know is that the entries of this vector are enough to tell you\\nboth what the word is and where it exists in the context. Let's go ahead and denote these\\nembeddings with the letter E, the goal is to have a series of computations produce a\\nnew refined set of embeddings where, for example, those corresponding to the nouns have ingested\\nthe meaning from their corresponding adjectives.\\nAnd playing the deep learning game, we want most of the computations involved to look\\nlike matrix-vector products where the matrices are full of tunable weights, things that the\\nmodel will learn based on data.\\nTo be clear, I'm making up this example of adjectives updating nouns just to illustrate\\nthe type of behavior that you could imagine an intention had doing.\\nAs with so much deep learning, the true behavior is much harder to parse, because it's based\\non tweaking and tuning a huge number of parameters to minimize some cost function.\\nIt's just that as we step through all of the different matrices filled with parameters\\nthat are involved in this process, I think it's really helpful to have an imagined example\\nof something that it could be doing to help keep it all more concrete.\\nFor the first step of this process, you might imagine each noun, like creature, asking the\\nquestion, hey, are there any adjectives sitting in front of me, and for the words fluffy and\\nblue to each be able to answer, yeah, I'm an adjective and I'm in that position.\\nThat question is somehow encoded as yet another vector, another list of numbers, which we\\ncall the query for this word.\\nThis query vector, though, has a much smaller dimension than the embedding vector, say 128.\\nComputing this query looks like taking a certain matrix, which I'll label wq, and multiplying\\nit by the embedding.\\nCompressing things a bit, let's write that query vector as q, and then anytime you see\\nme put a matrix next to an arrow like this one, it's meant to represent that multiplying\\nthis matrix by the vector at the arrow's start gives you the vector at the arrow's end.\\nIn this case, you multiply this matrix by all of the embeddings in the context, producing\\none query vector for each token.\\nThe entries of this matrix are parameters of the model, which means the true behavior\\nis learned from data, and in practice what this matrix does in a particular attention\\nhead is challenging to parse.\\nBut for our sake, imagining an example that we might hope it would learn, we'll suppose\\nthat this query matrix maps the embeddings of nouns to certain directions in this smaller\\nquery space that somehow encodes the notion of looking for adjectives in preceding positions.\\nAs to what it does to other embeddings, who knows, maybe it simultaneously tries to accomplish\\nsome other goal with those, right now we're laser focused on the nouns.\\nAt the same time, associated with this is a second matrix called the key matrix, which\\nyou also multiply by every one of the embeddings.\\nThis produces a second sequence of vectors that we call the keys.\\nConceptually you want to think of the keys as potentially answering the queries.\\nThis key matrix is also full of tunable parameters, and just like the query matrix it maps the\\nembedding vectors to that same smaller dimensional space.\\nYou think of the keys as matching the queries whenever they closely align with each other.\\nIn our example, you would imagine that the key matrix maps the adjectives, like fluffy\\nand blue, to vectors that are closely aligned with the query produced by the word creature.\\nTo measure how well each key matches each query, you compute a dot product between each\\npossible key-query pair.\\nI like to visualize a grid full of a bunch of dots, where the bigger dots correspond\\nthe larger dot products, the places where the keys and queries align. For our adjective-noun example,\\nthat would look a little more like this, where if the keys produced by fluffy and blue really do\\nalign closely with the query produced by creature, then the dot products in these two spots would be\\nsome large positive numbers. In the lingo, machine learning people would say that this means the\\nembeddings of fluffy and blue attend to the embedding of creature. By contrast to the dot\\nproduct between the key for some other word like the and the query for creature would be some small\\nor negative value that reflects that these are unrelated to each other. So we have this grid of\\nvalues that can be any real number from negative infinity to infinity giving us a score for how\\nrelevant each word is to updating the meaning of every other word. The way we're about to use these\\nscores is to take a certain weighted sum along each column weighted by the relevance. So instead\\nInstead of having values range from negative infinity to infinity, what we want is for\\nthe numbers in these columns to be between 0 and 1, and for each column to add up to\\n1, as if they were a probability distribution.\\nIf you're coming in from the last chapter, you know what we need to do then.\\nWe compute a softmax along each one of these columns to normalize the values.\\nIn our picture, after you apply softmax to all of the columns, we'll fill in the grid\\nwith these normalized values.\\nAt this point, you're safe to think about each column as giving weights\\naccording to how relevant the word on the left is to the corresponding value at the top.\\nWe call this grid an attention pattern.\\nNow, if you look at the original Transformer paper,\\nthere's a really compact way that they write this all down.\\nHere, the variables q and k represent the full arrays of query and key vectors respectively,\\nthose little vectors you get by multiplying the embeddings by the query and the key matrices.\\nThis expression up in the numerator is a really compact way to represent the grid of all possible\\ndot products between pairs of keys and queries. A small technical detail that I didn't mention\\nis that for numerical stability it happens to be helpful to divide all of these values by the\\nsquare root of the dimension in that key query space. Then this softmax that's wrapped around\\nthe full expression, is meant to be understood to apply column by column.\\nAs to that V term, we'll talk about it in just a second.\\nBefore that, there's one other technical detail that so far I've skipped.\\nDuring the training process, when you run this model on a given text example, and all\\nof the weights are slightly adjusted and tuned to either reward or punish it based on how\\nhigh a probability it assigns to the true next word in the passage, it turns out to\\nmake the whole training process a lot more efficient if you simultaneously have it predict\\nevery possible next token following each initial sub-sequence of tokens in this passage.\\nFor example, with the phrase that we've been focusing on, it might also be predicting what\\nwords follow creature, and what words follow the.\\nThis is really nice, because it means what would otherwise be a single training example\\neffectively acts as many.\\nFor the purposes of our attention pattern, it means that you never want to allow later\\nwords to influence earlier words, since otherwise they could kind of give away the answer for\\nwhat comes next. What this means is that we want all of these spots here, the ones representing\\nlater tokens influencing earlier ones, to somehow be forced to be zero. The simplest thing you might\\nthink to do is to set them equal to zero, but if you did that the columns wouldn't add up to one\\nanymore, they wouldn't be normalized. So instead a common way to do this is that before applying\\nsoftmax you set all of those entries to be negative infinity. If you do that then after\\nAfter applying softmax, all of those get turned into zero, but the columns stay normalized.\\nThis process is called masking.\\nThere are versions of attention where you don't apply it, but in our GPT example, even\\nthough this is more relevant during the training phase than it would be, say, running it as\\na chatbot or something like that, you do always apply this masking to prevent later tokens\\nfrom influencing earlier ones.\\nAnother fact that's worth reflecting on about this attention pattern is how its size is\\nequal to the square of the context size.\\nSo this is why context size can be a really huge bottleneck for large language models,\\nand scaling it up is non-trivial.\\nAs you might imagine, motivated by a desire for bigger and bigger context windows, recent\\nyears have seen some variations to the attention mechanism aimed at making context more scalable.\\nBut right here, you and I are staying focused on the basics.\\nOkay, great, computing this pattern lets the model deduce which words are relevant to which\\nother words.\\nNow you need to actually update the embeddings, allowing words to pass information to whichever\\nother words they're relevant to.\\nFor example, you want the embedding of fluffy to somehow cause a change to creature that\\nmoves it to a different part of this 12,000 dimensional embedding space that more specifically\\nencodes a fluffy creature.\\nWhat I'm going to do here is first show you the most straightforward way that you could\\ndo this, though there's a slight way that this gets modified in the context of multi-headed\\nattention.\\nThis most straightforward way would be to use a third matrix, what we call the value\\nmatrix, which you multiply by the embedding of that first word, for example fluffy.\\nThe result of this is what you would call a value vector, and this is something that\\nyou add to the embedding of the second word, in this case something you add to the embedding\\nof creature.\\nSo, this value vector lives in the same very high dimensional space as the embeddings.\\nWhen you multiply this value matrix by the embedding of a word, you might think of it\\nas saying if this word is relevant to adjusting the meaning of something else, what exactly should\\nbe added to the embedding of that something else in order to reflect this? Looking back in our\\ndiagram, let's set aside all of the keys and the queries, since after you compute the attention\\npattern you're done with those, then you're going to take this value matrix and multiply it by every\\none of those embeddings to produce a sequence of value vectors. You might think of these value\\nvectors as being kind of associated with the corresponding keys.\\nFor each column in this diagram, you multiply each of the value vectors by the corresponding\\nweight in that column.\\nFor example, here, under the embedding of creature, you would be adding large proportions\\nof the value vectors for fluffy and blue, while all of the other value vectors get zeroed\\nout, or at least nearly zeroed out.\\nAnd then finally, the way to actually update the embedding associated with this column,\\npreviously encoding some context-free meaning of creature, you add together all of these\\nrescaled values in the column, producing a change that you want to add that I'll label\\ndelta E, and then you add that to the original embedding.\\nHopefully what results is a more refined vector encoding the more contextually rich meaning,\\nlike that of a fluffy blue creature.\\nAnd of course you don't just do this to one embedding, you apply the same weighted sum\\nacross all of the columns in this picture, producing a sequence of changes.\\nAdding all of those changes to the corresponding embeddings produces a full sequence of more\\nrefined embeddings popping out of the attention block.\\nZooming out, this whole process is what you would describe as a single head of attention.\\nAs I've described things so far, this process is parameterized by three distinct matrices,\\nall filled with tunable parameters, the key, the query, and the value.\\nI want to take a moment to continue what we started in the last chapter with the scorekeeping\\nwhere we count up the total number of model parameters using the numbers from GPT-3.\\nThese key and query matrices each have 12,288 columns, matching the embedding dimension,\\nand 128 rows, matching the dimension of that smaller key query space.\\nThis gives us an additional 1.5 million or so parameters for each one.\\nIf you look at that value matrix by contrast, the way I've described things so far would\\nsuggest that it's a square matrix that has 12,288 columns and 12,288 rows, since both\\nits inputs and its outputs live in this very large embedding space.\\nIf true, that would mean about 150 million added parameters.\\nAnd to be clear, you could do that, you could devote orders of magnitude more parameters\\nto the value map than to the key and query.\\nBut in practice, it is much more efficient if instead you make it so that the number\\nof parameters devoted to this value map is the same as the number devoted to the key\\nin the query.\\nThis is especially relevant in the setting of running multiple attention heads in parallel.\\nThe way this looks is that the value map is factored as a product of two smaller matrices.\\nConceptually, I would still encourage you to think about the overall linear map, one\\nwith inputs and outputs both in this larger embedding space, for example taking the embedding\\nof blue to this blueness direction that you would add to nouns.\\nIt's just that it's broken up into two separate steps.\\nThe first matrix on the right here has a smaller number of rows, typically the same size as\\nthe key query space.\\nWhat this means is you can think of it as mapping the large embedding vectors down to\\na much smaller space.\\nThis is not the conventional naming, but I'm going to call this the value down matrix.\\nThe second matrix maps from this smaller space back up to the embedding space, producing\\nthe vectors that you use to make the actual updates.\\nI'm going to call this one the value-up matrix, which, again, is not conventional.\\nThe way that you would see this written in most papers looks a little different.\\nI'll talk about it in a minute.\\nIn my opinion, it tends to make things a little more conceptually confusing.\\nTo throw in linear algebra jargon here, what we're basically doing is constraining the\\noverall value map to be a low-rank transformation.\\nTurning back to the parameter count, all four of these matrices have the same size, and\\nThen adding them all up, we get about 6.3 million parameters for one attention head.\\nAs a quick side note, to be a little more accurate, everything described so far is what\\npeople would call a self-attention head, to distinguish it from a variation that comes\\nup in other models that's called cross-attention.\\nThis isn't relevant to our GPT example, but if you're curious, cross-attention involves\\nmodels that process two distinct types of data, like text in one language and text in\\nanother language that's part of an ongoing generation of a translation.\\nOr maybe audio input of speech, and an ongoing transcription.\\nA cross-attention head looks almost identical.\\nThe only difference is that the key and query maps act on different datasets.\\nIn a model doing translation, for example, the keys might come from one language, while\\nthe queries come from another, and the attention pattern could describe which words from one\\nlanguage correspond to which words in another.\\nAnd in this setting there would typically be no masking, since there's not really any\\nnotion of later tokens affecting earlier ones.\\nStaying focused on self-attention though, if you understood everything so far, and if\\nyou were to stop here, you would come away with the essence of what attention really\\nis.\\nAll that's really left to us is to lay out the sense in which you do this many, many\\ndifferent times.\\nIn our central example we focused on adjectives updating nouns, but of course there are lots\\nof different ways that context can influence the meaning of a word.\\nIf the words they crashed the preceded the word car, it has implications for the shape\\nand the structure of that car, and a lot of associations might be less grammatical.\\nIf the word wizard is anywhere in the same passage as Harry, it suggests that this might\\nbe referring to Harry Potter, whereas if instead the words Queen, Sussex, and William were\\nin that passage, then perhaps the embedding of Harry should instead be updated to refer\\nto the prince.\\nFor every different type of contextual updating that you might imagine, the parameters of\\nthese key and query matrices would be different to capture the different attention patterns,\\nand the parameters of our value map would be different based on what should be added to the\\nembeddings. And again, in practice the true behavior of these maps is much more difficult\\nto interpret, where the weights are set to do whatever the model needs them to do to best\\naccomplish its goal of predicting the next token. As I said before, everything we described is a\\nsingle head of attention, and a full attention block inside a transformer consists of what's\\ncalled multi-headed attention where you run a lot of these operations in parallel each with its own\\ndistinct key query and value maps. GPT-3 for example uses 96 attention heads inside each block.\\nConsidering that each one is already a bit confusing it's certainly a lot to hold in your\\nhead. Just to spell it all out very explicitly this means you have 96 distinct key and query\\nmatrices producing 96 distinct attention patterns. Then each head has its own distinct value matrices\\nused to produce 96 sequences of value vectors. These are all added together using the\\ncorresponding attention patterns as weights. What this means is that for each position in the\\ncontext, each token, every one of these heads produces a proposed change to be added to the\\nembedding in that position. So what you do is you sum together all of those proposed changes,\\none for each head, and you add the result to the original embedding of that position.\\nThis entire sum here would be one slice of what's outputted from this multi-headed attention block,\\na single one of those refined embeddings that pops out the other end of it.\\nAgain, this is a lot to think about, so don't worry at all if it takes some time to sink in.\\nThe overall idea is that by running many distinct heads in parallel,\\nyou're giving the model the capacity to learn many distinct ways that context changes meaning.\\nPulling up our running tally for parameter count with 96 heads, each including its own variation\\nof these four matrices, each block of multi-headed attention ends up with around 600 million\\nparameters. There's one added slightly annoying thing that I should really mention for any of you\\nwho go on to read more about transformers. You remember how I said that the value map is factored\\nout into these two distinct matrices, which I labeled as the value down and the value up\\nmatrices. The way that I framed things would suggest that you see this pair of matrices\\ninside each attention head, and you could absolutely implement it this way. That would\\nbe a valid design. But the way that you see this written in papers and the way that it's\\nimplemented in practice looks a little different. All of these value up matrices for each head\\nappear stapled together in one giant matrix that we call the output matrix, associated with\\nthe entire multi-headed attention block. And when you see people refer to the value matrix for a\\ngiven attention head, they're typically only referring to this first step, the one that I\\nwas labeling as the value down projection into the smaller space. For the curious among you,\\nI've left an on-screen note about it. It's one of those details that runs the risk of distracting\\nfrom the main conceptual points, but I do want to call it out just so that you know if you read\\nabout this in other sources. Setting aside all the technical nuances, in the preview from the\\nlast chapter, we saw how data flowing through a transformer doesn't just flow through a single\\nattention block. For one thing, it also goes through these other operations called multi-layer\\nperceptrons. We'll talk more about those in the next chapter. And then it repeatedly goes through\\nmany, many copies of both of these operations. What this means is that after a given word imbibes\\nsome of its context, there are many more chances for this more nuanced embedding to be influenced\\nby its more nuanced surroundings. The further down the network you go, with each embedding\\ntaking in more and more meaning from all the other embeddings, which themselves are getting\\nmore and more nuanced, the hope is that there's the capacity to encode higher level and more\\nabstract ideas about a given input beyond just descriptors and grammatical structure.\\nThings like sentiment and tone and whether it's a poem and what underlying scientific truths are\\nare relevant to the piece, and things like that.\\nTurning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the\\ntotal number of key, query, and value parameters is multiplied by another 96, which brings\\nthe total sum to just under 58 billion distinct parameters devoted to all of the attention\\nheads.\\nThat is a lot, to be sure, but it's only about a third of the 175 billion that are\\nin the network in total.\\nSo even though attention gets all of the attention, the majority of parameters come from the blocks\\nsitting in between these steps.\\nIn the next chapter, you and I will talk more about those other blocks and also a lot more\\nabout the training process.\\nA big part of the story for the success of the attention mechanism is not so much any\\nspecific kind of behavior that it enables, but the fact that it's extremely parallelizable,\\nmeaning that you can run a huge number of computations in a short time using GPUs.\\nthat one of the big lessons about deep learning in the last decade or two has been that scale\\nalone seems to give huge qualitative improvements in model performance. There's a huge advantage to\\nparallelizable architectures that let you do this. If you want to learn more about this stuff, I've\\nleft lots of links in the description. In particular, anything produced by Andre Karpathy or Chris Ola\\ntend to be pure gold. In this video, I wanted to just jump into attention in its current form,\\nbut if you're curious about more of the history for how we got here and how you might reinvent\\nthis idea for yourself, my friend Vivek just put up a couple videos giving a lot more of\\nthat motivation. Also, Britt Cruz from the channel The Art of the Problem\\nhas a really nice video about the history of large language models.\\nyou\\n\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "document = [Document(page_content=\"\\n\".join([t[\"text\"] for t in transcript[\"script\"]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_client.py          :1786 2024-10-12 11:31:22,301 HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "summary_chain = create_stuff_documents_chain(llm,summary_prompt)\n",
    "result = await summary_chain.ainvoke({\"context\": document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- ðŸ¥“ í•œ ë‚¨ìžê°€ ë² ì´ì»¨ì„ ê°€ì ¸ì˜´.  \\n- ðŸ¥š ê³„ëž€ì„ ê¹¨ê³  ë…¸ë¥¸ìžë¥¼ ë”°ë¡œ ë‹´ìŒ.  \\n- ðŸ¥„ í°ìžëŠ” ìƒìœ¼ë¡œ ë¨¹ê³ , ì†Œê¸ˆì„ ë„£ìŒ.  \\n- ðŸŒ³ ë‚˜ë¬´ì “ê°€ë½ì„ ì‚¬ìš©í•¨.  \\n- ðŸ íŒŒìŠ¤íƒ€ë¥¼ ë„£ê³  ìž¬ë£Œë¥¼ ì„žìŒ.  \\n- ðŸ§‚ í›„ì¶”ì™€ ê·¸ë¼ë¼ë¹ ë‹¤ë…¸ë¥¼ ë¿Œë¦¼.  \\n- ðŸ”¥ ë² ì´ì»¨ì„ êµ¬ì›Œ ê³„ëž€ì¹˜ì¦ˆ ì†ŒìŠ¤ë¥¼ ì„žìŒ.  \\n- ðŸ½ï¸ ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ì˜ˆì˜ê²Œ ë‹´ì•„ ì™„ì„±í•¨.  \\n- ðŸ¤¤ ì €ë„ í•œë²ˆ ê¼­ ë¨¹ì–´ë³´ê³  ì‹¶ë„¤ìš”.  '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/0f7nfvt16ln8630csjtkk_1w0000gn/T/ipykernel_41602/2497576997.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- ðŸ¥“ í•œ ë‚¨ìžê°€ ë² ì´ì»¨ì„ ê°€ì ¸ì˜´.  ',\n",
       " '- ðŸ¥š ê³„ëž€ì„ ê¹¨ê³  ë…¸ë¥¸ìžë¥¼ ë”°ë¡œ ë‹´ìŒ.  ',\n",
       " '- ðŸ¥„ í°ìžëŠ” ìƒìœ¼ë¡œ ë¨¹ê³ , ì†Œê¸ˆì„ ë„£ìŒ.  ',\n",
       " '- ðŸŒ³ ë‚˜ë¬´ì “ê°€ë½ì„ ì‚¬ìš©í•¨.  ',\n",
       " '- ðŸ íŒŒìŠ¤íƒ€ë¥¼ ë„£ê³  ìž¬ë£Œë¥¼ ì„žìŒ.  ',\n",
       " '- ðŸ§‚ í›„ì¶”ì™€ ê·¸ë¼ë¼ë¹ ë‹¤ë…¸ë¥¼ ë¿Œë¦¼.  ',\n",
       " '- ðŸ”¥ ë² ì´ì»¨ì„ êµ¬ì›Œ ê³„ëž€ì¹˜ì¦ˆ ì†ŒìŠ¤ë¥¼ ì„žìŒ.  ',\n",
       " '- ðŸ½ï¸ ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ì˜ˆì˜ê²Œ ë‹´ì•„ ì™„ì„±í•¨.  ',\n",
       " '- ðŸ¤¤ ì €ë„ í•œë²ˆ ê¼­ ë¨¹ì–´ë³´ê³  ì‹¶ë„¤ìš”.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mcreate_documents([t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transcript[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[0;32m----> 3\u001b[0m     doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43msummary\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "documents = text_splitter.create_documents([t[\"text\"] for t in transcript[\"script\"]])\n",
    "for doc in documents:\n",
    "    doc.page_content += \"\\n\" + summary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "you_url = \"https://youtube.com/shorts/a--NSC19MXM?si=yiun-HK_7wX1sNvL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'id': 'sync-26147017-ff6e-408d-9622-80c484868c42-e1', 'status': 'IN_QUEUE'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = \"https://api.runpod.ai/v2/uq96boxkzy99ev/runsync\"\n",
    "\n",
    "# FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„° (ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„° ì„¤ì •)\n",
    "body = {\"input\":{\n",
    "    \"api\":{\n",
    "        \"method\":\"POST\",\n",
    "        \"endpoint\":\"/ping\",\n",
    "    },\n",
    "    \"payload\":{},\n",
    "}}\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: IN_QUEUE\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# ìž‘ì—… ID (ìž‘ì—… ì™„ë£Œëœ job ID)\n",
    "job_id = response.json()['id']\n",
    "\n",
    "# RunPod API STATUS ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "status_url = f\"https://api.runpod.ai/v2/wm1xrz07all039/status/{job_id}\"\n",
    "\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# ìž‘ì—… ìƒíƒœ ë° ê²°ê³¼ í™•ì¸ ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.get(status_url, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    job_result = response.json()\n",
    "    if job_result.get(\"status\") == \"COMPLETED\":\n",
    "        print(\"Job Completed! Result:\", job_result.get(\"output\"))\n",
    "    else:\n",
    "        print(f\"Job Status: {job_result.get('status')}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'delayTime': 6071, 'executionTime': 3825, 'id': 'sync-c9bea7a9-08ea-447d-bd62-e481515985b4-e1', 'output': {'hashtags': '#íŒŒë¿Œë¦¬ #ìƒì¼ #ì¹œêµ¬ #ì˜ˆëŠ¥ #ë…¸ëž­ì´', 'title': 'ìˆ˜ì œ ê¹€ë°¥ 30ì¤„ë¡œ ìƒì¼ íŒŒí‹°í•©ë‹ˆë‹¤!! ì—­ëŒ€ê¸‰ ì„ ë¬¼ ì–¸ë°•ì‹±ê¹Œì§€!!!!!!!'}, 'status': 'COMPLETED', 'workerId': 'vto3bvdf9z7v0a'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = f\"https://api.runpod.ai/v2/{endpoint_id}/runsync\"\n",
    "you_url = \"https://youtu.be/omEk2BNDt1I?si=xjtbYANtlux5CTfB\"\n",
    "\n",
    "\n",
    "# FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„°\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"endpoint\": \"/get_title_hash\",\n",
    "        \"method\": \"GET\",\n",
    "        # \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "        \"params\": {\"url\": you_url},\n",
    "    }\n",
    "}\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "# api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "# endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# # RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "# url = f\"https://api.runpod.ai/v2/{endpoint_id}/runsync\"\n",
    "\n",
    "# # FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„°\n",
    "# payload = {\n",
    "#     \"input\": {\n",
    "#         \"endpoint\": \"/get_script_summary\",\n",
    "#         \"method\": \"GET\",\n",
    "#         \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "#         \"params\": {\"url\": you_url},\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {api_key}\",\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "# # RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "# response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# # ì‘ë‹µ í™•ì¸\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Response:\", response.json())\n",
    "# else:\n",
    "#     print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Response: {'id': 'c2cb7372-07b6-4146-b2a4-7c8ad4e0eb34-e1', 'status': 'IN_QUEUE'}\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: COMPLETED\n",
      "ê²°ê³¼ê°’:{'delayTime': 6033, 'executionTime': 191359, 'id': 'c2cb7372-07b6-4146-b2a4-7c8ad4e0eb34-e1', 'output': {'language': 'ko', 'script': [{'end': 1.92, 'start': 0, 'text': ' ì˜¤ëŠ˜ ìš°ë¦¬ ë…¸ëž­ì´ ìƒì¼ìž…ë‹ˆë‹¤!'}, {'end': 8.32, 'start': 4.38, 'text': ' íŒì½˜ì´ê°€ ë©¤ë²„ë“¤ ìƒì¼ì„ ë§žì€ ì†Œì›ì„ ì¢€ ë“¤ì–´ì£¼ê³  ìžˆì–´ìš”.'}, {'end': 10.08, 'start': 8.32, 'text': ' ì˜¤ëŠ˜ ë…¸ëž­ì´ì˜ ì†Œì›ì€ ë°”ë¡œ'}, {'end': 12.36, 'start': 10.08, 'text': ' ë…¸ëž­ì´ê°€ ê°€ìž¥ ì¢‹ì•„í•˜ëŠ” ìŒì‹ ë­ì£ ?'}, {'end': 13.8, 'start': 12.36, 'text': ' ê¹€ë°¥ íŒŒí‹°ìž…ë‹ˆë‹¤.'}, {'end': 16.06, 'start': 13.8, 'text': ' ìš°ì™€ ê¹€ë°¥ ë§›ìžˆê² ë‹¤.'}, {'end': 17.36, 'start': 16.06, 'text': ' ê¹€ë°¥ì´ ì•½ê°„ ì¢€ ìƒì†Œí•˜ì§€ ì•Šë‚˜?'}, {'end': 21.04, 'start': 17.36, 'text': ' ë…¸ëž­ì´ê°€ ê¹€ë°¥ì„ ì¢‹ì•„í•œë‹¤ëŠ” ê²ƒì„ ëª¨ë¥´ëŠ” ë¶„ë“¤ë„ ì¢€ ìžˆì„ í…ë°'}, {'end': 23.76, 'start': 21.04, 'text': ' ì‚¬ì‹¤ ì €í¬ ì–´ë¨¸ë‹ˆëŠ” ì•„ì‹­ë‹ˆë‹¤.'}, {'end': 25.72, 'start': 23.76, 'text': ' ì œê°€ ê¹€ë°¥ì„ ì¢‹ì•„í•˜ê¸° ë•Œë¬¸ì—'}, {'end': 28.04, 'start': 25.72, 'text': ' ê¸°ì ˆ ë•Œ ê¹€ë°¥ í•´ë‹¬ë¼ê³  ì œê°€ ì¡°ë¥´ê±°ë“ ìš”.'}, {'end': 31.4, 'start': 28.04, 'text': ' ëª…ì ˆì— ë¨¹ì„ ì •ë„ë©´ ì´ê±´ ì¸ì •ìž…ë‹ˆê¹Œ?'}, {'end': 33.12, 'start': 31.4, 'text': ' ì†”ì§ížˆ ì‚¬ë¨¹ëŠ” ê¹€ë°¥ ì¤‘ì—'}, {'end': 34.96, 'start': 33.12, 'text': ' ìš°ë¦¬ ì—„ë§ˆ ê¹€ë°¥ì´ ì—†ë”ë¼ê³ .'}, {'end': 39.5, 'start': 35.98, 'text': ' ê·¸ëž˜ì„œ ì˜¤ëŠ˜ ìš°ë¦¬ê°€ ë…¸ëž­ì´ ìƒì¼ ê¸°ë…ìœ¼ë¡œ'}, {'end': 41.72, 'start': 39.5, 'text': ' ê¹€ë°¥ì„ í•œë²ˆ ë§Œë“¤ì–´ë³´ë ¤ê³  ì´ë ‡ê²Œ ìž¬ë£Œë“¤ì„'}, {'end': 43.76, 'start': 41.72, 'text': ' ì•¼ì˜¤ë¯¸!'}, {'end': 47.72, 'start': 43.76, 'text': ' ê³¼ì—° ì´ ìž¬ë£Œë¡œ ë…¸ëž­ì´ì˜ í–¥ìˆ˜ë¥¼ ì €í¬ê°€ ëŠë¼ê²Œ í•´ì¤„ ìˆ˜ ìžˆì„ì§€'}, {'end': 49.98, 'start': 47.72, 'text': ' ì–´ë¨¸ë‹ˆë§Œí¼ì€ ì•ˆ ë¼.'}, {'end': 53.24, 'start': 49.98, 'text': ' íž˜ë“¤ê² ì§€ë§Œ ì•„ë²„ì§€ë§Œí¼ì€ í•  ìˆ˜ ìžˆì§€.'}, {'end': 56.72, 'start': 53.24, 'text': ' ìš°ë¦¬ ë‹¤ ê°™ì´ ì´ë ‡ê²Œ ê¹€ë°¥ ì˜¤ìˆœë…¸ì†Œ ë§Œë“¤ë©´ì„œ ìž¬ë°Œê²Œ ë†€ì•„ë³´ìžê³ .'}, {'end': 57.64, 'start': 56.72, 'text': ' ì¢‹ìŠµë‹ˆë‹¤.'}, {'end': 59.4, 'start': 57.64, 'text': ' ê²°êµ­ì—” ê¹€ë°¥ ë§›ì´ ì¤‘ìš”í•œ ê²Œ ì•„ë‹ˆì•¼.'}, {'end': 60.52, 'start': 59.4, 'text': ' ì˜¤ìˆœë„ìˆœì´ ì¤‘ìš”í•œ ê±°ì•¼.'}, {'end': 61.64, 'start': 60.52, 'text': ' ì•„ë‹ˆì•¼. ê·¼ë° ë§›ë„ ì¤‘ìš”í•˜ìž–ì•„.'}, {'end': 62.88, 'start': 61.64, 'text': ' ì•„ ë§žë‚˜.'}, {'end': 63.88, 'start': 62.88, 'text': ' ë§›ìžˆê²Œ ë¨¹ì–´ì•¼ì§€.'}, {'end': 65.32, 'start': 63.88, 'text': ' ì•„ë‹ˆì•¼.'}, {'end': 66.14, 'start': 65.32, 'text': ' ì•„ë‹ˆì•¼. ì•„ë‹ˆì•¼.'}, {'end': 66.72, 'start': 66.14, 'text': ' ì•„ë‹ˆì•¼.'}, {'end': 68.82, 'start': 66.72, 'text': ' ê±°ê¸°ì„œ ì¤€ë¹„ë˜ë©´ ì•ˆ ë¼.'}, {'end': 71.52, 'start': 68.82, 'text': ' ë¬´ìŠ¨ ë§ë§Œ í•˜ë©´ ìš”ì¦˜ ë”± í›„ì‚°ì´ ë­.'}, {'end': 72.76, 'start': 71.52, 'text': ' ì˜¤ëŠ˜ì˜ ë£° ìžˆìŠµë‹ˆê¹Œ?'}, {'end': 73.52, 'start': 72.76, 'text': ' ìƒì¼ ë£°.'}, {'end': 74.88, 'start': 73.52, 'text': ' ì•„ ìƒì¼ ë£°?'}, {'end': 75.72, 'start': 74.88, 'text': ' ìš• ê¸ˆì§€.'}, {'end': 76.32, 'start': 75.72, 'text': ' ì•„ ìš•.'}, {'end': 77.16, 'start': 76.32, 'text': ' ì•„ ìš• ê¸ˆì§€.'}, {'end': 78.72, 'start': 77.16, 'text': ' ì €ë²ˆì— ë§í–ˆë˜ ëŒ€ë¡œ í•œë²ˆ'}, {'end': 80.1, 'start': 78.72, 'text': ' ì™¸ëž˜ì–´ ê¸ˆì§€ í•œë²ˆ í•´ë³¼ê¹Œìš”?'}, {'end': 81.2, 'start': 80.1, 'text': ' ì•„ ì§„ì§œë¡œ ì™¸ëž˜ì–´ë¥¼ ê¸ˆì§€.'}, {'end': 82.4, 'start': 81.2, 'text': ' ì™¸ëž˜ì–´ ê¸ˆì§€.'}, {'end': 83.8, 'start': 82.4, 'text': ' ë§‰ ì´ë ‡ê²Œ ì“°ë©´?'}, {'end': 85.24, 'start': 83.8, 'text': ' ì“°ë©´ ì§œì˜¤ê°€'}, {'end': 85.6, 'start': 85.24, 'text': ' ì–´ë¨¸.'}, {'end': 86.6, 'start': 85.6, 'text': ' ì›€ì§ì—¬ì¤˜.'}, {'end': 87.56, 'start': 86.6, 'text': ' ì•„ ê·¸ëŸ¬ë©´ ìžê¸°ê°€ ì“°ë©´'}, {'end': 88.8, 'start': 87.56, 'text': ' ìžê¸°ê°€ ìžê¸°ë¥¼ ì‘ì§•í•˜ë‚˜?'}, {'end': 90.96, 'start': 89.8, 'text': ' ì•„ ì €ëŠ” ê¹ë‘ê¸°.'}, {'end': 92, 'start': 90.96, 'text': ' ë„¤ê°€ ì™œ.'}, {'end': 93.7, 'start': 92, 'text': ' ì €ëŠ” ì§„í–‰ì„ í•´ì•¼ ë˜ë‹ˆê¹ìš”.'}, {'end': 97.14, 'start': 95.7, 'text': ' ì•½ê°„ ì´ ë‘˜ì´ê°€ ë¶ˆë¦¬í•´.'}, {'end': 98.04, 'start': 97.14, 'text': ' ì˜ë¬¸í•™ê³¼.'}, {'end': 100.08, 'start': 98.04, 'text': ' ë˜ ì™¸ê³  ì¶œì‹ .'}, {'end': 101.38, 'start': 100.08, 'text': ' í°ì¼ ë‚¬ë„¤.'}, {'end': 104.84, 'start': 101.38, 'text': ' ì™¸ëž˜ì–´ê°€ ê¸ˆì§€ëœ ë…¸ìž‰ì´ì˜ ê¹€ë°¥ ìƒì¼ ìž”ì¹˜.'}, {'end': 106.48, 'start': 104.84, 'text': ' ì‹œìž‘í•´ ë³´ê² ìŠµë‹ˆë‹¤.'}, {'end': 107.34, 'start': 106.48, 'text': ' ì‰½ì§€ ì•Šë„¤.'}, {'end': 108.78, 'start': 107.34, 'text': ' ë°œ ì—†ë‚˜? ë°œ.'}, {'end': 109.34, 'start': 108.78, 'text': ' ë°œ?'}, {'end': 109.68, 'start': 109.34, 'text': ' ì–´.'}, {'end': 111.08, 'start': 109.68, 'text': ' ë°œ.'}, {'end': 114.76, 'start': 113.78, 'text': ' ì–´ ìš• ê¸ˆì§€.'}, {'end': 115.68, 'start': 114.76, 'text': ' ìš• ê¸ˆì§€.'}, {'end': 116.42, 'start': 115.68, 'text': ' ìš•í•˜ë©´ ì•ˆ ë¼.'}, {'end': 117.56, 'start': 116.42, 'text': ' í‘œì •ìœ¼ë¡œ ìš•í•˜ê³ '}, {'end': 118.32, 'start': 117.56, 'text': ' ì•Œì•„ì„œ ìš• ê¸ˆì§€.'}, {'end': 119.9, 'start': 118.32, 'text': ' ë°œì´ ì‹œë¼ì´.'}, {'end': 120.86, 'start': 119.9, 'text': ' ì´ê±° ë­ì•¼?'}, {'end': 121.96, 'start': 120.86, 'text': ' ì´ê±° ëˆ„êµ¬ ê±°ì•¼?'}, {'end': 122.9, 'start': 121.96, 'text': ' ì‚¼ê²¹ì‚´ì´ë„¤.'}, {'end': 124.7, 'start': 122.9, 'text': ' ì•„ ìš”ì¦˜ ì‚¼ê²¹ì‚´ì—ìš”.'}, {'end': 125.6, 'start': 124.7, 'text': ' ê¹»ìžŽ ë„£ì–´ê°€ì§€ê³ '}, {'end': 126.5, 'start': 125.6, 'text': ' ë³¼ë„ ë§ê³ .'}, {'end': 128.04, 'start': 126.5, 'text': ' ì´ê±° í˜•ì´ ë§Œë“  ê±°ì•¼.'}, {'end': 128.74, 'start': 128.04, 'text': ' ë„ˆê°€ ì¨ë„ ë¼.'}, {'end': 130.08, 'start': 128.74, 'text': ' ë‚˜ëŠ” ì§„í–‰ì„ í•´ì•¼ ë˜ê¸° ë•Œë¬¸ì—.'}, {'end': 131.54, 'start': 130.08, 'text': ' ì‹«ì–´.'}, {'end': 132.58, 'start': 131.54, 'text': ' ìž‘ì •í•˜ê³  ë§‰.'}, {'end': 133.68, 'start': 132.58, 'text': ' ìž‘ì •í•˜ê³  ê³¨íŒ¡ ë‚˜ê³ .'}, {'end': 134.92, 'start': 133.68, 'text': ' ì•„ë‹ˆ.'}, {'end': 136.48, 'start': 134.92, 'text': ' ì•¼ ìš°ë¦¬ ë°¥ ëª‡ ê°œë‚˜ ì“°ë ¤ë‚˜.'}, {'end': 137.98, 'start': 136.48, 'text': ' ì—­ì‹œ ì•ˆë°•ì„œ 12ê°œì¸ë°.'}, {'end': 138.58, 'start': 137.98, 'text': ' ì–´? ì–´?'}, {'end': 140.48, 'start': 138.58, 'text': ' ë‹¹ì‹  ê·¸ ë§ ì¡°ì‹¬í•´ì•¼ ë©ë‹ˆë‹¤.'}, {'end': 141.52, 'start': 140.48, 'text': ' ìƒìž.'}, {'end': 143.66, 'start': 141.52, 'text': ' ìž ì—¬ëŸ¬ë¶„ë“¤ ì´ì œ ì§„ì§œ ì‹œìž‘í•©ë‹ˆë‹¤.'}, {'end': 145.16, 'start': 143.66, 'text': ' ìƒì¼ìžê°€ ì„œë¥¸ ì›ìž…ë‹ˆë‹¤. ì„œë¥¸ ì›.'}, {'end': 146.68, 'start': 145.16, 'text': ' ì™¸ëž˜ì–´ ê¸ˆì§€ ì‹œìž‘ì´ë¼ê³ .'}, {'end': 147.4, 'start': 146.68, 'text': ' ì™¸ëž˜ì–´ ê¸ˆì§€.'}, {'end': 148.8, 'start': 147.56, 'text': ' ìŒˆë„.'}, {'end': 150.36, 'start': 148.8, 'text': ' ì˜¤ì¼€ì´ ë§ˆì§€ë§‰ìž…ë‹ˆë‹¤.'}, {'end': 151.36, 'start': 150.36, 'text': ' ì‹œìž‘ìž…ë‹ˆë‹¤.'}, {'end': 153.8, 'start': 151.36, 'text': ' ìž ì—¬ê¸° ìˆ˜ë§Žì€ ìž¬ë£Œë“¤ì´ ìžˆëŠ”ë° ì§±ë°°ëŠ”?'}, {'end': 155.76, 'start': 153.8, 'text': ' ì•„ ì € ê°™ì€ ê²½ìš°ì—ëŠ” ë°”ë¡œ ì´'}, {'end': 157.4, 'start': 155.76, 'text': ' ìƒˆìš°ë¥¼ ì´ìš©í•  ê²ë‹ˆë‹¤.'}, {'end': 157.9, 'start': 157.4, 'text': ' ìƒˆìš°?'}, {'end': 159.34, 'start': 157.9, 'text': ' ì´ ë…¸ëž˜ê°€ ìƒˆìš° ì¢‹ì•„í•˜ëŠ” ê±° ì•„ë‹ˆì•¼?'}, {'end': 161.78, 'start': 159.34, 'text': ' ê·¼ë° ìƒìƒˆìš°ë¥¼ ì‚¬ìš©í•˜ë©´ì€'}, {'end': 163.14, 'start': 161.78, 'text': ' ì´ í˜•ë“¤ì´'}, {'end': 164.04, 'start': 163.14, 'text': ' ì•„'}, {'end': 167.22, 'start': 166.04, 'text': ' ì–´ìš° ìƒí•˜ê²Œ ì–˜ê¸°í•´.'}, {'end': 168.24, 'start': 167.22, 'text': ' ì™œì™œì™œ.'}, {'end': 170.78, 'start': 168.24, 'text': ' ê±°ë¶€ ë°˜ì‘ì´ ì¼ì–´ë‚˜ê°€ì§€ê³ '}, {'end': 172.16, 'start': 170.78, 'text': ' ê±°ë¶€ ë°˜ì‘ ë•Œë¬¸ì— ì¢€'}, {'end': 172.96, 'start': 172.16, 'text': ' ë°ì¹  ê²ë‹ˆë‹¤.'}, {'end': 177.02, 'start': 175.56, 'text': ' ì•„ ë§Œë“¤ì–´ì„œ í•˜ë‚˜ì”© ìª¼ì„œ ë¨¹ëŠ”êµ¬ë‚˜.'}, {'end': 177.5, 'start': 177.02, 'text': ' ê¹€ë°¥ì„'}, {'end': 177.52, 'start': 177.5, 'text': ' ê¹€ë°¥ì„'}, {'end': 177.56, 'start': 177.52, 'text': ' ê¹€ë°¥ì„'}, {'end': 179, 'start': 177.56, 'text': ' ê¹€ë°¥ì„ ì´ë ‡ê²Œ ìª¼ì„œ ë¨¹ëŠ” ë§›ì´ ìžˆì–´.'}, {'end': 181.64, 'start': 179, 'text': ' ì´ê±° í–„ì€ ë­ êµ¬ì›Œì„œ ë„£ì–´? ì•„ë‹ˆë©´ ê·¸ëƒ¥ ë„£ì–´?'}, {'end': 182.86, 'start': 181.64, 'text': ' ê·¸ëƒ¥ ë„£ì–´ ê·¸ëƒ¥ ë„£ì–´ ê·¸ëƒ¥ ë„£ì–´ ê·¸ëƒ¥ ë„£ì–´.'}, {'end': 184.04, 'start': 182.86, 'text': ' í•˜ìž ë³¶ì•„ì•¼ì§€.'}, {'end': 185.6, 'start': 184.04, 'text': ' ê·¸ëŸ¼ ì§±ë°°ê°€ ì¢€ ë³¶ì•„ì¤„ëž˜?'}, {'end': 187.8, 'start': 185.6, 'text': ' ê·¸ëž˜ ë‚´ê°€ ë‚´ê°€ ë³¶ì•„ì•¼ ë¼.'}, {'end': 189.24, 'start': 187.8, 'text': ' í˜¹ì‹œ'}, {'end': 190.7, 'start': 189.24, 'text': ' ì•„ëƒì•„ëƒ ê·¸ê±° ë§ê³  ì¢€ ì¢€ ì¢€.'}, {'end': 192.9, 'start': 190.7, 'text': ' ì´ê±° ì™œ ì´ë ‡ê²Œ ìƒˆê¹Œë§¤?'}, {'end': 194.88, 'start': 192.9, 'text': ' ì´ê±° í–‰ì„± í­ë°œì´ìž–ì•„ ì´ê±°.'}, {'end': 196.92, 'start': 194.88, 'text': ' ì´ê±° ìŠ¤ëª¨í‚¤ í–¥ ë‚´.'}, {'end': 199.54, 'start': 196.92, 'text': ' ìŠ¤ëª¨í‚¤ ìš©ë„ë¡œ ì“°ëŠ” ê±° ì•„ë‹ˆì•¼.'}, {'end': 200.52, 'start': 199.54, 'text': ' ìž ì‹œë§Œìš”.'}, {'end': 201.92, 'start': 200.52, 'text': ' ìž ì‹œë§Œìš”.'}, {'end': 202.78, 'start': 201.92, 'text': ' ì•ˆë…•.'}, {'end': 204.28, 'start': 202.78, 'text': ' ë¹µ.'}, {'end': 206.56, 'start': 204.28, 'text': ' ìƒê°ë³´ë‹¤ ì¢€ ì‹¬í•´ì•¼ê² ë„¤.'}, {'end': 207.52, 'start': 206.56, 'text': ' ëª¨ëž˜ì´ê°€ ìƒê°í•˜ëŠ”.'}, {'end': 209.16, 'start': 207.52, 'text': ' ê¹€ë°¥ì˜ ìƒëª…ì€ ë­ì£ ?'}, {'end': 210.46, 'start': 209.16, 'text': ' ë‹¨ë¬´ì§€.'}, {'end': 212.8, 'start': 210.46, 'text': ' ë‹¨ë¬´ì§€ ì•ˆ ë“¤ì–´ê°€ë©´ ì†”ì§ížˆ ê¹€ë°¥ ë§›ì´ ì•ˆ ë‚˜.'}, {'end': 215.3, 'start': 212.8, 'text': ' ë‹¨ë¬´ì§€ê°€ ì•½ê°„ ê¹€ë°¥ì˜ ì •ì²´ì„±ì´ë‹¤.'}, {'end': 216.16, 'start': 215.3, 'text': ' ë„¤.'}, {'end': 217.3, 'start': 216.16, 'text': ' ê·¸ ì¢€ íŠ¹ë³„í•©ë‹ˆê¹Œ?'}, {'end': 219.76, 'start': 217.3, 'text': ' ê·¸ ì–´ë¨¸ë‹ˆì˜ ê¹€ë°¥ì— ë“¤ì–´ê°€ëŠ” ìž¬ë£Œë“¤ì´.'}, {'end': 220.9, 'start': 219.76, 'text': ' ì•„ íŠ¹ë³„í•˜ì§€ ì•Šì•„.'}, {'end': 223.24, 'start': 220.9, 'text': ' í–„, ê³„ëž€, ë‹¨ë¬´ì§€, ì‹œê¸ˆì¹˜.'}, {'end': 225, 'start': 223.24, 'text': ' í•œ ìš” ì •ë„ë§Œ ë“¤ì–´ê°€ëŠ” ê±° ê°™ì•„.'}, {'end': 226.24, 'start': 225, 'text': ' ê·¸ë ‡ê²Œë§Œ í–ˆëŠ”ë°ë„'}, {'end': 227.88, 'start': 226.24, 'text': ' ë°–ì—ì„œ ì‚¬ ë¨¹ìœ¼ë©´ ê·¸ ë§›ì´ ì•ˆ ë‚˜.'}, {'end': 231.04, 'start': 227.88, 'text': ' ì•½ê°„ ì–´ë¨¸ë‹ˆ ê³ ìœ ì˜ ë°‘ê°„ì´ë‚˜ ì´ëŸ° ê²Œ ë˜ ìžˆë‚˜ ë´.'}, {'end': 231.64, 'start': 231.04, 'text': ' ì•„ ê·¸ëŸ¼ìš” ê·¸ëŸ¼ìš”.'}, {'end': 234.04, 'start': 231.64, 'text': ' ë…¸ëž­ì´ ì–´ë¨¸ë‹ˆê°€ ì§„ì§œë¡œ ì§„ì§œ ìš”ë¦¬ë¥¼ ìž˜í•˜ì„¸ìš”.'}, {'end': 236.88, 'start': 234.04, 'text': ' ì•„ ì§„ì§œ ê±°ì˜ ë­ í•œì‹ ì „ë¬¸ê°€ê¸‰ì´ë¼ì„œ.'}, {'end': 237.48, 'start': 236.88, 'text': ' ë§›ë„ ì œë²•.'}, {'end': 238.34, 'start': 237.48, 'text': ' ì–´ ì§„ì§œ.'}, {'end': 239.98, 'start': 238.34, 'text': ' ì–´?'}, {'end': 242.46, 'start': 239.98, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 244.18, 'start': 242.46, 'text': ' ê¹€ë°¥.'}, {'end': 246.52, 'start': 244.18, 'text': ' ì•„ ì–¼ë§ˆë‚˜ ê·¸ ë¶€ë¶„ì„.'}, {'end': 247.42, 'start': 246.52, 'text': ' ì–´ ë„ˆë¬´ ìž¬ë°Œë‹¤.'}, {'end': 249.6, 'start': 247.42, 'text': ' ìž ê¹ë§Œ.'}, {'end': 250.62, 'start': 249.6, 'text': ' ì§„í–‰ìžì˜ˆìš”.'}, {'end': 252.66, 'start': 250.62, 'text': ' ì•„ ì¹´ë©”ë¼ ìž¡ê³  ìžˆì–´.'}, {'end': 253.52, 'start': 252.66, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 254.36, 'start': 253.52, 'text': ' ë‚´ê°€ í˜•ë‹˜.'}, {'end': 255.56, 'start': 254.36, 'text': ' ê¹€ë°¥.'}, {'end': 256.6, 'start': 255.56, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 257.36, 'start': 256.6, 'text': ' ì–´ ì•¼ ì´ê±°.'}, {'end': 258.34, 'start': 257.36, 'text': ' ë°©ì‹¬í•˜ë©´ ì•ˆ ë˜ê² ë‹¤.'}, {'end': 260.36, 'start': 258.34, 'text': ' ì–´ ê·¼ë° ì¸ë””ì—… í•œë²ˆ ë´ì£¼ëŠ” ê²ë‹ˆê¹Œ?'}, {'end': 261.08, 'start': 260.36, 'text': ' ì–´?'}, {'end': 261.64, 'start': 261.08, 'text': ' ì–´?'}, {'end': 262.04, 'start': 261.64, 'text': ' ì–´?'}, {'end': 262.58, 'start': 262.04, 'text': ' ì–´?'}, {'end': 263.1, 'start': 262.58, 'text': ' ì–´?'}, {'end': 263.64, 'start': 263.1, 'text': ' ì–´?'}, {'end': 265.28, 'start': 263.64, 'text': ' ì§„í–‰ìžê°€.'}, {'end': 266.84, 'start': 265.28, 'text': ' ì•„ ê·¼ë° ìš°ë¦¬ ë‹¤ í–ˆìž–ì•„ ê·¼ë°.'}, {'end': 269.08, 'start': 266.84, 'text': ' ì•„ë‹ˆ ì˜¤ëŠ˜ ì œê°€ ìž… ë‹«ê³  ìžˆì—ˆì–´.'}, {'end': 271.12, 'start': 269.08, 'text': ' ìž ê·¸ëŸ¬ë©´ ìš°ë¦¬ ë°¥ ë“ì—¬ì•¼ê² ë„¤.'}, {'end': 272.34, 'start': 271.12, 'text': ' ì›ìˆ­ì´.'}, {'end': 274.42, 'start': 272.34, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 276.52, 'start': 274.42, 'text': ' ë§›ì‚´ ìš”ì •ë„ ìŸ¤ ì“°ë©´ ë­ ì–´ë•Œ?'}, {'end': 277.22, 'start': 276.52, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 278.26, 'start': 277.22, 'text': ' ë§›ì‚´ ë¬´ë¤ì´ë‹¤.'}, {'end': 279.52, 'start': 278.26, 'text': ' ì‚°ì‚°ì‚° ìŒ“ì´ê² ë‹¤.'}, {'end': 280.46, 'start': 279.52, 'text': ' ì•„ ì´ê±´ ê·¸ëƒ¥ ë¨¹ì–´ì•¼ì§€.'}, {'end': 280.96, 'start': 280.46, 'text': ' ì–´.'}, {'end': 283.72, 'start': 280.96, 'text': ' í–„ì„ êµ½ê² ìŠµë‹ˆë‹¤.'}, {'end': 284.82, 'start': 283.72, 'text': ' ì–´.'}, {'end': 285.96, 'start': 284.82, 'text': ' ê¸°ë¦„ ë¶€ì´ëŠ” ê±° ì¡°ì‹¬í•˜ê³ .'}, {'end': 286.8, 'start': 285.96, 'text': ' ì•„ìž‰.'}, {'end': 287.3, 'start': 286.8, 'text': ' ìž˜ ëë‹¤.'}, {'end': 289.1, 'start': 287.3, 'text': ' ê¹€ë°¥ë„ ë§Œë“¤ì–´ë³´ìž.'}, {'end': 291.1, 'start': 289.1, 'text': ' ì´ê²Œ ì§„ì§œ ê¹€ë°¥ ì•„ì´ê°€?'}, {'end': 292.4, 'start': 291.1, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 294.46, 'start': 292.4, 'text': ' ê¹€ì´ íŽ„íŽ„ ë‚˜ëŠ” ë°¥ì´ ë¬´ìŠ¨.'}, {'end': 295.6, 'start': 294.46, 'text': ' ì™€.'}, {'end': 296.2, 'start': 295.6, 'text': ' ì•¼.'}, {'end': 297.7, 'start': 296.84, 'text': ' ì§€ë‹¨.'}, {'end': 298.74, 'start': 297.7, 'text': ' ì¢‹ì•„.'}, {'end': 300.04, 'start': 298.74, 'text': ' ì¶•êµ¬ì„ ìˆ˜ ì•„ë‹™ë‹ˆë‹¤.'}, {'end': 304.48, 'start': 300.04, 'text': ' ì§€ë‹¨ë„ ê·¸ë ‡ê²Œ ë§Žì´ í•„ìš”í•˜ë©´ ì§‘ì—ì„œ ì¼ì¼ì´ ë§Œë“¤ í•„ìš” ì—†ì´ ì´ë ‡ê²Œ íŒ”ì•„.'}, {'end': 308.12, 'start': 304.48, 'text': ' ì œê°€ ì˜ˆì „ì— GS ë‚©í’ˆí•˜ëŠ” ë„ì‹œë½ ê³µìž¥ì—ì„œ ì¼í–ˆì—ˆê±°ë“ ìš”.'}, {'end': 308.96, 'start': 308.12, 'text': ' ìš”ëŸ° ê±° ë‹¤ ì¨.'}, {'end': 309.72, 'start': 308.96, 'text': ' ìŒ.'}, {'end': 310.32, 'start': 309.72, 'text': ' GS.'}, {'end': 311.02, 'start': 310.32, 'text': ' GS.'}, {'end': 311.62, 'start': 311.02, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 312.12, 'start': 311.62, 'text': ' ì–´?'}, {'end': 313.22, 'start': 312.12, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 314.02, 'start': 313.22, 'text': ' ì›ìˆ­ì´.'}, {'end': 316.46, 'start': 314.02, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 317.62, 'start': 316.46, 'text': ' ìž ìƒì¼ìžë„.'}, {'end': 318.36, 'start': 317.62, 'text': ' ìž ìƒì¼ìžë„.'}, {'end': 320.2, 'start': 318.36, 'text': ' ì›ì£¼ë¯¼ë°¥ ë§›ìžˆë„¤.'}, {'end': 321.9, 'start': 320.2, 'text': ' í˜•ë‹˜ ê·¸ê±° í˜¹ì‹œ ê¼½ëŠ” ê¹€ì—.'}, {'end': 323.1, 'start': 321.9, 'text': ' ìš”ê²ƒë„.'}, {'end': 323.86, 'start': 323.1, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 325.56, 'start': 323.86, 'text': ' ì˜¤ ìž˜ ê¼½ê³  ìžˆë„¤ ê±°ì˜.'}, {'end': 326.16, 'start': 325.56, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 326.7, 'start': 326.16, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 327.38, 'start': 326.84, 'text': ' êµ­ë¬¼.'}, {'end': 328.8, 'start': 327.38, 'text': ' êµ­ë¬¼.'}, {'end': 329.58, 'start': 328.8, 'text': ' êµ­ë¬¼.'}, {'end': 330.28, 'start': 329.58, 'text': ' êµ­ê¸° ìž˜ í–ˆë‚˜?'}, {'end': 331.34, 'start': 330.28, 'text': ' ì•¼ êµ­ê¸° ìž˜ í–ˆë‹¤.'}, {'end': 331.78, 'start': 331.34, 'text': ' ì˜ˆ.'}, {'end': 332.68, 'start': 331.78, 'text': ' ê³ ì˜€ë‹¤ë‹ˆê¹Œ.'}, {'end': 335.62, 'start': 332.68, 'text': ' êµ­ë¬¼ ê°™ì´ ë„£ì–´ì•¼ ë” ì‹¤í•œ ìžˆì§€ ì•Šì„ê¹Œ.'}, {'end': 337.56, 'start': 335.62, 'text': ' ì—¬ê¸° ì‚´ì§ ë§ˆìš”.'}, {'end': 338.18, 'start': 337.56, 'text': ' ì–´?'}, {'end': 338.52, 'start': 338.18, 'text': ' ì–´?'}, {'end': 339.96, 'start': 338.52, 'text': ' ê·¸ëŸ¬ì§€ ë§ˆìš”.'}, {'end': 341.58, 'start': 339.96, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 341.96, 'start': 341.58, 'text': ' êµ­ë¬¼.'}, {'end': 342.56, 'start': 341.96, 'text': ' êµ­ë¬¼.'}, {'end': 343.8, 'start': 342.56, 'text': ' êµ­ë¬¼ ë„£ëŠ” ê±° ê·¸ëŸ¬ì§€ ë§ˆìš”.'}, {'end': 344.72, 'start': 343.8, 'text': ' ì˜¤ì˜¤.'}, {'end': 346.46, 'start': 344.72, 'text': ' ì•¼ ì˜¤ëŠ˜.'}, {'end': 347.36, 'start': 346.46, 'text': ' ê°€ë©´ ì¹´ë©”ë¼.'}, {'end': 348.02, 'start': 347.36, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 349.5, 'start': 348.02, 'text': ' í•˜í•˜í•˜í•˜.'}, {'end': 351.56, 'start': 349.5, 'text': ' ì–´ì–´ì–´.'}, {'end': 353.44, 'start': 351.56, 'text': ' ì–´ë‘¡ë‹¤.'}, {'end': 354, 'start': 353.44, 'text': ' ë°¥.'}, {'end': 354.4, 'start': 354, 'text': ' ì–´?'}, {'end': 355.84, 'start': 354.4, 'text': ' ë…¸ëž­ì´ ë§Žì´ ìˆ˜ë‹¤.'}, {'end': 356.16, 'start': 355.84, 'text': ' ì˜ˆ.'}, {'end': 357.76, 'start': 356.16, 'text': ' ê°„ë‹¨í•˜ê²Œ í•˜ë‚˜ ë§ì•„ë³´ì£ .'}, {'end': 362.98, 'start': 361.92, 'text': ' ì§œìž”!'}, {'end': 364.26, 'start': 363.4, 'text': ' ê°„ë‹¨í•˜ê²Œ.'}, {'end': 366.48, 'start': 364.92, 'text': ' ìž ì˜¤ëŠ˜ì˜ 1í˜¸ ê¹€ë°¥.'}, {'end': 367.44, 'start': 366.48, 'text': ' ì²« ìž…ìž…ë‹ˆë‹¤.'}, {'end': 368.98, 'start': 367.86, 'text': ' ì—­ì‚¬ì ì¸ í•œ ìž….'}, {'end': 373.42, 'start': 372.4, 'text': ' ë§›ìžˆì–´, ì‚¬ë‚˜.'}, {'end': 377.2, 'start': 375.42, 'text': ' 2í˜¸ ê¹€ë°¥ ì™„ì„±.'}, {'end': 378.1, 'start': 377.2, 'text': ' ì–´ 2í˜¸ ê¹€ë°¥.'}, {'end': 382.76, 'start': 381.22, 'text': ' ì™œ ì´ë ‡ê²Œ í•œìª½ìœ¼ë¡œ ì ë ¤?'}, {'end': 383.8, 'start': 382.76, 'text': ' ë°˜ë°˜ì´ ë˜ë„¤.'}, {'end': 385.48, 'start': 383.8, 'text': ' ì•¼ ë„ˆë¬´ ê°ˆë¼ì¹˜ê¸° ëœ ê±° ì•„ë‹ˆì•¼?'}, {'end': 386.54, 'start': 385.48, 'text': ' ê·¸ëž˜, ê·¸ëž˜ë„ ë§›ìžˆìž–ì•„.'}, {'end': 389.08, 'start': 387.7, 'text': ' ë°¥ì´ ì¢€ ì§ˆ ë‚˜?'}, {'end': 392.72, 'start': 390.3, 'text': ' ì›ëž˜ ë°¥ì—ë„ ë­˜ ì´ë ‡ê²Œ í•˜ì§€ ì•ŠìŠµë‹ˆê¹Œ?'}, {'end': 398.62, 'start': 395.52, 'text': ' ì™€ ê·¼ë° ì´ ë°¥ ìžì²´ë¡œë„ ì´ë¯¸ ë§›ìžˆëŠ” í•˜ë‚˜ê°€ ëì–´.'}, {'end': 403.78, 'start': 402.62, 'text': ' ì•„ ë°œë¡œ ë¨¹ì—ˆë„¤.'}, {'end': 404.66, 'start': 403.78, 'text': ' ì˜¤ëŠ˜ ì§„ì§œ..'}, {'end': 408.5, 'start': 407.66, 'text': ' ë°œë¡œ ë¨¹ì–´.'}, {'end': 410.2, 'start': 408.5, 'text': ' ì–´ ë°œë¡œ..'}, {'end': 411.08, 'start': 410.2, 'text': ' ì™€ ëë‹¤.'}, {'end': 412.46, 'start': 411.6, 'text': ' í™”ëª©ì´!'}, {'end': 414.5, 'start': 412.7, 'text': ' ì•„ì§ ì—¬ì „ížˆ ì¢€ ì ë ¤ìžˆì–´.'}, {'end': 417.48, 'start': 415.48, 'text': ' í™”ëª©ì´ì˜ ì²« ìž…ì€ ì§±ë² ì—ê²Œ.'}, {'end': 418.48, 'start': 417.48, 'text': ' ì´ëŸ´ ìˆ˜ê°€.'}, {'end': 424.16, 'start': 423.66, 'text': ' ì–´ë•Œ?'}, {'end': 424.92, 'start': 424.16, 'text': ' ë§›ìžˆë‹¤.'}, {'end': 426.16, 'start': 424.92, 'text': ' ì˜¤ ë§›ìžˆì–´ìš”?'}, {'end': 429.12, 'start': 426.52, 'text': ' ê°ì •ì´ ë” ë¬»ì–´ë‚˜ë‹ˆê¹Œ ë” ë§›ìžˆëŠ” ê²ƒ ê°™ì•„.'}, {'end': 430.42, 'start': 429.12, 'text': ' ì§±ë²  ìž…ìž¥ì—ì„œëŠ”.'}, {'end': 431.08, 'start': 430.42, 'text': ' ì—¬ëŸ¬ë¶„ë“¤.'}, {'end': 433.2, 'start': 431.7, 'text': ' ê°ê²©ì‚¬ìž êº¼ì¡ŒìŠµë‹ˆë‹¤.'}, {'end': 434.96, 'start': 433.2, 'text': ' ì•„ ì¢‹ì•„ìš”.'}, {'end': 435.96, 'start': 434.96, 'text': ' ë§‘ì•„ ì´ì œ.'}, {'end': 439.8, 'start': 438.7, 'text': ' ì˜¤ ì´ê±° ê¸°ëŒ€ë©ë‹ˆë‹¤.'}, {'end': 440.44, 'start': 439.8, 'text': ' ì°¸ì¹˜.'}, {'end': 441.2, 'start': 440.44, 'text': ' ìž ë‚˜ì˜¤ë¼.'}, {'end': 443.04, 'start': 442.2, 'text': ' ì´ê±° ë´ìš”.'}, {'end': 444.48, 'start': 443.04, 'text': ' ì§œìž”.'}, {'end': 445.48, 'start': 444.48, 'text': ' ì˜¤.'}, {'end': 447.08, 'start': 446, 'text': ' ë„ˆë„ ì ë ¸ë„¤.'}, {'end': 450.38, 'start': 448.08, 'text': ' ì–´ ë‚˜ë„ í•œìª½ìœ¼ë¡œ ì ë ¸ì§€ë§Œ.'}, {'end': 451.24, 'start': 450.38, 'text': ' ìŒ ë§›ìžˆì–´!'}, {'end': 451.96, 'start': 451.24, 'text': ' ì°¸ì¹˜ê¹€ë°¥.'}, {'end': 456.08, 'start': 454.72, 'text': ' í˜¹ì‹œ ì°¸ì¹˜ê¹€ë°¥ ë³„ë¡œ ì•ˆ ì¢‹ì•„?'}, {'end': 459.72, 'start': 458.6, 'text': ' ì§€í¼ì—¬ì˜.'}, {'end': 462.34, 'start': 460.72, 'text': ' ìš”ëŸ° ê±° ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.'}, {'end': 465.32, 'start': 463.72, 'text': ' ìž ì§±ë²  ë„ˆ ë§í•´ë„ ë¼. ë§í•´ë„ ë¼.'}, {'end': 465.82, 'start': 465.32, 'text': ' ê·¸ëž˜?'}, {'end': 468.18, 'start': 465.82, 'text': ' ì €ëŠ” ì €í¬ ë‘˜ì§¸ ìž¬ë£Œ.'}, {'end': 469.6, 'start': 468.18, 'text': ' ë¶„ìˆ˜ ë“¤ì–´ê°‘ë‹ˆë‹¤.'}, {'end': 470.88, 'start': 469.6, 'text': ' ì–´ ë¶„ìˆ˜?'}, {'end': 474.26, 'start': 471.48, 'text': ' ì—¬ê¸° ì œê°€ ë§Œë“  ì°¸ì¹˜ê¹€ë°¥ë„ ìžˆìŠµë‹ˆë‹¤.'}, {'end': 475.36, 'start': 474.6, 'text': ' ì–´ë¼.'}, {'end': 476.92, 'start': 475.48, 'text': ' í›„ì°¨ë‹˜ ë¨¹ì–´ë³´ê³  ì‹¶ì€ ì‚¬ëžŒ?'}, {'end': 477.58, 'start': 476.92, 'text': ' ì•¼!'}, {'end': 478.34, 'start': 477.58, 'text': ' ì•ˆ ì¢‹ì•„í•œë‹¤ë©°?'}, {'end': 478.84, 'start': 478.34, 'text': ' ë§žì•„.'}, {'end': 485.72, 'start': 482.44, 'text': ' ì „ ìƒˆìš°ë¥¼ ë“¬ë¿ ë„£ì€ ìƒˆìš° ê¸°ë„ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.'}, {'end': 486.98, 'start': 485.72, 'text': ' ì•¼ ë‚˜ ì²˜ìŒ ë´.'}, {'end': 488.38, 'start': 486.98, 'text': ' ë‚˜ë„ ì²˜ìŒ ë³¸ë‹¤.'}, {'end': 490.08, 'start': 488.38, 'text': ' ì•¼ ì´ê±° ì–´ë–»ê²Œ ë§í•˜ìžë‚˜ìš”?'}, {'end': 491.18, 'start': 490.08, 'text': ' ë„ˆì˜ ëŠë‚ŒëŒ€ë¡œ.'}, {'end': 493.14, 'start': 491.18, 'text': ' ìš°ë¦¬ ì—„ë§ˆëŠ” ë°œì„ ì•ˆ ì“´ë‹¤ëŠ”ë°.'}, {'end': 494.12, 'start': 493.14, 'text': ' ì˜³ì§€ ì˜³ì§€ ì˜³ì§€ ì˜³ì§€.'}, {'end': 495.42, 'start': 494.12, 'text': ' ì˜¤ ë‹ˆ ìž˜í•œë‹¤!'}, {'end': 496.02, 'start': 495.42, 'text': ' ì˜³ì§€!'}, {'end': 497.18, 'start': 496.02, 'text': ' ì™€ ê·¸ëƒ¥ ë§ì•„ë²„ë¦°ë‹¤.'}, {'end': 498.52, 'start': 497.18, 'text': ' ì°¸ì•¼ ë‹ˆ ìž¬ëŠ¥ ìžˆë‹¤!'}, {'end': 499.98, 'start': 498.52, 'text': ' ì–´? ê°ê°ì´ ë‹¬ë¼ìš”?'}, {'end': 501.08, 'start': 499.98, 'text': ' ì œê°€ ë¨¼ì € ë¨¹ì–´ë³´ê² ìŠµë‹ˆë‹¤ ê·¸ëŸ¬ë©´.'}, {'end': 501.58, 'start': 501.08, 'text': ' ê·¸ëž˜.'}, {'end': 509.42, 'start': 505.48, 'text': ' ë³„ë§›ì´ ì•ˆ ë‚¬ë„¤ ìƒê°ë³´ë‹¤ ìƒìƒˆìš° ì‚´ì´.'}, {'end': 511.54, 'start': 509.42, 'text': ' ì•ˆì— ë­ ì–‘ë…ê±°ë‚˜ ì•„ë‹ˆë©´ ì´ˆìž¥ì´ë‚˜ ì´ëŸ° ê±°.'}, {'end': 513.78, 'start': 511.54, 'text': ' ì´ˆìž¥ ëŠë‚Œ ìžˆë„¤.'}, {'end': 515.52, 'start': 513.78, 'text': ' ì œê°€ ë§ì”€ë“œë¦¬ëŠ” ê±´ ì§„ë©¸ì´ì£ .'}, {'end': 518.64, 'start': 515.52, 'text': ' ì˜¤! ê°€ìž¥ ì–„ìŒí•œ ê¹€ë°¥ì´ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤.'}, {'end': 520.54, 'start': 518.64, 'text': ' ì§„ë©¸ì´ ê¹€ë°¥.'}, {'end': 524.58, 'start': 520.54, 'text': ' ì´ë”°ê°€ ë‚´ê°€ ê¹€ë°¥ ìž”ì¹˜ë¥¼ ë” í™”ëˆí•˜ê²Œ ë§Œë“¤ì–´ì¤„'}, {'end': 527.48, 'start': 524.58, 'text': ' ë–¡ë³¶ì´ë¥¼ ì¤€ë¹„í•´ë³´ê² ìŠµë‹ˆë‹¤.'}, {'end': 528.48, 'start': 527.48, 'text': ' ì°ì–´ë¨¹ìœ¼ë©´ ë§›ìžˆìž–ì•„ìš”?'}, {'end': 530.38, 'start': 528.48, 'text': ' ë‚´ê°€ ë˜ ì˜›ë‚ ì— ìƒì–´...'}, {'end': 531.58, 'start': 530.38, 'text': ' ìƒì–´ ë¨¹ì—ˆì§€ ì•ŠìŠµë‹ˆê¹Œ?'}, {'end': 533.22, 'start': 531.58, 'text': ' ê³  ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ'}, {'end': 535.28, 'start': 533.22, 'text': ' í™œìš© ì ì ì„ ì°ì–´ë¨¹ê² ìŠµë‹ˆë‹¤.'}, {'end': 535.98, 'start': 535.28, 'text': ' ì¢‹ì•„ìš”.'}, {'end': 537.68, 'start': 535.98, 'text': ' ì´ë²ˆì—ëŠ” ìµì€ ê±°.'}, {'end': 539.58, 'start': 537.68, 'text': ' ì‚´ì§ë§Œ.'}, {'end': 540.88, 'start': 539.58, 'text': ' ë”°ëž€!'}, {'end': 542.32, 'start': 540.88, 'text': ' ì˜¤ìž¥ëŒ€ì˜ ì´ˆìž¥ ê¹€ë°¥.'}, {'end': 546.18, 'start': 542.32, 'text': ' ì–´! ì§„ì´ì•¼.'}, {'end': 547.52, 'start': 546.18, 'text': ' ìŒ!'}, {'end': 549.82, 'start': 547.52, 'text': ' ì´ê±´ê°€ ë´!'}, {'end': 552.42, 'start': 549.82, 'text': ' ì¡°ìš©ížˆ í•˜ì„¸ìš”. ë” í•˜ë‹ˆê¹Œ ë”.'}, {'end': 553.82, 'start': 552.42, 'text': ' ìŒ!'}, {'end': 556.18, 'start': 553.82, 'text': ' ì•„! ì†ŒìŠ¤ì˜€ìŠµë‹ˆë‹¤ ì—¬ëŸ¬ë¶„ë“¤!'}, {'end': 558.22, 'start': 556.18, 'text': ' ì†ŒìŠ¤ì˜€ì–´ìš”.'}, {'end': 560.52, 'start': 558.22, 'text': ' í•˜í•˜í•˜í•˜í•˜í•˜'}, {'end': 563.84, 'start': 560.52, 'text': ' ë„ˆë¬´ ì¢‹ì•„ì„œ.'}, {'end': 565.02, 'start': 563.84, 'text': ' ì˜¤ì§•ì–´!'}, {'end': 565.52, 'start': 565.02, 'text': ' ê¹€ë°¥!'}, {'end': 567.02, 'start': 565.52, 'text': ' ì˜¤ì§•ì–´ ê¹€ë°¥!'}, {'end': 569.12, 'start': 567.02, 'text': ' ê¹€ë°¥!'}, {'end': 572.92, 'start': 569.12, 'text': ' í•˜í•˜í•˜í•˜í•˜í•˜'}, {'end': 573.52, 'start': 572.92, 'text': ' ì™€ìš°!'}, {'end': 574.36, 'start': 573.52, 'text': ' ì•„ì§ ì•ˆ ëë‚¬ë„¤.'}, {'end': 575.26, 'start': 574.36, 'text': ' ì™€ìš°!'}, {'end': 578.02, 'start': 575.26, 'text': ' í•˜í•˜í•˜í•˜í•˜í•˜'}, {'end': 579.98, 'start': 578.02, 'text': ' ì•¼! ì•¼! ì™¸êµ­ì¸ ì•„ë‹ˆì•¼?'}, {'end': 583.68, 'start': 579.98, 'text': ' ìž, ìš°ë¦¬ëŠ” ì´ì œ ê³µìž¥ì²˜ëŸ¼ ê¹€ë°¥ì„ ìƒì‚° ì¤‘ìž…ë‹ˆë‹¤.'}, {'end': 584.72, 'start': 583.68, 'text': ' ì§„ì§œ ê¹€ë°¥ ê³µìž¥ì´ì•¼.'}, {'end': 586.86, 'start': 584.72, 'text': ' ìž, ì´ì œ ë‚´ê°€ ìƒê°ì‚¬ë¥¼ í™œìš©í•œ ë°©ë²•ì„ ì•Œë ¤ì¤„ê²Œ.'}, {'end': 587.72, 'start': 586.86, 'text': ' ë„¤ê°€ ë§í•´ë´ ë´.'}, {'end': 588.68, 'start': 587.72, 'text': ' ì´ê±° ìž˜ ë§žëŠ” ê²ƒ ê°™ì•„.'}, {'end': 589.38, 'start': 588.68, 'text': ' ì‘?'}, {'end': 590.22, 'start': 589.38, 'text': ' ê¿€ íŒ”ë¼ ê·¸ëŸ¬ë„¤.'}, {'end': 591.56, 'start': 590.22, 'text': ' ê¶ê¸ˆí•˜ë‹¤. ê¶ê¸ˆí•œ ì‚¬ëžŒ ë‚˜ì™€ë´.'}, {'end': 593.92, 'start': 591.56, 'text': ' ê°ˆê³ , ê±°ê¸°ë‹¤ê°€ ì´ì œ ê¹»ìžŽ í•œ ë‘ ìž¥ ì •ë„.'}, {'end': 594.92, 'start': 593.92, 'text': ' ê¼­ë‹¤ë¦¬ ë”´ ë’¤ì—.'}, {'end': 595.52, 'start': 595.02, 'text': ' ì–´.'}, {'end': 598.32, 'start': 595.52, 'text': ' ì‚¼ê²¹ì‚´ í•œ ì¤„.'}, {'end': 599.68, 'start': 598.32, 'text': ' ë‹¨ë¬´ì§€ëž‘ ìš°ì—‰ë§Œ.'}, {'end': 600.82, 'start': 599.68, 'text': ' ë‹¨ë¬´ì§€ëž‘ ìš°ì—‰ë§Œ.'}, {'end': 601.62, 'start': 600.82, 'text': ' ì•¼, ì´ê±¸ ë§ ìˆ˜ ìžˆë‚˜?'}, {'end': 603.18, 'start': 601.62, 'text': ' ìž, ê·¸ë¦¬ê³  ì—¬ê¸°ì„œ í•µì‹¬ì¸ë°.'}, {'end': 605.82, 'start': 603.18, 'text': ' ìž, ì €ê¸° ëƒ‰ìž¥ê³  ì•ˆì— ìŒˆìž¥ì´ ìžˆì–´.'}, {'end': 606.72, 'start': 605.82, 'text': ' ì•„!'}, {'end': 607.72, 'start': 606.72, 'text': ' ìŒˆìž¥ í•œ ë²ˆ ê°€ì ¸ì™€.'}, {'end': 608.68, 'start': 607.72, 'text': ' ì¢‹ì•„, ì¢‹ì•„, ì¢‹ì•„.'}, {'end': 610.92, 'start': 608.68, 'text': ' ì•„ì£¼ ì¢‹ì•„!'}, {'end': 612.48, 'start': 610.92, 'text': ' ì•„, ê¿€íŒì¸ë°?'}, {'end': 613.42, 'start': 612.48, 'text': ' ì•„, ìž˜í•´.'}, {'end': 615.02, 'start': 613.42, 'text': ' ì•„, ìž˜í•´.'}, {'end': 616.72, 'start': 615.02, 'text': ' ë‚˜ ê³„ì† ì¼ ì‹œí‚¤ë ¤ê³  ìžë„í•œ ê±° ì•„ë‹ˆì•¼?'}, {'end': 617.96, 'start': 616.72, 'text': ' ì•„ë‹ˆì•¼, ì§„ì§œ ìž˜í•´.'}, {'end': 620.08, 'start': 617.96, 'text': ' ì´ ì—­ì‚¬ì ì¸ í•œ ìž…ì€ ìƒì¼ìžê°€ ì‚¬ì•¼ ëœë‹¤.'}, {'end': 621.92, 'start': 620.08, 'text': ' ì•„, ìƒì¼!'}, {'end': 623.92, 'start': 621.92, 'text': ' ì•„, ìƒì¼!'}, {'end': 624.72, 'start': 623.92, 'text': ' ë§›ìžˆì–´.'}, {'end': 626.22, 'start': 625.02, 'text': ' ì˜¤!'}, {'end': 627.02, 'start': 626.22, 'text': ' ê·¸ëƒ¥ ê¹”ë”í•˜ê²Œ ë§›ìžˆì–´.'}, {'end': 628.02, 'start': 627.02, 'text': ' ì§€ê¸ˆ ì¹´ë©”ë¼ë§Œ í‹€ì–´ë´.'}, {'end': 629.72, 'start': 628.02, 'text': ' ì´ê±´ ê°œë°œìžê°€ ë¨¹ì–´ì•¼ ë¼.'}, {'end': 630.72, 'start': 629.72, 'text': ' ê·¸ëž˜, ê°œë°œìž í•œ ìž….'}, {'end': 637.52, 'start': 636.72, 'text': ' ë„ˆë¬´ ë§›ìžˆì–´.'}, {'end': 638.32, 'start': 637.52, 'text': ' ê³ ê¸° ì¢‹ì•„.'}, {'end': 639.42, 'start': 638.32, 'text': ' ì°¸ì¹˜ê¹Œì§€.'}, {'end': 640.92, 'start': 639.42, 'text': ' ì•„, ë°¥ì´ ë³„ë¡œ ì—†ë„¤ìš”.'}, {'end': 642.42, 'start': 640.92, 'text': ' ê·¸ëŸ¼ ë§›ì‚´ë§Œ í•œ ë²ˆ í•´ë³¼ê¹Œ?'}, {'end': 644.12, 'start': 642.42, 'text': ' ë°¥ ëŒ€ì‹  ë§›ì‚´.'}, {'end': 645.02, 'start': 644.12, 'text': ' ì €ê±´ ì¢€...'}, {'end': 645.72, 'start': 645.02, 'text': ' ì•„, ì´ëŸ´ ë•Œ í•´ë³´ì§€.'}, {'end': 646.32, 'start': 645.72, 'text': ' ì–´ì°Œí•˜ê² ì–´.'}, {'end': 647.02, 'start': 646.32, 'text': ' ê·¸ëž˜.'}, {'end': 648.72, 'start': 647.02, 'text': ' ë‚œ ë°¥ ëŒ€ì‹  ë¶€ì¶” í•´ë³¼ëž˜, ê·¸ëŸ¼.'}, {'end': 650.62, 'start': 648.72, 'text': ' ë°¥ ì¢€ ë” ë°ì›Œì¤˜.'}, {'end': 652.62, 'start': 650.62, 'text': ' ë‘ ê°œë§Œ ë” í•˜ë©´ ë”± í•œ ìƒìžì•¼.'}, {'end': 654.42, 'start': 652.62, 'text': ' ë„ˆ ê·¸ê±° ëŒë ¤, ëŒë ¤, ëŒë ¤!'}, {'end': 656.22, 'start': 655.02, 'text': ' ì¼ë‹¨ ìƒˆìš°ë§Œ ë„£ì–´ë³´ê² ìŠµë‹ˆë‹¤.'}, {'end': 657.32, 'start': 656.22, 'text': ' ìš°ì™€.'}, {'end': 660.02, 'start': 657.32, 'text': ' ì§¬ë°°ëŠ” ì‚¼ê²¹ì‚´ì´ëž‘ ìƒˆìš°.'}, {'end': 661.52, 'start': 660.02, 'text': ' ì§¬ë°°ëŠ” ë¶€ì¶”.'}, {'end': 663.52, 'start': 661.52, 'text': ' ë¶€ì¶”.'}, {'end': 664.72, 'start': 663.52, 'text': ' ë²Œì¹™ì¸ê°€ìš”?'}, {'end': 666.02, 'start': 664.72, 'text': ' ì•„ë‹ˆ, ì¼ë‹¨ ì§¬ë§Œ ë“¤ì–´ê°€ë©´ ê´œì°®ì•„ìš”.'}, {'end': 666.72, 'start': 666.02, 'text': ' ì§¬ë§Œ ë“¤ì–´ê°€ë©´.'}, {'end': 669.02, 'start': 666.72, 'text': ' ë‹¬ê¸°ì— ë˜ ì˜ë¯¸ê°€ ìžˆë‹¤.'}, {'end': 671.72, 'start': 669.02, 'text': ' ì™€, ê¸°ê´€ì´.'}, {'end': 673.22, 'start': 671.72, 'text': ' ì•¼, ì´ê²Œ ë­ì•¼.'}, {'end': 675.02, 'start': 673.22, 'text': ' í•˜í•˜í•˜í•˜í•˜í•˜.'}, {'end': 676.82, 'start': 675.02, 'text': ' ìŠ‰ì°½.'}, {'end': 677.42, 'start': 676.82, 'text': ' ìŠ‰ì°½.'}, {'end': 679.02, 'start': 677.42, 'text': ' ì˜¤ì˜¤ì˜¤, ê¹Šê²Œ ë“¤ì–´ê°”ì–´ìš”.'}, {'end': 683.02, 'start': 682.22, 'text': ' ì•„, ê´œì°®ë„¤?'}, {'end': 683.72, 'start': 683.02, 'text': ' ì–´, ê´œì°®ë„¤?'}, {'end': 684.02, 'start': 683.72, 'text': ' ì–´.'}, {'end': 685.52, 'start': 684.02, 'text': ' ë…¸ëž­ì´ í•œë²ˆ ì¤˜, ë…¸ëž­ì´ í•œë²ˆ ì¤˜.'}, {'end': 687.02, 'start': 685.52, 'text': ' ìœ¼ìŒ.'}, {'end': 688.02, 'start': 687.02, 'text': ' ì €ê±° ë°˜íƒ•ì¸ë°.'}, {'end': 689.52, 'start': 688.02, 'text': ' í•˜í•˜í•˜í•˜í•˜í•˜.'}, {'end': 690.52, 'start': 689.52, 'text': ' ì–´, ê¹€ì´ ì—†ë„¤?'}, {'end': 691.52, 'start': 690.52, 'text': ' ì•„, ë§žë„¤.'}, {'end': 692.52, 'start': 691.52, 'text': ' ë” ì•ˆ ê±¸ë ¤ë„ ë˜ê² ë‹¤.'}, {'end': 694.02, 'start': 692.52, 'text': ' ì•¼, ê·¸ëŸ¼ ì°¸ì¹˜ëž‘ ë¹„ë²¼.'}, {'end': 695.02, 'start': 694.02, 'text': ' ì¢‹ì€ ë°¥ì—.'}, {'end': 696.52, 'start': 695.02, 'text': ' ì˜¤, ë…¸ëž­ì´ ë¹„ë¹”ë°¥?'}, {'end': 698.52, 'start': 696.52, 'text': ' ì™€, ì§„ì§œ ì•Œì°¨ê²Œ.'}, {'end': 699.02, 'start': 698.52, 'text': ' ì•„, ì—¬ëŸ¬ë¶„.'}, {'end': 700.52, 'start': 699.02, 'text': ' ë–¡ë³¶ì´ê°€ ë‹¤ ëìŠµë‹ˆë‹¤.'}, {'end': 701.52, 'start': 700.52, 'text': ' ê·¸ëž¬ì–´.'}, {'end': 702.52, 'start': 701.52, 'text': ' í• , í• .'}, {'end': 705.02, 'start': 702.52, 'text': ' ì•„ê¹Œ ê°•ìš°ì´ê°€ ì–‘ê°ìž¥ë„ ì§ì ‘ ë§Œë“¤ë”ë¼ê³ .'}, {'end': 705.52, 'start': 705.02, 'text': ' ë„¤.'}, {'end': 707.02, 'start': 705.52, 'text': ' ì™€, ì´ê±° ì§„ì§œ ë§›ìžˆê² ë‹¤.'}, {'end': 707.52, 'start': 707.02, 'text': ' ì§„ì§œ ë§›ìžˆê² ë‹¤.'}, {'end': 710.52, 'start': 707.52, 'text': ' ì‹œì¤‘ì— ìžˆëŠ” ë ˆì‹œí”¼ë¥¼ ì¡°ê¸ˆ ì°¸ê³ í•´ì„œ'}, {'end': 712.02, 'start': 710.52, 'text': ' ì œ ì‹ëŒ€ë¡œ í•œë²ˆ ë°”ê¿”ë´¤ìŠµë‹ˆë‹¤.'}, {'end': 712.52, 'start': 712.02, 'text': ' ì™€.'}, {'end': 714.52, 'start': 714.02, 'text': ' ë„¤.'}, {'end': 715.02, 'start': 714.52, 'text': ' í•œ...'}, {'end': 743.52, 'start': 715.02, 'text': ' í•œ...'}, {'end': 746.58, 'start': 744.02, 'text': ' ê¹€ë°¥ì´ëž‘ ê°™ì´ ì°ì–´ ë¨¹ëŠ” ê±¸ ì¢€ ìƒê°í–ˆìŠµë‹ˆë‹¤.'}, {'end': 749.36, 'start': 746.58, 'text': ' ì˜¤ë¬˜í•œ ìœ¡í–¥ì´ ëŠê»´ì§€ëŠ”ë° ì–´ë””ì„œ ë‚¸ ê²ë‹ˆê¹Œ, ì´ê±°?'}, {'end': 750.78, 'start': 749.36, 'text': ' ì•„ì£¼ ì •í™•í•˜êµ¬ë§Œ.'}, {'end': 753.56, 'start': 750.78, 'text': ' ì§±ë°°ê°€ êµ¬ìš´ ì‚¼ê²¹ì‚´ì— ê¸°ë¦„ì„ ì¢€ ë‹¬ì•„ì£¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤.'}, {'end': 754.64, 'start': 753.56, 'text': ' ì•„, ê·¸ëž˜.'}, {'end': 755.94, 'start': 754.64, 'text': ' ë²„ì„¯ ìºì¹˜í•œë‹¤ê³ ?'}, {'end': 756.9, 'start': 755.94, 'text': ' ì•¼, ì˜¤ëŠ˜ ì•„ë“¤í•˜ê³ .'}, {'end': 758.1, 'start': 756.9, 'text': ' ê°€ëž˜ë‹¤ ë¬¼ì„ ë¶€ì³ì•¼ ë¼.'}, {'end': 758.9, 'start': 758.1, 'text': ' ì´ë ‡ê²Œ.'}, {'end': 760.14, 'start': 758.9, 'text': ' ì°¸ì¹˜ê¹€ë°¥.'}, {'end': 762.9, 'start': 760.14, 'text': ' ì´ê±° ê³ ê¸° ì†¡ìˆ˜ ì°ì–´ê°€ì§€ê³ .'}, {'end': 763.9, 'start': 762.9, 'text': ' ë­ì•¼, ë­ì•¼.'}, {'end': 770.44, 'start': 768.9, 'text': ' ì•¼, ê°€í›ˆì´ ë„ˆë¬´ ë§›ìžˆë‹¤, ì´ê±°.'}, {'end': 771.88, 'start': 770.44, 'text': ' ì°ì–´ ë¨¹ìœ¼ë‹ˆê¹Œ ì¢€ ê´œì°®ë‹¤.'}, {'end': 773.28, 'start': 771.88, 'text': ' ìž, ìž˜ë¼ ë†“ì€ ê²ƒë„ ì¢€ ë“œì‹œê³ .'}, {'end': 774.28, 'start': 773.28, 'text': ' ê°ì‚¬í•´ìš”.'}, {'end': 775.28, 'start': 774.28, 'text': ' ìš°ì™€.'}, {'end': 777.28, 'start': 775.28, 'text': ' í‰ì†Œì— ê°•í›ˆì´ê°€ ì´ëŸ° ê±° ìž˜ ì•ˆ í•´ì£¼ëŠ”ë°.'}, {'end': 777.98, 'start': 777.28, 'text': ' ìƒì¼ì¸ ê²Œ ë­ì•¼?'}, {'end': 779.28, 'start': 777.98, 'text': ' ìƒì¼ì´ìž–ì•„, ì¹œêµ¬ê°€.'}, {'end': 781.28, 'start': 779.28, 'text': ' ê·¸ëŸ¬ë‹ˆê¹Œ, ê°ë™ë°›ì„ ê²ƒ ê°™ë‹¤.'}, {'end': 782.78, 'start': 781.28, 'text': ' ì¹œêµ¬ ìƒì¼ì—ë§Œ ìžˆëŠ” íŠ¹ë³„ ì„œë¹„ìŠ¤.'}, {'end': 784.28, 'start': 782.78, 'text': ' ë‚´ì¼ë¶€í„° ì´ëŸ° ê±° ì—†ì–´.'}, {'end': 786.28, 'start': 785.28, 'text': ' íŠ¹ë³„.'}, {'end': 789.78, 'start': 788.28, 'text': ' ë¨¹ê³  ì–˜ê¸°í•´, ë¨¹ê³  ì–˜ê¸°í•´.'}, {'end': 790.78, 'start': 789.78, 'text': ' ê°•í›ˆì´ê°€ íŠ¹ë³„.'}, {'end': 792.28, 'start': 790.78, 'text': ' ë•¡ë•¡ë•¡ì´ë¼ê³  í–ˆì–´.'}, {'end': 793.28, 'start': 792.28, 'text': ' ì•„, íŠ¹ë³„.'}, {'end': 794.78, 'start': 793.28, 'text': ' ì•„, ì´ë²¤íŠ¸ë¼ê³  í–ˆë‹¤ê³ .'}, {'end': 799.28, 'start': 797.78, 'text': ' ì¡°ì§ì€ ê·œì¹™ì´ìž–ì•„.'}, {'end': 801.28, 'start': 800.28, 'text': ' ë‹¤ êµ³ì—ˆì–´.'}, {'end': 805.28, 'start': 803.28, 'text': ' ì˜¤, ë§›ìžˆë‹¤.'}, {'end': 807.28, 'start': 805.28, 'text': ' ì—¬ëŸ¬ë¶„ë“¤, ìžŠì§€ ë§ê³  ì—¬ê¸° ì£¼ë¨¹ë°¥ë„ ìžˆì–´ìš”.'}, {'end': 808.28, 'start': 807.28, 'text': ' ì•„, ë§žì•„.'}, {'end': 809.28, 'start': 808.28, 'text': ' ê·¼ë° ì™œ ê·¸ê²Œ ë‹¬ë¼?'}, {'end': 810.28, 'start': 809.28, 'text': ' ì ì  ê°ˆìˆ˜ë¡.'}, {'end': 813.28, 'start': 812.28, 'text': ' ë„ˆë¬´ ê°€ëŠ˜ì–´.'}, {'end': 814.28, 'start': 813.28, 'text': ' ì‹±ê±°ìš¸ ìˆ˜ë„ ìžˆì–´.'}, {'end': 815.28, 'start': 814.28, 'text': ' ì‘.'}, {'end': 817.28, 'start': 815.28, 'text': ' ì´ëŸ´ ë•Œ ë–¡ë³¶ì´ë¥¼ ê°™ì´ ë¨¹ìœ¼ë©´.'}, {'end': 818.28, 'start': 817.28, 'text': ' ì™„ë²½í•´.'}, {'end': 819.28, 'start': 818.28, 'text': ' ì¤‘ê°„ í¬ê¸°.'}, {'end': 822.28, 'start': 820.28, 'text': ' ì£¼ë¨¹ë°¥ì€ ì£¼ë¨¹ë§Œ í•´ì•¼ì§€.'}, {'end': 825.28, 'start': 824.28, 'text': ' ìž˜í•œë‹¤.'}, {'end': 826.28, 'start': 825.28, 'text': ' ìŒ.'}, {'end': 827.28, 'start': 826.28, 'text': ' ê±°ì˜ ë§¨ë°¥.'}, {'end': 832.28, 'start': 829.28, 'text': ' ë¨¹ìœ¼ë©´ì„œ ìš°ë¦¬ ë…¸ëž­ì´ ë¯¸ë‹´ í•œ ê°œì”©ë§Œ í•˜ìž.'}, {'end': 833.28, 'start': 832.28, 'text': ' ì•„.'}, {'end': 834.28, 'start': 833.28, 'text': ' ë¯¸ë‹´?'}, {'end': 835.28, 'start': 834.28, 'text': ' ì‘.'}, {'end': 836.28, 'start': 835.28, 'text': ' ê·¸ëŸ¼ ì„ ë¬¼ë¡œ ê°€ìž.'}, {'end': 840.28, 'start': 839.28, 'text': ' ì„ ë¬¼ í•˜ë‚˜ì”© ì£¼ë©´ì„œ.'}, {'end': 841.28, 'start': 840.28, 'text': ' ì‘.'}, {'end': 842.28, 'start': 841.28, 'text': ' ì–´, ë¯¸ë‹´ í•˜ë‚˜ì”©.'}, {'end': 843.28, 'start': 842.28, 'text': ' ë‚œ ê·¸ëŸ° ê±° ì¢‹ì•„.'}, {'end': 846.28, 'start': 844.28, 'text': ' ìž, ëˆ„êµ¬ë¶€í„° ì„ ë¬¼ ì¦ì •í• ê¹Œìš”?'}, {'end': 848.28, 'start': 846.28, 'text': ' ì–´, ì œê°€ ë¨¼ì € í•˜ê² ìŠµë‹ˆë‹¤.'}, {'end': 851.28, 'start': 848.28, 'text': ' ì €ëŠ” 3ì´ˆ ë‘ë°”ì´ ì´ˆì½œë¦¿ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.'}, {'end': 853.28, 'start': 851.28, 'text': ' ê·¸ëƒ¥ ë‘ë°”ì´ ì´ˆì½œë¦¿ë„ ì•„ë‹ˆê³ .'}, {'end': 854.28, 'start': 853.28, 'text': ' ê·¸ê²Œ ë­”ë°?'}, {'end': 856.28, 'start': 854.28, 'text': ' ë­”ê°€ 3ì´ˆ ë™ì•ˆ ë‘ë°”ì´ ì´ˆì½œë¦¿ì„ ë³´ìž…ë‹ˆë‹¤.'}, {'end': 857.28, 'start': 856.28, 'text': ' ì§œìž”.'}, {'end': 858.28, 'start': 857.28, 'text': ' ì–´? ìš°ì™€.'}, {'end': 860.28, 'start': 858.28, 'text': ' ê²Œìž„ì˜ ì™“ì¸  ì ¤ë‹¤.'}, {'end': 861.28, 'start': 860.28, 'text': ' ì›ëž˜ ì‹œê³„ì¸ë°.'}, {'end': 862.28, 'start': 861.28, 'text': ' ì–´.'}, {'end': 864.28, 'start': 862.28, 'text': ' ì´ ì•ˆì— ê²Œìž„ì´ ë‚´ìž¥ë˜ì–´ ìžˆì–´.'}, {'end': 867.28, 'start': 864.28, 'text': ' ì œê°€ ì´ê±° ë§ˆë¦¬ì˜¤ ë²„ì „ì´ ìžˆëŠ”ë° ì‚´ê¹Œ ë§ê¹Œ ê³ ë¯¼ ë§Žì´ í–ˆë˜ ê±´ë°.'}, {'end': 868.28, 'start': 867.28, 'text': ' ìš°ì™€.'}, {'end': 869.28, 'start': 868.28, 'text': ' ëŒ€ë°•.'}, {'end': 873.28, 'start': 869.28, 'text': ' ì´ ì•ˆì— ì ¤ë‹¤ 1, ì ¤ë‹¤ 2, ì ¤ë‹¤ ì–´ì›¨ì´í‚¹ê¹Œì§€ ìžˆìŠµë‹ˆë‹¤.'}, {'end': 874.28, 'start': 873.28, 'text': ' ì•„.'}, {'end': 875.28, 'start': 874.28, 'text': ' ë°”ë¡œ ëœ¯ì–´ë´ì•¼ê² ë‹¤.'}, {'end': 876.28, 'start': 875.28, 'text': ' ì–´ë¨¸.'}, {'end': 877.28, 'start': 876.28, 'text': ' ì´ ì™¸ëž˜ì–´ ì“°ëŠ” ê±´ ì¸ì •í•˜ëŠ” ë¶€ë¶„ì´ì£ ?'}, {'end': 878.28, 'start': 877.28, 'text': ' ì•„.'}, {'end': 879.28, 'start': 878.28, 'text': ' ì´ì œ ëë‚¬ì–´.'}, {'end': 880.28, 'start': 879.28, 'text': ' ëë‚¬ì–´.'}, {'end': 881.28, 'start': 880.28, 'text': ' ì•„.'}, {'end': 882.28, 'start': 881.28, 'text': ' ëë‚¬ì–´.'}, {'end': 883.28, 'start': 882.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 884.28, 'start': 883.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 885.28, 'start': 884.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 886.28, 'start': 885.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 887.28, 'start': 886.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 888.28, 'start': 887.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 889.28, 'start': 888.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 890.28, 'start': 889.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 891.28, 'start': 890.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 892.28, 'start': 891.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 893.28, 'start': 892.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 894.28, 'start': 893.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 895.28, 'start': 894.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 896.28, 'start': 895.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 897.28, 'start': 896.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 898.28, 'start': 897.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 899.28, 'start': 898.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 900.28, 'start': 899.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 901.28, 'start': 900.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 902.28, 'start': 901.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 903.28, 'start': 902.28, 'text': ' ì˜¤ì¼€ì´.'}, {'end': 904.28, 'start': 903.28, 'text': ' ì˜¢.'}, {'end': 905.28, 'start': 904.28, 'text': 'ä¸œ ê²½ìš° ì§‘ì— à¤®rafly í¬ìž¥ë˜ì–´ ìžˆì–´ìš”.'}, {'end': 906.28, 'start': 905.28, 'text': ' ì˜¤.'}, {'end': 907.28, 'start': 906.28, 'text': ' ì˜¤.'}, {'end': 908.28, 'start': 907.28, 'text': ' ì˜¤!'}, {'end': 909.28, 'start': 908.28, 'text': ' ì˜¤!'}, {'end': 910.28, 'start': 909.28, 'text': ' ì˜¤!'}, {'end': 911.28, 'start': 910.28, 'text': ' ì˜¤!'}, {'end': 912.28, 'start': 911.28, 'text': 'fed....'}, {'end': 913.28, 'start': 912.28, 'text': ' ë“œë””ì–´.'}, {'end': 914.28, 'start': 913.28, 'text': ' ì˜¤!'}, {'end': 915.28, 'start': 914.28, 'text': ' ì˜¤ë„¤ï¿½ 04.'}, {'end': 916.28, 'start': 915.28, 'text': ' pussy naj.'}, {'end': 917.28, 'start': 916.28, 'text': ' ì˜¤!'}, {'end': 918.28, 'start': 917.28, 'text': ' ì˜¤!'}, {'end': 919.28, 'start': 918.28, 'text': ' ì˜¤.'}, {'end': 920.28, 'start': 919.28, 'text': ' í•˜!'}, {'end': 921.42, 'start': 920.28, 'text': ' ì•„, ê°ì‚¬í•©ë‹ˆë‹¤.'}, {'end': 924.1, 'start': 921.96, 'text': ' ì €ëŠ” ë­ ê·¼ë° ê·€ë‹´ì´ë¼ê³ ..'}, {'end': 929.08, 'start': 924.1, 'text': ' ë…¸ëž­ì´ê°€ ì•½ê°„ ì¢€ ì€ê·¼ížˆ ì•Œê²Œ ëª¨ë¥´ê²Œ ê¿€íŒì´ë‚˜ ì´ëŸ° ê±° ê°ì¢… ì •ë³´ë“¤ ì•Œë ¤ì£¼ê±°ë“ .'}, {'end': 931.04, 'start': 929.08, 'text': ' ì›ëž˜ ê·¸ëŸ° ê±° ë„˜ì–´ê°ˆ ìˆ˜ë„ ìžˆìž–ì•„.'}, {'end': 932.74, 'start': 931.04, 'text': ' ì œë¡œ ë¹„ë½ì‹œì¼œ ì„¸ì¼í•œë‹¤ ì´ê±°.'}, {'end': 935.72, 'start': 932.74, 'text': ' ì‚¬ì´ì¦ˆ ì‚¬ê²Œ ì‚´ ìˆ˜ ìžˆë‹¤ ë§í¬ ë§‰ ì˜¬ë ¤ì£¼ê³ .'}, {'end': 939.72, 'start': 935.72, 'text': ' ê·¸ë¦¬ê³  íŠ¹ížˆë‚˜ ì €ëŠ” ë…¸ëž­ì´í•œí…Œ ì•½ê°„ ì´ëŸ° ê°ì¢… ë¬¼ê±´ë“¤ ë§‰ ì´ë ‡ê²Œ ë§‰'}, {'end': 942.32, 'start': 939.72, 'text': ' ê±°ì˜ í™ê°’ì— ë§‰ ì´ë ‡ê²Œ êµ¬ë§¤í•œ ì ë„ ë§ŽìŠµë‹ˆë‹¤.'}, {'end': 943.68, 'start': 942.32, 'text': ' ì•„, ë§žì•„. ë§‰ ì €ë ´í•˜ê²Œ.'}, {'end': 944.88, 'start': 943.68, 'text': ' ë…¸ëž­ì´ê°€ ì“°ë˜ ì—ì–´íŒŸ í”„ë¡œ.'}, {'end': 948.68, 'start': 944.88, 'text': ' ê·¸ë¦¬ê³  ë˜ ë§‰ ê·¸ íŒí”Œ ì˜ìƒì—ë„ ì¢€ ìžì£¼ ë§‰ ë‚˜ì™”ì—ˆë˜ ì˜¨í´ë ˆì–´ íŒ¨ë”©.'}, {'end': 951.36, 'start': 948.68, 'text': ' ì¼ìƒì—ì„œ ê·¸ëŸ° ì†Œì†Œí•œ ë­ëž„ê¹Œ ë„ì›€ë“¤ì„ ì§„ì§œ ë§Žì´ ì¤˜ìš”.'}, {'end': 954.44, 'start': 951.36, 'text': ' ë§žì•„ìš”. ì €í¬ ì¤‘ì—ì„œë„ ê°€ìž¥ ì •ë³´ê²€ìƒ‰ì™•ì´ê±°ë“ ìš”.'}, {'end': 957.06, 'start': 954.44, 'text': ' ë‹¨ìˆœížˆ ê·¸ëƒ¥ ì •ë³´ê°€ ë§Žë‹¤ëŠ” ê²Œ ì•„ë‹ˆì•¼.'}, {'end': 960.98, 'start': 957.06, 'text': ' í•™ì°½ì‹œ ì‹œì ˆì— ì •ë³´ê²€ìƒ‰ëŠ¥ë ¥ëŒ€íšŒì—ì„œ ìž¥êµì‚¬ê°€ ë‚˜ì™”ì–´.'}, {'end': 961.86, 'start': 960.98, 'text': ' ë§žì•„ìš”, ë§žì•„ìš”.'}, {'end': 963.92, 'start': 961.86, 'text': ' ì•„, ìž¥êµì‚¬ëŠ” ë­”ê°€ ì¢€ ê³ ë¯¼ë˜ëŠ”..'}, {'end': 965.26, 'start': 963.92, 'text': ' ì•„ë‹ˆì•¼, ìƒë°˜ë˜ëŠ” ê±°ì•¼.'}, {'end': 966.22, 'start': 965.26, 'text': ' ê³ ë¯¼ë˜ëŠ”..'}, {'end': 967.12, 'start': 966.22, 'text': ' ìž, ê·¸ëŸ° ì˜ë¯¸ì—ì„œ..'}, {'end': 970.76, 'start': 967.12, 'text': ' ì§€ê°‘ì„ ì§€ì¼œì¤„ ìˆ˜ ìžˆì§€ëŠ” ì•Šì§€ë§Œ ê·¸ëž˜ë„'}, {'end': 973.36, 'start': 970.76, 'text': ' ì–‘ìœ¼ë¡œ ìŠ¹ë¶€í•˜ê² ìŠµë‹ˆë‹¤.'}, {'end': 974.58, 'start': 973.36, 'text': ' ì¼ë‹¨ ì´ê±°..'}, {'end': 977.78, 'start': 976.68, 'text': ' ê°€ë©´ë¼ì´ë”!'}, {'end': 978.66, 'start': 977.78, 'text': ' ê°€ë©´ë¼ì´ë”!'}, {'end': 982.46, 'start': 978.66, 'text': ' ì´ê±´ ìµœê·¼ì— íŒí”Œì´ êµ‰ìž¥ížˆ ìž¬ë°Œê²Œ ë´¤ì—ˆë˜ ë½‘ê¸°ë¡œ ë½‘ì•˜ëŠ”ë°'}, {'end': 983.74, 'start': 982.46, 'text': ' ì´ë ‡ê²Œ ë…¸ëž­ì´ ìƒê°ì´ ë‚˜ì„œ'}, {'end': 984.58, 'start': 983.74, 'text': ' ì¶•í•˜í•´.'}, {'end': 986.14, 'start': 984.58, 'text': ' ì•„, ì§„ì§œ?'}, {'end': 988.46, 'start': 986.14, 'text': ' Aìƒì´ë©´ ì—„ì²­ ë½‘ê¸° íž˜ë“  ê±°ê±°ë“ .'}, {'end': 990.02, 'start': 988.46, 'text': ' í•œ ë²ˆ ë½‘ì•˜ëŠ”ë° ì´ë ‡ê²Œ ë‚˜ì™”ì–´.'}, {'end': 990.62, 'start': 990.02, 'text': ' ìš°ì™€!'}, {'end': 993, 'start': 990.62, 'text': ' ê·¼ë° ë½‘ê¸° í•œ ë²ˆì— ë§Œ ì›, ì´ë§Œ ì› í•˜ìž–ì•„.'}, {'end': 996.26, 'start': 993, 'text': ' ê·¸ë¦¬ê³  ì¤‘ìš”í•œ ì˜ë¯¸ëŠ” ì € ë¬¼ê±´ì´ ë½‘ê¸°ê°€ ì•„ë‹ˆë©´ êµ¬í•  ìˆ˜ê°€ ì—†ëŠ” ë¬¼ê±´ì´ë‹ˆê¹Œ.'}, {'end': 997.62, 'start': 996.26, 'text': ' ë§žì•„, ë§žì•„.'}, {'end': 1000.32, 'start': 997.62, 'text': ' ë‚œ ë½‘ê¸°ë¡œ ë½‘ì€ ê±¸ ì£¼ê¸°ì—ëŠ” ë˜ ê·¸ëŸ´ ê²ƒ ê°™ì•„ì„œ'}, {'end': 1001.42, 'start': 1000.32, 'text': ' ë˜ ë”°ë¡œ ì¶”ê°€ë¡œ..'}, {'end': 1002.54, 'start': 1001.42, 'text': ' ì•„ë‹ˆ, ì™€..'}, {'end': 1003.56, 'start': 1002.54, 'text': ' ë„¤..'}, {'end': 1004.82, 'start': 1003.56, 'text': ' ì´ê±´ ë­ì•¼?'}, {'end': 1008.66, 'start': 1004.82, 'text': ' ì´ê±°ëŠ” ì´ì œ ë…¸ëž­ì´ê°€ êµ‰ìž¥ížˆ ì¢‹ì•„í•˜ëŠ” ê²Œìž„ ì¤‘ì— í•˜ë‚˜ì£ .'}, {'end': 1010.42, 'start': 1008.66, 'text': ' ìŠ¹ë¦¬ì˜ ì—¬ì‹ .'}, {'end': 1011.06, 'start': 1010.42, 'text': ' ì˜¤!'}, {'end': 1013.82, 'start': 1011.06, 'text': ' ì œê°€ ì–¼ë§ˆ ì „ì— ë˜ íŒì—…ìŠ¤í† ì–´ê¹Œì§€ ë‹¤ë…€ì™”ëŠ”ë°'}, {'end': 1017.66, 'start': 1013.82, 'text': ' ì´ê±°ëŠ” í‰ë²”í•œ íŒì—…ìŠ¤í† ì–´ì˜ êµ¿ì¦ˆê°€ ìžˆëŠ”ë°'}, {'end': 1020.04, 'start': 1017.66, 'text': ' ìž ê¹ë§Œ, ë°©ì†¡ì— ë‚˜ê°ˆ ìˆ˜ ìžˆëŠ” ê±°ì•¼?'}, {'end': 1022.7, 'start': 1020.04, 'text': ' ì•¼, ì¼ë‹¨ ë´ë´, ì´ê±° ê²€ì—´ ë ê¹Œ, ì´ê±°?'}, {'end': 1024.7, 'start': 1022.7, 'text': ' ê´œì°®ì„ê¹Œ?'}, {'end': 1025.9, 'start': 1024.7, 'text': ' ë‚˜ëŠ” ê´œì°®ì„ ê²ƒ ê°™ì€ë°?'}, {'end': 1026.82, 'start': 1025.9, 'text': ' ì˜¤, ìž ê¹ë§Œ.'}, {'end': 1028.5, 'start': 1026.82, 'text': ' ìžì„¸ížˆ ë³´ì§€ ë§ê³ .'}, {'end': 1029.82, 'start': 1028.5, 'text': ' ì•„, ìž ê¹ë§Œ.'}, {'end': 1031.9, 'start': 1029.82, 'text': ' ì¢€ ë” ê²€ì—´ì„ ë§Žì´ í•´ì•¼ ë  ê²ƒ ê°™ì•„ìš”.'}, {'end': 1033.82, 'start': 1031.9, 'text': ' ì´ ìºë¦­í„°ë¡œ ê°€ë ¤ê°€ì§€ê³ .'}, {'end': 1036.66, 'start': 1033.82, 'text': ' ì•„, ì´ ìºë¦­í„°!'}, {'end': 1037.66, 'start': 1036.66, 'text': ' ì•„, ìºë¦­í„°!'}, {'end': 1038.5, 'start': 1037.66, 'text': ' ì•¨ë¦¬ìŠ¤!'}, {'end': 1039.7, 'start': 1038.5, 'text': ' ì´ê²Œ ì œê°€ ì¢‹ì•„í•˜ëŠ” ìºë¦­í„°ìž…ë‹ˆë‹¤.'}, {'end': 1041, 'start': 1039.7, 'text': ' ì•„, ë§žì•„ìš”. ì•„, ë…¸ëž­ì´ê°€ ë˜ ë´¤ì–´.'}, {'end': 1044.2, 'start': 1041, 'text': ' ìœ„í‚¤ì˜ ì¶œì‹œ 1ì£¼ë…„ ê¸°ë… í›„ì¿ ì˜¤ì¹´.'}, {'end': 1044.8, 'start': 1044.2, 'text': ' ê°€ì •ìž…ë‹ˆê¹Œ?'}, {'end': 1045.46, 'start': 1044.8, 'text': ' ë„¤, ê°€ì •ìž…ë‹ˆë‹¤.'}, {'end': 1046.8, 'start': 1045.46, 'text': ' ìš°ì™€!'}, {'end': 1050.2, 'start': 1046.8, 'text': ' ì•„, ê·¼ë° ì•ˆ ëœ¯ê³  ì´ë ‡ê²Œ ë³´ê´€í•˜ê³  ì‹¶ë‹¤.'}, {'end': 1051.2, 'start': 1050.2, 'text': ' ì•„, ì´ê±° ê¶ê¸ˆí•˜ë„¤ìš”, ê°œì¸ì ìœ¼ë¡œ.'}, {'end': 1052.7, 'start': 1051.2, 'text': ' ì™€, ì´ê±° ê½¤ í¬ë”ë¼ê³ ìš”.'}, {'end': 1053.7, 'start': 1052.7, 'text': ' ì´ê²Œ ëª¨ê³µí’ˆìž…ë‹ˆë‹¤.'}, {'end': 1055.9, 'start': 1053.7, 'text': ' ìš°ì™€!'}, {'end': 1056.7, 'start': 1055.9, 'text': ' ëŒ€ë°•!'}, {'end': 1057.5, 'start': 1056.7, 'text': ' í¬ë„¤ìš”?'}, {'end': 1060, 'start': 1057.5, 'text': ' í›„ë…ì´ë“¤ì´ ìš°ë¦¬ê°€ ë‚˜ì´ì— ì•ˆ ë§žë‹¤ê³  ìƒê°í•˜ì‹¤ ìˆ˜ë„ ìžˆëŠ”ë°'}, {'end': 1061.5, 'start': 1060, 'text': ' ì €í¬ íŠ¹ì² ë¬¼ ë˜ê²Œ ì¢‹ì•„í•©ë‹ˆë‹¤.'}, {'end': 1064.2, 'start': 1061.5, 'text': ' ìƒˆë¡œìš´ ë³€ì‹  ë‚˜ì˜¬ ë•Œë§ˆë‹¤ ë‹¤ ê°™ì´'}, {'end': 1065, 'start': 1064.2, 'text': ' ìš°ì™€!'}, {'end': 1065.8, 'start': 1065, 'text': ' ì´ëŸ¬ê³  ì„œê±°ë“ ìš”.'}, {'end': 1066.5, 'start': 1065.8, 'text': ' ìƒˆë¡œìš´ ìŠˆíŠ¸.'}, {'end': 1070.2, 'start': 1068.5, 'text': ' ì˜ˆ!'}, {'end': 1071.2, 'start': 1070.2, 'text': ' í€„ë¦¬í‹° ë­ì•¼?'}, {'end': 1072.2, 'start': 1071.2, 'text': ' ìš°ì™€!'}, {'end': 1074, 'start': 1072.2, 'text': ' ì˜¤, ë‚´ê°€ í•œ ê°€ì§€ ëŠë‚€ ì .'}, {'end': 1076.3, 'start': 1074, 'text': ' ë¨¼ì € í•˜ê¸¸ ìž˜í–ˆë‹¤.'}, {'end': 1078, 'start': 1076.3, 'text': ' ì¿ ì˜¤ì¹´ì˜ ê·¸ë‹¤ìŒì€ ëˆ„êµ½ë‹ˆê¹Œ?'}, {'end': 1079.3, 'start': 1078, 'text': ' ì§œì˜¤, ê·¸ëŸ¼ í•˜ë‚˜.'}, {'end': 1080.3, 'start': 1079.3, 'text': ' ì–´, ì¼ë‹¨ ë¯¸ë‹´.'}, {'end': 1081.8, 'start': 1080.3, 'text': ' ì–´, ì§œì˜¤ì˜ ë¯¸ë‹´, ì§œì˜¤.'}, {'end': 1084.3, 'start': 1081.8, 'text': ' ì¼ë‹¨ ë…¸ëž­ì´ëŠ” ì˜í™”ê´‘ìž…ë‹ˆë‹¤, ì˜í™”ê´‘.'}, {'end': 1086.2, 'start': 1084.3, 'text': ' í¬ìŠ¤í„°ë„ ëª¨ìœ¼ê³  í•˜ë‹¤ ë³´ë‹ˆê¹Œ'}, {'end': 1088.5, 'start': 1086.2, 'text': ' í¬ìŠ¤í„°ë¥¼ ë°›ê¸° ìœ„í•´ ë³´ëŠ” ì˜í™”ë„ ìžˆì–´.'}, {'end': 1091.7, 'start': 1088.5, 'text': ' ì•„, ê·¼ë° ê·¸ëŸ° ì™€ì¤‘ì— ë˜ ìž‘í’ˆì„± ìžˆëŠ” ì˜í™”ë“¤ë„ ë˜ê²Œ ë§Žì´ ë³´ê¸° ë•Œë¬¸ì—'}, {'end': 1094.3, 'start': 1091.7, 'text': ' ê·¸ëŸ° ê±° ìžˆìœ¼ë©´ ì €í•œí…Œ ê¼­ í•œë²ˆ ë¬¼ì–´ë´…ë‹ˆë‹¤, ê±°ì˜.'}, {'end': 1095.5, 'start': 1094.3, 'text': ' ì¶”ì²œí•´ ì¤ë‹ˆë‹¤, ì œê°€.'}, {'end': 1097.5, 'start': 1095.5, 'text': ' ìµœê·¼ì— ìœ„ëŒ€í•œ ì‡¼ë§¨ì„ ìž¬ê³ ìš©ì„ í–ˆëŠ”ë°.'}, {'end': 1098.5, 'start': 1097.5, 'text': ' ìµœê·¼ì— ìœ„ëŒ€í•œ ì‡¼ë§¨ì„ ìž¬ê³ ìš©ì„ í–ˆëŠ”ë°.'}, {'end': 1101.8, 'start': 1098.5, 'text': ' ëŒë¹„ ì‹œë„¤ë§ˆì—ì„œ í•œë‹¤ê³  ì´ë ‡ê²Œ ì•Œë ¤ì¤˜ê°€ì§€ê³ '}, {'end': 1103.8, 'start': 1101.8, 'text': ' ì—¬ìžì¹œêµ¬ê°€ ì§„ì§œ ìž¬ë°Œê²Œ ë³´ê³ .'}, {'end': 1106.8, 'start': 1103.8, 'text': ' ì—¬ìžì¹œêµ¬ê°€ ì§„ì§œ ë…¸ëž­ì´í•œí…Œ ê°ì‚¬í–ˆì–´, ê·¸ê±°.'}, {'end': 1110.9, 'start': 1106.8, 'text': ' ìŒì•… ì˜í™”ë“¤ì´ ëŒë¹„ ì‹œë„¤ë§ˆì—ì„œ ë³´ë©´ ì§„ì§œ ê·¸ ìš¸ë¦¼ì´ ë‹¬ë¼.'}, {'end': 1112.5, 'start': 1110.9, 'text': ' ì „ ê¼­ ì¶”ì²œí•´ ì£¼ê³  ì‹¶ì—ˆê±°ë“ .'}, {'end': 1114.1, 'start': 1112.5, 'text': ' ì´ëŸ° ê±°ë¥¼ ì €ë„ ì¢‹ì•„í•˜ëŠ”ë°'}, {'end': 1116.3, 'start': 1114.1, 'text': ' í•­ìƒ ê·¸ëŸ° ì •ë³´ ì°¾ëŠ” ê±°ì— ëŒ€í•´ì„œ ë¯¸ìˆ™í–ˆëŠ”ë°'}, {'end': 1118, 'start': 1116.3, 'text': ' ë…¸ëž­ì´ê°€ ìžˆìœ¼ë©´ ì•Œë ¤ì£¼ê³ '}, {'end': 1120.5, 'start': 1118, 'text': ' ê°€ì„œ ë³´ë©´ ë˜ ì¢‹ì•„í•´ì„œ ë‚œ ë˜ ê°ì‚¬í•´ê³ .'}, {'end': 1125.8, 'start': 1120.5, 'text': ' ê·¼ë° ë‹¤ë“¤ ì—¬ê¸°ëŠ” í‹°ì¼“íŒ…, ì—¬ê¸°ëŠ” ë¬¼ê±´ êµ¬ë§¤í•  ë•Œ, ì—¬ê¸° ì˜í™” ë³¼ ë•Œ.'}, {'end': 1128.3, 'start': 1125.8, 'text': ' ì´ê±°ëŠ” ì €í¬ ë…¸ëž­ì´ í•˜ëŠ” ê±°ìž–ì•„.'}, {'end': 1131.1, 'start': 1128.3, 'text': ' íšŒì˜ëŠ” ìƒí’ˆì„ ë°›ì•„ë¼.'}, {'end': 1134.4, 'start': 1131.1, 'text': ' ì´ëŸ° ê²ƒ ì¢€ ì´ì œ ê°™ì´ ë‚˜ëˆ„ë©´ ë‚˜ë„ ì¢‹ê² ë„¤.'}, {'end': 1137.6, 'start': 1134.4, 'text': ' ì„ ë¬¼ì€ ë­ ê·¸ë ‡ê²Œ í° ì˜ë¯¸ê°€ ìžˆëŠ” ê±´ ì•„ë‹™ë‹ˆë‹¤ë§Œ'}, {'end': 1139, 'start': 1137.6, 'text': ' í•˜ì§€ë§Œ ë§Œë“œëŠ” ê±° ì¢‹ì•„í•˜ëŠ”ë°.'}, {'end': 1141.4, 'start': 1139, 'text': ' ì˜¤, ì»¤.'}, {'end': 1144.5, 'start': 1141.4, 'text': ' ì´ëŸ° ê±°ëŠ” ë³¸ ì ì´ ì—†ì„ ê±°ì˜ˆìš”.'}, {'end': 1146.6, 'start': 1144.5, 'text': ' ì•¼, ì´ê²Œ ë­ì•¼?'}, {'end': 1149.9, 'start': 1146.6, 'text': ' í¼ì¦ì¸ë° ê·¸ ì¢…ì´ë¡œ ë¼ ìžˆëŠ” ê±°.'}, {'end': 1151.5, 'start': 1149.9, 'text': ' ê·¼ë° ì´ê²Œ ì¤‘ìš”í•œ ê±°ëŠ” ì €'}, {'end': 1153.8, 'start': 1151.5, 'text': ' ì´ì œ ê·€ì—½ íŒŒì¸ ë¥¼ ì“°ë©´ ìžë™ìœ¼ë¡œ ëŒì•„ê°€.'}, {'end': 1155.4, 'start': 1153.8, 'text': ' ì•„, ì§„ì§œ?'}, {'end': 1156.9, 'start': 1155.4, 'text': ' ì´ëŸ° ê±° ì¢‹ì•„í•´ê°€ì§€ê³ '}, {'end': 1158.3, 'start': 1156.9, 'text': ' ê·¸ ì˜›ë‚ ì— ì´ˆì½”íŒŒì´ì˜€ë‚˜?'}, {'end': 1159.6, 'start': 1158.3, 'text': ' ê·¸ ìƒí’ˆ ë“¤ì–´ìžˆì—ˆì–´ìš”.'}, {'end': 1161.2, 'start': 1159.6, 'text': ' ê·¸ë ‡ì§€, ê·¸ë ‡ì§€.'}, {'end': 1162, 'start': 1161.2, 'text': ' ì½”ë¹Œ, ì½”ë¹Œ.'}, {'end': 1163.2, 'start': 1162, 'text': ' ì½”ë¹Œì¸ê°€?'}, {'end': 1166.2, 'start': 1163.2, 'text': ' ì•¼, ê·¼ë° ì²« í”„ë¼ì´ ì¹˜ê³ ëŠ” ë‚œì´ë„ê°€ ì¢€ ë†’ë‹¤.'}, {'end': 1167.4, 'start': 1166.2, 'text': ' ì•„, ì–˜ ìžˆì–´, ì–˜ ìžˆì–´.'}, {'end': 1169, 'start': 1167.4, 'text': ' ë‚œì´ë„ê°€ ìžˆìž–ì•„.'}, {'end': 1170.3, 'start': 1169, 'text': ' ë‚œì´ë„ ì¼ë‹¨ ë³„ 4ê°œ.'}, {'end': 1171.5, 'start': 1170.3, 'text': ' ì´ê±° ì£¼ëŠ” ì˜ë¯¸ëŠ”'}, {'end': 1174.9, 'start': 1171.5, 'text': ' ì´ ë°‘ì— ë³´ë©´ ì´ê²Œ ì„¸ê³„ì ì¸ ì•½ê°„ ëª…ì†Œë“¤ì´ ìžˆì–´.'}, {'end': 1176.5, 'start': 1174.9, 'text': ' ì•„, í•¸ë“œë§ˆí¬ ê°™ì€ ê±°.'}, {'end': 1178.2, 'start': 1176.5, 'text': ' ê·¸ëž˜ì„œ í˜¹ì‹œë‚˜ ë§Œì•½ì— ì—¬ê¸° ë“¤ë¦´ ì¼ ìžˆìœ¼ë©´'}, {'end': 1180.3, 'start': 1178.2, 'text': ' ê±°ê¸° ë¬¼í’ˆ ì‚¬ì™€ì„œ ì—¬ê¸° ë³´ê´€í•˜ê³  ë­ ê·¸ëŸ°.'}, {'end': 1181.6, 'start': 1180.3, 'text': ' ì•„, ê·¸ëŸ° ê±°.'}, {'end': 1183.6, 'start': 1181.6, 'text': ' ì§„ì§œ ì €ê±° ì±„ìš°ëŠ” ìž¬ë¯¸ê°€ ìžˆê² ë‹¤.'}, {'end': 1184.6, 'start': 1183.6, 'text': ' ì•„, ê°ì‚¬í•©ë‹ˆë‹¤.'}, {'end': 1187.1, 'start': 1184.6, 'text': ' ìš°ì™€.'}, {'end': 1188.1, 'start': 1187.1, 'text': ' ì•¼, ì´ê±°.'}, {'end': 1189.6, 'start': 1188.3, 'text': ' ë§ˆì§€ë§‰ ì„ ë¬¼ ê¸°ì˜ì‹  ì¤„ ì•Œì•˜ëŠ”ë°.'}, {'end': 1190.5, 'start': 1189.6, 'text': ' ì•¼, ì œì¼.'}, {'end': 1192.8, 'start': 1190.5, 'text': ' ì•„ë‹ˆ, ë­ ê·¸ëŸ° ê±´ ì•„ë‹ˆì§€, ì•„ë‹ˆì§€.'}, {'end': 1193.8, 'start': 1192.8, 'text': ' ì–¼êµ´ ë¹¨ê°œì§„ë‹¤.'}, {'end': 1195.9, 'start': 1193.8, 'text': ' ë‚´ê°€ ì„ ë¬¼ì„ ìž˜ í•  ì¤„ì€ ëª°ë¼.'}, {'end': 1197, 'start': 1195.9, 'text': ' ê³ ë¯¼ì„ ì¢€ í–ˆì£ .'}, {'end': 1198, 'start': 1197, 'text': ' ë­˜ í•´ì•¼ ë˜ë‚˜.'}, {'end': 1199.2, 'start': 1198, 'text': ' ê³ ë¯¼ì„ í•˜ë‹¤ê°€'}, {'end': 1201.7, 'start': 1199.2, 'text': ' ë”ë¶ˆì–´ ì•½ê°„ ë…¸ëž­ì´ë¼ëŠ” ì¸ê°„ì— ëŒ€í•´ì„œ'}, {'end': 1203.4, 'start': 1201.7, 'text': ' ìƒê°ì„ í•´ë´¤ìŠµë‹ˆë‹¤.'}, {'end': 1204.8, 'start': 1203.4, 'text': ' ì´ ì¹œêµ¬ê°€ ì—†ì—ˆë”ë¼ë©´'}, {'end': 1207.3, 'start': 1204.8, 'text': ' ì œ ì¸ìƒì´ ì¢€ ë§Žì´ ë‹¬ë¼ì§€ì§€ ì•Šì•˜ì„ê¹Œ.'}, {'end': 1208.2, 'start': 1207.3, 'text': ' ê·¸ëŸ° ìƒê°ì„ í•´ì„œ'}, {'end': 1210.1, 'start': 1208.2, 'text': ' ì‚¬ì‹¤ ë…¸ëž­ì´ì™€ì˜ ë¯¸ë‹´'}, {'end': 1211.8, 'start': 1210.1, 'text': ' ì—†ì–´ìš”.'}, {'end': 1214.4, 'start': 1211.8, 'text': ' ê·¸ëƒ¥ ë…¸ëž­ì´ì™€ í•¨ê»˜ ì‚´ì•„ì˜¨ ì¸ìƒì´'}, {'end': 1216.3, 'start': 1214.4, 'text': ' ë„¤ ìƒì´ì—ˆë‹¤.'}, {'end': 1217.7, 'start': 1216.3, 'text': ' ì•„ë¦„ë‹¤ìš´ ì¸ìƒ.'}, {'end': 1219.5, 'start': 1217.7, 'text': ' ë…¸ëž­ì´ë¥¼ ì²˜ìŒ ë§Œë‚¬ë˜ ê·¸ë‚ '}, {'end': 1223, 'start': 1219.5, 'text': ' ë°©ì†¡ë¶€ì—ì„œ ì›¬ ë„ì‹¤ë„ì‹¤í•œ ì•„ì´ê°€ í•œ ëª… ìžˆì–´ê°€ì§€ê³ '}, {'end': 1225.1, 'start': 1223, 'text': ' ë‚˜ëŠ” 1í•™ë…„ 5ë°˜ì˜ ë°•ê°•í›ˆì´ë‹¤.'}, {'end': 1226.9, 'start': 1225.1, 'text': ' ì‹œìž‘.'}, {'end': 1228.7, 'start': 1226.9, 'text': ' ì € ë©˜íŠ¸ê°€ íŠ¹ì´í–ˆì–´.'}, {'end': 1231.1, 'start': 1228.7, 'text': ' ë³´í†µ ê³ ë“±í•™ìƒ ë•Œ ì¹œêµ¬ ë§Œë‚˜ë©´'}, {'end': 1233.1, 'start': 1231.1, 'text': ' ì–´, ë°˜ê°‘ë‹¤ ì´ë ‡ê²Œë§Œ í•˜ì§€.'}, {'end': 1234, 'start': 1233.1, 'text': ' ê°‘ìžê¸° ì™€ê°€ì§€ê³ '}, {'end': 1236.4, 'start': 1234, 'text': ' ì–´, ë‚˜ëŠ” 1í•™ë…„ 5ë°˜ì˜ ë°•ê°•í›ˆì´ë‹¤.'}, {'end': 1238.5, 'start': 1236.4, 'text': ' ê·¸ëƒ¥ ì™¸êµ­ì‹ ì¸ì‚¬ì¸ë°.'}, {'end': 1240.7, 'start': 1238.5, 'text': ' ì´ ì—­ì‚¬ê°€ ì•„ì£¼ íž™í•©ì´ë‹¤.'}, {'end': 1241.9, 'start': 1240.7, 'text': ' ì „ì„¤ì˜ ì‹œìž‘ì´ì—ˆë„¤ìš”.'}, {'end': 1243.5, 'start': 1241.9, 'text': ' ì „ì„¤ì˜ ì‹œìž‘.'}, {'end': 1245.3, 'start': 1243.5, 'text': ' ì§€ê°€ ì§€ ìž…ìœ¼ë¡œ.'}, {'end': 1247.5, 'start': 1245.3, 'text': ' ì „ì„¤ì˜ ì‹œìž‘ì´ì—ˆìž–ì•„.'}, {'end': 1250.7, 'start': 1247.7, 'text': ' ì˜›ë‚ ì— ì±… ì¸í„°ë·°ì—ì„œ ì“´ ê±° ìžˆìž–ì•„.'}, {'end': 1253.4, 'start': 1250.7, 'text': ' ê·¸ ë‚´ìš©ì„ ë‚´ê°€ í•œë²ˆ ë´¤ê±°ë“ . ì–˜ íŒŒíŠ¸ë¥¼.'}, {'end': 1255.5, 'start': 1253.4, 'text': ' ì–˜ê°€ íŒ¥ë¿Œë¦¬ë¥¼ ë„ˆë¬´ ì¢‹ì•„í•©ë‹ˆë‹¤.'}, {'end': 1260.1, 'start': 1255.5, 'text': ' ìš°ë¦¬ë¥¼ ë§Œë‚œ ê±°ë¥¼ ìžê¸° ì¸ìƒì—ì„œ ë³µì´ë¼ê³  ìƒê°í•˜ëŠ”ë°'}, {'end': 1263.2, 'start': 1260.1, 'text': ' ì–˜ê°€ ì›ëž˜ ê²‰ìœ¼ë¡œ ê·¸ëŸ° í‘œí˜„ì„ ìž˜ ì•ˆ í•œë‹¨ ë§ì´ì•¼.'}, {'end': 1266.5, 'start': 1263.2, 'text': ' ë‹¤ ê°™ì´ í•˜ëŠ” í™œë™ë“¤ì´ ì¢€ ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìŠ¤íƒ€ì¼ì´ì—ˆê±°ë“ .'}, {'end': 1267.9, 'start': 1266.5, 'text': ' ê²Œìž„í•˜ê³  ë§Œë“¤ê³ '}, {'end': 1268.5, 'start': 1267.9, 'text': ' ë§žì•„ ë§žì•„.'}, {'end': 1269.9, 'start': 1268.5, 'text': ' ê·¸ëŸ¬ëŠ” ê²Œ ì¢‹ë”ë¼ê³ .'}, {'end': 1273.1, 'start': 1269.9, 'text': ' ê²°êµ­ì— ê·¸ë ‡ê²Œ ë†€ë˜ ê²Œ íŒ¥ë¿Œë¦¬ê°€ ë˜ì—ˆë‹¤.'}, {'end': 1276.9, 'start': 1273.1, 'text': ' ê·¸ëž˜ì„œ ê·¸ëƒ¥ ìš”ì¦˜ì— ë…¸ëž­ì´ê°€ ì§‘ì— ê°ˆ ë•Œ ì¢€ ê±¸ì–´ê°€ìš”.'}, {'end': 1281.7, 'start': 1277.7, 'text': ' ê·¸ëŸ¬ë©´ì„œ í‰ì†Œë³´ë‹¤ ë§Žì´ ì“°ëŠ” ê²Œ ì—ì–´ì½˜ì´ì—ìš”.'}, {'end': 1284.9, 'start': 1281.7, 'text': ' í•˜ë£¨ì— 1ì‹œê°„ ì´ìƒì€ ê¼­ ì´ê±¸ ë¼ê³  ìžˆë”ë¼ê³ .'}, {'end': 1288.7, 'start': 1284.9, 'text': ' ê·¸ëž˜ì„œ ì„¤ë§ˆ ì¢‹ì€ ì†Œë¦¬ ë“¤ìœ¼ë¼ê³ ?'}, {'end': 1291.7, 'start': 1288.7, 'text': ' ë‚´ê°€ ì–´ì œ ì“´ ì´ í”„ë¡œë¼ëŠ” ê±°.'}, {'end': 1293.7, 'start': 1291.7, 'text': ' ì™€, ì†Œë¦¬ ë„ˆë¬´ ë§Žì´ ë‚˜ì˜¨ ê±° ì•„ì´ê°€.'}, {'end': 1294.7, 'start': 1293.7, 'text': ' ìŠ¤ë…¸ìš°ë³´ì´í„°.'}, {'end': 1295.7, 'start': 1294.7, 'text': ' ìŠ¤ë…¸ìš°ë³´ì´í„°.'}, {'end': 1296.7, 'start': 1295.7, 'text': ' ìŠ¤ë…¸ìš°ë³´ì´í„°.'}, {'end': 1301.7, 'start': 1300.7, 'text': ' ê³ ê¸‰ìŠ¤ëŸ½ë‹¤.'}, {'end': 1306.7, 'start': 1305.7, 'text': ' ë„¤ ëª©ì†Œë¦¬ë§Œ ë“¤ë ¤.'}, {'end': 1312.7, 'start': 1307.7, 'text': ' ì£¼ë³€ ì†Œë¦¬ ë“£ê¸° í•˜ë‹ˆê¹Œ ë„ˆí¬ ëª©ì†Œë¦¬ê°€ ê·¸ëƒ¥ ì•”ê¸° ê²ƒì²˜ëŸ¼ ìž˜ ë“¤ë ¤.'}, {'end': 1313.7, 'start': 1312.7, 'text': ' ë¹„êµí•´ë´.'}, {'end': 1315.7, 'start': 1313.7, 'text': ' ì™€ ì™€ ì™€ ì™€ ì™€.'}, {'end': 1317.7, 'start': 1315.7, 'text': ' ë‚˜ë§Œ ì¼œ.'}, {'end': 1318.7, 'start': 1317.7, 'text': ' ì•ˆ ë“¤ë ¤.'}, {'end': 1320.7, 'start': 1318.7, 'text': ' ìš°ì™€.'}, {'end': 1322.7, 'start': 1320.7, 'text': ' ìš°ì™€ í•˜ëŠ” ê±´ ë“¤ë ¤.'}, {'end': 1323.7, 'start': 1322.7, 'text': ' ìš°ì™€ í•˜ëŠ” ê±´ ë“¤ë ¤.'}, {'end': 1324.7, 'start': 1323.7, 'text': ' ì‹ ê¸°í•˜ë‹¤.'}, {'end': 1325.7, 'start': 1324.7, 'text': ' ì‹ ê¸°í•˜ë‹¤.'}, {'end': 1327.7, 'start': 1325.7, 'text': ' ë§ì†Œë¦¬ê°€ ì•„ì˜ˆ ë‹¤ ì°¨ë‹¨ë˜ëŠ” ê±´ ì•„ë‹Œê°€ ë´.'}, {'end': 1329.7, 'start': 1327.7, 'text': ' ì ë‹¹ížˆ.'}, {'end': 1330.7, 'start': 1329.7, 'text': ' ì™€.'}, {'end': 1331.7, 'start': 1330.7, 'text': ' ì™€.'}, {'end': 1332.7, 'start': 1331.7, 'text': ' ì™€.'}, {'end': 1334.7, 'start': 1332.7, 'text': ' ì´ìª½ì—ëŠ” ë˜ ìŒì•…ì´ í•˜ëŠ” ë‹¨ì§€ì— ë‚˜ì˜¨ë‹¤.'}, {'end': 1335.7, 'start': 1334.7, 'text': ' ë§ ë“¤ë¦¬ë‚˜?'}, {'end': 1336.7, 'start': 1335.7, 'text': ' ë§ ë“¤ë¦¬ë‚˜?'}, {'end': 1337.7, 'start': 1336.7, 'text': ' ìš°ë¦¬ë§ì´ ë“¤ë¦¬ë‚˜?'}, {'end': 1339.7, 'start': 1337.7, 'text': ' ìžê¸°ë§Œì˜ ì„¸ê³„ë¡œ ë§žì¶°ì„œ.'}, {'end': 1342.7, 'start': 1339.7, 'text': ' ì™€ ì´ ì—ì–´íŒŸì´ëž‘ ë² ì´ìŠ¤ê°€ ì¢€ ë‹¤ë¥¸ë°?'}, {'end': 1343.7, 'start': 1342.7, 'text': ' ì•„ ê·¸ëž˜ìš”?'}, {'end': 1344.7, 'start': 1343.7, 'text': ' ì§„ì§œ.'}, {'end': 1345.7, 'start': 1344.7, 'text': ' ì•„ ë“¤ì–´ë´ë´.'}, {'end': 1352.7, 'start': 1351.7, 'text': ' ì§„ì§œ ì•ˆ ë“¤ë¦¬ë„¤?'}, {'end': 1353.7, 'start': 1352.7, 'text': ' ì•ˆ ë“¤ë¦¬ì§€?'}, {'end': 1359.7, 'start': 1358.7, 'text': ' ê°ì‚¬í•©ë‹ˆë‹¤.'}, {'end': 1360.7, 'start': 1359.7, 'text': ' ì¶•í•˜í•©ë‹ˆë‹¤.'}, {'end': 1363.7, 'start': 1362.7, 'text': ' ê°ì‚¬í•©ë‹ˆë‹¤.'}, {'end': 1365.7, 'start': 1363.7, 'text': ' ë„ˆë„¤ë„ ê·¸ëƒ¥ ì•Œì°¨ê²Œ ë§žì¶¤í˜• ì„ ë¬¼ë¡œ.'}, {'end': 1366.7, 'start': 1365.7, 'text': ' ì¹œêµ¬ë“¤ì´.'}, {'end': 1368.7, 'start': 1366.7, 'text': ' ì˜¤ ì§„ì§œ ì œì¼ ë‹¨ë‹¤.'}, {'end': 1369.7, 'start': 1368.7, 'text': ' ì œì¼ ë‹¨ë‹¤.'}, {'end': 1370.7, 'start': 1369.7, 'text': ' ì œì¼ ë‹¨ë‹¤.'}, {'end': 1371.7, 'start': 1370.7, 'text': ' ìž ì¶©ì „í•˜ê³  ì™”ìŠµë‹ˆë‹¤.'}, {'end': 1372.7, 'start': 1371.7, 'text': ' ì¼œë³¼ê¹Œë‚˜.'}, {'end': 1373.7, 'start': 1372.7, 'text': ' ì˜¤ ê¶ê¸ˆí•´.'}, {'end': 1374.7, 'start': 1373.7, 'text': ' ì˜¤ ì œì¼ ë‹¨ ì†Œë¦¬.'}, {'end': 1375.7, 'start': 1374.7, 'text': ' ì´ê²Œ ì´ì œ ì‹œê³„ í™”ë©´ì¸ ê±°ê³ .'}, {'end': 1376.7, 'start': 1375.7, 'text': ' ê·¸ë¦¬ê³  ì´ì œ ê²Œìž„ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê²Œìž„ì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.'}, {'end': 1377.7, 'start': 1376.7, 'text': ' ì™€ìš° ì™€ìš°.'}, {'end': 1378.7, 'start': 1377.7, 'text': ' ì•„ìš° ê²Œìž„ì— ë¹ ì ¸ë“¤ì—ˆì–´.'}, {'end': 1379.7, 'start': 1378.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1380.7, 'start': 1379.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1381.7, 'start': 1380.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1382.7, 'start': 1381.7, 'text': ' ë§ˆë¬´ë¦¬í• ê²Œ.'}, {'end': 1383.7, 'start': 1382.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1384.7, 'start': 1383.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1385.7, 'start': 1384.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1386.7, 'start': 1385.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1387.7, 'start': 1386.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1388.7, 'start': 1387.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1389.7, 'start': 1388.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1390.7, 'start': 1389.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1391.7, 'start': 1390.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1392.7, 'start': 1391.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1393.7, 'start': 1392.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1394.7, 'start': 1393.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1395.7, 'start': 1394.7, 'text': ' ê·¸ë§Œí•´.'}, {'end': 1396.7, 'start': 1395.7, 'text': ' ê·¸ëƒ¥ ëë‚˜ê³ .'}, {'end': 1397.7, 'start': 1396.7, 'text': ' ëë‚˜ê³  ì´ê±° ë„¤ê³  ë¨¹ìœ¼ë©´ì„œ.'}, {'end': 1398.7, 'start': 1397.7, 'text': ' ëë‚˜ë„¤.'}, {'end': 1399.7, 'start': 1398.7, 'text': ' ì•„ ë„ˆë¬´ ê°ì‚¬í•©ë‹ˆë‹¤.'}, {'end': 1400.7, 'start': 1399.7, 'text': ' ìž¬ë°Œì—ˆì–´.'}, {'end': 1403.62, 'start': 1400.7, 'text': ' ë„¤ ì–´ì¨Œë“  ë˜ ìš°ë¦¬ ë…¸ëž­ì´ì˜ ìƒì¼.'}, {'end': 1405.92, 'start': 1403.62, 'text': ' ìš°ë¦¬ ë½€ë‘¥ì´ë¶„ë“¤ ë§Žì´ë§Žì´ ì¶•í•˜í•´ ì£¼ì‹œê³ .'}, {'end': 1408.22, 'start': 1405.92, 'text': ' ë‹¤ìŒ ìƒì¼ ì§„ì—´ì´ ìƒì¼ì—.'}, {'end': 1409.22, 'start': 1408.22, 'text': ' ì™€.'}, {'end': 1410.56, 'start': 1409.22, 'text': ' ì¢€ ë§Žì´ ë‚¨ì•˜ì–´ ì•„ì§.'}, {'end': 1411.56, 'start': 1410.56, 'text': ' ë„¤.'}, {'end': 1414.14, 'start': 1411.56, 'text': ' ê·¸ë•Œ í•œë²ˆ ì–´ë–¤ íŒŒí‹°ë¥¼ í•´ë³¼ì§€.'}, {'end': 1415.48, 'start': 1414.14, 'text': ' ì§„ì—´ì´ê°€ í•œë²ˆ ìƒê°í•´ ë³´ì‹œì£ .'}, {'end': 1416.16, 'start': 1415.48, 'text': ' ì œê°€ ì´ë ‡ê²Œ ë†€ì•„ë³´ìž.'}, {'end': 1455.68, 'start': 1425.7, 'text': ' ì‹œì²­í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.'}], 'summary_result': \"- ðŸŽ‰ ì˜¤ëŠ˜ì€ ë…¸ëž­ì´ì˜ ìƒì¼ìž…ë‹ˆë‹¤!\\n- ðŸ£ ë…¸ëž­ì´ê°€ ê°€ìž¥ ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ ê¹€ë°¥ìž…ë‹ˆë‹¤.\\n- ðŸ‘©\\u200dðŸ³ ìš°ë¦¬ëŠ” ë…¸ëž­ì´ì˜ ìƒì¼ì„ ê¸°ë…í•˜ì—¬ ê¹€ë°¥ì„ ë§Œë“¤ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.\\n- ðŸ¥³ ê¹€ë°¥ì˜ ë§›ë³´ë‹¤ í•¨ê»˜í•˜ëŠ” ì‹œê°„ì´ ë” ì¤‘ìš”í•˜ë‹¤ê³  ì´ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤.\\n- ðŸ“œ ìƒì¼ ë£°ë¡œ ìš•ê³¼ ì™¸ëž˜ì–´ ì‚¬ìš© ê¸ˆì§€ê°€ ì •í•´ì¡ŒìŠµë‹ˆë‹¤.\\n- ðŸ¤ ë…¸ëž­ì´ì˜ ì–´ë¨¸ë‹ˆê°€ ë§Œë“  ê¹€ë°¥ì„ ê·¸ë¦¬ì›Œí•˜ë©° ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.\\n- ðŸŽ ì¹œêµ¬ë“¤ì´ ì„ ë¬¼ê³¼ ë¯¸ë‹´ì„ ë‚˜ëˆ„ë©° ìƒì¼ì„ ì¶•í•˜í–ˆìŠµë‹ˆë‹¤.\\n- ðŸ² ë–¡ë³¶ì´ì™€ í•¨ê»˜ ê¹€ë°¥ì„ ì¦ê¸°ë©° ë‹¤ ê°™ì´ ìž¬ë¯¸ìžˆê²Œ ë†€ì•˜ìŠµë‹ˆë‹¤.\\n\\n- ðŸŽ‰ Today is Norangi's birthday!\\n- ðŸ£ Norangi's favorite food is gimbap.\\n- ðŸ‘©\\u200dðŸ³ We decided to make gimbap to celebrate Norangi's birthday.\\n- ðŸ¥³ We talked about the importance of time together over the taste of gimbap.\\n- ðŸ“œ The birthday rules included a ban on swearing and foreign words.\\n- ðŸ¤ We prepared gimbap while reminiscing about Norangi's mother's cooking.\\n- ðŸŽ Friends shared gifts and compliments to celebrate the birthday.\\n- ðŸ² We enjoyed gimbap along with tteokbokki and had fun together.\"}, 'status': 'COMPLETED', 'workerId': 'jxd93hs8fbpe4z'}\n",
      "Error fetching results: 404\n",
      "Error message: 404 page not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = f\"https://api.runpod.ai/v2/{endpoint_id}/run\"\n",
    "\n",
    "# FastAPIì˜ /hello ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­í•˜ê¸° ìœ„í•œ ë°ì´í„°\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"endpoint\": \"/get_script_summary\",\n",
    "        \"method\": \"GET\",\n",
    "        \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "        \"params\": {\"url\": you_url},\n",
    "    }\n",
    "}\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Initial Response:\", result)\n",
    "    \n",
    "    if result.get('status') in ['IN_PROGRESS',\"IN_QUEUE\"]:\n",
    "        job_id = result.get('id')\n",
    "        status_url = f\"https://api.runpod.ai/v2/{endpoint_id}/status/{job_id}\"\n",
    "        \n",
    "        while True:\n",
    "            status_response = requests.get(status_url, headers=headers)\n",
    "            if status_response.status_code == 200:\n",
    "                status_data = status_response.json()\n",
    "                print(f\"Current status: {status_data.get('status')}\")\n",
    "                \n",
    "                if status_data.get('status') == 'COMPLETED':\n",
    "                    print(f\"ê²°ê³¼ê°’:{status_data}\")\n",
    "                    result_url = f\"https://api.runpod.ai/v2/{endpoint_id}/result/{job_id}\"\n",
    "                    result_response = requests.get(result_url, headers=headers)\n",
    "                    \n",
    "                    if result_response.status_code == 200:\n",
    "                        final_result = result_response.json()\n",
    "                        print(\"Final Result:\", final_result)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Error fetching results: {result_response.status_code}\")\n",
    "                        print(f\"Error message: {result_response.text}\")\n",
    "                        break\n",
    "                elif status_data.get('status') == 'FAILED':\n",
    "                    print(\"Job failed\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Error checking status: {status_response.status_code}\")\n",
    "                print(f\"Error message: {status_response.text}\")\n",
    "                break\n",
    "            \n",
    "            time.sleep(5)  # 5ì´ˆ ëŒ€ê¸° í›„ ë‹¤ì‹œ ìƒíƒœ í™•ì¸\n",
    "    else:\n",
    "        print(\"Job completed immediately\")\n",
    "        print(\"Final Result:\", result)\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n",
      "Job status: IN_PROGRESS\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "endpoint_id = os.getenv(\"RUNPOD_ENDPOINT_ID\")\n",
    "\n",
    "# RunPod RUNSYNC ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "url = f\"https://api.runpod.ai/v2/{endpoint_id}/status/{job_id}\"\n",
    "url2 = f\"https://api.runpod.ai/v2/{endpoint_id}/result/{job_id}\"\n",
    "\n",
    "# ìš”ì²­ í—¤ë”ì— API í‚¤ ì¶”ê°€\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "while True:\n",
    "    # RUNSYNC ìš”ì²­ ë³´ë‚´ê¸°\n",
    "    response = requests.get(url,headers=headers)\n",
    "\n",
    "    # ì‘ë‹µ í™•ì¸\n",
    "    if response.status_code == 200:\n",
    "        if response.json().get(\"status\") == \"COMPLETED\":\n",
    "            response = requests.get(url2,headers=headers)\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Job status: {response.json().get('status')}\")\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'404 page not found'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "RUNPOD_API_URL = f\"https://api.runpod.ai/v2/{endpoint_id}/runsync\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"endpoint\": \"/rag_stream_chat\",\n",
    "        \"method\": \"POST\",\n",
    "        \"headers\": {\"x-session-id\": \"1234asdf\"},\n",
    "        \"params\": {\"prompt\": \"ì˜ìƒì˜ ì£¼ì œê°€ ë­”ê°€ìš”?\"},\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    RUNPOD_API_URL, headers=headers, json=payload, stream=True\n",
    ")\n",
    "\n",
    "# for chunk in response.iter_content(chunk_size=None):\n",
    "#     if chunk:\n",
    "#         chunk_data = chunk.decode(\"utf-8\").strip()\n",
    "#         if chunk_data.startswith(\"data: \"):\n",
    "#             chunk_content = chunk_data[6:]\n",
    "#             if chunk_content == \"[DONE]\":\n",
    "#                 break\n",
    "#             try:\n",
    "#                 content = json.loads(chunk_content)\n",
    "#                 print(\"Stream content:\", content)\n",
    "#             except json.JSONDecodeError:\n",
    "#                 print(\"Invalid JSON:\", chunk_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì˜ìƒ\n",
      "ì˜ìƒì˜\n",
      "ì˜ìƒì˜ ì£¼\n",
      "ì˜ìƒì˜ ì£¼ì œ\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ”\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œ\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì—\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤.\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒ\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ”\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² \n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨,\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€,\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ”\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œ\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ”\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê³ \n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê³  ìžˆìŠµë‹ˆë‹¤\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê³  ìžˆìŠµë‹ˆë‹¤.\n",
      "ì˜ìƒì˜ ì£¼ì œëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ ìš”ë¦¬ ê³¼ì •ì— ëŒ€í•œ ë‚´ìš©ìž…ë‹ˆë‹¤. ì˜ìƒì—ì„œëŠ” ë² ì´ì»¨, ê³„ëž€, ë©´ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë§›ìžˆëŠ” ê¹Œë¥´ë³´ë‚˜ë¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê³  ìžˆìŠµë‹ˆë‹¤.[DONE]\n"
     ]
    }
   ],
   "source": [
    "answer = \"\"\n",
    "for chunk in response.json().get(\"output\"):\n",
    "    answer += chunk.get(\"content\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"script.txt\",\"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the last chapter, you and I started to step through the internal workings of a transformer.\n",
      "This is one of the key pieces of technology inside large language models, and a lot of\n",
      "other tools in the modern wave of AI.\n",
      "It first hit the scene in a now-famous 2017 paper called Attention is All You Need, and\n",
      "in this chapter, you and I will dig into what this attention mechanism is, visualizing how\n",
      "it processes data.\n",
      "As a quick recap, here's the important context I want you to have in mind.\n",
      "The goal of the model that you and I are studying is to take in a piece of text and predict\n",
      "what word comes next.\n",
      "The input text is broken up into little pieces that we call tokens, and these are very often\n",
      "words or pieces of words, but just to make the examples in this video easier for you\n",
      "and me to think about, let's simplify by pretending that tokens are always just words.\n",
      "The first step in a transformer is to associate each token with a high-dimensional vector,\n",
      "what we call its embedding.\n",
      "Now the most important idea I want you to have in mind is how directions in this high-dimensional\n",
      "space of all possible embeddings can correspond with semantic meaning.\n",
      "In the last chapter we saw an example for how direction can correspond to gender, in\n",
      "the sense that adding a certain step in this space can take you from the embedding of a\n",
      "masculine noun to the embedding of the corresponding feminine noun.\n",
      "just one example, you could imagine how many other directions in this high-dimensional space\n",
      "could correspond to numerous other aspects of a word's meaning. The aim of a transformer is to\n",
      "progressively adjust these embeddings so that they don't merely encode an individual word,\n",
      "but instead they bake in some much, much richer contextual meaning. I should say up front that a\n",
      "lot of people find the attention mechanism, this key piece in a transformer, very confusing, so\n",
      "don't worry if it takes some time for things to sink in. I think that before we dive into the\n",
      "computational details and all the matrix multiplications, it's worth thinking about a\n",
      "couple examples for the kind of behavior that we want attention to enable. Consider the phrases\n",
      "American true mole, one mole of carbon dioxide, and take a biopsy of the mole. You and I know\n",
      "that the word mole has different meanings in each one of these, based on the context.\n",
      "But after the first step of a transformer, the one that breaks up the text and associates each\n",
      "token with a vector, the vector that's associated with mole would be the same in all three of these\n",
      "cases, because this initial token embedding is effectively a lookup table with no reference to\n",
      "the context. It's only in the next step of the transformer that the surrounding embeddings have\n",
      "the chance to pass information into this one. The picture you might have in mind is that there\n",
      "are multiple distinct directions in this embedding space encoding the multiple distinct meanings of\n",
      "the word mole, and that a well-trained attention block calculates what you need to add to the\n",
      "generic embedding to move it to one of these more specific directions, as a function of the context.\n",
      "To take another example, consider the embedding of the word tower. This is presumably some very\n",
      "generic, non-specific direction in the space, associated with lots of other large, tall nouns.\n",
      "If this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update\n",
      "this vector so that it points in a direction that more specifically encodes the Eiffel Tower,\n",
      "maybe correlated with vectors associated with Paris and France and things made of steel.\n",
      "If it was also preceded by the word miniature, then the vector should be updated even further\n",
      "so that it no longer correlates with large tall things. More generally than just refining the\n",
      "meaning of a word, the attention block allows the model to move information encoded in one\n",
      "embedding to that of another, potentially ones that are quite far away, and potentially\n",
      "with information that's much richer than just a single word.\n",
      "What we saw in the last chapter was how after all of the vectors flow through the network,\n",
      "including many different attention blocks, the computation that you perform to produce\n",
      "a prediction of the next token is entirely a function of the last vector in the sequence.\n",
      "So imagine, for example, that the text you input is most of an entire mystery novel,\n",
      "way up to a point near the end which reads, therefore the murderer was, if the model is\n",
      "going to accurately predict the next word, that final vector in the sequence which began its life\n",
      "simply embedding the word was will have to have been updated by all of the attention blocks\n",
      "to represent much much more than any individual word, somehow encoding all of the information\n",
      "from the full context window that's relevant to predicting the next word. To step through the\n",
      "the computations though let's take a much simpler example. Imagine that the input includes the\n",
      "phrase a fluffy blue creature roamed the verdant forest and for the moment suppose that the only\n",
      "type of update that we care about is having the adjectives adjust the meanings of their\n",
      "corresponding nouns. What I'm about to describe is what we would call a single head of attention\n",
      "and later we will see how the attention block consists of many different heads run in parallel.\n",
      "Again, the initial embedding for each word is some high-dimensional vector\n",
      "that only encodes the meaning of that particular word with no context.\n",
      "Actually, that's not quite true. They also encode the position of the word.\n",
      "There's a lot more to say about the specific way that positions are encoded,\n",
      "but right now all you need to know is that the entries of this vector are enough to tell you\n",
      "both what the word is and where it exists in the context. Let's go ahead and denote these\n",
      "embeddings with the letter E, the goal is to have a series of computations produce a\n",
      "new refined set of embeddings where, for example, those corresponding to the nouns have ingested\n",
      "the meaning from their corresponding adjectives.\n",
      "And playing the deep learning game, we want most of the computations involved to look\n",
      "like matrix-vector products where the matrices are full of tunable weights, things that the\n",
      "model will learn based on data.\n",
      "To be clear, I'm making up this example of adjectives updating nouns just to illustrate\n",
      "the type of behavior that you could imagine an intention had doing.\n",
      "As with so much deep learning, the true behavior is much harder to parse, because it's based\n",
      "on tweaking and tuning a huge number of parameters to minimize some cost function.\n",
      "It's just that as we step through all of the different matrices filled with parameters\n",
      "that are involved in this process, I think it's really helpful to have an imagined example\n",
      "of something that it could be doing to help keep it all more concrete.\n",
      "For the first step of this process, you might imagine each noun, like creature, asking the\n",
      "question, hey, are there any adjectives sitting in front of me, and for the words fluffy and\n",
      "blue to each be able to answer, yeah, I'm an adjective and I'm in that position.\n",
      "That question is somehow encoded as yet another vector, another list of numbers, which we\n",
      "call the query for this word.\n",
      "This query vector, though, has a much smaller dimension than the embedding vector, say 128.\n",
      "Computing this query looks like taking a certain matrix, which I'll label wq, and multiplying\n",
      "it by the embedding.\n",
      "Compressing things a bit, let's write that query vector as q, and then anytime you see\n",
      "me put a matrix next to an arrow like this one, it's meant to represent that multiplying\n",
      "this matrix by the vector at the arrow's start gives you the vector at the arrow's end.\n",
      "In this case, you multiply this matrix by all of the embeddings in the context, producing\n",
      "one query vector for each token.\n",
      "The entries of this matrix are parameters of the model, which means the true behavior\n",
      "is learned from data, and in practice what this matrix does in a particular attention\n",
      "head is challenging to parse.\n",
      "But for our sake, imagining an example that we might hope it would learn, we'll suppose\n",
      "that this query matrix maps the embeddings of nouns to certain directions in this smaller\n",
      "query space that somehow encodes the notion of looking for adjectives in preceding positions.\n",
      "As to what it does to other embeddings, who knows, maybe it simultaneously tries to accomplish\n",
      "some other goal with those, right now we're laser focused on the nouns.\n",
      "At the same time, associated with this is a second matrix called the key matrix, which\n",
      "you also multiply by every one of the embeddings.\n",
      "This produces a second sequence of vectors that we call the keys.\n",
      "Conceptually you want to think of the keys as potentially answering the queries.\n",
      "This key matrix is also full of tunable parameters, and just like the query matrix it maps the\n",
      "embedding vectors to that same smaller dimensional space.\n",
      "You think of the keys as matching the queries whenever they closely align with each other.\n",
      "In our example, you would imagine that the key matrix maps the adjectives, like fluffy\n",
      "and blue, to vectors that are closely aligned with the query produced by the word creature.\n",
      "To measure how well each key matches each query, you compute a dot product between each\n",
      "possible key-query pair.\n",
      "I like to visualize a grid full of a bunch of dots, where the bigger dots correspond\n",
      "the larger dot products, the places where the keys and queries align. For our adjective-noun example,\n",
      "that would look a little more like this, where if the keys produced by fluffy and blue really do\n",
      "align closely with the query produced by creature, then the dot products in these two spots would be\n",
      "some large positive numbers. In the lingo, machine learning people would say that this means the\n",
      "embeddings of fluffy and blue attend to the embedding of creature. By contrast to the dot\n",
      "product between the key for some other word like the and the query for creature would be some small\n",
      "or negative value that reflects that these are unrelated to each other. So we have this grid of\n",
      "values that can be any real number from negative infinity to infinity giving us a score for how\n",
      "relevant each word is to updating the meaning of every other word. The way we're about to use these\n",
      "scores is to take a certain weighted sum along each column weighted by the relevance. So instead\n",
      "Instead of having values range from negative infinity to infinity, what we want is for\n",
      "the numbers in these columns to be between 0 and 1, and for each column to add up to\n",
      "1, as if they were a probability distribution.\n",
      "If you're coming in from the last chapter, you know what we need to do then.\n",
      "We compute a softmax along each one of these columns to normalize the values.\n",
      "In our picture, after you apply softmax to all of the columns, we'll fill in the grid\n",
      "with these normalized values.\n",
      "At this point, you're safe to think about each column as giving weights\n",
      "according to how relevant the word on the left is to the corresponding value at the top.\n",
      "We call this grid an attention pattern.\n",
      "Now, if you look at the original Transformer paper,\n",
      "there's a really compact way that they write this all down.\n",
      "Here, the variables q and k represent the full arrays of query and key vectors respectively,\n",
      "those little vectors you get by multiplying the embeddings by the query and the key matrices.\n",
      "This expression up in the numerator is a really compact way to represent the grid of all possible\n",
      "dot products between pairs of keys and queries. A small technical detail that I didn't mention\n",
      "is that for numerical stability it happens to be helpful to divide all of these values by the\n",
      "square root of the dimension in that key query space. Then this softmax that's wrapped around\n",
      "the full expression, is meant to be understood to apply column by column.\n",
      "As to that V term, we'll talk about it in just a second.\n",
      "Before that, there's one other technical detail that so far I've skipped.\n",
      "During the training process, when you run this model on a given text example, and all\n",
      "of the weights are slightly adjusted and tuned to either reward or punish it based on how\n",
      "high a probability it assigns to the true next word in the passage, it turns out to\n",
      "make the whole training process a lot more efficient if you simultaneously have it predict\n",
      "every possible next token following each initial sub-sequence of tokens in this passage.\n",
      "For example, with the phrase that we've been focusing on, it might also be predicting what\n",
      "words follow creature, and what words follow the.\n",
      "This is really nice, because it means what would otherwise be a single training example\n",
      "effectively acts as many.\n",
      "For the purposes of our attention pattern, it means that you never want to allow later\n",
      "words to influence earlier words, since otherwise they could kind of give away the answer for\n",
      "what comes next. What this means is that we want all of these spots here, the ones representing\n",
      "later tokens influencing earlier ones, to somehow be forced to be zero. The simplest thing you might\n",
      "think to do is to set them equal to zero, but if you did that the columns wouldn't add up to one\n",
      "anymore, they wouldn't be normalized. So instead a common way to do this is that before applying\n",
      "softmax you set all of those entries to be negative infinity. If you do that then after\n",
      "After applying softmax, all of those get turned into zero, but the columns stay normalized.\n",
      "This process is called masking.\n",
      "There are versions of attention where you don't apply it, but in our GPT example, even\n",
      "though this is more relevant during the training phase than it would be, say, running it as\n",
      "a chatbot or something like that, you do always apply this masking to prevent later tokens\n",
      "from influencing earlier ones.\n",
      "Another fact that's worth reflecting on about this attention pattern is how its size is\n",
      "equal to the square of the context size.\n",
      "So this is why context size can be a really huge bottleneck for large language models,\n",
      "and scaling it up is non-trivial.\n",
      "As you might imagine, motivated by a desire for bigger and bigger context windows, recent\n",
      "years have seen some variations to the attention mechanism aimed at making context more scalable.\n",
      "But right here, you and I are staying focused on the basics.\n",
      "Okay, great, computing this pattern lets the model deduce which words are relevant to which\n",
      "other words.\n",
      "Now you need to actually update the embeddings, allowing words to pass information to whichever\n",
      "other words they're relevant to.\n",
      "For example, you want the embedding of fluffy to somehow cause a change to creature that\n",
      "moves it to a different part of this 12,000 dimensional embedding space that more specifically\n",
      "encodes a fluffy creature.\n",
      "What I'm going to do here is first show you the most straightforward way that you could\n",
      "do this, though there's a slight way that this gets modified in the context of multi-headed\n",
      "attention.\n",
      "This most straightforward way would be to use a third matrix, what we call the value\n",
      "matrix, which you multiply by the embedding of that first word, for example fluffy.\n",
      "The result of this is what you would call a value vector, and this is something that\n",
      "you add to the embedding of the second word, in this case something you add to the embedding\n",
      "of creature.\n",
      "So, this value vector lives in the same very high dimensional space as the embeddings.\n",
      "When you multiply this value matrix by the embedding of a word, you might think of it\n",
      "as saying if this word is relevant to adjusting the meaning of something else, what exactly should\n",
      "be added to the embedding of that something else in order to reflect this? Looking back in our\n",
      "diagram, let's set aside all of the keys and the queries, since after you compute the attention\n",
      "pattern you're done with those, then you're going to take this value matrix and multiply it by every\n",
      "one of those embeddings to produce a sequence of value vectors. You might think of these value\n",
      "vectors as being kind of associated with the corresponding keys.\n",
      "For each column in this diagram, you multiply each of the value vectors by the corresponding\n",
      "weight in that column.\n",
      "For example, here, under the embedding of creature, you would be adding large proportions\n",
      "of the value vectors for fluffy and blue, while all of the other value vectors get zeroed\n",
      "out, or at least nearly zeroed out.\n",
      "And then finally, the way to actually update the embedding associated with this column,\n",
      "previously encoding some context-free meaning of creature, you add together all of these\n",
      "rescaled values in the column, producing a change that you want to add that I'll label\n",
      "delta E, and then you add that to the original embedding.\n",
      "Hopefully what results is a more refined vector encoding the more contextually rich meaning,\n",
      "like that of a fluffy blue creature.\n",
      "And of course you don't just do this to one embedding, you apply the same weighted sum\n",
      "across all of the columns in this picture, producing a sequence of changes.\n",
      "Adding all of those changes to the corresponding embeddings produces a full sequence of more\n",
      "refined embeddings popping out of the attention block.\n",
      "Zooming out, this whole process is what you would describe as a single head of attention.\n",
      "As I've described things so far, this process is parameterized by three distinct matrices,\n",
      "all filled with tunable parameters, the key, the query, and the value.\n",
      "I want to take a moment to continue what we started in the last chapter with the scorekeeping\n",
      "where we count up the total number of model parameters using the numbers from GPT-3.\n",
      "These key and query matrices each have 12,288 columns, matching the embedding dimension,\n",
      "and 128 rows, matching the dimension of that smaller key query space.\n",
      "This gives us an additional 1.5 million or so parameters for each one.\n",
      "If you look at that value matrix by contrast, the way I've described things so far would\n",
      "suggest that it's a square matrix that has 12,288 columns and 12,288 rows, since both\n",
      "its inputs and its outputs live in this very large embedding space.\n",
      "If true, that would mean about 150 million added parameters.\n",
      "And to be clear, you could do that, you could devote orders of magnitude more parameters\n",
      "to the value map than to the key and query.\n",
      "But in practice, it is much more efficient if instead you make it so that the number\n",
      "of parameters devoted to this value map is the same as the number devoted to the key\n",
      "in the query.\n",
      "This is especially relevant in the setting of running multiple attention heads in parallel.\n",
      "The way this looks is that the value map is factored as a product of two smaller matrices.\n",
      "Conceptually, I would still encourage you to think about the overall linear map, one\n",
      "with inputs and outputs both in this larger embedding space, for example taking the embedding\n",
      "of blue to this blueness direction that you would add to nouns.\n",
      "It's just that it's broken up into two separate steps.\n",
      "The first matrix on the right here has a smaller number of rows, typically the same size as\n",
      "the key query space.\n",
      "What this means is you can think of it as mapping the large embedding vectors down to\n",
      "a much smaller space.\n",
      "This is not the conventional naming, but I'm going to call this the value down matrix.\n",
      "The second matrix maps from this smaller space back up to the embedding space, producing\n",
      "the vectors that you use to make the actual updates.\n",
      "I'm going to call this one the value-up matrix, which, again, is not conventional.\n",
      "The way that you would see this written in most papers looks a little different.\n",
      "I'll talk about it in a minute.\n",
      "In my opinion, it tends to make things a little more conceptually confusing.\n",
      "To throw in linear algebra jargon here, what we're basically doing is constraining the\n",
      "overall value map to be a low-rank transformation.\n",
      "Turning back to the parameter count, all four of these matrices have the same size, and\n",
      "Then adding them all up, we get about 6.3 million parameters for one attention head.\n",
      "As a quick side note, to be a little more accurate, everything described so far is what\n",
      "people would call a self-attention head, to distinguish it from a variation that comes\n",
      "up in other models that's called cross-attention.\n",
      "This isn't relevant to our GPT example, but if you're curious, cross-attention involves\n",
      "models that process two distinct types of data, like text in one language and text in\n",
      "another language that's part of an ongoing generation of a translation.\n",
      "Or maybe audio input of speech, and an ongoing transcription.\n",
      "A cross-attention head looks almost identical.\n",
      "The only difference is that the key and query maps act on different datasets.\n",
      "In a model doing translation, for example, the keys might come from one language, while\n",
      "the queries come from another, and the attention pattern could describe which words from one\n",
      "language correspond to which words in another.\n",
      "And in this setting there would typically be no masking, since there's not really any\n",
      "notion of later tokens affecting earlier ones.\n",
      "Staying focused on self-attention though, if you understood everything so far, and if\n",
      "you were to stop here, you would come away with the essence of what attention really\n",
      "is.\n",
      "All that's really left to us is to lay out the sense in which you do this many, many\n",
      "different times.\n",
      "In our central example we focused on adjectives updating nouns, but of course there are lots\n",
      "of different ways that context can influence the meaning of a word.\n",
      "If the words they crashed the preceded the word car, it has implications for the shape\n",
      "and the structure of that car, and a lot of associations might be less grammatical.\n",
      "If the word wizard is anywhere in the same passage as Harry, it suggests that this might\n",
      "be referring to Harry Potter, whereas if instead the words Queen, Sussex, and William were\n",
      "in that passage, then perhaps the embedding of Harry should instead be updated to refer\n",
      "to the prince.\n",
      "For every different type of contextual updating that you might imagine, the parameters of\n",
      "these key and query matrices would be different to capture the different attention patterns,\n",
      "and the parameters of our value map would be different based on what should be added to the\n",
      "embeddings. And again, in practice the true behavior of these maps is much more difficult\n",
      "to interpret, where the weights are set to do whatever the model needs them to do to best\n",
      "accomplish its goal of predicting the next token. As I said before, everything we described is a\n",
      "single head of attention, and a full attention block inside a transformer consists of what's\n",
      "called multi-headed attention where you run a lot of these operations in parallel each with its own\n",
      "distinct key query and value maps. GPT-3 for example uses 96 attention heads inside each block.\n",
      "Considering that each one is already a bit confusing it's certainly a lot to hold in your\n",
      "head. Just to spell it all out very explicitly this means you have 96 distinct key and query\n",
      "matrices producing 96 distinct attention patterns. Then each head has its own distinct value matrices\n",
      "used to produce 96 sequences of value vectors. These are all added together using the\n",
      "corresponding attention patterns as weights. What this means is that for each position in the\n",
      "context, each token, every one of these heads produces a proposed change to be added to the\n",
      "embedding in that position. So what you do is you sum together all of those proposed changes,\n",
      "one for each head, and you add the result to the original embedding of that position.\n",
      "This entire sum here would be one slice of what's outputted from this multi-headed attention block,\n",
      "a single one of those refined embeddings that pops out the other end of it.\n",
      "Again, this is a lot to think about, so don't worry at all if it takes some time to sink in.\n",
      "The overall idea is that by running many distinct heads in parallel,\n",
      "you're giving the model the capacity to learn many distinct ways that context changes meaning.\n",
      "Pulling up our running tally for parameter count with 96 heads, each including its own variation\n",
      "of these four matrices, each block of multi-headed attention ends up with around 600 million\n",
      "parameters. There's one added slightly annoying thing that I should really mention for any of you\n",
      "who go on to read more about transformers. You remember how I said that the value map is factored\n",
      "out into these two distinct matrices, which I labeled as the value down and the value up\n",
      "matrices. The way that I framed things would suggest that you see this pair of matrices\n",
      "inside each attention head, and you could absolutely implement it this way. That would\n",
      "be a valid design. But the way that you see this written in papers and the way that it's\n",
      "implemented in practice looks a little different. All of these value up matrices for each head\n",
      "appear stapled together in one giant matrix that we call the output matrix, associated with\n",
      "the entire multi-headed attention block. And when you see people refer to the value matrix for a\n",
      "given attention head, they're typically only referring to this first step, the one that I\n",
      "was labeling as the value down projection into the smaller space. For the curious among you,\n",
      "I've left an on-screen note about it. It's one of those details that runs the risk of distracting\n",
      "from the main conceptual points, but I do want to call it out just so that you know if you read\n",
      "about this in other sources. Setting aside all the technical nuances, in the preview from the\n",
      "last chapter, we saw how data flowing through a transformer doesn't just flow through a single\n",
      "attention block. For one thing, it also goes through these other operations called multi-layer\n",
      "perceptrons. We'll talk more about those in the next chapter. And then it repeatedly goes through\n",
      "many, many copies of both of these operations. What this means is that after a given word imbibes\n",
      "some of its context, there are many more chances for this more nuanced embedding to be influenced\n",
      "by its more nuanced surroundings. The further down the network you go, with each embedding\n",
      "taking in more and more meaning from all the other embeddings, which themselves are getting\n",
      "more and more nuanced, the hope is that there's the capacity to encode higher level and more\n",
      "abstract ideas about a given input beyond just descriptors and grammatical structure.\n",
      "Things like sentiment and tone and whether it's a poem and what underlying scientific truths are\n",
      "are relevant to the piece, and things like that.\n",
      "Turning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the\n",
      "total number of key, query, and value parameters is multiplied by another 96, which brings\n",
      "the total sum to just under 58 billion distinct parameters devoted to all of the attention\n",
      "heads.\n",
      "That is a lot, to be sure, but it's only about a third of the 175 billion that are\n",
      "in the network in total.\n",
      "So even though attention gets all of the attention, the majority of parameters come from the blocks\n",
      "sitting in between these steps.\n",
      "In the next chapter, you and I will talk more about those other blocks and also a lot more\n",
      "about the training process.\n",
      "A big part of the story for the success of the attention mechanism is not so much any\n",
      "specific kind of behavior that it enables, but the fact that it's extremely parallelizable,\n",
      "meaning that you can run a huge number of computations in a short time using GPUs.\n",
      "that one of the big lessons about deep learning in the last decade or two has been that scale\n",
      "alone seems to give huge qualitative improvements in model performance. There's a huge advantage to\n",
      "parallelizable architectures that let you do this. If you want to learn more about this stuff, I've\n",
      "left lots of links in the description. In particular, anything produced by Andre Karpathy or Chris Ola\n",
      "tend to be pure gold. In this video, I wanted to just jump into attention in its current form,\n",
      "but if you're curious about more of the history for how we got here and how you might reinvent\n",
      "this idea for yourself, my friend Vivek just put up a couple videos giving a lot more of\n",
      "that motivation. Also, Britt Cruz from the channel The Art of the Problem\n",
      "has a really nice video about the history of large language models.\n",
      "you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "url = \"https://www.youtube.com/watch?v=yF_YIxxjWU4\"\n",
    "yt = YouTube(url, use_po_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the tool: https://github.com/YunzheZJU/youtube-po-token-generator, to get the token\n"
     ]
    }
   ],
   "source": [
    "yt.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
